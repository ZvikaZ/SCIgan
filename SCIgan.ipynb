{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SCIgan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZvikaZ/SCIgan/blob/master/SCIgan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGA8AJdzP7Ao",
        "colab_type": "text"
      },
      "source": [
        "#SCIgan - An Automatic CS Paper Generator#\n",
        "\n",
        "## Data Science Workshop\n",
        "#### By Elad Yitzhaik and Zvika Haramaty\n",
        "#### Mentor: Idan Alter\n",
        "#### 9 June 2020"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF95rXemUEiT",
        "colab_type": "text"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "In this work, we'll try to auto generate papers CS papers, by using GAN.\n",
        "As a first step, we've created a classifier, that can classify a published paper in CS with ~93% accuracy. Later, we'll extend that with a GAN.\n",
        "\n",
        "## History\n",
        "\n",
        "There were several similar attempts, in various directions. The most famous one is probably [SCIgen - An Automatic CS Paper Generator](https://pdos.csail.mit.edu/archive/scigen/) created at circa 2005 by (then) two graduate students at MIT. One of their generated papers was even admitted to a conference...\n",
        "\n",
        "Although the SCIgen inspired us, it's using a completely different technology - a hand-written context-free grammar.\n",
        "\n",
        "However, there are even earlier scientific paper generators - such as http://www.elsewhere.org/pomo/, from 1 April 1996, which specialize at generating Post Modernism papers.\n",
        "\n",
        "That leads us to maybe the most famous fictive scientific paper - [the Sokal hoax](https://en.wikipedia.org/wiki/Sokal_affair). Alan Sokal, a physics professor, sent a meaningless paper, titled \"Transgressing the Boundaries: Towards a Transformative Hermeneutics of Quantum Gravity\", to a social studies magazine, and it was surprisingly admitted.\n",
        "\n",
        "Indeed, Sokal didn't use any automatic generators; however, he raised the question of the boundaries between real, meaningful, scientific papers, and bogus papers.\n",
        "\n",
        "Sadly, analyzing the full implications of Sokal hoax is beyond the scope of this work.\n",
        "\n",
        "More recent attempt with text generation is [Andrej Karpathy's 'The Unreasonable Effectiveness of Recurrent Neural Networks'](http://karpathy.github.io/2015/05/21/rnn-effectiveness/). He's using a different attitude, of character level generation with RNN, and without GAN; and achieved  quite impressing results, such as fake Wikipedia article, fake scientific paper and even fake Linux kernel source code (including license and comments...)\n",
        "\n",
        "An interesting review of the 2018 advances in NLP, relevant to our work -  \"Finally, a Machine That Can Finish Your Sentence\" can be found at [this NY Times article](https://www.nytimes.com/2018/11/18/technology/artificial-intelligence-language.html).\n",
        "\n",
        "## Methodology\n",
        "\n",
        "In order to generate a CS paper, we first need to understand what *is* a CS paper. Therefore, in this proposal, we've focused on classifying CS papers.\n",
        "\n",
        "### Data\n",
        "\n",
        "We need a large collection of CS papers; some of them published in journals, some of them aren't. A useful option is [arXiv.org](https://arxiv.org/), because it's becoming a common practice to pre-publish papers over there, until the peer review process will finish. Therefore, if we check old enough papers over there, we can distinguish between papers that have been peer reviewed and accepted to publication, and papers that haven't.\n",
        "\n",
        "Furthermore, the arXiv has the original .tex files, which make it easier to analyze (we don't need to run PDFs through OCR).\n",
        "\n",
        "### Transfer learning\n",
        "\n",
        "Following [fast.ai documentation](https://docs.fast.ai/text.html), we're using transfer learning - instead of training our models from scratch, we start from a \"good known point\" - similar to what is done in vision - where models come pre-trained on [ImageNet](http://www.image-net.org/), and only the last layers are fine tuned. Similar approach for text is using [ULMFiT](https://arxiv.org/abs/1801.06146), a model that has already been trained over the English Wikipedia, and therefore knows a lot about English texts, and only needs fine tuning for the specific field.\n",
        "\n",
        "### Language model ###\n",
        "\n",
        "In our approach, we first train a `language model`, that receives a word, and predicts what the next word will be. ~30% accuracy is thought to be good for the general case, and can raise up to 50% for specific fields. We've achieved ~40%.\n",
        "\n",
        "In this phase, we don't care whether a paper is peer reviewed, or not; we just want our model to 'understand' how text from all kinds of papers look like and 'behave'.\n",
        "\n",
        "### Classifier ###\n",
        "\n",
        "With the language model at hand, we can build a classifier. Conveniently, `fast.ai` wraps `NLTK`, and our language model handles the tokenization and conversion to numbers. Now all we need to do is give our language model a labeled dataset, and let it distinguish between peer reviewed and not peer reviewed papers. Thus, we've reached ~93% accuracy.\n",
        "\n",
        "## Problems with our methodology, and mitigations\n",
        "\n",
        "1. We haven't found a precedent for efficient large text generation with GAN.\n",
        "* *but it's still worth trying...*\n",
        "2. There might be papers in arXiv.org that haven't been peer-reviewed, but are of peer review quality, because of few reasons:\n",
        "    1. It's still in the peer review process\n",
        "    * *therefore, we take only papers that have been published at the arXiv at least 3 years ago*\n",
        "    2. The author believes in Open Source values, and refuses to publish in regular journals\n",
        "    * *we assume that it's negligible*\n",
        "    3. The author doesn't want publicity (e.g., the case of [Grigori Perelman's refusal to publish his proof of Poincar√© conjecture](https://en.wikipedia.org/wiki/Grigori_Perelman)\n",
        "    * *we assume that it's even more negligible*\n",
        "3. Currently our criteria is only whether it was published, in *any* journal\n",
        "* *we'll address that after the proposal phase, by using only highly ranked journals*\n",
        "4. There might be papers in arXiv.org that haven't passed peer review, because they were never meant to be sent to peer review\n",
        "* *it's not really a problem; our classifier needs to differentiate between 'peer-reviewed' and 'not peer-reviewed', and indeed, these papers aren't peer reviewed; thus it should only be a good example*\n",
        "5. We might have very low ratio of peer reviewed papers out of the total papers\n",
        "* *currently it's ~10%, and seems OK. If needed, we'll toss some 'not peer-reviewed' papers to improve the ratio*\n",
        "\n",
        "# Plans for the project ##\n",
        "1. Add the generation phase.\n",
        "2. Increase the datasets we're using.\n",
        "3. Differentiate between the journals which publish papers.\n",
        "4. Check the influence of the metadata on the results.\n",
        "5. Currently we've used only AI sub field of CS; we might use other sub fields as well.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dLGHWv3QhTl",
        "colab_type": "code",
        "outputId": "f2311e77-6d11-4a70-8bb1-257056b27429",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# setup\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        " \n",
        "from fastai.text import *\n",
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_dir = \"/content/gdrive/My Drive/\"\n",
        "base_dir = root_dir + 'fastai-v3/SCIgan/'\n",
        " \n",
        "batch_size = 48\n",
        "OUTPUT_BASE = os.path.join(base_dir, r\"clean\")\n",
        "path = Path(OUTPUT_BASE)\n",
        "\n",
        "np.random.seed(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jd032KOnQif8",
        "colab_type": "text"
      },
      "source": [
        "## Scraping articles from https://arxiv.org ##\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q73171jtPNMX",
        "colab_type": "code",
        "outputId": "5750bf9b-c59c-4b7a-ae5b-5474830ccc3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#TODO: ELAD - just write here your script\n",
        "print(\"Downloading...\")\n",
        "\n",
        "# for now, lat's take if from Google Drive\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbPV23TUq2Sa",
        "colab_type": "text"
      },
      "source": [
        "The papers downloaded from arxiv.org come with directories, each built from 1 or more .tex files (among other, not interesting files)\n",
        "\n",
        "The code below make a clean copy, with a single .tex file for each paper.\n",
        "If there's a `main.tex` that imports other files, it's parsed accordingly.\n",
        "If not, we're searching for the file that behaves as the main file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TmV8imKTSZ4",
        "colab_type": "code",
        "outputId": "aa31502f-6907-4279-ea7a-2244c1623102",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import sys\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if not IN_COLAB:\n",
        "    root_dir = 'data_science-20200603T080022Z-001'\n",
        "    base_dir = '.'\n",
        "\n",
        "INPUT_BASE = os.path.join(root_dir, 'data_science')     # take from Google drive\n",
        "OUTPUT_BASE = os.path.join(base_dir, r\"clean\")\n",
        "\n",
        "labels = (\"peer_reviewed\", \"not_peer_reviewed\")\n",
        "\n",
        "def warning(msg):\n",
        "    print(\"WARNING: \" + msg)\n",
        "\n",
        "def output(label, filename):\n",
        "    dst = os.path.join(os.path.join(OUTPUT_BASE, label), os.path.basename(os.path.dirname(filename))) + \".tex\"\n",
        "\n",
        "    # I'd rather use simple copy, like this ...\n",
        "    #shutil.copy(filename, dst)\n",
        "\n",
        "    # ... but there are files with problematic encodings, we need to clean that\n",
        "    print(\"Copying %s to %s\" % (filename, dst))\n",
        "    with open(dst, 'w', encoding='utf8') as output_f:\n",
        "        with open(filename, encoding='utf8') as input_f:\n",
        "            try:\n",
        "                for line in input_f:\n",
        "                    output_f.write(line)\n",
        "            except UnicodeDecodeError:\n",
        "                warning(\"Decoding error in: \" + filename)\n",
        "\n",
        "def dump_file(output_f, include_file):\n",
        "    with open(include_file) as f:\n",
        "        for line in f:\n",
        "            output_f.write(line)\n",
        "\n",
        "def parse(label, dir, tex_files, main='main.tex'):\n",
        "    r = re.compile(r'\\\\(include|input)\\s+(\\S+)')\n",
        "\n",
        "    dst = os.path.join(os.path.join(OUTPUT_BASE, label), os.path.basename(dir)) + \".tex\"\n",
        "    print(\"Copying %s/%s/*.tex to %s\" % (label, dir, dst))\n",
        "\n",
        "    with open(dst, 'w', encoding='utf8') as output_f:\n",
        "        with open(os.path.join(dir, main), encoding='utf8') as input_f:\n",
        "            for line in input_f:\n",
        "                if r.match(line):\n",
        "                    included = r.match(line).group(2) + '.tex'\n",
        "                    # note: currently we assume no recursive includes, we'd check later if it's needed adding\n",
        "                    dump_file(output_f, os.path.join(dir, included))\n",
        "                else:\n",
        "                    output_f.write(line)\n",
        "\n",
        "\n",
        "def search_main_tex(label, dir, tex_files):\n",
        "    r = re.compile(r'^\\s*\\\\documentclass')\n",
        "    for tex_file in tex_files:\n",
        "        filename = os.path.join(dir, tex_file)\n",
        "        with open(filename) as f:\n",
        "            try:\n",
        "                for line in f:\n",
        "                    if r.match(line):\n",
        "                        return tex_file\n",
        "            except UnicodeDecodeError:\n",
        "                warning(\"Decoding error in: \" + filename)\n",
        "    return None\n",
        "\n",
        "\n",
        "def handle_dir(label, dir):\n",
        "    tex_files = [f for f in os.listdir(dir) if os.path.isfile(os.path.join(dir, f)) and f.endswith(\".tex\")]\n",
        "    if len(os.listdir(dir)) == 0:\n",
        "        warning(\"label %s, empty directory %s\" % (label, dir))\n",
        "    elif len(tex_files) == 0:\n",
        "        warning(\"label %s, directory %s without .tex files\" % (label, dir))\n",
        "    elif len(tex_files) == 1:\n",
        "        output(label, os.path.join(dir, tex_files[0]))\n",
        "    elif 'main.tex' not in tex_files:\n",
        "        main = search_main_tex(label, dir, tex_files)\n",
        "        if main is None:\n",
        "            warning(\"label %s, directory %s is without main.tex file\" % (label, dir))\n",
        "        else:\n",
        "            parse(label, dir, tex_files, main)\n",
        "    else:\n",
        "        parse(label, dir, tex_files)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        shutil.rmtree(OUTPUT_BASE)\n",
        "    except:\n",
        "        pass\n",
        "    os.mkdir(OUTPUT_BASE)\n",
        "\n",
        "    for label in labels:\n",
        "        os.mkdir(os.path.join(OUTPUT_BASE, label))\n",
        "        root = os.path.join(INPUT_BASE, label)\n",
        "        dirs = [d for d in os.listdir(root) if os.path.isdir(os.path.join(root, d))]\n",
        "        for dir in dirs:\n",
        "            handle_dir(label, os.path.join(root, dir))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying /content/gdrive/My Drive/data_science/peer_reviewed/2006.00212v1.tar.gz_extracted/manuscript.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/peer_reviewed/2006.00212v1.tar.gz_extracted.tex\n",
            "Copying peer_reviewed//content/gdrive/My Drive/data_science/peer_reviewed/2006.00917v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/peer_reviewed/2006.00917v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/peer_reviewed/2005.14656v1.tar.gz_extracted/GP.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/peer_reviewed/2005.14656v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/peer_reviewed/2005.13275v1.tar.gz_extracted/celino-human-explanability.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/peer_reviewed/2005.13275v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/peer_reviewed/2005.11797v2.tar.gz_extracted/midl-shortpaper.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/peer_reviewed/2005.11797v2.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/peer_reviewed/2005.13399v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/peer_reviewed/2005.13399v1.tar.gz_extracted.tex\n",
            "Copying peer_reviewed//content/gdrive/My Drive/data_science/peer_reviewed/2005.11895v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/peer_reviewed/2005.11895v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/peer_reviewed/2005.12644v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/peer_reviewed/2005.12644v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/peer_reviewed/2005.14080v2.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/peer_reviewed/2005.14080v2.tar.gz_extracted.tex\n",
            "WARNING: Decoding error in: /content/gdrive/My Drive/data_science/peer_reviewed/2005.14080v2.tar.gz_extracted/main.tex\n",
            "Copying peer_reviewed//content/gdrive/My Drive/data_science/peer_reviewed/2005.13270v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/peer_reviewed/2005.13270v1.tar.gz_extracted.tex\n",
            "Copying peer_reviewed//content/gdrive/My Drive/data_science/peer_reviewed/2005.03648v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/peer_reviewed/2005.03648v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/peer_reviewed/2005.02576v1.tar.gz_extracted/MAIN-MalabyE.120.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/peer_reviewed/2005.02576v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/peer_reviewed/2005.09755v1.tar.gz_extracted/paper.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/peer_reviewed/2005.09755v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/peer_reviewed/2005.10960v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/peer_reviewed/2005.10960v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/peer_reviewed/2005.04912v1.tar.gz_extracted/DanPaper.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/peer_reviewed/2005.04912v1.tar.gz_extracted.tex\n",
            "Copying peer_reviewed//content/gdrive/My Drive/data_science/peer_reviewed/2005.00813v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/peer_reviewed/2005.00813v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/peer_reviewed/2005.06587v1.tar.gz_extracted/acl2020.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/peer_reviewed/2005.06587v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/peer_reviewed/2005.05268v1.tar.gz_extracted/GA_Feature_Selection.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/peer_reviewed/2005.05268v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/peer_reviewed/2005.10872v2.tar.gz_extracted/root.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/peer_reviewed/2005.10872v2.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/peer_reviewed/2005.04016v1.tar.gz_extracted/Concept_Drift_TKDE.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/peer_reviewed/2005.04016v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/peer_reviewed/2004.14684v1.tar.gz_extracted/Example.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/peer_reviewed/2004.14684v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/peer_reviewed/2004.08144v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/peer_reviewed/2004.08144v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/peer_reviewed/2004.08607v1.tar.gz_extracted/template.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/peer_reviewed/2004.08607v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/peer_reviewed/2004.09044v1.tar.gz_extracted/dark.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/peer_reviewed/2004.09044v1.tar.gz_extracted.tex\n",
            "Copying peer_reviewed//content/gdrive/My Drive/data_science/peer_reviewed/2004.08866v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/peer_reviewed/2004.08866v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/peer_reviewed/2004.10048v1.tar.gz_extracted/Revised_Manuscript.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/peer_reviewed/2004.10048v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/peer_reviewed/2004.08646v1.tar.gz_extracted/corl2019.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/peer_reviewed/2004.08646v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/peer_reviewed/2004.14171v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/peer_reviewed/2004.14171v1.tar.gz_extracted.tex\n",
            "Copying peer_reviewed//content/gdrive/My Drive/data_science/peer_reviewed/2004.09312v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/peer_reviewed/2004.09312v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/peer_reviewed/2004.06883v1.tar.gz_extracted/mirrorritual.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/peer_reviewed/2004.06883v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/peer_reviewed/2004.00716v1.tar.gz_extracted/root.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/peer_reviewed/2004.00716v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/peer_reviewed/2004.02671v1.tar.gz_extracted/icicel-sample.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/peer_reviewed/2004.02671v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/peer_reviewed/2004.04917v1.tar.gz_extracted/egpaper_for_review.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/peer_reviewed/2004.04917v1.tar.gz_extracted.tex\n",
            "Copying peer_reviewed//content/gdrive/My Drive/data_science/peer_reviewed/2004.01223v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/peer_reviewed/2004.01223v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/peer_reviewed/2004.03744v2.tar.gz_extracted/egpaper_for_review.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/peer_reviewed/2004.03744v2.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/peer_reviewed/2003.11102v1.tar.gz_extracted/neurips_2019.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/peer_reviewed/2003.11102v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/peer_reviewed/2004.00689v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/peer_reviewed/2004.00689v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/peer_reviewed/2004.04131v1.tar.gz_extracted/lazzarottof1.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/peer_reviewed/2004.04131v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/peer_reviewed/2004.01694v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/peer_reviewed/2004.01694v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2006.01096v1.tar.gz_extracted/Sonar2020.IRM-RL.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2006.01096v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2006.00997v1.tar.gz_extracted/temporal-differential-arxiv.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2006.00997v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2006.01016v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2006.01016v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2006.00979v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2006.00979v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2006.01011v1.tar.gz_extracted/paper.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2006.01011v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2006.00970v1.tar.gz_extracted/arXivUAI2020.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2006.00970v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2006.01067v1.tar.gz_extracted/tacl2018v2-template.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2006.01067v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2006.00900v1.tar.gz_extracted/manuscript.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2006.00900v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2006.01023v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2006.01023v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2006.00954v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2006.00954v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2006.00888v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2006.00888v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2006.00555v1.tar.gz_extracted/main_arxiv.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2006.00555v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2006.00587v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2006.00587v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2006.00778v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2006.00778v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2006.00715v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2006.00715v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2006.00618v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2006.00618v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2006.00882v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2006.00882v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2006.00592v1.tar.gz_extracted/EDM_Article_Submission.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2006.00592v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2006.00871v1.tar.gz_extracted/conference_101719.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2006.00871v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2006.00622v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2006.00622v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2006.00483v1.tar.gz_extracted/ms.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2006.00483v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2006.00417v1.tar.gz_extracted/coling2020.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2006.00417v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2006.00390v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2006.00390v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2006.00283v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2006.00283v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.14684v1.tar.gz_extracted/HPGN.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.14684v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2006.00195v1.tar.gz_extracted/PM_IEEEACCESS_rvf.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2006.00195v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.14664v1.tar.gz_extracted/nnconj-clean-arxiv.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.14664v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.14621v1.tar.gz_extracted/fairness.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.14621v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2006.00059v1.tar.gz_extracted/STAIRS20-arXiv.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2006.00059v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2006.00088v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2006.00088v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.14662v1.tar.gz_extracted/main_en.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.14662v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2006.00093v1.tar.gz_extracted/reference.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2006.00093v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.14601v1.tar.gz_extracted/sample.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.14601v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.14408v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.14408v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.14549v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.14549v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.14410v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.14410v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.14259v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.14259v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.14381v1.tar.gz_extracted/sample.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.14381v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.14299v1.tar.gz_extracted/What_is_SemEval_evaluating.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.14299v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.14501v1.tar.gz_extracted/ms.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.14501v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.14230v1.tar.gz_extracted/sample-authordraft.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.14230v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.14223v1.tar.gz_extracted/jmlr-sample.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.14223v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.14156v1.tar.gz_extracted/CoG-MazeDash.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.14156v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.13685v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.13685v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.13872v1.tar.gz_extracted/arxiv.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.13872v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.13635v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.13635v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.13766v2.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.13766v2.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.13778v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.13778v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.13857v1.tar.gz_extracted/rss-2020.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.13857v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.13970v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.13970v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.13976v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.13976v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.14037v1.tar.gz_extracted/arXivepgm2020.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.14037v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.13625v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.13625v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.13170v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.13170v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.13407v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.13407v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.13139v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.13139v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.13239v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.13239v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.13186v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.13186v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.13289v1.tar.gz_extracted/arxiv.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.13289v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.13596v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.13596v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.13406v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.13406v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.13601v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.13601v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.13129v1.tar.gz_extracted/dst.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.13129v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.13109v2.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.13109v2.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.12800v1.tar.gz_extracted/MDAI-arxiv.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.12800v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.12841v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.12841v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.12801v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.12801v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.12981v1.tar.gz_extracted/DHAN_SIGIR_final.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.12981v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.12713v1.tar.gz_extracted/arxiv_systemw.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.12713v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.12737v1.tar.gz_extracted/sample-sigconf.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.12737v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.12826v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.12826v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.12974v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.12974v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.12697v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.12697v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.12508v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.12508v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.12535v1.tar.gz_extracted/Bio-Morphism.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.12535v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.12529v1.tar.gz_extracted/ms.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.12529v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.12533v1.tar.gz_extracted/ULL_Oracle.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.12533v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.12638v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.12638v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.12501v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.12501v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.12579v1.tar.gz_extracted/conference_041818.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.12579v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.12632v1.tar.gz_extracted/paper_1_6_arxiv.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.12632v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.12553v1.tar.gz_extracted/HAMXCS.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.12553v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.12474v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.12474v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.12327v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.12327v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.12254v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.12254v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.12360v1.tar.gz_extracted/aamas.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.12360v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.12132v1.tar.gz_extracted/sigir20-tail.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.12132v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.12175v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.12175v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.12256v2.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.12256v2.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.12267v1.tar.gz_extracted/SLR-BigDataIDS.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.12267v1.tar.gz_extracted.tex\n",
            "WARNING: Decoding error in: /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.12267v1.tar.gz_extracted/SLR-BigDataIDS.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.12364v1.tar.gz_extracted/bare_jrnl.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.12364v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.12339v1.tar.gz_extracted/IncidentalSupervision.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.12339v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.12442v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.12442v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.12069v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.12069v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.12064v1.tar.gz_extracted/formalization.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.12064v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.11730v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.11730v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.11810v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.11810v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.11247v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.11247v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.11203v1.tar.gz_extracted/preprint_200522.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.11203v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.11176v1.tar.gz_extracted/dialogue.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.11176v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.11729v2.tar.gz_extracted/sample-base.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.11729v2.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.11267v1.tar.gz_extracted/draft.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.11267v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.11816v2.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.11816v2.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.11335v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.11335v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.11164v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.11164v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.10934v1.tar.gz_extracted/0-arxiv.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.10934v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.11077v1.tar.gz_extracted/paper.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.11077v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.10956v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.10956v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.11019v1.tar.gz_extracted/microPhantom.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.11019v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.11014v1.tar.gz_extracted/ecai.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.11014v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.11153v1.tar.gz_extracted/template.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.11153v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.11016v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.11016v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.11093v2.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.11093v2.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.11081v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.11081v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.10738v1.tar.gz_extracted/jfsma_va_rr.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.10738v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.10622v2.tar.gz_extracted/root.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.10622v2.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.10674v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.10674v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.10430v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.10430v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.10691v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.10691v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.10539v1.tar.gz_extracted/iccc.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.10539v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.10411v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.10411v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.10450v1.tar.gz_extracted/AAAI-PengS.3369.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.10450v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.10619v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.10619v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.10383v1.tar.gz_extracted/inattention-corr.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.10383v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.10696v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.10696v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.10381v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.10381v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.10349v1.tar.gz_extracted/template.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.10349v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.10297v1.tar.gz_extracted/teamplans.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.10297v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.10329v1.tar.gz_extracted/eccv2020submission.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.10329v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.09998v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.09998v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.10000v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.10000v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.10131v1.tar.gz_extracted/focus.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.10131v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.10050v1.tar.gz_extracted/_paper.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.10050v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.10284v2.tar.gz_extracted/neurips_2020.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.10284v2.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.10327v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.10327v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.10180v1.tar.gz_extracted/interventions.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.10180v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.09971v1.tar.gz_extracted/Hofmann.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.09971v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.09833v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.09833v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.09611v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.09611v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.09645v1.tar.gz_extracted/mctst+.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.09645v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.09624v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.09624v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.09961v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.09961v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.09512v1.tar.gz_extracted/conference_101719.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.09512v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.09460v1.tar.gz_extracted/vigiflood-may2020.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.09460v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.09814v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.09814v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.09900v1.tar.gz_extracted/samplepaper.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.09900v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.09453v2.tar.gz_extracted/neurips_2020.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.09453v2.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.09198v1.tar.gz_extracted/template.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.09198v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.09109v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.09109v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.09406v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.09406v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.09253v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.09253v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.09220v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.09220v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.09331v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.09331v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.09343v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.09343v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.09330v1.tar.gz_extracted/DDPR_arxiv.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.09330v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.09046v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.09046v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.08954v1.tar.gz_extracted/paper.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.08954v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.08636v2.tar.gz_extracted/col_gen_heuristic_sc.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.08636v2.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.08792v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.08792v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.08516v1.tar.gz_extracted/ijcai20.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.08516v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.08384v1.tar.gz_extracted/2019-12-07-fixstream_AI_revised.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.08384v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.08874v3.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.08874v3.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.08231v1.tar.gz_extracted/main_biases.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.08231v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.08502v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.08502v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.08368v1.tar.gz_extracted/sample-sigconf.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.08368v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.08679v1.tar.gz_extracted/no_comments.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.08679v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.08225v1.tar.gz_extracted/ijcai20.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.08225v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.08068v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.08068v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.08006v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.08006v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.08090v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.08090v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.08114v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.08114v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.08129v1.tar.gz_extracted/sample-sigconf.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.08129v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.07979v1.tar.gz_extracted/arxiv.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.07979v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.08016v1.tar.gz_extracted/paper.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.08016v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.08078v1.tar.gz_extracted/Final_-_Ontology_and_Cognitive_Outcomes.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.08078v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.08083v1.tar.gz_extracted/0_Main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.08083v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.07960v1.tar.gz_extracted/bookchapter.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.07960v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.07782v1.tar.gz_extracted/UDRL.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.07782v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.07666v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.07666v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.07648v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.07648v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.07941v1.tar.gz_extracted/AIEC_CHR_Globecom.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.07941v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.07667v1.tar.gz_extracted/conference_071817.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.07667v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.07677v1.tar.gz_extracted/conference_101719.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.07677v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.07870v2.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.07870v2.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.07654v2.tar.gz_extracted/main-arxiv.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.07654v2.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.07845v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.07845v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.07647v1.tar.gz_extracted/ms.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.07647v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.07371v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.07371v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.07404v1.tar.gz_extracted/ijcai20-multiauthor.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.07404v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.07376v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.07376v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.07493v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.07493v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.07385v1.tar.gz_extracted/safer-motion-planning.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.07385v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.07478v1.tar.gz_extracted/manuscript.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.07478v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.07415v2.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.07415v2.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.07541v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.07541v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.07513v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.07513v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.07362v1.tar.gz_extracted/acl2020.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.07362v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.07023v1.tar.gz_extracted/root.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.07023v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.07099v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.07099v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.07328v2.tar.gz_extracted/co-creation.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.07328v2.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.07050v1.tar.gz_extracted/Paradoxes.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.07050v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.07293v1.tar.gz_extracted/ms.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.07293v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.07064v1.tar.gz_extracted/acl2019.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.07064v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.07025v1.tar.gz_extracted/template.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.07025v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.07156v1.tar.gz_extracted/thesis.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.07156v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.07073v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.07073v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.06922v1.tar.gz_extracted/main_cav20.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.06922v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.06616v1.tar.gz_extracted/samplepaper.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.06616v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.06641v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.06641v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.06764v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.06764v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.06850v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.06850v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.06612v1.tar.gz_extracted/covid_fan.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.06612v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.06852v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.06852v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.06879v1.tar.gz_extracted/formatting-instructions-latex-2019.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.06879v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.06695v1.tar.gz_extracted/arxiv.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.06695v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.06584v1.tar.gz_extracted/main_yusan_final.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.06584v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.06527v2.tar.gz_extracted/ijcai20.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.06527v2.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.06223v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.06223v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.06148v2.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.06148v2.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.06224v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.06224v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.06274v1.tar.gz_extracted/ecai20.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.06274v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.06249v1.tar.gz_extracted/mrc.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.06249v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.06293v1.tar.gz_extracted/ms.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.06293v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.06369v1.tar.gz_extracted/iclr2020_conference.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.06369v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.06282v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.06282v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.06139v1.tar.gz_extracted/manuscript.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.06139v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.06117v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.06117v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.06105v2.tar.gz_extracted/ISSI-2019-11-0432_Kim.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.06105v2.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.06061v1.tar.gz_extracted/toma.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.06061v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.05849v1.tar.gz_extracted/comma20.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.05849v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.05763v1.tar.gz_extracted/WinoWhy-with-appendix.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.05763v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.05951v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.05951v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.05960v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.05960v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.06060v1.tar.gz_extracted/ic-vs-chem.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.06060v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.05886v2.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.05886v2.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.05842v2.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.05842v2.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.05909v2.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.05909v2.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.06022v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.06022v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.05721v1.tar.gz_extracted/comma20.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.05721v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.05298v2.tar.gz_extracted/emnlp2020.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.05298v2.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.05490v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.05490v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.05420v1.tar.gz_extracted/iros_2020.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.05420v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.05440v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.05440v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.05418v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.05418v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.05579v1.tar.gz_extracted/Example.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.05579v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.05712v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.05712v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.05672v1.tar.gz_extracted/paper.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.05672v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.05339v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.05339v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.05256v1.tar.gz_extracted/mybibliography.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.05256v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.05069v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.05069v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.05085v1.tar.gz_extracted/aiotbench.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.05085v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.05178v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.05178v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.05151v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.05151v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.05066v2.tar.gz_extracted/MFCGA.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.05066v2.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.05131v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.05131v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.05098v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.05098v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.05239v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.05239v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.05240v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.05240v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.05065v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.05065v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.05051v1.tar.gz_extracted/elsarticle-template-harv.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.05051v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.04589v1.tar.gz_extracted/cognitive-energetics_v2.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.04589v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.04735v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.04735v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.04560v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.04560v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.04790v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.04790v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.04855v1.tar.gz_extracted/walsh.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.04855v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.04954v1.tar.gz_extracted/ijcai2020.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.04954v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.05021v3.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.05021v3.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.04987v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.04987v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.04625v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.04625v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.04544v2.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.04544v2.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.04318v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.04318v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.04374v1.tar.gz_extracted/learn_soc.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.04374v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.04306v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.04306v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.04536v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.04536v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.04379v1.tar.gz_extracted/acl2020.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.04379v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.04397v2.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.04397v2.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.04466v1.tar.gz_extracted/paper.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.04466v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.04369v1.tar.gz_extracted/tifs19_ppdr.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.04369v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.04543v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.04543v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.04269v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.04269v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.04166v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.04166v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.04120v2.tar.gz_extracted/template.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.04120v2.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.04022v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.04022v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.03947v2.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.03947v2.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.04151v1.tar.gz_extracted/template.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.04151v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.03977v1.tar.gz_extracted/FL_RFOWC_WPT_Final.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.03977v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.04095v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.04095v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.03954v3.tar.gz_extracted/acl2020.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.03954v3.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.04067v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.04067v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.04123v1.tar.gz_extracted/forgetsize.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.04123v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.03898v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.03898v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.03620v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.03620v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.03818v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.03818v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.03632v2.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.03632v2.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.03529v1.tar.gz_extracted/eswc2020.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.03529v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.03742v1.tar.gz_extracted/Lenia-Expanded.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.03742v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.03597v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.03597v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.03474v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.03474v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.03863v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.03863v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.03789v1.tar.gz_extracted/main_full.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.03789v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.03374v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.03374v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.03098v2.tar.gz_extracted/ArneDecadt.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.03098v2.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.03230v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.03230v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.03299v1.tar.gz_extracted/acl2020.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.03299v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.03233v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.03233v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.03356v1.tar.gz_extracted/egbib.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.03356v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.03186v1.tar.gz_extracted/NewTSPTheory_arXiv-1.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.03186v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.03086v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.03086v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.03350v2.tar.gz_extracted/template.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.03350v2.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.03182v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.03182v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.03066v1.tar.gz_extracted/coling2020.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.03066v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.03003v1.tar.gz_extracted/main-dsn-fa-cr-arxiv.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.03003v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.02934v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.02934v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.02880v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.02880v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.02986v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.02986v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.02940v2.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.02940v2.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.02963v1.tar.gz_extracted/samplepaper.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.02963v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.03063v1.tar.gz_extracted/template.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.03063v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.02979v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.02979v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.02878v2.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.02878v2.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.02810v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.02810v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.02618v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.02618v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.02597v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.02597v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.02575v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.02575v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.02623v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.02623v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.02632v1.tar.gz_extracted/root.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.02632v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.02573v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.02573v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.02801v1.tar.gz_extracted/NE_Consciousness_v1.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.02801v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.02659v1.tar.gz_extracted/HolisticAlg.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.02659v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.02645v1.tar.gz_extracted/arxiv05-2.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.02645v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.02558v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.02558v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.02530v2.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.02530v2.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.02480v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.02480v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.02431v2.tar.gz_extracted/samplepaper.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.02431v2.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.02230v1.tar.gz_extracted/paper.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.02230v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.02335v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.02335v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.02259v1.tar.gz_extracted/popper.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.02259v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.02525v1.tar.gz_extracted/samplepaper.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.02525v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.02181v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.02181v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.02305v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.02305v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.02342v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.02342v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.02094v1.tar.gz_extracted/ms.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.02094v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.02074v1.tar.gz_extracted/kr2020.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.02074v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.02006v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.02006v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.01810v1.tar.gz_extracted/acl2020.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.01810v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.01908v1.tar.gz_extracted/aij.xai.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.01908v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.02073v1.tar.gz_extracted/journal.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.02073v1.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.01831v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.01831v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.02008v1.tar.gz_extracted/acl2020.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.02008v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.01777v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.01777v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.01935v1.tar.gz_extracted/root.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.01935v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.01795v1.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.01795v1.tar.gz_extracted.tex\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.01654v2.tar.gz_extracted/main.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.01654v2.tar.gz_extracted.tex\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.01643v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.01643v1.tar.gz_extracted.tex\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.01427v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.01539v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.01556v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.01399v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.01633v1.tar.gz_extracted without .tex files\n",
            "Copying not_peer_reviewed//content/gdrive/My Drive/data_science/not_peer_reviewed/2005.01642v1.tar.gz_extracted/*.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.01642v1.tar.gz_extracted.tex\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.01627v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.01574v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.01525v2.tar.gz_extracted\n",
            "Copying /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.01291v1.tar.gz_extracted/arxiv_1.tex to /content/gdrive/My Drive/fastai-v3/SCIgan/clean/not_peer_reviewed/2005.01291v1.tar.gz_extracted.tex\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.01278v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.01117v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.00928v2.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.01246v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.00904v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.01157v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.00961v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.01138v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.01192v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.01075v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.00887v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.00728v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.00840v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.00789v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.00769v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.00724v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.00856v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.00811v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.00782v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.00804v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.00705v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.00700v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.00691v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.00683v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.00693v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.00631v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.00660v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.00689v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.00697v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.00653v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.00669v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.00610v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.00463v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.00558v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.00582v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.00527v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.00545v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.00565v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.00330v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.00571v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.00603v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.00329v3.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.00206v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.00130v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.00316v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.00115v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.00110v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2005.00171v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.14975v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.15004v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.14973v2.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.14969v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.14939v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.14841v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.14648v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.14646v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.14843v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.14690v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.14545v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.14507v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.14677v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.14547v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.14378v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.14362v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.14309v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.14120v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.14283v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.14174v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.14265v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.14201v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.14162v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.14303v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.14069v2.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.14254v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.14067v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.13912v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.13936v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.13835v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.14025v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.14014v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.14034v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.13836v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.13954v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.14035v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.13832v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.13702v2.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.13786v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.13829v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.13823v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.13710v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.13821v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.13789v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.13831v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.13818v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.13657v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.13654v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.13631v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.13637v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.13482v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.13529v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.13579v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.13527v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.13577v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.13553v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.13477v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.13455v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.13230v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.13248v3.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.13242v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.13384v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.13161v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.12960v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.13439v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.13102v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.13291v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.12919v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.12916v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.12908v2.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.12873v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.12750v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.12554v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.12527v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.12770v3.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.12781v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.12846v2.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.12684v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.12734v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.12850v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.12485v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.12481v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.12480v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.12317v2.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.12316v3.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.12277v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.12357v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.12399v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.12303v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.12330v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.12363v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.12311v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.12212v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.11870v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.12171v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.12152v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.12117v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.12062v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.12092v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.12059v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.11947v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.12193v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.11861v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.11410v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.11812v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.11763v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.11434v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.11339v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.11345v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.11667v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.11469v3.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.11638v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.11858v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.11302v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.10978v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.10927v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.11145v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.10958v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.11113v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.10966v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.10984v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.10908v2.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.11204v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.10888v3.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.10645v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.10489v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.10746v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.10808v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.10667v3.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.10876v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.10698v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.10521v3.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.10518v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.10439v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.10386v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.10430v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.10301v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.10404v2.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.10119v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.10099v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.10151v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.10293v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.10263v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.10037v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.09969v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.09931v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.10014v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.09957v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.09999v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.09855v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.09986v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.09853v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.10030v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.09846v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.09473v2.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.09392v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.09703v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.09456v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.09507v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.09406v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.09685v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.09551v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.09524v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.09218v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.09141v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.08830v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.08763v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.09124v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.08672v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.09134v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.08694v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.08892v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.08858v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.08648v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.08600v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.08519v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.08555v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.08279v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.08366v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.08599v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.08356v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.08128v3.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.08440v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.08051v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.07950v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.07804v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.07707v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.07780v3.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.07928v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.07822v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.07633v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.07790v3.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.07879v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.07690v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.07530v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.07473v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.07347v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.07383v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.07333v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.07506v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.07499v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.07447v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.07462v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.07511v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.07200v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.07141v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.06971v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.07017v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.06675v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.06684v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.07027v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.06961v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.06894v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.06774v2.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.06856v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.06627v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.06581v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.06040v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.06564v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.06223v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.06353v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.06076v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.06063v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.06559v3.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.06089v4.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.06519v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.05966v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.05722v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.05937v3.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.05930v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.05802v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.05940v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.05773v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.05915v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.05886v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.05827v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.05704v2.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.05388v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.05512v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.05417v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.05569v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.05473v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.05565v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.05654v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.05499v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.05380v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.05352v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.05269v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.05002v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.05205v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.05146v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.05155v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.04938v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.05219v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.05268v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.05077v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.05267v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.04851v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.04722v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.04647v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.04574v4.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.04479v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.04778v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.04768v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.04640v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.04849v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.04733v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.04464v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.04100v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.04450v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.04198v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.04305v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.04376v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.04423v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.04412v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.04188v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.04000v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.03868v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.03592v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.03573v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.03788v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.03636v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.03755v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.03761v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.03762v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.03846v3.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.03644v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.03561v2.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.03267v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.03343v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.03397v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.03238v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.03329v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.03484v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.03386v3.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.03340v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.03237v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.03188v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.02988v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.02780v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.03070v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.02919v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.03168v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.03101v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.03053v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.02958v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.02973v2.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.02762v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.02673v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.02575v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.02557v3.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.02596v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.02594v3.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.02746v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.02610v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.02603v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.02614v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.02502v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.02082v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.02349v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.02438v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.02047v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.02326v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.02462v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.02490v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.02275v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.02289v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.02032v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.02028v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.01781v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.01770v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.02001v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.01768v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.01980v3.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.01909v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.02002v3.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.01981v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.01949v2.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.01740v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.01703v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.01521v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.01218v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.01608v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.01431v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.01697v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.01251v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.01430v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.01387v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.01168v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.01167v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.00981v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.00963v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.00817v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.00945v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.01098v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.00980v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.01056v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.00994v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.00915v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.00801v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.00768v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.00686v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.00646v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.00427v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.00425v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.00384v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.00603v3.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.00530v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.00600v3.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.00470v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.00567v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.00387v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.00377v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.00204v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.00094v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.00235v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.00071v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.00225v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.00151v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.00100v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.00055v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.00061v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.14027v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.14210v2.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.14415v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.14093v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.13956v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.14332v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.14132v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.13949v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.14324v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2004.00048v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.13861v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.13839v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.13668v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.13741v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.13590v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.13755v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.13633v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.13661v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.13676v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.13754v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.13532v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.13159v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.12909v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.12924v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.12613v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.13084v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.12828v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.12694v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.12900v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.12718v3.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.12948v3.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.13085v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.12587v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.12530v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.12172v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.12526v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.12331v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.12168v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.12218v5.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.12383v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.12381v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.12012v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.12239v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.11941v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.11334v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.11631v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.11618v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.11778v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.11458v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.11336v2.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.11706v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.11708v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.11619v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.11126v1.tar.gz_extracted without .tex files\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.11118v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.11082v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.10942v1.tar.gz_extracted\n",
            "WARNING: label not_peer_reviewed, empty directory /content/gdrive/My Drive/data_science/not_peer_reviewed/2003.11001v1.tar.gz_extracted\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnEILNWuVPVT",
        "colab_type": "text"
      },
      "source": [
        "## Language Model\n",
        "\n",
        "As described in the introduction, after gathering the data, we build a language model - a model that predicts what the next word in the sentence will be."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eblDq-Ajjj7Q",
        "colab_type": "code",
        "outputId": "edd49b44-b1bd-4154-a62f-bab79aa50321",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "# take the .tex files\n",
        "# randomly split and keep 10% for validation\n",
        "# in this phase, we don't care what's the label of paper (peer reviewed or not)\n",
        "data_lm = TextList.from_folder(path, extensions={'.tex'}).split_by_rand_pct(0.1).label_for_lm().databunch(bs = batch_size)\n",
        "          \n",
        "# through out our code, we'll `save` sometimes, and `load` afterwards\n",
        "# this allows continuing a new session from the middle, without\n",
        "# having to start all over again\n",
        "data_lm.save(base_dir + 'data_lm.pkl')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xd220S8KsmZN",
        "colab_type": "code",
        "outputId": "be919608-68a9-4906-a4bb-4125e080e8cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "23wqe4data_lm = load_data(path, base_dir + 'data_lm.pkl', bs=batch_size)\n",
        "data_lm.show_batch()\n",
        " \n",
        "# transfer learning, starting with Wikipedia model, and fine tuning with our data\n",
        "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>idx</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>\\n \\n  \\ xxunk = true , bookmarks = false]{hyperref } \\n \\n  \\ cvprfinalcopy % * * * xxmaj uncomment this line for the final submission \\n \\n \\n  \\ def \\ httilde { \\ mbox { \\ tt \\ raisebox{-.5ex } { \\ symbol{126 xxrep 4 } \\n \\n  \\ setcounter{page}{1 } \\n  \\ begin{document } \\n \\t \\n \\t % \\t</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>they ranged in age from 19 to 70 ( with an average age of 37 ) , and again ranged in self - reported political views from ` ` extremely xxunk ' ' to ` ` extremely conservative ' ' , and in educational achievement from ` ` some high school , no diploma ' ' to ` ` doctorate degree ' ' . xxmaj participants took between 1.5 minutes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>that returns are much higher than those of a single bet . xxmaj this however comes at the expense of an increased risk . xxmaj indeed , only a single selection need to lose for the entire accumulator bet to lose } . \\ \\ \\n \\n  { xxmaj let us consider for the sake of illustration $ k$ independent single bets ( i.e. no bets on conflicting outcomes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>xxmaj readers that are interested in this technique are suggested to check \\ citet{mai2019contextual } for more details . xxunk \\ subsection{query xxmaj embedding xxmaj computing } \\ label{subsubsec : xxunk } \\n  \\ citet{hamilton2018embedding } proposed a way to compute the query embedding of a xxup cgq $ \\ cgq$ based on these three components . xxmaj given a xxup cgq $ \\ cgq$ , we can encode</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>is consensus that a reliable evaluation should --- despite high costs --- be carried out by humans . \\n \\n  xxmaj various methods have been proposed for the human evaluation of xxup mt quality \\ xxunk } . xxmaj what they have in common is that the xxup mt output to be rated is paired with a translation hint : the source text or a reference translation . xxmaj</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://s3.amazonaws.com/fast-ai-modelzoo/wt103-fwd.tgz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Yt6Q7RF5Hcz",
        "colab_type": "code",
        "outputId": "9037a84f-d9ca-4830-9141-e6af130b4d29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "# explore and plot the learning rates\n",
        "learn.lr_find() \n",
        "learn.recorder.plot(skip_end=15)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/1 00:00<00:00]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='99' class='' max='1248' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      7.93% [99/1248 00:13<02:35 11.0037]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEGCAYAAABPdROvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXhU5d3/8fd3spKQhUAIO2FfRECMICgoLijutrVu1bpSfKxaW21r/VV9ultrrdbWpVStu1blcccdFBUwSNj3PWwJW0IgG8n9+yODxpiNTE5OZvJ5XddcmTnnzJnvzZnwyX2W+5hzDhERkaYK+F2AiIiENwWJiIiEREEiIiIhUZCIiEhIFCQiIhKSaL8LOFydOnVymZmZfpchIhJW5s+fv9M5l+7FusMuSDIzM8nOzva7DBGRsGJmG71at3ZtiYhISBQkIiISEgWJiIiEREEiIiIhUZCIiEhIFCQiIhISBYmIiIREQeKTsoOVzF69k2mfrGP9zv1+lyMi0mRhd0FiOCksKWfR5gIcjkO3fcnbV8pHK/L4eFU++0oPAvC7N5cztm9HLh7Ti9OOyCAuOsrHqkVEDk+bCZIFm/bw5OcbKS6roLi86nGwopJuqe3o2ymRPumJZHZMJCk+muhAgJjoANEBY2dRKVv3lrBlzwG2FpSwv/Qglc5RUemoqIS+6Yl8d1QPuqTEf/VZpQcreHrOJv7+4Wr2Hij/Vi3pSXGcObwrJw/JYFBGEq8v2srzX2zixucWkJYYyw+O7c0V4zJJS4xtyX8iEZEmsXC7Q2JWVpZryhApH63M485Xl9IuJor42CjaxQSIChi5e4rZvPsAlY34Z4iNDpAUF00gYESZETDYWlBCwODEQZ258JielJRXcM87K8ndU8z4AZ24ZnxfEmOrehhmkBAbzaCMJAIB+8a6Kysds9fs5MnPN/D+8jziYwJcmNWTa8b3pWdawmG3V0SkOjOb75zL8mTdbSVI6lN2sJJNuw+wcdd+DpRVUF5RycEKR1lFJWmJsXRPbUe31HZ0ah+L2TcDYOOu/byYvZn/ZueSt68UgCFdk7lt8mAmDGza+Gird+zjkY/X8WrOFiodXHhMT3566kA6tY8Lua0i0jYpSKrxIkiaw8GKSj5enU95hePUIRnf6nE0xbaCYh6euZZn5m4iPiaK6yf258rjMomP0TEUETk8CpJqWmuQeGltfhF/fGsF7y/fQffUdlwzvg9nDu9K56T4ht8sIkIYB4mZpQLTgGGAA65yzn1ebf6lwC8AA/YB1znnFta3zrYYJId8tmYnd89YwcLcAgIGx/XvxNkjunHGkV1pH9dmzpsQkSYI5yD5D/CJc26amcUCCc65vdXmjwOWO+f2mNlk4C7n3Jj61tmWg+SQ1Tv28drCrbyas5VNuw+QmhDDjyb04/KxvUlUoIhILcIySMwsBcgB+rpGfIiZdQCWOOe617ecguRrzjm+3LSHBz9cw0cr8+mYGMvUE/rxg2N70y5Wx1FE5GvhGiQjgUeBZcAIYD5wk3Ou1su4zewWYLBz7ppa5k0BpgD06tXr6I0bPbvRV9iav3EPf3t/FZ+s3kmn9nFMPaEvl4zpRUKseigiEr5BkgXMAY5zzs01s/uBQufcr2tZdiLwT+B459yu+tarHkn95q3fzf0frOLTNbvo1D6Wa8f35bKxvRUoIm2cl0Hi5VhbuUCuc25u8PVLwKiaC5nZcKoOyJ/bUIhIw0b3SeOZa47lpaljGdI1mT++vYLj7/6Ih2etZX9wSBYRkebkWZA457YDm81sUHDSyVTt5vqKmfUCXgEuc86t8qqWtigrM42nrh7Dy9eNY1j3FP709grG//kjHpqpQBGR5uX1WVsjqeptxALrgCuBCwGccw+b2TTgu8Chgx4HG+p6addW03y5aQ/3v7+aWavyMYOUdjGktoshJSGWHqntuH5if4Z2S/a7TBHxSFgeI/GKgiQ0X27aw8wVeewtLmfvgXL2FpezKHcvhcXlXDS6Fz87dSAdNRSLSMTxMkh0BLaNGdWrA6N6dfjGtIID5fztg1U8+flGXl+4lZtOHsBlY3trOHsRaRTd2EpISYjhzrOPYMZN4xnZM5XfvbmciffM5Jm5Gyk7WOl3eSLSyilI5CsDMpJ48qrRPHX1aLqkxHP79CVM/MtMnpu3iYMVChQRqZ2CRL7BzBg/IJ2XrxvHf64aTXpSHLe9spjvPvQZq3bs87s8EWmFFCRSKzPjhIHpTP+fcfz94qPYvKeYsx6YzYMfrqZcvRMRqUYH26VeZsbZI7oxrl9H7nhtKX95dxVvL9lOVu8OlB6sDD4qKCqtoLC4nH0l5ewrOUhmx0TOGdmNM4/sSgfdMlgkoun0Xzksby/exu/fWk5R6UFiowLExQSIjQrQPj6G5PhokuNjSIyL4stNe1mTV0R0oKpnM7hrEruKythZVMbOolKiAsYR3ZIZ1j2FI7unMKBze6Kj1EEW8YquI6lGQRIenHMs21bIazlbeW3hVvL2lZKWGEun9nF0ah9LSXkFy7YWsr+sAoCYKKNnhwR6d0ygd8dEMjsm0LtTIn06JtKjQzuFjEiIFCTVKEjCj3MO5/jW7YcrKx3rd+1nyZYCVmzfx6ZdB9iwaz8bdu7/KmAAogNGn06JXHV8Hy44uodCRaQJFCTVKEgin3OOnUVlX4XKhl37+XTNLnI276VveiI/P20Qpx3RBTNreGUiAihIvkFB0jY553hv2Q7+/M5K1uQVMbxHCkO6JBMbHSAuOkB8TBRj+qYxrl8nogIKGJGaFCTVKEjatoMVlbz8ZS6Pzd7A3uIyyoJnjpWUV1DpICM5jnNHdue8kd0PaxDKnUWlFJdV0DMtwcPqRfyjIKlGQSK1KSmv4MMVebzy5RZmrszjYKUjs2MCJwxM54RB6Rzbt+O3bu61dW8x7yzdzttLtpO9YTeVDsb27cjlY3tz6tAMHYuRiKIgqUZBIg3Zvb+MNxdv46MVeXy+dhfF5RXERgXonBxHRaWjotJRGTwOAzAoI4nTh3UhNjrAs3M3sWVvMV2S4/l+Vg+OH5DOiJ4pGsBSwp6CpBoFiRyOkvIKsjfs4ePV+ewsKiU6YEQFjIAZ3Tu04/QjutA3vf1Xy1dUOj5ckceTn29g9pqdOAdx0QGO6pXKsX07MmFgOiN6pOo4jIQdBUk1ChJpKXsPlDFv/W7mrt/N3PW7WLq1EOegQ0IMEwamc8LAdEb16kDvjgk6g0xaPd2PRMQHqQmxTDqiC5OO6ALAnv1lfLw6n1kr85m1Kp9Xc7YCVXebHN4jhZE9UzlnRDcGZCT5WbZIi1OPRKQJKisdK7bvY2HuXhbl7mXh5gJW7thHRaXjuP4duWJcH04a3Fm7wKTV0K6tahQk0lrtKirl+S828/ScjWwrKKFnWjsmDe3C6D5pHJOZRpoGrxQfKUiqUZBIa3ewopJ3l+3g2bmb+GLDbkqDd5kc0Lk9Zw7vyhXjMklNUKhIywrbIDGzVGAaMAxwwFXOuc+rzR8MPA6MAm53zv2loXUqSCSclB6sYHFuAfM27ObTNTv5dM0uEmKjuHRML64Z35eM5Hi/S5Q2IpyD5D/AJ865aWYWCyQ45/ZWm98Z6A2cB+xRkEikW7G9kIdnruX1RduIMmPi4HSOyUwjKzONI7olE6OLIMUjYRkkZpYC5AB9XQMfYmZ3AUUKEmkrNu06wL9nr+Ojlfls2n0AgPiYACcN7swtkwZ949oWkeYQrkEyEngUWAaMAOYDNznn9tey7F3UEyRmNgWYAtCrV6+jN27c6EnNIn7YUVhC9oY9zFu/i5fm51J6sJIfHNubm04eoLtLSrMJ1yDJAuYAxznn5prZ/UChc+7XtSx7F+qRiJC/r5T73l/F8/M20T4ump9NGsTlY3vrgkcJmZdB4uUO2Vwg1zk3N/j6JaoOqotIHdKT4vjD+Ucy4ycTGNEzlTtfW8r/vr6MysrwOrtS2hbPgsQ5tx3YbGaDgpNOpmo3l4g0YGBGEv+5cjTXHN+HJz7bwM0v5lBeUel3WSK18nqIlBuAZ4JnbK0DrjSzqQDOuYfNrAuQDSQDlWb2E2Coc67Q47pEWr1AwLj9zCGktY/lzzNWUlBczj8vHfWt4fBF/KYLEkXCwHPzNnH79MUM7pLMJWN6cerQDF2DIoclLA+2e0VBIm3VO0u384e3lrNxV9XpwiN6pjJ5WBcuHdOLpPgYn6uT1k5BUo2CRNoy5xyr84p4b9kO3l26nYW5BXRMjOUnpw7komN66oJGqZOCpBoFicjXFuXu5XdvLmfe+t30S0/kl5OHcMqQzjpdWL4lXE//FRGPDe+RygtTjuVfl2fhgGufzOaiR+ewcPPeBt8r0lwUJCJhzsw4dWgG7/xkAr899wjW5hdx7j8+5YbnFrApeDxFxEsKEpEIERMV4LKxmcy8dSI3nNSf95Zt55S/zuLVnC1+lyYRTkEiEmEODa0y69aJHNUrlZ++uJD3l+3wuyyJYAoSkQiVkRzPv684hmHdkvmfZ7/ks7U7/S5JIpSCRCSCtY+L5okrR9M7LYFr/5Otg/DiCQWJSITrkBjLU1ePIa19LD98fB4rt+/zuySJMAoSkTagS0o8z1x9LLFRAS6dNpc1eUV+lyQRREEi0kb06pjAs9ceCzgu+dcc1u/81j3mRJpEQSLShvTv3J5nrz2Wg5VVYaLrTKQ5KEhE2piBGUk8ffUYissruPhfc8jdozCR0ChIRNqgod2SefrqMewrKecH0+aSt6/E75IkjClIRNqoYd1TePzK0ewoLOXyf8+joLjc75IkTClIRNqwo3t34JHLjmZtfhFXP/EFxWUVfpckYUhBItLGTRiYzv0XHcWXm/Zw3TPzKTuoe8PL4VGQiAhnHNmVP5x/JDNX5nPbK4v9LkfCjIJERAC4aHQvbjypPy9/mcv0Bbl+lyNhxNMgMbNUM3vJzFaY2XIzG1tjvpnZA2a2xswWmdkoL+sRkfrdePIAsnp34Nf/t1TXmEijed0juR+Y4ZwbDIwAlteYPxkYEHxMAR7yuB4RqUd0VIC/XTQSM7jx+QWUV+h4iTTMsyAxsxRgAvBvAOdcmXOu5tCj5wJPuipzgFQz6+pVTSLSsB4dEvjjd44kZ/NeHvhgtd/lSBjwskfSB8gHHjezBWY2zcwSayzTHdhc7XVucNo3mNkUM8s2s+z8/HzvKhYRAM4a3o0Lju7Bgx+tYc66XX6XI62cl0ESDYwCHnLOHQXsB37ZlBU55x51zmU557LS09Obs0YRqcNd5xxBZsdEbn4hhz37y/wuR1oxL4MkF8h1zs0Nvn6JqmCpbgvQs9rrHsFpIuKzxLho/n7xUewqKuOW/y7EOed3SdJKeRYkzrntwGYzGxScdDKwrMZirwGXB8/eOhYocM5t86omETk8w7qncNsZg/lgRR6PfbrB73KklYr2eP03AM+YWSywDrjSzKYCOOceBt4CzgDWAAeAKz2uR0QO0xXjMvls7S7+9PZyjsnswPAeqX6XJK2MhVt3NSsry2VnZ/tdhkibsvdAGWc+MJuogPHGjceTHB/jd0lymMxsvnMuy4t168p2EWlQakIsD1w8ki17i7ntlcU6XiLfoCARkUY5uncaP5s0kDcXbeO/2RpCRb6mIBGRRps6oR/j+nXkzteWsja/yO9ypJVQkIhIowUCxn0XjiQ+JsCNzy2g9KDuXyIKEhE5TBnJ8dzzvREs3VrIPTNW+l2OtAIKEhE5bKcMzeDysb2ZNns9M1fm+V2O+ExBIiJN8qszhjAoI4lb/rtI93tv4xQkItIk8TFR3Pv9EezaX8qDH2qU4LZMQSIiTTasewoXHN2DJz7bwMZd+/0uR3yiIBGRkNwyaRAxUQH+9PYKv0sRnyhIRCQknZPjue6Efry9ZDtzde+SNklBIiIhu2Z8X7qmxPO7N5dTWanhU9oaBYmIhKxdbBQ/P30Qi7cU8H85uqVQW6MgEZFmce6I7ozokcKfZ6zkQNlBv8uRFqQgEZFmEQgYvz5rKNsLS3j043V+lyMtSEEiIs0mKzONM4d35eFZa9lWUOx3OdJCFCQi0qx+efpgKh38WeNwtRkKEhFpVj3TErh2fB+mL9jCgk17/C5HWkCjgsTMEs0sEHw+0MzOMTPda1NEanXdif1JT4rjN28s090U24DG9kg+BuLNrDvwLnAZ8ERDbzKzDWa22MxyzOxbN1o3sw5mNt3MFpnZPDMbdjjFi0jr1D4umltPG8SCTXt5beFWv8sRjzU2SMw5dwD4DvBP59wFwBGNfO9E59zIOm46/ysgxzk3HLgcuL+R6xSRVu57o3pwRLdk7n57BcVlugFWJGt0kJjZWOBS4M3gtKhm+PyhwIcAzrkVQKaZZTTDekXEZ4GAccdZQ9laUMK0T3Q6cCRrbJD8BLgNmO6cW2pmfYGPGvE+B7xrZvPNbEot8xdS1cvBzEYDvYEejaxJRFq5MX07MnlYF/45cy07Ckv8Lkc80qggcc7Ncs6d45y7O3jQfadz7sZGvPV459woYDJwvZlNqDH/T0CqmeUANwALgG/1gc1sipllm1l2fn5+Y0oWkVbitslDqKh03POOTgeOVI09a+tZM0s2s0RgCbDMzG5t6H3OuS3Bn3nAdGB0jfmFzrkrnXMjqTpGkg58qw/snHvUOZflnMtKT09vTMki0kr06pjAlcdl8vKXuSzZUuB3OeKBxu7aGuqcKwTOA94G+lB15ladgqcMJx16DkyiKoSqL5NqZrHBl9cAHwc/R0QiyPUn9SctIVanA0eoxgZJTPC6kfOA15xz5VQd/6hPBjDbzBYC84A3nXMzzGyqmU0NLjMEWGJmK6na/XXT4TdBRFq75PgYfjppIPPW7+adpdv9LkeaWXQjl3sE2EDVwfGPzaw3UG/PwTm3DhhRy/SHqz3/HBjY2GJFJHxdmNWTJz/byB/eWsHEwZ2Ji26OEz+lNWjswfYHnHPdnXNnuCobgYke1yYiESQ6KsD/O2sIm3Yf4IlPN/hdjjSjxh5sTzGzvx46c8rM7gUSPa5NRCLM+AHpnDy4M3//cA35+0r9LkeaSWOPkTwG7AO+H3wUAo97VZSIRK7bzxxC6cEK7n1XpwNHisYGST/n3J3OuXXBx/8Cfb0sTEQiU9/09vxwbCYvZG/W6cARorFBUmxmxx96YWbHAbprjYg0yQ0nD6CDTgeOGI0NkqnAP4Kj+W4AHgR+5FlVIhLRUtrF8LPg6cBvL9HpwOGusWdtLXTOjQCGA8Odc0cBJ3lamYhEtIuO6cXgLkn84a3llJRrdOBwdlh3SAwOaXLo+pGfelCPiLQRUcHRgXP3FPPoxxodOJyFcqtda7YqRKRNGte/E2ce2ZUHP1rDhp37/S5HmiiUINERMhEJ2R1nDyU2KsCvX12iA+9hqt4gMbN9ZlZYy2Mf0K2FahSRCJaRHM8tkwbyyeqdvLFom9/lSBPUGyTOuSTnXHItjyTnXGPH6RIRqddlYzM5snsKv3ljGYUl5X6XI4cplF1bIiLNIipg/OH8I9lVVMpfdAOssKMgEZFW4cgeKVw+NpOn5mxk4ea9fpcjh0FBIiKtxs8mDSS9fRy/1RXvYUVBIiKtRlJ8DDeePIDsjXuYtSrf73KkkRQkItKqfD+rJz06tOPed1epVxImFCQi0qrERgf4ySkDWbylgHeW7vC7HGkEBYmItDrnjexG3/RE/vreSioq1Stp7RQkItLqREcFuPmUgazaUcQbi7b6XY40wNMgCQ47v9jMcswsu5b5KWb2upktNLOlZnall/WISPg488iuDO6SxH3vreJgRaXf5Ug9WqJHMtE5N9I5l1XLvOuBZcEh6k8E7jWz2BaoSURauUDA+NmkQWzYdYCXv8z1uxyph9+7thyQZGYGtAd2Awf9LUlEWotThnRmRM9U7ntvNQfK9F9Da+V1kDjgXTObb2ZTapn/IDAE2AosBm5yzn2rD2tmU8ws28yy8/N1brlIW2Fm/L8zh7C9sIRHZumeJa2V10FyvHNuFDAZuN7MJtSYfxqQQ9VIwiOBB80sueZKnHOPOueynHNZ6enpHpcsIq3JMZlpnDm8K498vJZtBcV+lyO18DRInHNbgj/zgOnA6BqLXAm84qqsAdYDg72sSUTCzy9PH0ylgz/P0ICOrZFnQWJmiWaWdOg5MAlYUmOxTcDJwWUygEGA+q8i8g090xK4dnwfpi/YwoJNe/wuR2rwskeSAcw2s4XAPOBN59wMM5tqZlODy/wWGGdmi4EPgF8453Z6WJOIhKnrTuxPelIcv9GAjq2OZzencs6tA0bUMv3has+3UtVTERGpV/u4aG6dNIifv7yI1xZu5dyR3f0uSYL8Pv1XRKTRvnt0D47olszv31zO7v1lfpcjQQoSEQkbUQHj7u8OZ8+BMn7x8iLt4molFCQiElaGdU/h56cN5r1lO3h23ia/yxEUJCIShq4+vg/jB3Tit28sY03ePr/LafMUJCISdgIB494LRpAQG82Nz+VQerDC75LaNAWJiISlzsnx3P3d4SzbVshf3tGFin5SkIhI2Dp1aAaXjunFtNnrWbG90O9y2iwFiYiEtVtPG0RSXDR/fGuF36W0WQoSEQlrqQmx3HDSAGatymf2ag2M4QcFiYiEvcvH9aZHh3b84a3lVOoe7y1OQSIiYS8uOopbTxvEsm2FTF+wxe9y2hwFiYhEhLOHd+PI7inc++5KSsp1OnBLUpCISEQIBIxfnTGErQUlPPbper/LaVMUJCISMcb268jJgzvz0Edr2aNBHVuMgkREIsovJg+mqOwgD81a63cpbYaCREQiysCMJM4/qjv/+WwD2wtK/C6nTVCQiEjEufmUgVQ6x/0frPa7lDZBQSIiEadnWgKXjO7Fi9mbWb9zv9/lRDwFiYhEpB+fNIDYqAB/fW+V36VEPAWJiESk9KQ4rjo+k9cXbmXp1gK/y4longaJmW0ws8VmlmNm2bXMvzU4L8fMlphZhZmleVmTiLQdUyb0I6VdjIaZ91hL9EgmOudGOueyas5wzt0TnDcSuA2Y5Zzb3QI1iUgbkNIuhqkn9OOjlfnMXJnndzkRqzXt2roYeM7vIkQkslx1fCYDOrfntlcWU1hS7nc5EcnrIHHAu2Y238ym1LWQmSUApwMv1zF/ipllm1l2fn6+R6WKSCSKi47ingtGsKOwhD++tdzvciKS10FyvHNuFDAZuN7MJtSx3NnAp3Xt1nLOPeqcy3LOZaWnp3tVq4hEqJE9U7l2fF+em7dZ9yzxgKdB4pzbEvyZB0wHRtex6EVot5aIeOjmUwfSNz2RX7y8iKLSg36XE1E8CxIzSzSzpEPPgUnAklqWSwFOAF71qhYRkfiYKO753nC2FhTzp7e1i6s5edkjyQBmm9lCYB7wpnNuhplNNbOp1ZY7H3jXOafLT0XEU0f3TuPq4/rw9JxNzFm3y+9yIoY5F163pczKynLZ2d+6JEVEpFGKyyqY9LdZxEVH8daN44mNbk0nr3rHzObXdhlGc2gb/4IiIkHtYqP4zTnDWJNXxL8+Wed3ORFBQSIibc7EwZ2ZPKwLD3ywms27D/hdTthTkIhIm3TH2UOJDhh3vLqEcNvF39ooSESkTeqa0o6bTx3IRyvzeWfpdr/LCWsKEhFps64Yl8mQrsn87+vLdG1JCBQkItJmRUcF+P35w9heWKIRgkOgIBGRNm1Urw78cGwmT3y2gXnrNfh4UyhIRKTN+/npg+iZ1o6fv7SQ4rIKv8sJOwoSEWnzEmKjufs7w9mw6wB/fU+7uA6XgkREBBjXvxOXjOnFv2ev58tNe/wuJ6woSEREgm6bPJguyfHc+t+FlJRrF1djKUhERIKS4mP443eHszZ/P3fPWOF3OWFDQSIiUs0JA9O5Ylwmj3+6gVdztvhdTlhQkIiI1PCrM4ZwTGYHfvnyYlZsL/S7nFZPQSIiUkNsdIB/XDKK9vHR/Oip+RQUl/tdUqumIBERqUXn5HgeunQUW/YU89MXcqis1MCOdVGQiIjUISszjTvOHsoHK/J48KM1fpfTailIRETqcdmxvTlvZDf+9v4qPlu70+9yWiUFiYhIPcyM359/JJmdErnp+Rzy95X6XVKr42mQmNkGM1tsZjlmVuuN1s3sxOD8pWY2y8t6RESaIjEumn9cMorC4nJufiGHCh0v+YaW6JFMdM6NrO2m82aWCvwTOMc5dwRwQQvUIyJy2IZ0Teauc45g9pqd/FPHS77B711blwCvOOc2ATjn8nyuR0SkThcd05NzR3bjvvdXMWfdLr/LaTW8DhIHvGtm881sSi3zBwIdzGxmcJnLPa5HRKTJvjpe0jGRm1/I0fUlQV4HyfHOuVHAZOB6M5tQY340cDRwJnAa8GszG1hzJWY2xcyyzSw7Pz/f45JFROrWPi6a+y4cSd6+Uu56banf5bQKngaJc25L8GceMB0YXWORXOAd59x+59xO4GNgRC3redQ5l+Wcy0pPT/eyZBGRBo3omcqPJ/Zn+oItvLV4m9/l+M6zIDGzRDNLOvQcmAQsqbHYq8DxZhZtZgnAGGC5VzWJiDSXH5/Un+E9Urh9+mLy9pX4XY6vvOyRZACzzWwhMA940zk3w8ymmtlUAOfccmAGsCi4zDTnXM2wERFpdWKiAvz1+yM4UFbBL19ejHNt95RgC7fGZ2VluezsWi9JERFpcY/NXs9v3ljGH79zJBeP7uV3OXUys/m1XYbRHPw+/VdEJKxdMS6T4/p35M7XlvLpmrY5hIqCREQkBIGA8eDFo+jTMZFrn8xm/sa2d793BYmISIg6JMby1NWj6ZwUx5WPz2Pp1gK/S2pRChIRkWbQOTmep68ZQ2JcNJf/ex5r8or8LqnFKEhERJpJjw4JPHPNGMzg0mlzWL1jn98ltQgFiYhIM+qb3p6nrxlDRSVc8Mjn5Gze63dJnlOQiIg0s8Fdknn5urEkxUdzyb/mMHt1aGdzVVQ6Hpq5liVbWuexFwWJiIgHendM5KWp4+jZIYGrnviCNxc1bSiVrXuLuXTaHO6esYLXF21t5iqbh4JERMQjGcnxvPijsQzrnsz1z37JWX//hCc/30DBgcaNGvzW4m1Mvv8TFuUWcM/3hvPL04k99gAAAAi9SURBVAd7W3AT6cp2ERGPlZRX8MIXm3nhi80s21ZIbHSAU4dmkNW7A0O7JjO0WzJJ8TGUlFewJq+IFdv3MWtVPq8v3MqInqncf+FIMjslhlSDl1e2K0hERFrQki0FvJi9mbcWb2dn0df3f++cFMeu/WVf3cY3LjrAteP7ctMpA4iJCn3nkZdBEu3FSkVEpHbDuqcwrHsKvzl3GHmFJSzdWsiybYWszS+ie2o7BndJZlCXJDI7JhDdDAHSEhQkIiI+6ZwcT+fkeCYO7ux3KSEJj7gTEZFWS0EiIiIhUZCIiEhIFCQiIhISBYmIiIREQSIiIiFRkIiISEgUJCIiEpKwGyLFzPKBjTUmpwA1x1euOa2+14eeV5/WCWjq2M+11XM4yxxuexp6HkpbGqq1oWUiads0pi01p3m5bfQ9q396uH7P6poX6rZJdM6lN1h5Uzjnwv4BPNrQtPpeH3peY1p2c9ZzOMscbnsaeh5KW0JtTyRtm8a0pSW3jb5nkfk9a43bpqFHpOzaer0R0+p7/XodyzRnPYezzOG2pzHPQxFKeyJp2zSmLTWneblt9D2rf3q4fs/qmufntqlX2O3aailmlu08GimzpUVSWyCy2qO2tF6R1B6v2xIpPRIvPOp3Ac0oktoCkdUetaX1iqT2eNoW9UhERCQk6pGIiEhIFCQiIhKSiA8SM3vMzPLMbEkT3nu0mS02szVm9oCZWbV5N5jZCjNbamZ/bt6q662p2dtjZneZ2RYzywk+zmj+ymutx5NtE5z/MzNzZtap+SpusCYvts1vzWxRcLu8a2bdmr/yWuvxoi33BH9nFpnZdDNLbf7K66zJi/ZcEPz9rzQzzw/Kh9KGOtb3QzNbHXz8sNr0en+3auXlucWt4QFMAEYBS5rw3nnAsYABbwOTg9MnAu8DccHXncO8PXcBt0TCtgnO6wm8Q9WFq53CuT1AcrVlbgQeDuO2TAKig8/vBu4O820zBBgEzASyWmsbgvVl1piWBqwL/uwQfN6hvvbW94j4Holz7mNgd/VpZtbPzGaY2Xwz+8TMBtd8n5l1peqXeI6r+td9EjgvOPs64E/OudLgZ+R524qvedQeX3jYlvuAnwMteiaJF+1xzhVWWzSRFmqTR2151zl3MLjoHKCHt634mkftWe6cW9kS9Qc/r0ltqMNpwHvOud3OuT3Ae8DpTf1/IuKDpA6PAjc4544GbgH+Wcsy3YHcaq9zg9MABgLjzWyumc0ys2M8rbZhobYH4MfBXQ6PmVkH70ptUEhtMbNzgS3OuYVeF9pIIW8bM/u9mW0GLgXu8LDWhjTH9+yQq6j6a9dPzdkevzSmDbXpDmyu9vpQu5rU3uhGfmjEMLP2wDjgv9V2/cUd5mqiqeoSHgscA7xoZn2DCd6imqk9DwG/peqv3d8C91L1i96iQm2LmSUAv6JqF4rvmmnb4Jy7HbjdzG4Dfgzc2WxFNlJztSW4rtuBg8AzzVNdk2potvb4pb42mNmVwE3Baf2Bt8ysDFjvnDu/uWtpc0FCVS9sr3NuZPWJZhYFzA++fI2q/1yrd717AFuCz3OBV4LBMc/MKqkaFC3fy8LrEHJ7nHM7qr3vX8AbXhZcj1Db0g/oAywM/mL1AL40s9HOue0e116b5viuVfcM8BY+BAnN1BYzuwI4CzjZjz+8qmnubeOHWtsA4Jx7HHgcwMxmAlc45zZUW2QLcGK11z2oOpayhaa01+sDRK3hAWRS7QAV8BlwQfC5ASPqeF/Ng05nBKdPBX4TfD6Qqi6ihXF7ulZb5mbg+XBtS41lNtCCB9s92jYDqi1zA/BSGLfldGAZkN6S28Tr7xotdLC9qW2g7oPt66k60N4h+DytMe2ttS4/NmgLf3meA7YB5VT1JK6m6q/WGcDC4Bf7jjremwUsAdYCD/L1SACxwNPBeV8CJ4V5e54CFgOLqPorrGu4tqXGMhto2bO2vNg2LwenL6JqAL7uYdyWNVT90ZUTfLTIGWgetuf84LpKgR3AO62xDdQSJMHpVwW3yRrgyobaW99DQ6SIiEhI2upZWyIi0kwUJCIiEhIFiYiIhERBIiIiIVGQiIhISBQkEhHMrKiFP++zZlrPiWZWYFWj+64ws7804j3nmdnQ5vh8keagIBGphZnVO+qDc25cM37cJ67q6uSjgLPM7LgGlj8PUJBIq6EgkYhV18ioZnZ2cMDNBWb2vpllBKffZWZPmdmnwFPB14+Z2UwzW2dmN1Zbd1Hw54nB+S8FexTPHLp/g5mdEZw2P3hfh3qHnnHOFVN1od6hASivNbMvzGyhmb1sZglmNg44B7gn2IvpF8IIsCLNQkEikayukVFnA8c6544CnqdqyPlDhgKnOOcuDr4eTNWQ26OBO80sppbPOQr4SfC9fYHjzCweeISqezkcDaQ3VGxw1OUBwMfBSa84545xzo0AlgNXO+c+o2r0gVudcyOdc2vraadIi2iLgzZKG9DA6K49gBeC916IpWqcoUNeC/YMDnnTVd13ptTM8oAMvjnMNsA851xu8HNzqBoPqQhY55w7tO7ngCl1lDvezBZSFSJ/c18PMDnMzH4HpALtqbpZ1+G0U6RFKEgkUtU5Mirwd+CvzrnXzOxEqu4Qecj+GsuWVnteQe2/M41Zpj6fOOfOMrM+wBwze9E5lwM8AZznnFsYHDX3xFreW187RVqEdm1JRHJVdxZcb2YXAFiVEcHZKXw9NPYPa3t/M1gJ9DWzzODrCxt6Q7D38ifgF8FJScC24O60S6stui84r6F2irQIBYlEigQzy632+ClV//leHdxttBQ4N7jsXVTtCpoP7PSimODusf8BZgQ/Zx9Q0Ii3PgxMCAbQr4G5wKfAimrLPA/cGjxZoB91t1OkRWj0XxGPmFl751xR8CyufwCrnXP3+V2XSHNTj0TEO9cGD74vpWp32iM+1yPiCfVIREQkJOqRiIhISBQkIiISEgWJiIiEREEiIiIhUZCIiEhI/j+9dhFFgGb4JAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AQz_0ip5KOu",
        "colab_type": "code",
        "outputId": "6a9dfa8c-3ccc-4b2f-d901-e6aed9345a57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "# train the language model\n",
        "# we can see from the previous graph that 1e-1 is a good point,\n",
        "# the loss is still decreasing, and before overfitting\n",
        "learn.fit_one_cycle(1, 1e-1, moms=(0.8,0.7))\n",
        "\n",
        "# and save our good work\n",
        "learn.save(base_dir + 'fit_head')\n",
        "learn.save_encoder(base_dir + 'fit_head_enc')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.496226</td>\n",
              "      <td>4.028318</td>\n",
              "      <td>0.329913</td>\n",
              "      <td>02:54</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBHM7QOTatMC",
        "colab_type": "code",
        "outputId": "8087c2db-a759-49b3-e962-a24a18a7a97a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "# we have reached an accuracy of ~33%, but let's improve it:\n",
        "\n",
        "# fine tune\n",
        "learn.load(base_dir + 'fit_head');\n",
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(8, 1e-2, moms=(0.8,0.7))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.289804</td>\n",
              "      <td>3.708222</td>\n",
              "      <td>0.361674</td>\n",
              "      <td>03:22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.407731</td>\n",
              "      <td>3.722636</td>\n",
              "      <td>0.356064</td>\n",
              "      <td>03:22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3.243773</td>\n",
              "      <td>3.600091</td>\n",
              "      <td>0.375017</td>\n",
              "      <td>03:22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.127868</td>\n",
              "      <td>3.524820</td>\n",
              "      <td>0.385568</td>\n",
              "      <td>03:22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.918436</td>\n",
              "      <td>3.431346</td>\n",
              "      <td>0.395880</td>\n",
              "      <td>03:22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.841487</td>\n",
              "      <td>3.377506</td>\n",
              "      <td>0.405866</td>\n",
              "      <td>03:22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2.587384</td>\n",
              "      <td>3.353596</td>\n",
              "      <td>0.412259</td>\n",
              "      <td>03:23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2.412118</td>\n",
              "      <td>3.372801</td>\n",
              "      <td>0.411203</td>\n",
              "      <td>03:22</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfLKWcwxxL2-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we have reached 41%, and the loss just starts to raise, let's stop here\n",
        "# save the model and the encoder\n",
        "learn.save(base_dir + 'fine_tuned')\n",
        "learn.save_encoder(base_dir + 'fine_tuned_enc')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bP3MQPd24Gz",
        "colab_type": "code",
        "outputId": "06e5d965-eb4c-4ced-8478-df9587ba7f07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# let's check the language model - continue the sentence with 10 random words\n",
        "learn.load(base_dir + 'fine_tuned');\n",
        "learn.predict(\"This is a survey\", n_words=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This is a survey , which provides a tool to an INTELLIGENT model'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llVyjxa4bZ_o",
        "colab_type": "text"
      },
      "source": [
        "## Classifier\n",
        "\n",
        "As described in the introduction, with the learning model we can start build the classifier itself.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dv-MVsXqj7Fl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = Path(OUTPUT_BASE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WrOP1PpbyyZ",
        "colab_type": "code",
        "outputId": "613b8f81-5165-4d46-8d79-08b4ebf4679a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "# build a classifier with:\n",
        "# - the .tex files\n",
        "# - same vocabulary used in language model\n",
        "# - 80% of the data used for learning, 20% of the data used for validation\n",
        "# - use labels [\"peer_reviewed\", \"not_peer_reviewed\"] according to folder names\n",
        "data_clas = TextList.from_folder(path, extensions={'.tex'}, vocab=data_lm.vocab).split_by_rand_pct(0.2) .label_from_folder(classes=[\"peer_reviewed\", \"not_peer_reviewed\"]) .databunch(bs = batch_size)\n",
        " \n",
        "data_clas.save(base_dir + 'data_clas.pkl')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6a_w4E-b1d_",
        "colab_type": "code",
        "outputId": "7b2d36c8-ec32-402b-ec71-e261b540cd81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "data_clas = load_data(path, base_dir + 'data_clas.pkl', bs=batch_size)\n",
        "data_clas.show_batch()\n",
        " \n",
        "# We can now create a model to classify those reviews and load the encoder we saved before.\n",
        "learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5)\n",
        "learn.load_encoder(base_dir + 'fine_tuned_enc')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>xxbos % version : % xxunk , % dalal27 % xxunk \\n  % \\ def \\ year{2018 } \\ relax \\n  % \\ documentclass[twoside,11pt]{article } \\n  \\ xxunk , xxunk } \\n  % \\ usepackage{jair , xxunk } \\n  % \\ documentclass[letterpaper]{article } % xxup do xxup not xxup change xxup this \\n  % \\ xxunk } % xxmaj required \\n  % joe32</td>\n",
              "      <td>not_peer_reviewed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos \\ typeout { } \\n  \\ xxunk ghosts of forgotten things : a study on size after forgetting } \\n  \\ typeout { } \\n \\n  \\ documentclass[12pt]{article } \\n \\n  % xxunk } \\n  xxrep 26 % xxmaj miscellaneous \\n \\n  \\ let \\ xxunk \\ relax \\n \\n  \\ makeatletter \\n  \\ def \\n  xxunk { \\n</td>\n",
              "      <td>not_peer_reviewed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos \\ documentclass[twoside,11pt]{article } \\n  \\ usepackage{jair , xxunk , xxunk } \\n \\n  \\ xxunk / 20 } { ? } \\n  \\ xxunk xxmaj linear xxmaj constraints into xxup sat } \\n  { xxmaj ab { \\ ' \\ xxunk , xxmaj mayer - xxmaj eichberger \\ &amp; xxmaj xxunk } \\n  \\ xxunk } \\n \\n  \\ usepackage{etex } \\n</td>\n",
              "      <td>not_peer_reviewed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos % \\n  % \\n  \\ xxunk = acmsmall , screen = xxunk } \\n  % \\n \\n  % \\n  % \\n  % \\n  % \\n  % \\n  % \\n  % \\n  % \\n \\n \\n  ewif \\ ifsubmission \\n  \\ xxunk \\n \\n  % \\n  % \\n  % \\n  % \\n</td>\n",
              "      <td>not_peer_reviewed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos \\ documentclass[11pt]{article } \\n \\n  \\ usepackage{fullpage } \\n  \\ usepackage{url } \\n  \\ usepackage{microtype } \\n \\n  \\ usepackage[utf8]{inputenc } \\n  \\ usepackage{amsmath } \\n  \\ usepackage{graphicx } \\n  \\ usepackage{upgreek } \\n  \\ usepackage{amsfonts } \\n  \\ usepackage{amssymb } \\n  \\ usepackage{amsthm } \\n  \\ usepackage[mathscr]{euscript } \\n  \\ usepackage{mathtools } \\n  \\ usepackage{multirow</td>\n",
              "      <td>not_peer_reviewed</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (316 items)\n",
              "x: TextList\n",
              "xxbos \\ documentclass[10pt , twocolumn , letterpaper]{article } \n",
              " \n",
              "  \\ usepackage{cvpr } \n",
              "  \\ usepackage{times } \n",
              "  \\ usepackage{epsfig } \n",
              "  \\ usepackage{graphicx } \n",
              "  \\ usepackage{amsmath } \n",
              "  \\ usepackage{amssymb } \n",
              "  \\ usepackage{multirow } \n",
              "  \\ usepackage{float } \n",
              "  % \\ usepackage{subfigure } \n",
              "  \\ usepackage{color } \n",
              "  \\ usepackage{array } \n",
              "  \\ usepackage{mathrsfs } \n",
              "  \\ usepackage{tabularx } \n",
              "  \\ usepackage{bm } \n",
              "  % \\ xxunk } \n",
              " \n",
              "  \\ xxunk = true , bookmarks = false]{hyperref } \n",
              " \n",
              "  \\ cvprfinalcopy % * * * xxmaj uncomment this line for the final submission \n",
              " \n",
              " \n",
              "  \\ def \\ httilde { \\ mbox { \\ tt \\ raisebox{-.5ex } { \\ symbol{126 xxrep 4 } \n",
              " \n",
              "  \\ setcounter{page}{1 } \n",
              "  \\ begin{document } \n",
              " \t \n",
              " \t % \t  \\ title { xxmaj deep xxmaj sequential xxmaj visual xxmaj understanding through xxmaj semi - xxmaj coupled xxmaj structure } \n",
              " \t  \\ xxunk xxmaj sequential xxmaj understanding through the xxmaj awareness of xxmaj spatial and xxmaj temporal xxmaj concepts } \n",
              " \t  \\ xxunk xxmaj xxunk , xxmaj xxunk xxmaj zha , xxmaj xxunk xxmaj cao , xxmaj xxunk xxmaj tang , xxmaj xxunk xxmaj yu , xxmaj xxunk xxmaj lu * \\ \\ \n",
              " \t\t xxmaj shanghai xxmaj jiao xxmaj tong xxmaj university \\ \\ \n",
              " \t\t { \\ tt \\ small \\ { xxunk , xxmaj kevin \\ _ zha , xxunk \\ _ xxunk , xxunk , xxunk , xxunk \\ } xxunk } } \n",
              " \t \n",
              " \t \n",
              " \t  \\ maketitle \n",
              " \t  \\ renewcommand { \\ thefootnote } { \\ fnsymbol{footnote } } \n",
              " \t \n",
              " \t  \\ begin{abstract } \n",
              " \t\t xxmaj understanding sequential information is a fundamental \n",
              " \t\t task for artificial intelligence . xxmaj current neural \n",
              " \t\t networks attempt to learn spatial and temporal information as a whole , limited their abilities to represent large scale spatial representations over long - range sequences . xxmaj here , we introduce a new modeling strategy called xxmaj semi - xxmaj coupled xxmaj structure ( xxup scs ) , which \t consists of deep neural networks that decouple the complex \n",
              " \t\t spatial and temporal concepts learning . xxmaj semi - xxmaj coupled xxmaj structure can learn to implicitly separate input information into independent parts and process \n",
              " \t\t these parts respectively . xxmaj experiments demonstrate that a xxmaj semi - xxmaj coupled xxmaj structure can successfully annotate the outline of an object in images sequentially and perform video action recognition . xxmaj for sequence - to - sequence problems , a xxmaj semi - xxmaj coupled xxmaj structure can predict future meteorological radar echo images based on observed images . xxmaj taken together , our results demonstrate that a xxmaj semi - xxmaj coupled xxmaj structure has the capacity to improve the performance of xxup lstm - like models on large scale sequential tasks . \n",
              " \t  \\ end{abstract } \n",
              " \t \n",
              " \t xxmaj complex sequential tasks involve extremely high - dimensional spatial signal over long timescales . xxmaj neural networks have made breakthroughs in sequential learning~ \\ xxunk , xxunk } , visual understanding~ \\ cite{krizhevsky2012imagenet , xxunk , xxunk } , and robotic tasks~ \\ cite{levine2016end , schulman2015trust } . \n",
              " \t xxmaj conventional neural networks treat spatial and temporal information as a whole , processing these parts together . xxmaj this limits their ability to solve complex sequential tasks involving high - dimensional spatial and temporal components~ \\ cite{feichtenhofer2018slowfast , xxunk } . a natural idea to address this limitation is to learn the two different concepts relatively independently . \n",
              " \t \n",
              " \t xxmaj here , we introduce a structure that decouples spatial and temporal information , implicitly learning respective spatial and temporal concepts through a deep comprehensive model . xxmaj we find that such concept decomposition significantly simplifies the learning and understanding process of complex sequences . \n",
              " \t xxmaj due to the differentiable property of this structure , which we call xxmaj semi xxmaj coupled xxmaj structure ( xxup scs ) , we can train it end to end with gradient descent , allowing it to effectively learn to decouple and integrate information in a goal - directed manner . \n",
              " \t \n",
              " \t  \\ begin{figure * } \n",
              " \t\t  \\ begin{center } \n",
              " \t\t\t  \\ includegraphics[width= \\ xxunk } \n",
              " \t\t  \\ end{center } \n",
              " \t\t  \\ caption { \\ textbf{the whole pipeline of our xxmaj semi - xxmaj coupled xxmaj structure } . \\ textbf{a } , xxmaj with input $ \\ mathbf{x}$ , $ \\ mathcal{g}$ decouples the spatial - temporal information by $ h_t$ which focuses on temporal features , $ h_s$ that mainly extracts spatial features , and $ \\ mathcal{f}$ integrates them to form the complete temporal - spatial semi - coupled system . \\ textbf{b } , xxmaj to keep the semi - coupled xxunk in a deep structure , we design the xxmaj spatial - xxmaj temporal xxmaj switch xxmaj gradient xxmaj descent ( xxup stsgd ) method ( see xxmaj sec.~ \\ ref{sec : xxup stsgd } ) that stops the gradient back propagating through the dashed lines in a certain probability $ p$ to decouple the training processes of $ h_s$ and $ h_t$. $ \\ mathcal{t}^1 $ and $ \\ mathcal{t}^2 $ are utilized to make $ h_s ( { \\ xxunk and $ h_t ( \\ cdot)$ further focus on their own roles and monitor the training schedule of $ h_s$ to adjust $ q$ in xxmaj advanced xxup stsgd ( xxup astsgd ) . \\ textbf{c } , xxmaj except the main training loss ( $ xxmaj xxunk ) of xxmaj semi - xxmaj coupled xxmaj structure based on main goal $ g$ , there are another two losses $ xxmaj xxunk , $ xxmaj xxunk based on sub - goals $ r_s$ , $ r_t$ for $ \\ mathcal{t}^1 $ , and $ \\ mathcal{t}^2 $ to guide $ h_s$ and $ h_t$ to focus on spatial and temporal features respectively . } \n",
              " \t\t  \\ label{fig : pipeline } \n",
              " \t  \\ end{figure * } \n",
              " \t \n",
              " \t  \\ xxunk of xxmaj spatial and xxmaj temporal xxmaj concept } \\ label{sec : aware } \n",
              " \t xxmaj in the brain , there are two different pathways that feed temporal information and contextual representations respectively into the xxunk \\ xxunk } . xxmaj this implies that spatial and temporal concepts are learnt by different cognitive mechanisms and , moreover , that they should be synchronized in order to effectively process sequential information . xxmaj taking inspiration from this mechanism in the brain , the deep neural model that is implicitly aware of the two concepts can be formulated as : \n",
              " \t  \\ begin{align } \n",
              " \t  \\ xxunk ( \\ xxunk \\ psi_s ) , h_t ( \\ xxunk \\ psi_t ) ] \\ label{eq : split } \n",
              " \t  \\ end{align } \n",
              " \t where $ \\ mathbf{x}$ is the input , and $ \\ xxunk and $ \\ xxunk are the parameters to optimize . $ h_s$ aims at extracting spatial information , while $ h_t$ is designed to handle temporal learning . xxmaj these two kinds of information are fed into $ \\ mathcal{f}$ which is designed to output the final processing results , just like the hippocampus . \n",
              " \t \n",
              " \t  \\ begin{figure * } \n",
              " \t\t  \\ begin{center } \n",
              " \t\t\t  \\ includegraphics[width= \\ xxunk } \n",
              " \t\t  \\ end{center } \n",
              " \t\t  \\ caption { \\ xxunk experiments for semi - coupling xxmaj structure } . \\ textbf{a } , xxmaj the toy examples designed to demonstrate the xxup scs scheme can successfully decouple the temporal - spatial features . xxmaj the contents of input sequences are moving geometries . xxmaj we let the model to distinguish the shapes ( left two sequences ) and the moving directions ( right two sequences ) . \\ textbf{b } , xxmaj the feature maps from $ h_s$ , $ h_t$ and $ \\ mathcal{f}$ in the top layer of the model on the tasks described in \\ textbf{a } . xxmaj when distinguish the geometry 's shape ( left three columns ) , we can see that $ h_s$ and $ \\ mathcal{f}$ only contain spatial information , and temporal features in $ h_t$ do not xxunk into $ h_s$ in high layers due to the filter function of $ \\ mathcal{f}$ in low layers . xxmaj while for the task to distinguish the moving directions , we can see that the temporal information is integrated into $ \\ mathcal{f}$ and the spatial features in $ h_s$ are weakened . \\ textbf{c } , xxmaj feature maps of $ h_s$ and $ h_t$ on auto driving tasks . xxmaj the highlighting parts in the feature maps of $ h_t$ describe more information about the scene changing , while the highlighting parts in $ h_s$ focus on the outline of the objects and roads . } \n",
              " \t\t  \\ label{fig : toyexample } \n",
              " \t  \\ end{figure * } \n",
              " \t \n",
              " \t \n",
              " \t xxmaj we further advance our model by considering the fact that spatial and temporal information are deeply coupled with each other , when processed by a brain~ \\ xxunk } . xxmaj therefore , the model can naturally be extended as a deep nested structure to model such mutual - coupling . xxmaj we define the $ i^{th}$ coupling unit as : \n",
              " \t  \\ begin{align } \n",
              " \t  \\ xxunk ( \\ mathbf{x}_i ) = \\ xxunk ( \\ xxunk \\ xxunk ) , h_t ( \\ xxunk \\ xxunk ) ] \\ label{eq : g } \n",
              " \t  \\ end{align } \n",
              " \t thus , the deep spatial - temporal xxmaj semi - xxmaj coupled xxmaj structure can be expressed as : \n",
              " \t  \\ begin{align } \n",
              " \t  \\ mathcal{t } [ \\ mathbf{x } ; \\ xxmaj psi_s , \\ xxmaj psi_t ] = \\ mathcal{g}_1 \\ circ \\ mathcal{g}_2 \\ circ ... \\ circ \\ xxunk ( \\ mathbf{x } ) \\ label{eq : xxmaj gs } \n",
              " \t  \\ end{align } \n",
              " \t where $ n$ is the depth of the deep nested model , and $ \\ xxmaj psi_s = \\ { \\ xxunk , ... , \\ xxunk \\ } $ and $ \\ xxmaj psi_t = \\ { \\ xxunk , ... , \\ xxunk \\ } $ are the parameter sets . \n",
              " \t \n",
              " \t xxmaj in this structure , spatial and temporal information are intertwined deeply and collaboratively , meanwhile , $ h_s ( \\ cdot)$ and $ h_t ( \\ cdot)$ are responsible for spatial and temporal concept processing respectively . xxmaj to this end , we propose two design paradigms ( see xxmaj fig.~ \\ ref{fig : pipeline } ) . \n",
              " \t \n",
              " \t \n",
              " \t  \\ begin{itemize } \n",
              " \t\t  \\ item \\ xxunk xxmaj xxunk $ h_s ( \\ cdot)$ and $ h_t ( \\ cdot)$ work as their roles by their different structural designs . xxmaj at a certain time stamp of the sequence , the structure of $ h_t ( \\ cdot)$ should have access to the temporal information of other stamps in the sequence like the xxmaj recurrent xxmaj neural xxmaj network ( xxup rnn ) . xxmaj while for $ h_s ( \\ cdot)$ , it has no direct connection to the samples of other time stamps , so it can focus on the spatial information , which normally can be a xxup cnn structure . \n",
              " \t\t \n",
              " \t\t  \\ item \\ textbf{task xxmaj xxunk xxmaj because of the deep nested structure , $ h_s ( \\ cdot)$ and $ h_t ( \\ cdot)$ will disturb each other . xxmaj to make $ h_s ( \\ cdot)$ and $ h_t ( \\ cdot)$ further focus on their roles , besides the main goal : $ g= \\ mathcal{t } [ \\ mathbf{x } ; \\ xxmaj psi_s , \\ xxmaj psi_t]$ , we assign two extra sub - goals : $ r_s = \\ mathcal{t}^1 [ \\ mathbf{x } ; \\ xxmaj psi_s , \\ xxmaj psi_t]$ and $ r_t = \\ mathcal{t}^2 [ \\ mathbf{x } ; \\ xxmaj psi_s , \\ xxmaj psi_t]$ , where $ \\ mathcal{t}^1 $ and $ \\ mathcal{t}^2 $ share the same model components and parameters with $ \\ mathcal{t}$. xxmaj we also call $ r_s$ and $ r_t$ as the spatial and temporal indicating goals which can reflect the qualities of spatial and temporal features . xxmaj the key design is to make both two indicating goals only impact on their own parameters : $ \\ xxmaj xxunk or $ \\ xxmaj xxunk xxmaj that is , in $ \\ mathcal{t}^1 $ , $ { \\ partial r_s } / { \\ partial \\ xxmaj psi_t } = 0 $ and in $ \\ mathcal{t}^2 $ , $ { \\ partial r_t } / { \\ partial \\ xxmaj psi_s } = 0$. xxmaj the specific definition of the sub - goals depends on different tasks . xxmaj taking action recognition as an example , $ r_s$ can be human poses in a single frame that is unrelated to temporal information but useful for action understanding , and $ r_t$ can be the estimates of optical flow . \n",
              " \t  \\ end{itemize } \n",
              " \t xxmaj this new modeling strategy is called xxmaj semi - xxmaj coupled xxmaj structure ( xxup scs ) . xxmaj it is a general framework that is easy to be revised to fit various applications . xxmaj if the temporal indicating label of a specific application is difficult to provide , we find that only $ r_s$ is enough to encourage $ h_s ( \\ cdot)$ to focus on spatial learning , and $ h_t ( \\ cdot)$ can naturally take the responsibility of the remain ( temporal ) information . \n",
              " \t \n",
              " \t  \\ paragraph{discussion } xxmaj the proposed xxup scs makes each component be responsible for a specific sub - concept ( spatial or temporal ) . xxmaj this strategy widely exists in the brain using several different xxunk regions to complete a single complex task~ \\ xxunk , xxunk } . xxmaj during this process , our method learns to separate temporal and spatial information , even though we do not define them separately . xxmaj there are previous works that also try to separate the temporal and spatial information , but they adopt the hand - craft spatial and temporal definitions , like xxmaj two - xxmaj stream model~ \\ cite{simonyan2014two } which uses optical flow~ \\ xxunk } to define temporal information and slowfast xxmaj networks~ \\ cite{feichtenhofer2018slowfast } that uses xxunk spatial and temporal sampling density to distinguish and define them . xxmaj fig.~ \\ ref{fig : toyexample } illustrates that xxup scs can successfully decouple the temporal and spatial information in visual sequences . xxmaj in a toy experiment , the visual sequences show different geometries moving in different directions ( see xxmaj fig.~ \\ ref{fig : toyexample } \\ textbf{a } for details ) and we note that our method outperforms xxup lstm~ \\ cite{hochreiter1997long } on recognizing ` ` xxmaj which direction is the geometry going ? \" when it encounters a specific geometry it never saw and ` ` what is the geometry ? \" when the motion is xxunk . xxmaj fig.~ \\ ref{fig : toyexample } \\ textbf{b } shows the feature maps of $ h_t ( \\ mathbf{x})$ and $ h_s ( \\ mathbf{x})$ , and we can primarily recognize that $ h_t ( \\ mathbf{x})$ represents temporal - related features and $ h_s ( \\ mathbf{x})$ is for the spatial one from the viewpoint of human vision . xxmaj interestingly , our model can quantitatively indicate how important the temporal information is toward the final goal by comparing the indicating goals $ r_s$ and $ r_t$ , thanks to the awareness of the temporal and spatial concepts . xxmaj we believe this quantitative indicator will largely benefit the sequential analysis . \n",
              " \t \n",
              " \t  \\ section{performance xxmaj profiling on xxmaj academic and xxmaj reality xxmaj datasets } \n",
              " \t  \\ xxunk action recognition experiments } \n",
              " \t xxmaj to investigate the capacity of the xxmaj semi - xxmaj coupled xxmaj structure , we conduct the first experiment on video action recognition task . xxmaj we choose xxup xxunk \\ xxunk } , xxup xxunk \\ xxunk } and xxmaj xxunk \\ cite{carreira2017quo } datasets which consist of short videos describing human actions collected from website . xxmaj correct classification is xxunk from the comprehensive abilities of extracting temporal and spatial information : for example , distinguishing ` ` triple jump \" and ` ` long jump \" requires a structure to precisely understand temporal information , while to tell ` ` xxunk floor \" and ` ` xxunk floor \" apart requires great spatial information processing ability . xxmaj we find that our xxup scs can successfully learn the temporal information over long - range sequences on limited resources and compared to the conventional sequential models , such as xxup lstm stacked on xxup xxunk \\ cite{donahue2015long } and xxunk \\ cite{xingjian2015convolutional } , our xxup scs achieves remarkable improvements ( see xxmaj tab.~ \\ ref{tab : actionresult } for details ) . xxmaj unlike the previous architectures , our xxup scs can be trained end - to - end without the support of a backbone network ( such as xxup xxunk \\ xxunk } , resnet~ \\ cite{he2016deep } , and xxmaj xxunk \\ xxunk } . xxmaj due to the temporal and spatial semi - coupling , the network can reduce the interference from the temporal unit to the spatial one so that we can still get high - quality spatial features . \n",
              " \t \n",
              " \t  \\ xxunk outline sequentially annotation experiments } \n",
              " \t xxmaj although the video action recognition task takes a sequence as input , each sequence only need to be assigned one action label . xxmaj therefore , modeling it as a pattern recognition problem instead of a sequence learning is also a way to go . xxmaj for example , xxup 3d convolution model~ \\ cite{ji20133d , carreira2017quo } is widely used recently . xxmaj based on this consideration , we need a typical sequential task to further validate the xxup scs 's performance . xxmaj we , therefore , turn to the outline annotation task . \n",
              " \t \n",
              " \t xxmaj unlike video action recognition , outline annotation task calls for a point sequence to represent the outline of the target . xxmaj each input consists of an image with a start point to declare which object is the annotation target and an end point to indicate which direction to annotate . xxmaj the annotation models are trained to give out the outline 's key points of the target object one by one from the provided start point to the end point . a new key point is generated based on the already calculated key points ( xxmaj fig.~ \\ ref{fig : experiments } a ) . xxmaj the generated key points form the predicted outline and we adopt the iou between the predicted and ground - truth outline as the evaluation metric . \n",
              " \t xxmaj because it is not easy to give out the complete sequential key points in one step only with the start and end point , it is not suitable to model this task as a pattern recognition task like the video action recognition task . \n",
              " \t \n",
              " \t xxmaj we adopt cityscapes dataset~ \\ xxunk } as our data source and the target objects are all from the outdoor scene . xxmaj the relatively complex backgrounds require great ability to extract spatial features . xxmaj different from the action recognition task , the temporal information lies in the sequential key point positions which act as the attentions to assist the selection of the subsequent points . xxmaj as a benchmark we compare our xxup scs based model , a modified xxmaj polygon - xxup rnn model~ \\ cite{castrejon2017annotating } , with the original xxup lstm based xxmaj polygon - xxup rnn model . xxmaj in this case , our deep xxup scs model reaches an average of 70.4 in terms of iou , 15 \\ % relative improvements over the baseline . xxmaj fig.~ \\ ref{fig : experiments } c illustrates the training processes of xxunk with different depths and training strategies . \n",
              " \t \n",
              " \t  \\ xxunk - driving experiments } \n",
              " \t xxmaj next , we want to evaluate the performance of xxup scs on some cutting - edge applications . xxmaj still , we start from a pattern recognition like problem : the simplified auto - driving problem . xxmaj we treat the problem as a visual sequence processing task so that we only focus on the driving direction and ignore the route planning , strong driving safety and other things in the real driving environments . \n",
              " \t \n",
              " \t a driving agent , given the sequence of driver 's perspective images , needs to decide the driving direction for the last image . xxmaj it is worth noting that the agent does not know the historical direction to avoid it making ` ` lazy decision \" : simply repeating the recent direction . xxmaj as the previous experiments , this task also requires great ability to process spatial information to figure out the road direction and xxunk condition , and ability to capture temporal information to make coherent decisions . \n",
              " \t \n",
              " \t xxmaj we evaluate the xxup scs on the xxmaj xxunk dataset~ \\ xxunk } and the livi dataset~ \\ xxunk } . xxmaj the image sequences are the driving videos in real traffic including varied scenes such as highways and mountain roads , and the behaviours of the driver are recorded as the direction label . xxmaj by experiments , we find that features from $ h_s$ record more features of the current road and $ h_t$ records more about scene changes during driving ( xxmaj fig.~ \\ ref{fig : toyexample } c ) . xxmaj this indicates that they divide the works successfully and just as the design purpose , they focus on temporal and spatial features respectively so xxup scs can remarkably xxunk the learning pressure to different components . xxmaj again , the xxup scs performs substantially better than conventional xxup lstm models ( see xxmaj tab.~ \\ ref{tab : drivingresult } ) . \n",
              " \t \n",
              " \t  \\ xxunk forecasting experiments } \n",
              " \t xxmaj we further apply our xxup scs model to precipitation forecasting task in order to test its performance on sequence generation problem . xxmaj unlike the previous experiments , where the model receives the input sequence and gives out the output sequence synchronously , we apply a form of ` ` sequence to sequence \" learning~ \\ cite{sutskever2014sequence } in which the input sequence is encoded into a representation and then the model gives out the output sequence based on this representation . \n",
              " \t \n",
              " \t xxmaj our dataset , which we term as xxup reec-2018 , contains a set of meteorological xxmaj radar xxmaj echo images for xxmaj eastern xxmaj china in 2018 . xxmaj the metric of the radar echo is composite xxunk ( xxup cr ) which can be utilized to predict the precipitation intensity . a model , given a sequence of the radar echo images sorted in time , needs to predict a sequence of the future radar echo images from the previous evolution of xxup cr ( see xxmaj fig.~ \\ ref{fig : experiments } b ) . \n",
              " \t \n",
              " \t xxmaj through experiments , we find that our xxup scs model can successfully generate the results with original evolution trends , such as diffusion and translation . xxmaj compared with the convlstm , a conventional sequence model for visual , again , our xxup scs gains huge performance improvements . \n",
              " \t \n",
              " \t  \\ section{discussion } \n",
              " \t xxmaj in summary , we have built a xxmaj semi - xxmaj coupled xxmaj structure that can learn to divide the work of extracting features automatically . a major reason for utilizing such a structure is to alleviate the interference between learning temporal and spatial features . xxmaj many techniques like xxup stsgd and xxup ltsc ( see xxmaj methods and xxmaj fig.~ \\ ref{fig : xxup stsgd } ) are proposed to make the xxup scs easier to train . xxmaj the performances of our structure are provided by the experiments , and the theme connecting these experiments is the need to synthesize high dimensional temporal and spatial features embedded in data sequences . xxmaj all the experiments demonstrate that xxup scs is able to process visual sequential data regardless of whether the task is sensory processing or sequence learning . xxmaj moreover , we have seen that the temporal and spatial features are handled separately by different sub - structures due to the temporal - spatial semi - coupling mechanism ( see xxmaj fig.~ \\ ref{fig : toyexample } and xxmaj fig.~ \\ ref{fig : ablation_study } ) . \n",
              " \t \n",
              " \t  \\ section{related xxmaj work } \n",
              " \t\t  \\ xxunk models } \n",
              " \t\t xxmaj sequential tasks on high dimensional signal require a model to extract spatial representations as well as temporal features . a series of prior works has shed light on these tough problems : xxmaj constrained by the computational resource , xxunk methods~ \\ xxunk , xxunk , xxunk , xxunk } do not explicitly extract temporal feature , instead , acquire global features by combining spatial information , where pooling is a common method . xxmaj to extract temporal information , some researchers adopt low - level features , like optical flow~ \\ cite{simonyan2014two , carreira2017quo } , trajectories~ \\ xxunk , xxunk } , and pose xxunk \\ xxunk } to deal with temporal information . xxmaj these low - level features are easy to extract but they are xxunk to some extent , therefore , the performance is limited . xxmaj then with more computational resource , xxmaj recurrent xxmaj neural xxmaj networks ( xxup xxunk \\ cite{donahue2015long , xxunk , xxunk } are widely used , where hidden states take charge of ` ` remembering \" the history and extract the temporal features . xxmaj recently , xxup 3d convolutional networks~ \\ cite{ji20133d , carreira2017quo , xxunk , xxunk , xxunk } appear , where the temporal information is treated as the same with the spatial ones . xxmaj the large xxup 3d kernel makes this method consume a large amount of computational resource . \n",
              " \t\t  \\ xxunk to split temporal and spatial information } \n",
              " \t\t a simple method to split temporal - spatial information is to utilize relatively pure spatial information without temporal one to extract spatial features and pure temporal input for temporal ones . xxmaj for example , two - stream models~ \\ cite{simonyan2014two , carreira2017quo , xxunk } adopt one static image as spatial input and optical flows as temporal input . xxmaj one problem of this method is that the processes of extracting spatial and temporal features are completely independent , making it impossible to extract hierarchical spatial - temporal features . xxmaj another method is to adjust the density of these two types of information . xxmaj in slowfast network~ \\ cite{feichtenhofer2018slowfast } , the input of spatial stream has higher spatial resolution and lower temporal sampling rate , while the input of temporal stream is the opposite . \n",
              " \t \n",
              " \t \n",
              " \t  \\ xxunk \\ label{sec : xxmaj method } \n",
              " \t xxmaj in this section , we will introduce the detailed structure of xxup scs , the training method with spatial - temporal switch gradient descent , the strategy to deal with the high - dimension spatial signal and super long sequences , and the designs of the experiments . \n",
              " \t \n",
              " \t  \\ subsection{network for xxup scs } \n",
              " \t xxmaj at every time - stamp $ t$ , the network $ \\ mathcal{t}$ , consisting of $ n$ semi - coupled layers , receives an input matrix $ \\ xxunk from the dataset or environment and outputs an vector $ \\ mathbf{y}_t$ ( the main goal $ g$ ) to approximate the target ( ground truth ) vector $ \\ xxunk \n",
              " \t \n",
              " \t xxmaj as mentioned above , each semi - coupled layer satisfies the structure of $ \\ xxunk = \\ xxunk ( \\ mathbf{u}^{l-1}_t ) , h_t ( \\ xxunk , where $ \\ xxunk is the output of the $ xxunk layer at $ xxunk step and $ \\ xxunk is the input . xxmaj by defining $ \\ xxunk \\ xxunk , we get : \n",
              " \t  \\ begin{align } \n",
              " \t & \\ xxunk h_s ( \\ mathbf{u}^{l-1}_t ; \\ xxunk ) = { \\ rm xxmaj conv } ( \\ mathbf{u}^{l-1}_t ; \\ xxunk ) \\ label{eq : hs } \\ \\ \n",
              " \t & \\ xxunk h_t ( \\ mathbf{u}^{l-1}_t ; \\ xxunk ) = { \\ rm xxmaj conv } ( [ \\ mathbf{u}^{l-1}_t , \\ sigma ( \\ xxunk } ) ] ; \\ xxunk ) \\ label{eq : ht } \n",
              " \t  \\ end{align } \n",
              " \t where $ l$ is the layer index , $ \\ xxunk / ( xxunk is the logistic sigmoid function , $ \\ rm xxmaj conv$ is the convolutional neural layer , $ \\ xxunk and $ \\ xxunk are spatial state and temporal cell state matrix , respectively , of layer $ l$ at time $ t$. $ \\ xxunk \\ xxunk is true for all $ l$. xxmaj we adopt $ \\ rm xxmaj conv$ here for it is an excellent spatial feature extractor and of course , we can replace $ \\ rm xxmaj conv$ by other operators like fully connection , according to different tasks . xxmaj note that xxmaj eq.~ \\ ref{eq : hs } describes the structure of $ h_s$ and xxmaj eq.~ \\ ref{eq : ht } describes $ h_t$ which is a simple naive xxup rnn structure . xxmaj it is feasible to replace $ h_t$ with xxup lstm architecture~ \\ cite{xingjian2015convolutional } , but the computing complexity is too high to apply on visual tasks , so we do not practice this in this paper . \n",
              " \t \n",
              " \t xxmaj the synthesizer $ \\ mathcal{f}$ adopts a parameter - free structure : \n",
              " \t  \\ begin{align } \n",
              " \t & \\ xxunk { \\ rm xxmaj relu } ( \\ xxunk ) \\ circ { \\ rm xxmaj sigmoid } ( \\ xxunk ) \\ label{eq : xxmaj xxunk } \n",
              " \t  \\ end{align } \n",
              " \t \n",
              " \t where $ \\ circ$ denotes element - wise multiplication , $ { \\ rm xxmaj xxunk is the rectified linear unit and $ { \\ rm xxmaj xxunk 1 / ( 1 + e ^ { - x } ) $ is the sigmoid function . xxmaj in this way , the results of $ h_t$ are normalized to $ ( 0,1)$ , so $ h_t$ is treated as a control gate of $ h_s$ in the viewpoint of $ \\ mathcal{f}$. \n",
              " \t \n",
              " \t xxmaj as the network is recurrent , its outputs are a function of the complete sequence $ ( \\ mathbf{x}_1 , ... , \\ xxunk xxmaj we can further encapsulate the operation of the network as \n",
              " \t  \\ begin{align } \n",
              " \t & ( \\ mathbf{u}^n_1 , ... , \\ xxunk \\ mathcal{t } ( [ \\ mathbf{x}_1 , ... , \\ xxunk ] ; \\ xxmaj psi_s , \\ xxmaj psi_t ) \n",
              " \t  \\ end{align } \n",
              " \t where $ \\ bm { \\ xxmaj psi}$ is the set of trainable network weights and $ \\ xxunk is the output of the $ xxunk layer at time stamp $ t$. xxmaj finally , the output vector $ \\ mathbf{y}_t$ is defined by the assembly of $ ( \\ mathbf{u}^n_1 , ... , \\ xxunk : \n",
              " \t  \\ begin{align } \\ label{eq : xxunk } \n",
              " \t & \\ xxunk [ \\ mathbf{u}^n_1 , ... , \\ xxunk ] \n",
              " \t  \\ end{align } \n",
              " \t \n",
              " \t xxmaj for $ \\ mathcal{t}^1 $ and $ \\ mathcal{t}^2 $ , the sub - goal networks , we adopt the same $ h_s ( \\ cdot)$ and $ h_t ( \\ cdot)$ with $ \\ mathcal{t}$ , while the synthesizer $ \\ mathcal{f}$ is different . xxmaj in $ \\ mathcal{t}^1 $ , $ \\ mathcal{f}$ and sub - goal $ r_s$ ( or $ \\ mathbf{y}_t^ { \\ xxunk ) are defined as : \t \n",
              " \t  \\ begin{align } \n",
              " \t  \\ hat { \\ xxunk { \\ rm xxmaj relu } ( \\ xxunk ) \\ \\ \n",
              " \t  \\ mathbf{y}_t^ { \\ xxunk [ \\ hat { \\ xxunk , ... , \\ hat { \\ xxunk ] \n",
              " \t  \\ end{align } \n",
              " \t xxmaj while in $ \\ mathcal{t}^2 $ , $ \\ mathcal{f}$ and sub - goal $ r_t$ ( or $ \\ mathbf{y}_t^ { \\ xxunk ) are defined as : \t \n",
              " \t  \\ begin{align } \n",
              " \t  \\ hat { \\ xxunk { \\ rm xxmaj relu } ( \\ xxunk ) \\ \\ \n",
              " \t  \\ mathbf{y}_t^ { \\ xxunk [ \\ hat { \\ xxunk , ... , \\ hat { \\ xxunk ] \n",
              " \t  \\ end{align } \n",
              " \t  \\ subsection{deep xxmaj nested xxmaj semi - coupled xxmaj structure xxmaj xxunk \\ label{sec : xxup stsgd } \n",
              " \t \n",
              " \t xxmaj as discussed in section \\ ref{sec : aware } , on one hand , $ \\ mathcal{g}$ computes spatial and temporal information by separate modules . xxmaj on the other hand , we adopt deep nested structure of stacked $ \\ mathcal{g}$ , inspired from the spatial and temporal coupling in human brains . xxmaj but this structure leads to a difficult training process , because the deep nested structure actually merges the spatial and temporal information early in the shallow layers , which xxunk the pressure of spatial and temporal decomposition in the later layers as well as reduces the hierarchy of the decoupled features . xxmaj moreover , as the depth of layers and the length of sequences increase , both the number and the length of the back - propagation chains will grow significantly , which makes the training process much more challenging as well ( see xxmaj fig.~ \\ ref{fig : xxup stsgd } ) . \n",
              " \t \n",
              " \t \n",
              " \t  \\ begin{figure } \n",
              " \t\t  \\ begin{center } \n",
              " \t\t\t % \\ fbox { \\ xxunk in } \\ xxunk \\ xxunk } } \n",
              " \t\t\t  \\ includegraphics[width= \\ xxunk } \n",
              " \t\t  \\ end{center } \n",
              " \t\t  \\ caption { \\ xxunk numbers of back - propagation chains } . xxmaj the horizontal axis is the length of the back - propagation chain and the vertical axis is the exception number of the chains . xxmaj note that with the growing of the model depth and sequence length , the number and length of the chains grow significantly . xxmaj our xxup stsgd with large $ p$ can efficiently reduce the number of long sequences . } \n",
              " \t\t  \\ label{fig : xxup stsgd } \n",
              " \t  \\ end{figure } \n",
              " \n",
              " \t xxmaj to address this challenge , the xxmaj spatial - xxmaj temporal xxmaj switch xxmaj gradient xxmaj descent ( xxup stsgd ) is proposed to conduct a higher level of semi - coupling , in which the optimizer updates parameters based on either spatial or temporal information with a certain probability at each training step . \n",
              " \t xxmaj as the training goes on , we reduce the degree of this separation and finally the network can learn all the information . xxmaj this training strategy is also a practice of the semi - coupled mechanism : decoupling first then synthesizing . \n",
              " \t \n",
              " \t \n",
              " \t  \\ xxunk - xxmaj temporal xxmaj switch xxmaj gradient xxmaj descent } \n",
              " \t \n",
              " \t xxup stsgd is also a gradient based optimization method and the gradients are propagated by the xxup bp algorithm~ \\ xxunk } . xxmaj it works like a switch that turns off gradients on spatial and temporal modules with a certain probability . xxmaj this scheme largely reduces the interference between $ h_s ( \\ cdot)$ and $ h_t ( \\ cdot)$ induced by the deep nested structure . \n",
              " \t \n",
              " \t xxmaj given the definition xxmaj eq.~ \\ ref{eq : g } . xxmaj its forward propagation is : \n",
              " \t  \\ begin{align } \n",
              " \t & \\ xxunk = \\ xxunk \\ circ \\ ldots \\ circ \\ mathcal{g}_1 \n",
              " \t  \\ end{align } \n",
              " \t where $ \\ xxunk = \\ xxunk ( \\ cdot ) , h_s ( \\ cdot ) ; \\ xxunk is the $ i^{th}$ layer of the network and $ \\ bm { \\ xxunk is the set of the trainable parameters in the $ i^{th}$ layer . xxmaj the loss between $ \\ mathbf{y}_t$ and ground truth $ \\ xxunk is defined as : \n",
              " \t  \\ begin{align } \n",
              " \t e = \\ xxunk } = \\ xxunk ( \\ xxunk , \\ xxunk ) } \n",
              " \t  \\ end{align } \n",
              " \t where $ xxup l$ is the loss function . \n",
              " \t \n",
              " \t xxmaj then during back - propagation , according to the xxup xxunk xxunk , the gradient of $ \\ bm { \\ xxunk can be presented as : \n",
              " \t  \\ begin{equation } \n",
              " \t  \\ begin{aligned } \n",
              " \t  \\ frac { \\ partial e } { \\ partial \\ bm { \\ psi}_i } = & \\ sum_{t=1}^t \\ frac { \\ partial e } { \\ partial \\ mathcal{g}^t_{i+1 } } \\ frac { \\ partial \\ mathcal{g}^t_{i+1 } } { \\ partial \\ bm { \\ psi_i } } \n",
              " \t  \\ end{aligned } \n",
              " \t  \\ end{equation } \n",
              " \t and in conventional stochastic gradient descent methods , this exact gradient is adopted to update the parameters and continue back propagating . xxmaj in our xxup stsgd , we need to decouple the gradients based on the information carried by these two modules . xxmaj to this end , we rewrite the gradient as : \n",
              " \t  \\ begin{equation } \n",
              " \t  \\ begin{aligned } \n",
              " \t  \\ frac { \\ partial e } { \\ partial \\ bm { \\ psi}_i } & = \\ sum_{t=1}^t \\ frac { \\ partial e } { \\ partial \\ mathcal{g}^t_{i+1 } } ( \\ frac { \\ partial \\ mathcal{g}^t_{i+1 } } { \\ partial \\ mathbf{c}^{i+1}_{t } } \\ frac { \\ partial \\ mathbf{c}^{i+1}_{t } } { \\ partial \\ bm { \\ psi}_i } + \\ frac { \\ partial \\ mathcal{g}^t_{i+1 } } { \\ partial \\ mathbf{s}^{i+1}_{t } } \\ frac { \\ partial \\ mathbf{s}^{i+1}_{t } } { \\ partial \\ bm { \\ psi}_i } ) \n",
              " \t  \\ end{aligned } \n",
              " \t  \\ end{equation } \n",
              " \t \n",
              " \t xxmaj in the equation , the first term in the bracket is the gradient from $ h_t ( \\ cdot)$ and the second term is from $ h_s ( \\ cdot)$. xxmaj as the structures of $ h_t ( \\ cdot)$ and $ h_s ( \\ cdot)$ are designed for temporal and spatial information respectively , the gradients from them carry different concepts . \n",
              " \t \n",
              " \t xxmaj to decouple the gradients , we use a switch to prevent a certain part ( spatial or temporal ) from propagating its gradient in back - propagation , which can be defined as : \n",
              " \t  \\ begin{equation } \n",
              " \t  \\ begin{aligned } \n",
              " \t  \\ hat { \\ frac { \\ partial e } { \\ partial \\ bm { \\ psi}_i } } = \\ sum_{t=1}^t ( & \\ xxunk ) \\ frac { \\ partial e } { \\ partial \\ mathcal{g}^t_{i+1 } } \\ frac { \\ partial \\ mathcal{g}^t_{i+1 } } { \\ partial \\ mathbf{c}^{i+1}_{t } } \\ frac { \\ partial \\ mathbf{c}^{i+1}_{t } } { \\ partial \\ bm { \\ psi}_i } \\ \\ \n",
              " \t + & \n",
              " \t  \\ xxunk ) \\ frac { \\ partial e } { \\ partial \\ mathcal{g}^t_{i+1 } } \\ frac { \\ partial \\ mathcal{g}^t_{i+1 } } { \\ partial \\ mathbf{s}^{i+1}_{t } } \\ frac { \\ partial \\ mathbf{s}^{i+1}_{t } } { \\ partial \\ bm { \\ psi}_i } ) \\ label{eq : split } \n",
              " \t  \\ end{aligned } \n",
              " \t  \\ end{equation } \n",
              " \t where $ \\ gamma$ is a probability function defined as : \n",
              " \t  \\ begin{equation } \n",
              " \t  \\ xxunk ) = \\ left \\ { \n",
              " \t  \\ begin{aligned } \n",
              " \t 0 , & { \\ rm ~ with ~ the ~ probability ~ xxunk \\ \\ \n",
              " \t 1 , & { \\ rm ~ with ~ the ~ probability ~ xxunk ) \n",
              " \t  \\ end{aligned } \n",
              " \t  \\ right . \n",
              " \t  \\ end{equation } \n",
              " \t \n",
              " \t  \\ paragraph{discussion } xxmaj this scheme partly decouples the spatial and temporal learning process by initializing $ p_s$ and $ p_t$ to a relative high value ( $ p_s = xxunk $ ) and as the training goes on , $ p$ decreases to 0 to synthesize the spatial and temporal training processes . xxmaj from a macro perspective , it cuts off some paths in the back propagation with a certain probability , which reduces the number of back - propagation chains significantly , to make the training process more tractable ( see xxmaj fig.~ \\ ref{fig : xxup stsgd } ) . xxmaj according to the xxmaj assumption 4.3 in~ \\ xxunk } , if we set $ p_s = p_t$ , we get $ e ( \\ hat { \\ frac { \\ partial e } { \\ partial \\ bm { \\ xxunk { \\ frac { \\ partial e } { \\ partial \\ bm { \\ xxunk and this will lead to the similar convergence properties with the conventional stochastic gradient descent method . \n",
              " \t \n",
              " \t  \\ xxunk xxup stsgd } \n",
              " \t xxmaj note that , in xxup stsgd , the same value of $ p$ for $ h_s ( \\ cdot)$ and $ h_t ( \\ cdot)$ is the restriction for convergence and is a sufficient condition . xxmaj but , we hope the network can learn more spatial information at the beginning , since temporal information can not be captured given a very unreliable spatial representation . \n",
              " \t xxmaj after getting a relatively mature spatial representation , we hope the xxup stsgd can shift its learning focus between spatial and temporal features . xxmaj to this end , we modify the xxmaj eq.~ \\ ref{eq : split } with a dynamic ratio $ q \\ in [ 0,1]$ to : \n",
              " \t  \\ begin{equation } \n",
              " \t  \\ begin{aligned } \n",
              " \t  \\ hat { \\ frac { \\ partial e } { \\ partial \\ bm { \\ psi}_i } } = \\ sum_{t=1}^t ( & \\ xxunk ) \\ frac { \\ partial e } { \\ partial \\ mathcal{g}^t_{i+1 } } \\ frac { \\ partial \\ mathcal{g}^t_{i+1 } } { \\ partial \\ mathbf{c}^{i+1}_{t } } \\ frac { \\ partial \\ mathbf{c}^{i+1}_{t } } { \\ partial \\ bm { \\ psi}_i } \\ \\ \n",
              " \t + & \n",
              " \t  \\ xxunk ) \\ frac { \\ partial e } { \\ partial \\ mathcal{g}^t_{i+1 } } \\ frac { \\ partial \\ mathcal{g}^t_{i+1 } } { \\ partial \\ mathbf{s}^{i+1}_{t } } \\ frac { \\ partial \\ mathbf{s}^{i+1}_{t } } { \\ partial \\ bm { \\ psi}_i } ) \\ label{eq : xxunk } \n",
              " \t  \\ end{aligned } \n",
              " \t  \\ end{equation } \n",
              " \t \n",
              " \t \n",
              " \t xxmaj although there is no theory to guarantee the convergence of the xxmaj advanced xxup stsgd ( xxup astsgd ) , the experiment results show it works well . xxmaj moreover , to automatically control the process of decreasing $ q$ , we train a small network with 3 fully connection layers which takes $ r_s$ , $ r_t$ , and $ g$ as input to optimize $ q$. xxmaj to simplify the problem , we provide an empirical formula as another option : \n",
              " \t  \\ begin{align } \n",
              " \t q = q_0 + ( xxunk ) \\ frac { \\ max(0 , xxmaj xxunk { \\ rm xxunk } ) } { { \\ rm xxunk } - { \\ rm xxunk } } * ( \\ alpha ( \\ xxunk } xxunk ) \n",
              " \t  \\ end{align } \n",
              " \t where $ xxmaj l_s$ and $ xxmaj xxunk are the loss values of $ r_s$ and $ g$. $ q_0 $ is usually set as 0.5 . xxmaj in this equation , we monitor the decreasing process of $ xxmaj l_s$ to update $ q$. $ \\ rm xxunk is a hyper - parameter that acts as a threshold for $ xxmaj l_s$ , considering that $ xxmaj l_s$ is difficult to decrease to 0 and we want $ q$ get the minimum value when $ xxmaj l_s$ decreasing to $ \\ rm xxunk $ \\ rm xxunk is the initial training loss value of $ g$ , for example , the initial loss of an $ xxunk classification problem , the initial cross entropy loss , is $ xxunk $ \\ alpha$ is a hyper - parameter and the multiplier $ ( \\ xxunk / xxmaj xxunk is designed to balance the integral and spatial information . xxmaj if the task is more depended on the spatial information , we can set $ \\ alpha$ smaller , in this way the function will have a relative big value to better learn the spatial features . \n",
              " \t \n",
              " \t  \\ xxunk long sequences with xxup ltsc } \\ label{sec : xxup ltsc } \n",
              " \t xxmaj making use of the different properties between time and space , $ \\ mathcal{t } [ \\ mathbf{x } ; \\ xxmaj psi_s , \\ xxmaj psi_t]$ decouples the temporal and spatial information . xxmaj as the length of the sequence grows , the enormous increase in information which leads to huge computing requirements also brings up the demand of information decoupling . xxmaj briefly , \\ xxunk range temporal semi - coupling } ( xxup ltsc ) decouples the original long sequence $ \\ mathbf{d}$ into short sequences $ \\ { \\ xxunk = 1, ... ,n \\ } $ along the temporal dimension with a partitioning principle : \n",
              " \t  \\ begin{align } \n",
              " \t & \\ xxunk ... ,n } \\ { \\ tilde { \\ xxunk } \\ } = \\ tilde { \\ mathbf{d } } \\ \\ \n",
              " \t & \\ tilde { \\ xxunk } \\ cap \\ tilde { \\ xxunk \n",
              "  eq \\ varnothing \\ label{eq : overlap } \n",
              " \t  \\ end{align } \n",
              " \t where $ \\ tilde { \\ xxunk and $ \\ tilde { \\ xxunk are the set of $ \\ xxunk contained in sequence $ \\ mathbf{d}_i$ and $ \\ mathbf{d}$ , and $ { \\ xxunk is sorted by index of its first element . xxmaj eq.~ \\ ref{eq : overlap } requires overlaps between the adjacent sub - sequences which are the hinge to transmit the information , for it makes sure that there is no such a point in $ \\ mathbf{d}$ that information can not feed forward and backward across it . xxmaj for example , when splitting $ \\ mathbf{d } = ( \\ mathbf{x}_1 , \\ mathbf{x}_2 , \\ mathbf{x}_3 , \\ mathbf{x}_4)$ into $ \\ xxunk ( \\ mathbf{x}_1 , \\ xxunk and $ \\ xxunk ( \\ mathbf{x}_3 , \\ mathbf{x}_4)$ in which there is no overlap , information will never transfer between $ \\ mathbf{x}_2 $ and $ \\ mathbf{x}_3 $ , but if splitting $ \\ mathbf{d}$ into $ \\ xxunk = ( \\ mathbf{x}_1 , \\ mathbf{x}_2 , \\ xxunk and $ \\ xxunk ( \\ mathbf{x}_2 , \\ mathbf{x}_3 , \\ mathbf{x}_4)$ , there is no such issue . \n",
              " \t \n",
              " \t xxmaj as a hyper - parameter , a high overlap $ \\ eta$ will lead to high computing complexity and a low $ \\ eta$ means worse ability to transmit information . xxmaj in this paper , we chose 25 \\ % for $ \\ eta$. \n",
              " \t \n",
              " \t xxup ltsc can be adopted in any sequence task , while in this paper , xxup ltsc is nested with xxup scs network . \n",
              " \t xxup ltsc further utilizes the overlaps among $ \\ mathbf{d}_i$ to enhance the flow of information and we adopt an error function to shorten the distance between output of the adjacent $ \\ mathbf{d}_i$ : \n",
              " \t  \\ begin{align } \n",
              " \t & xxmaj xxunk \\ xxunk ... ,n } { \\ xxunk ( { \\ xxunk } ) , xxunk ( { \\ xxunk ) ) } \n",
              " \t  \\ end{align } \n",
              " \t where $ \\ xxunk , b)$ is defined as the overlap xxup mse function which calculates the xxup mse value of the overlap parts of $ a$ and $ b$. xxmaj this arrangement makes the output of $ xxunk with adjacent input $ \\ mathbf{d}_i$ be close in the overlap part . \n",
              " \t \n",
              " \t xxmaj note that there are other straightforward methods to decouple the long - range temporal information like xxup xxunk algorithm~ \\ xxunk } or simply sampling from the original $ \\ xxunk \\ cite{carreira2017quo , xxunk , xxunk , xxunk } , but these do not make sure that the semantic information can transmit through the whole sequence or just discard some percentage of information . \n",
              " \t \n",
              " \t a simple example demonstrates the smooth flow of semantic information in xxup ltsc . xxmaj the input visual sequence consists of an image of star and several of xxunk , and the star can appear at any temporal position . xxmaj our model needs to learn how far the current xxunk image is from the appeared star . xxmaj with xxup ltsc , the model can correctly output the results even if the star image appears 50 frames ago when the decoupled sequence lengths are smaller than 10 . xxmaj this can serve as a preliminary verification on xxup ltsc . \n",
              " \t \n",
              " \t  \\ begin{figure * } \n",
              " \t\t  \\ begin{center } \n",
              " \t\t\t  \\ includegraphics[width= \\ xxunk } \n",
              " \t\t  \\ end{center } \n",
              " \t\t  \\ caption { \\ xxunk study on action recognition task } . \\ textbf{a } , xxmaj feature maps of $ h_s$ and $ h_t$. xxmaj with sub - tasks , the splitting of spatial and temporal information is more obvious than without sub - tasks : 1 ) xxmaj with sub - tasks , $ h_s$ contains xxunk spatial information , while without sub - tasks , there is a little temporal information in $ xxunk 2 ) xxmaj without sub - tasks , $ h_t$ also extracts texture information , while sub - tasks makes it focus on the motion changes . xxmaj this reveals that sub - tasks can make $ h_s$ and $ h_t$ focus on their own jobs . \\ textbf{b } , $ q$ values during the training process . xxmaj at the beginning of training , $ q$ is about $ 1 $ , which leads xxup scs to focus on spatial information first . xxmaj as the training goes on , the value of $ q$ gradually approaches $ 0.5 $ to merge temporal and spatial information and the model treats them equally . } \n",
              " \t\t  \\ label{fig : ablation_study } \n",
              " \t  \\ end{figure * } \n",
              " \t \n",
              " \t  \\ begin{figure * } \n",
              " \t\t  \\ begin{center } \n",
              " \t\t\t  \\ includegraphics[width= \\ xxunk } \n",
              " \t\t  \\ end{center } \n",
              " \t\t  \\ caption { \\ xxunk annotation and precipitation forecasting experiments } . \\ textbf{a } , xxmaj to annotate the xxunk , we first crop out the objects , then give the start point ( the red one ) , finally the model needs to give out the outline points starting from it one by one to form a complete outline . \\ textbf{b } , xxmaj some example images annotated by our xxup scs structure . \\ textbf{c } , xxmaj from the training process of the model on outline annotation , we can see that our xxup scs model can benefit from the increasing model depth while xxup lstm model is difficult to train when stacked deep , which is because extracting the hierarchical spatial and temporal features together is difficult and our xxmaj semi - xxmaj coupled xxmaj structure can solve this problem . xxmaj moreover , a larger initial $ q$ can better decouple the training process of $ h_s$ and $ h_t$ , thus leads to a better performance . \\ textbf{d } , xxmaj the precipitation forecasting model consists of an encoder and a decoder . xxmaj the encoder integrates the observed radar echo images into an intermediate representation . xxmaj the decoder takes the representation and the last radar echo image as input , updates the intermediate representation and outputs the future image one by one . } \n",
              " \t\t  \\ label{fig : experiments } \n",
              " \t  \\ end{figure * } \n",
              " \t \n",
              " \t  \\ subsection{comparison with xxmaj deep xxup rnn and spatial - temporal attention model } \n",
              " \t \n",
              " \t xxmaj the xxmaj deep xxup rnn framework~ \\ cite{pang2018deep } is the predecessor to the xxup scs described in this work , yet they have significant differences . \n",
              " \t xxmaj firstly , in the xxmaj deep xxup rnn framework , the splitting of two flows is designed to make the deep recurrent structure easier to train by adding spatial shortcuts over temporal flows . xxmaj while in xxup scs , the semi - coupling mechanism aims at endowing the model with the awareness of spatial and temporal concepts . xxmaj moreover , $ h_s ( \\ cdot)$ and $ h_t ( \\ cdot)$ have the equal status to explicitly learn the two concepts . \n",
              " \t xxmaj secondly , the xxmaj deep xxup rnn framework has no mechanism to ensure the two flows focusing on the two kinds of information . xxmaj this is not an issue for the xxup scs which adopts two extra independent sub - goals and two stand - alone modules tailored for spatial and temporal features . xxmaj thirdly , in the training process , xxmaj deep xxup rnn has no way to control the training degree of the two flows , thus , no way of re - focusing on the spatial or temporal information . xxmaj this problem is addressed in xxup scs by the xxup stsgd mechanism . \n",
              " \t \n",
              " \t \n",
              " \t xxmaj the xxmaj spatial - xxmaj temporal xxmaj attention model ( xxup xxunk \\ xxunk } also introduces spatial and temporal concepts . xxmaj there are several differences between xxup stam and xxup scs . xxmaj firstly , xxup scs aims at extracting the temporal and spatial features ( concepts ) separately from the input , while xxup stam is designed to output the spatial and temporal attention from input features which integrate spatial and temporal information . xxmaj these attentions defined on skeleton key - points rely on human skeleton assumption very much and are not general features . xxmaj secondly , xxup stam is designed for small - scale data format ( skeleton coordinates , xxup xxunk only ) , thus , it is not suitable for the large scale problems which are the targets of xxup scs . xxmaj thirdly , xxup stam does not have awareness of general spatial and temporal concepts . xxmaj the heads of spatial and temporal attention modules are designed for the specific tasks : spatial one for skeleton keypoints and temporal one for video frames , thus , the spatial and temporal concepts are actually human - defined , not learnt by the model itself . \n",
              " \n",
              " \t \n",
              " \t  \\ subsection{action recognition task descriptions } \n",
              " \t xxmaj the experiments of action recognition are conducted on xxup ucf-101 , xxup hmdb-51 and xxmaj xxunk datasets , which comprise sets of 101 , 51 , 400 action categories respectively . xxmaj for each dataset , we follow the official training and testing splits . xxmaj for each video , the frames are rescaled with their shorter side into xxunk and a 224 $ \\ times$ 224 crop is randomly sampled from the rescaled frames or their horizontal flips . xxmaj colour augmentation is used , where all the random augmentation parameters are shared among the frames of each video . \n",
              " \t \n",
              " \t xxmaj for this task , we adopt two kinds of xxmaj semi - xxmaj coupled xxmaj structures : backbone - supported one and stand - alone structure without backbone . xxmaj for the backbone - supported structure , there is a xxup cnn backbone pre - trained on xxunk \\ cite{krizhevsky2012imagenet } ( we choose xxup vgg and xxunk as examples ) before the 15-layer xxup scs network . xxmaj while for the stand - alone version , the model only consists of a xxunk xxup scs network . xxmaj shortcuts between layers like resnet~ \\ cite{he2016deep } are adopted in xxup scs networks to simplify the training process . xxmaj the detailed structures are summarized in xxmaj tab.~ \\ ref{tab : xxunk } . \n",
              " \t \n",
              " \t  \\ begin{table } [ ] \n",
              " \t\t  \\ footnotesize \n",
              " \t\t  \\ caption{detailed stand - alone xxup scs structures for action recognition task . xxmaj there are residual lines between every layer blocks . \n",
              " \t\t } \n",
              " \t\t  \\ renewcommand { \\ xxunk } \n",
              " \t\t  \\ begin{center } \n",
              " \t\t\t  \\ begin{tabular}{c|c } \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t layer blocks & output size \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t % \\ hline \n",
              " \t\t\t\t $ 7 \\ xxunk , 64 , { \\ rm xxunk $ & 112 \\ \\ [ 1.5ex ] \n",
              " \t\t\t\t % \\ hline \n",
              " \t\t\t\t $ \\ left [ \\ begin{aligned } \n",
              " \t\t\t\t 3 \\ times3 , 64 \\ \\ \n",
              " \t\t\t\t 3 \\ times3 , 64 \n",
              " \t\t\t\t  \\ end{aligned } \n",
              " \t\t\t\t  \\ right ] \\ times 2 $ & 56 \\ \\ [ 4ex ] \n",
              " \t\t\t\t % \\ hline \n",
              " \t\t\t\t $ \\ left [ \\ begin{aligned } \n",
              " \t\t\t\t 3 \\ times3 , 128 \\ \\ \n",
              " \t\t\t\t 3 \\ times3 , 128 \n",
              " \t\t\t\t  \\ end{aligned } \n",
              " \t\t\t\t  \\ right ] \\ times 2 $ & 28 \\ \\ [ 4ex ] \n",
              " \t\t\t\t % \\ hline \n",
              " \t\t\t\t $ \\ left [ \\ begin{aligned } \n",
              " \t\t\t\t 3 \\ times3 , 256 \\ \\ \n",
              " \t\t\t\t 3 \\ times3 , 256 \n",
              " \t\t\t\t  \\ end{aligned } \n",
              " \t\t\t\t  \\ right ] \\ times 2 $ & 14 \\ \\ [ 4ex ] \n",
              " \t\t\t\t % \\ hline \n",
              " \t\t\t\t $ \\ left [ \\ begin{aligned } \n",
              " \t\t\t\t 3 \\ times3 , 512 \\ \\ \n",
              " \t\t\t\t 3 \\ times3 , 512 \n",
              " \t\t\t\t  \\ end{aligned } \n",
              " \t\t\t\t  \\ right ] \\ times 2 $ & 7 \\ \\ \n",
              " \t\t\t  \\ end{tabular } \n",
              " \t\t  \\ end{center } \n",
              " \t\t  \\ label{tab : xxunk } \n",
              " \t\t  \\ vspace{-0.2 in } \n",
              " \t  \\ end{table } \n",
              " \n",
              " \t xxmaj the main goal $ g$ of the network is to minimize the cross - entropy of the softmax outputs with respect to the action categories ; the final output is the average of the outputs of every time - stamp frame . xxmaj the spatial goal $ r_s$ is the same as the main goal and the temporal goal $ r_t$ is to estimate the optical flow between the current and last input frames . xxmaj for each step , the network processes a new video frame and the probability distribution over action categories is predicted based on the current processed frames . \n",
              " \t \n",
              " \t xxmaj adopting xxup ltsc enables our network to process much longer sequences than previous works on action recognition in which sampling methods are used to shorten the video length . xxmaj this places greater stress on the long - range memory capacity of the model but preserves more temporal information in the original video . xxmaj in addition , due to the deep structure of xxup scs network , we adopt xxup astsgd . \n",
              " \t \n",
              " \t xxmaj tab.~ \\ ref{tab : actionresult } lists the complete results and hyper - parameters of the experiments on action recognition for xxup scs , xxup lstm and pure xxup cnn model . xxmaj we can see that our xxup scs has much better performances than xxup lstm , convlstm , and xxup cbm~ \\ cite{pang2018deep } models . xxmaj compared with xxup xxunk , the new xxup scs decouples spatial and temporal information and adjusts its focus ( on spatial or temporal information ) strategically during the learning process . xxmaj detailed analysis is shown in ` ` xxmaj ablation xxmaj study \" . \n",
              " \t  \\ begin{table } [ ] \n",
              " \t\t  \\ footnotesize \n",
              " \t\t  \\ caption{action recognition accuracy on xxmaj kinetics , and end - to - end fine - tuning on xxup ucf-101 and xxup hmdb-51 . xxmaj note that our xxup scs model applies 17 layers . ` ` xxup bb \" denotes backbone . % ` ` * \" means the average value over three splits . \n",
              " \t\t } \n",
              " \t\t  \\ renewcommand { \\ arraystretch}{1.2 } \n",
              " \t\t  \\ begin{center } \n",
              " \t\t\t  \\ begin{tabular}{c|c|c|c } \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t xxmaj architecture & xxmaj kinetics & xxup ucf-101 & xxup hmdb-51 \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ multicolumn{2}{c| } { } & \\ xxunk - trained on xxmaj kinetics } \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t xxup lstm with xxup bb ( xxup xxunk \\ cite{donahue2015long } & 53.9 & 86.8 & 49.7 \\ \\ \n",
              " \t\t\t\t % xxup xxunk \\ cite{ji20133d } & 56.1 & 79.9 & xxunk \\ \\ \n",
              " \t\t\t\t % xxmaj two - xxmaj xxunk \\ cite{simonyan2014two } & 62.8 & 93.8 & 64.3 \\ \\ \n",
              " \t\t\t\t xxup 3d - xxmaj xxunk \\ xxunk } & xxunk & 91.5 & xxunk \\ \\ \n",
              " \t\t\t\t % xxup rgb xxup xxunk \\ cite{carreira2017quo } & xxunk & 95.1 * & xxunk * \\ \\ \n",
              " \t\t\t\t xxmaj stand - alone xxup cbm~ \\ cite{pang2018deep } & xxunk & xxunk & 61.7 \\ \\ \n",
              " \t\t\t\t xxmaj stand - alone xxup scs & 61.7 & 92.6 & 65.0 \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ multicolumn{2}{c| } { } & \\ xxunk pre - trained on xxmaj kinetics } \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t 15-layer convlstm & - & 68.9 & 34.2 \\ \\ \n",
              " \t\t\t\t xxup bb ( xxup vgg ) supported xxup cbm~ \\ cite{pang2018deep } & - & xxunk & 40.2 \\ \\ \n",
              " \t\t\t\t xxup bb ( xxup vgg ) supported xxup scs & - & 82.1 & 42.5 \\ \\ \n",
              " \t\t\t\t xxup bb ( xxmaj inception ) supported xxup scs & - & 87.9 & 52.1 \\ \\ xxunk \\ hline \n",
              " \t\t\t  \\ end{tabular } \n",
              " \t\t  \\ end{center } \n",
              " \t\t  \\ label{tab : actionresult } \n",
              " \t\t  \\ vspace{-0.2 in } \n",
              " \t  \\ end{table } \n",
              " \t \n",
              " \t  \\ xxunk xxmaj study } \n",
              " \t xxmaj since our xxup scs is a universal backbone , we conduct the ablation study on this low - level feature - driven task to show the function of each component . xxmaj the results are shown in xxmaj tab.~ \\ ref{tab : xxunk } . xxmaj we first test the design of the spatial - temporal sub - task paradigm . xxmaj from the view of the performances , it leads to 1.2 \\ % accuracy boost and from xxmaj fig.~ \\ ref{fig : ablation_study } \\ textbf{a } , we can see that this paradigm makes $ h_s$ and $ h_t$ more focus on their own functions : $ h_s$ for spatial features and $ h_t$ for temporal ones . xxmaj then we remove the xxup astsgd from the training process , leading to 1.4 \\ % accuracy drop . xxmaj in xxmaj fig.~ \\ ref{fig : ablation_study } \\ textbf{b } , we show the change tendency of $ q$ , which demonstrates that the model learns spatial information first then merges temporal features into it just as we expect . xxmaj the sub - tasks and xxup astsgd are the main improvements on xxup cbm~ \\ cite{pang2018deep } , which make $ h_s$ and $ h_t$ focus on their jobs , the training process controllable , and the model perform better . xxmaj without xxup ltsc , the model can only access a short clip due to the limit of computational resource and the accuracy drops 2 \\ % . \n",
              " \t \n",
              " \t \n",
              " \t  \\ begin{table } [ ] \n",
              " \t\t  \\ footnotesize \n",
              " \t\t  \\ caption{ablation study results ( accuracy ) on action recognition task with xxmaj kinetics and xxup ucf-101 dataset . ` ` w / o \" denotes ` ` without \" . } \n",
              " \t\t  \\ renewcommand { \\ arraystretch}{1.2 } \n",
              " \t\t  \\ begin{center } \n",
              " \t\t\t  \\ begin{tabular}{c|c|c } \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t xxmaj architecture & xxmaj kinetics & xxup hmdb-51 \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t xxmaj whole xxmaj stand - alone xxup scs & 61.7 & 65.0 \\ \\ \n",
              " \t\t\t\t xxmaj stand - alone xxup scs w / o two sub - tasks & 60.5 & xxunk \\ \\ \n",
              " \t\t\t\t xxmaj stand - alone xxup scs w / o sub - task $ xxup xxunk $ only & 61.3 & 64.2 \\ \\ \n",
              " \t\t\t\t xxmaj stand - alone xxup scs w / o xxup astsgd & 60.8 & 63.2 \\ \\ \n",
              " \t\t\t\t xxmaj stand - alone xxup scs w / o xxup ltsc & 59.7 & 62.9 \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t  \\ end{tabular } \n",
              " \t\t  \\ end{center } \n",
              " \t\t  \\ label{tab : xxunk } \n",
              " \t\t  \\ vspace{-0.2 in } \n",
              " \t  \\ end{table } \n",
              " \t \n",
              " \t  \\ xxunk annotation task descriptions } \n",
              " \t xxmaj we adopt cityscapes dataset~ \\ xxunk } to conduct the outline annotation task experiments . cityscapes dataset consists of the street view images and their segmentation labels . xxmaj we crop out the xxunk of the images and only preserve 8 kinds of the xxunk : xxmaj bicycle , xxmaj bus , xxmaj person , xxmaj train , xxmaj truck , xxmaj xxunk , xxmaj car and xxmaj xxunk . xxmaj after cropping , there are xxunk training images and 10k test images . xxmaj the preserved images are resized to 224 $ \\ times$ 224 . \n",
              " \t \n",
              " \t xxmaj similar with xxmaj polygon - xxup rnn~ \\ cite{castrejon2017annotating , xxunk } , a xxup vgg model is adopted first to extract the spatial features of the original images . xxmaj then a deep xxup scs network with 15 layers takes the image features and the outline point positions of time - stamp $ t-1 $ as input for each time - stamp $ t$ and generates the outline point positions sequentially . xxmaj in short , we replace the xxup rnn part in the \n",
              " \t original xxmaj polygon - xxup rnn model with our deep xxup scs network and adjust the optimizing method with our xxup ltsc and xxup stsgd schemes . \n",
              " \t \n",
              " \t xxmaj this task is also treated as a classification task . xxmaj each position of the image is a class and the loss function is the cross - entropy of the softmax outputs with respect to the image positions ( 28 $ \\ times$ 28 $ + $ 1 , 784 positions in total and a xxunk ) . xxmaj the spatial goal $ r_s$ and temporal goal $ r_t$ are the same as the main goal : predicting the positions of the outline 's key points . xxmaj though we do not adopt different targets for $ \\ mathcal{t}^1 $ and $ \\ mathcal{t}^2 $ , the independent optimization processes and xxunk structures allow them to focus on different information . xxmaj the outline position sequence makes up a polygon area and we adopt the iou between the predicted and ground - truth polygon area as the evaluation metric . \n",
              " \t \n",
              " \t xxmaj for each foreground , the model predicts 60 outline points at most . xxmaj with a 15-layer xxup scs network , this sequence length requires huge computing resources , so we adopt the xxup ltsc mechanism to split the sequence into 6 short clips and utilize xxup astsgd to decouple the temporal and spatial training process of the deep structure . \n",
              " \t \n",
              " \t xxmaj detailed results and hyper - parameters of the experiments on outline annotation for xxup scs - xxmaj polygon - xxup rnn , xxmaj polygon - xxup rnn and xxmaj polygon - xxup rnn++ are shown in xxmaj tab.~ \\ ref{tab : xxunk } . xxmaj compared with traditional xxup lstm or xxup gru module , our model can be stacked deeply and achieve better performances with less parameters . xxmaj our xxup scs does not achieve the state - of - the - art performance because xxmaj polygon - xxup rnn++ adopts many advanced tricks to improve the performance ( including reinforcement learning , graph neural network , and attention module ) . xxmaj these tricks are not the focus of this paper . xxmaj compared with xxup cbm~ \\ cite{pang2018deep } , the new xxup scs with sub - tasks and xxup astsgd achieves better performances . \n",
              " \t  \\ begin{table } [ ] \n",
              " \t\t \n",
              " \t\t  \\ caption{performance ( iou in \\ % ) on xxmaj cityscapes validation set ( used as test set in~ \\ cite{castrejon2017annotating } ) . xxmaj note that ` ` xxmaj polyg - xxup lstm \" denotes the original xxmaj polygon - xxup rnn structure with convlstm cell , ` ` xxmaj poly - xxup gru \" for xxmaj polygon - xxup rnn with xxup gru cell , and ` ` xxmaj polyg - xxup scs \" for xxmaj polygon - xxup rnn with our xxmaj semi - xxmaj coupled xxmaj structure . } \n",
              " \t\t  \\ renewcommand { \\ arraystretch}{1.2 } \n",
              " \t\t  \\ begin{center } \n",
              " \t\t\t  \\ footnotesize \n",
              " \t\t\t  \\ begin{tabular}{c|c|c|c } \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ xxunk } & iou \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ xxunk xxmaj polygon - xxup rnn~ \\ cite{castrejon2017annotating } } & xxunk \\ \\ \n",
              " \t\t\t\t  \\ multicolumn{3}{c|}{residual xxmaj polygon - xxup rnn~ \\ cite{acuna2018efficient } } & xxunk \\ \\ \n",
              " \t\t\t\t  \\ multicolumn{3}{c|}{residual xxmaj polygon - xxup rnn + attention + xxup rl~ \\ cite{acuna2018efficient } } & 67.2 \\ \\ \n",
              " \t\t\t\t  \\ multicolumn{3}{c|}{residual xxmaj polygon - xxup rnn + attention + xxup rl + xxup xxunk \\ cite{acuna2018efficient } } & 70.2 \\ \\ \n",
              " \t\t\t\t  \\ xxunk - xxup xxunk \\ cite{acuna2018efficient } } & \\ xxunk } \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t & \\ # layers & \\ # params of xxup rnn & \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t xxmaj polyg - xxup lstm & 2 & 0.47 m & xxunk \\ \\ \n",
              " \t\t\t\t xxmaj polyg - xxup lstm & 5 & 2.94 m & 63.0 \\ \\ \n",
              " \t\t\t\t xxmaj polyg - xxup lstm & 10 & 7.07 m & xxunk \\ \\ \n",
              " \t\t\t\t xxmaj polyg - xxup lstm & 15 & 15.71 m & 46.7 \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t xxmaj polyg - xxup gru & 5 & 2.20 m & 63.8 \\ \\ \n",
              " \t\t\t\t xxmaj polyg - xxup gru & 15 & 11.78 m & xxunk \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t xxmaj polyg - xxup cbm~ \\ cite{pang2018deep } & 5 & 1.13 m & 63.1 \\ \\ \n",
              " \t\t\t\t xxmaj polyg - xxup cbm~ \\ cite{pang2018deep } & 15 & 5.85 m & 70.4 \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t xxmaj polyg - xxup scs & 2 & 0.20 m & 62.9 \\ \\ \n",
              " \t\t\t\t xxmaj polyg - xxup scs & 5 & 1.13 m & xxunk \\ \\ \n",
              " \t\t\t\t xxmaj polyg - xxup scs & 10 & 2.68 m & 68.0 \\ \\ \n",
              " \t\t\t\t xxmaj polyg - xxup scs & 15 & 5.85 m & \\ xxunk } \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t  \\ end{tabular } \n",
              " \t\t  \\ end{center } \n",
              " \t\t  \\ label{tab : xxunk } \n",
              " \t\t  \\ vspace{-0.2 in } \n",
              " \t  \\ end{table } \n",
              " \t \n",
              " \t  \\ xxunk - driving task description } \n",
              " \t \n",
              " \t xxmaj auto driving is a complex task . xxmaj completely solving it requires to conduct scene sensing , route planning , security assurance and so on . xxmaj here we simplify the task into a sequential vision task : given a short video from driver 's perspective and outputting the driving direction in the form of steering wheel angles . xxmaj the experiments are conducted on xxunk \\ xxunk } and livi - xxmaj set~ \\ xxunk } datasets . xxmaj these sets record the real driving behaviours of human drivers and there are various road conditions including town streets , highways and mountain roads . xxmaj to make the model better focus on the road , we crop out the sky and other irrelevant information from the original images . xxmaj and the final input images are resized to 192 $ \\ times$ 64 . \n",
              " \t \n",
              " \t xxmaj we compare our xxup scs network with conventional xxup lstm model and xxup cnn model . xxmaj the xxup scs structure is the same as the stand - alone model used in action recognition and the xxup lstm model adopts a xxup cnn backbone ( xxup vgg ) like xxunk \\ cite{donahue2015long } . xxmaj these two models both take a short driving video as the input and extract the temporal - spatial features . xxmaj while for xxup cnn model , we adopt the resnet~ \\ cite{he2016deep } structure , and it only takes the current driving image as input and utilizes spatial features to commit predicting . \n",
              " \t \n",
              " \t xxmaj this is a regression problem and the main goal $ g$ of the network is set to minimize the xxup mse of the predicted steering angles with the ground truth . xxmaj the same with the action recognition task , the spatial goal $ r_s$ is the same as the main goal and the temporal goal $ r_t$ is to estimate the optical flow . xxmaj we adopt sigmoid function to normalize the angles because the angles before normalization are more likely distributed around 0 and this non - linear function can , to some extent , make the distribution more uniform . xxmaj accuracy is used as the metric which is defined as : \n",
              " \t  \\ begin{align } \n",
              " \t xxmaj xxunk \\ frac { \\ xxunk \\ lfloor { \\ min ( \\ frac { \\ xxunk { \\ rm xxunk { \\ rm xxunk + \\ epsilon } , 1 ) } \\ xxunk } \n",
              " \t  \\ end{align } \n",
              " \t where $ xxup i$ is the number of the samples , $ \\ lambda$ is a threshold , and $ \\ epsilon$ is a small value to prevent the denominator from being zero . $ { \\ rm xxunk and $ { \\ rm xxunk are the predicted angle value and label angle value of sample $ i$. xxmaj in short , if the difference between predicted angle and label angle is less than the threshold , we treat it as an accurate prediction . \n",
              " \t \n",
              " \t xxmaj to predict the current driving direction , the models need to review a short history driving video ( except the xxup cnn model ) . xxmaj we adopt our xxup ltsc scheme when reviewing relative long history and we adopt xxup stsgd for the deep xxup scs networks . xxmaj we find that , adopting xxup ltsc to access more temporal information makes the model achieve better performances without increasing memory resources . xxmaj and xxup stsgd relatively improves the performances by 9 \\ % on average . xxmaj the detailed comparison results are shown in xxmaj tab.~ \\ ref{tab : drivingresult } . \n",
              " \t \n",
              " \t  \\ begin{table } [ ] \n",
              " \t\t \n",
              " \t\t  \\ xxunk - driving performance of xxup scs and baselines ( xxup cnn , xxup xxunk ) on the xxunk and livi - xxmaj set validation set . xxmaj note that ` ` $ \\ lambda$ \" denotes the angle threshold , ` ` p \" denotes the initial probability to stop the back - propagation in xxup stsgd and ` ` length \" denotes the number of observed frames . } \n",
              " \t\t  \\ renewcommand { \\ arraystretch}{1.2 } \n",
              " \t\t  \\ begin{center } \n",
              " \t\t\t  \\ footnotesize \n",
              " \t\t\t  \\ begin{tabular } { xxwrep 2 c| c } \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ xxunk model } \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ multicolumn{2}{c| } { } & \\ xxunk } & \\ xxunk } \\ \\ \n",
              " \t\t\t\t  \\ cline{3 - 8 } \n",
              " \t\t\t\t  \\ multicolumn{2}{c| } { } & $ \\ lambda$=6 & $ \\ lambda$=3 & xxup mse & $ \\ lambda$=6 & $ \\ lambda$=3 & xxup mse \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ xxunk } & p=0.0 & 31.8 & 16.9 & xxunk & xxunk & 15.9 & 0.049 \\ \\ \n",
              " \t\t\t\t & p=0.3 & 34.1 & 17.4 & xxunk & 30.5 & 16.1 & 0.048 \\ \\ \n",
              " \t\t\t\t & p=0.5 & \\ xxunk } & \\ xxunk } & \\ xxunk } & \\ xxunk } & \\ xxunk } & \\ xxunk } \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ xxunk } & p=0.0 & xxunk & 24.5 & 0.060 & 42.5 & 22.9 & 0.05 \\ \\ \n",
              " \t\t\t\t & p=0.3 & xxunk & \\ xxunk } & 0.043 & 46.9 & xxunk & 0.044 \\ \\ \n",
              " \t\t\t\t & p=0.5 & \\ xxunk } & 25.0 & \\ xxunk } & \\ xxunk } & \\ xxunk } & \\ xxunk } \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ xxunk } \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ multicolumn{2}{c| } { } & \\ xxunk } & \\ xxunk } \\ \\ \n",
              " \t\t\t\t  \\ cline{3 - 8 } \n",
              " \t\t\t\t  \\ multicolumn{2}{c| } { } & $ \\ lambda$=6 & $ \\ lambda$=3 & xxup mse & $ \\ lambda$=6 & $ \\ lambda$=3 & xxup mse \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ xxunk } & 29.2 & 15.9 & 0.052 & 27.3 & 14.5 & 0.057 \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ xxunk } & 43.1 & 23.8 & 0.056 & xxunk & xxunk & 0.058 \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ xxunk } \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ multicolumn{2}{c| } { } & \\ xxunk } & \\ multicolumn{3}{c } { } \\ \\ \n",
              " \t\t\t\t  \\ cline{3 - 5 } \n",
              " \t\t\t\t  \\ multicolumn{2}{c| } { } & $ \\ lambda$=6 & $ \\ lambda$=3 & xxup mse & \\ multicolumn{3}{c } { } \\ \\ \n",
              " \t\t\t\t  \\ cline{1 - 5 } \n",
              " \t\t\t\t  \\ xxunk } & 24.5 & 13.0 & 0.057 & \\ multicolumn{3}{c } { } \\ \\ \n",
              " \t\t\t\t  \\ xxunk } & xxunk & 25.3 & 0.056 & \\ multicolumn{3}{c } { } \\ \\ \n",
              " \t\t\t\t  \\ hline xxunk \\ end{tabular } \n",
              " \t\t  \\ end{center } \n",
              " \t\t  \\ label{tab : drivingresult } \n",
              " \t\t  \\ vspace{-0.2 in } \n",
              " \t  \\ end{table } \n",
              " \t \n",
              " \t xxmaj we adopt this experiment to show that our xxup scs can quantitatively indicate how important the temporal information is toward the final goal . xxmaj in this analysis , we set $ r_s$ and $ r_t$ to the same with the main goal . xxmaj by calculating the accuracy of $ \\ mathcal{t}^1 $ and $ \\ mathcal{t}^2 $ , we can determine the importance of temporal and spatial information in different road conditions . xxmaj the results shown in xxmaj tab.~ \\ ref{tab : xxunk } are consistent with our intuition : xxmaj on straight roads , $ \\ mathcal{t}^1 $ and $ \\ mathcal{t}^2 $ have similar performances , which reveals that the temporal information is not so important on this condition . xxmaj while on crossroads , $ \\ mathcal{t}^2 $ performs much better than $ \\ mathcal{t}^1 $ , which shows that we need more temporal information to give out steering angles . xxmaj on these four conditions , the performance gaps of $ \\ mathcal{t}^2 $ and $ \\ mathcal{t}^1 $ can be ordered as : straight roads \\ textless xxunk roads \\ textless t - xxunk \\ textless crossroads . xxmaj this is reasonable and proves that $ \\ mathcal{t}^2 $ and $ \\ mathcal{t}^1 $ focus on temporal and spatial information separately . xxmaj moreover , it preliminarily shows that how can we utilize this method to reveal the importance of temporal information on a specific sample . \n",
              " \t \n",
              " \t  \\ begin{table } [ ] \n",
              " \t\t \n",
              " \t\t  \\ caption{accuracy of $ \\ mathcal{t}^1 $ and $ \\ mathcal{t}^2 $ on livi . xxmaj comparing their performances , we can get the importance of temporal information on different road conditions . } \n",
              " \t\t  \\ renewcommand { \\ arraystretch}{1.2 } \n",
              " \t\t  \\ begin{center } \n",
              " \t\t\t  \\ footnotesize \n",
              " \t\t\t  \\ begin{tabular } { xxwrep 2 c| c } \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ multicolumn{2}{c| } { } & \\ multicolumn{2}{c|}{$ \\ mathcal{t}^1 $ } & \\ multicolumn{2}{c|}{$ \\ mathcal{t}^2 $ } & \\ multicolumn{2}{c}{$ \\ mathcal{t}^2 - \\ mathcal{t}^1 $ } \\ \\ \n",
              " \t\t\t\t  \\ cline{3 - 8 } \n",
              " \t\t\t\t  \\ multicolumn{2}{c| } { } & $ \\ lambda$=6 & $ \\ lambda$=3 & $ \\ lambda$=6 & $ \\ lambda$=3 & $ \\ lambda$=6 & $ \\ lambda$=3 \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ multirow{4 } { * } { \\ xxunk } } & xxmaj crossroads & 18.3 & 10.2 & 29.1 & 16.3 & 10.8 & 6.1 \\ \\ \n",
              " \t\t\t\t & t - junction & xxunk & 12.6 & xxunk & 17.0 & 8.8 & 4.4 \\ \\ \n",
              " \t\t\t\t & xxmaj curve road & xxunk & 17.1 & 37.6 & 20.1 & 4.7 & 3.0 \\ \\ \n",
              " \t\t\t\t & xxmaj straight road & 39.1 & xxunk & 41.7 & 21.4 & 2.6 & 0.4 \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t  \\ end{tabular } \n",
              " \t\t  \\ end{center } \n",
              " \t\t  \\ label{tab : xxunk } \n",
              " \t  \\ end{table } \n",
              " \t \n",
              " \t  \\ xxunk forecasting experiments } \n",
              " \t  \\ begin{table } [ ] \n",
              " \t\t \n",
              " \t\t  \\ caption{performance on the xxup reec-2018 validation set . xxmaj note that ` ` p \" denotes the initial probability to stop the back - propagation in xxup stsgd . } \n",
              " \t\t  \\ renewcommand { \\ arraystretch}{1.2 } \n",
              " \t\t  \\ begin{center } \n",
              " \t\t\t  \\ footnotesize \n",
              " \t\t\t  \\ begin{tabular } { xxwrep 2 c| c } \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ xxunk } & xxup mse & xxup xxunk & xxup far & xxup xxunk & xxup cor \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ xxunk \\ cite{xingjian2015convolutional } } & xxunk & xxunk & xxunk & xxunk & xxunk \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ xxunk } & p=0.0 & xxunk & xxunk & xxunk & \\ xxunk } & xxunk \\ \\ \n",
              " \t\t\t\t & p=0.3 & xxunk & xxunk & xxunk & xxunk & \\ xxunk } \\ \\ \n",
              " \t\t\t\t & p=0.5 & \\ xxunk } & \\ xxunk } & \\ xxunk } & xxunk & \\ xxunk } \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t  \\ end{tabular } \n",
              " \t\t  \\ end{center } \n",
              " \t\t  \\ label{tab : precipitationresult } \n",
              " \t\t  \\ vspace{-0.2 in } \n",
              " \t  \\ end{table } \n",
              " \t \n",
              " \t xxmaj the composite reflectance ( xxup cr ) image received by the weather radar can reflect the precipitation situation in the specific area . xxmaj by predicting the morphological changes of xxup cr in the future we can forecast the precipitation . xxmaj in this task , the models take a short period of the xxup cr images as the input and generate the future xxup cr images . xxmaj the experiments are conducted on our xxup reec-2018 dataset which contains a set of xxup cr images of xxmaj eastern xxmaj china in 2018 and the xxup cr image is recorded every 6 minutes . xxmaj for better prediction , we select the top 100 rainy days from the dataset and crop a 224 $ \\ times$ 244 pixel region as our input images . xxmaj for preprocessing , we normalize the intensity value $ xxup z$ of each pixel to $ xxup z'$ by setting $ xxup xxunk \\ xxunk \\ min ( \\ { xxmaj z_i \\ } ) } { \\ max ( \\ { xxmaj z_i \\ } ) - \\ min ( \\ { xxmaj z_i \\ } ) } $ , where $ \\ { xxmaj z_i \\ } $ is the set of intensity values of all the pixels in the input image . \n",
              " \t \n",
              " \t xxmaj in this task , we compare our xxup scs network with the convlstm network . xxmaj both of them consist of an encoder and a decoder which have the same structure . xxmaj for our model , the encoder and the decoder are 15-layer xxup scs networks while there are multi - stacked xxunk in the convlstm version . xxmaj encoders take one frame in the xxup cr sequence as input for every time - stamp and then generate the intermediate representation of the observed sequence . xxmaj decoders take the intermediate representation as well as the last xxup cr image as input and generate the xxup cr image prediction and new intermediate representation as shown in xxmaj fig.~ \\ ref{fig : experiments } d. \n",
              " \t \n",
              " \t  \\ begin{table * } [ ] \n",
              " \t\t  \\ caption{hyper - parameter settings for action recognition , outline annotation , auto driving and precipitation forecasting experiments . } \n",
              " \t\t  \\ renewcommand { \\ arraystretch}{1.2 } \n",
              " \t\t  \\ begin{center } \n",
              " \t\t\t  \\ footnotesize \n",
              " \t\t\t  \\ begin{tabular } { xxwrep 2 c| c } \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ multirow{2 } { * } { } & \\ xxunk xxmaj recognition } & \\ xxunk xxmaj annotation } & \\ xxunk xxmaj driving } & \\ xxunk xxmaj forecasting } \\ \\ \n",
              " \t\t\t\t  \\ cline{2 - 9 } \n",
              " \t\t\t\t & xxup bb supported & xxmaj stand - alone & xxup lstm & xxup scs & xxup xxunk & xxup scs & convlstm & xxup scs \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t xxmaj batch size & 16 & 40 & 8 & 4 & 128 & 128 & 8 & 4 \\ \\ \n",
              " \t\t\t\t xxmaj learning rate & 1e-4 & 1e-4 & 1e-4 & 2e-4 & 2e-4 & 1e-4 & 1e-4 & 1e-4 \\ \\ \n",
              " \t\t\t\t xxmaj backbone & \\ { xxup vgg , xxmaj inception \\ } & - & xxup vgg & xxup vgg & xxunk \\ cite{he2016deep } & - & - & - \\ \\ \n",
              " \t\t\t\t xxmaj num . layers & xxup bb layers + 15 & 17 & \\ { 2,5 10 , 15 \\ } & \\ { 2,5 10 , 15 \\ } & 18 + 1 & 15 & 15 & 15 \\ \\ \n",
              " \t\t\t\t xxmaj training method & xxup stsgd & xxup stsgd & - & xxup stsgd & xxup xxunk & - & xxup astsgd \\ \\ \n",
              " \t\t\t\t xxup ltsc setting & $ 10 \\ times 7 $ & $ 5 \\ xxunk $ & - & $ 10 \\ times 4 $ & - & - & - & - \\ \\ \n",
              " \t\t\t\t xxmaj feature dimension & 512 & 512 & 256 & 256 & 512 & 512 & 64 & 128 \\ \\ \n",
              " \t\t\t\t $ \\ lambda$ & - & - & - & - & \\ { 3 , 6 \\ } & \\ { xxunk \\ } & - & - \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t  \\ end{tabular } \n",
              " \t\t  \\ end{center } \n",
              " \t\t  \\ label{tab : hyperparameter } \n",
              " \t\t  \\ vspace{-0.2 in } \n",
              " \t  \\ end{table * } \n",
              " \t \n",
              " \t xxmaj this is a regression problem and every pixel of xxup cr image represents the reflectance intensity of a specific geographic position . xxmaj the networks are trained under the xxup mse loss function ( the main goal $ g$ is the xxup mse loss ) . xxmaj the spatial goal $ r_s$ is the same as the main goal . xxmaj the temporal goal $ r_t$ is to estimate the optical flow and pixel - wise difference between frames since every pixel has its own independent meaning : the reflectance intensity of that location . xxmaj the optical flow guides $ \\ mathcal{t}^2 $ to learn the variation of wind direction while the pixel - wise difference is designed for the local precipitation changes . xxmaj we evaluate the models using several metrics following~ \\ cite{xingjian2015convolutional } , namely , mean squared error ( xxup mse ) , critical success index ( xxup xxunk ) , false alarm rate ( xxup far ) , probability of detection ( xxup xxunk ) and correlation . xxmaj since every pixel has stand - alone meaning , we evaluate the performance at pixel level . xxmaj we convert the prediction and the label to a 0 / 1 matrix using a threshold of 0.5 and define ` ` hit \" ( prediction = xxunk ) , ` ` miss \" ( xxunk , xxunk ) , ` ` falsealarm \" ( xxunk , label = 0 ) . xxmaj then the metrics are defined as : \n",
              " \t  \\ begin{align } \n",
              " \t & { \\ rm xxup xxunk \\ frac { \\ # { \\ rm hit } } { { \\ rm \\ # hit } + { \\ rm \\ # miss } + { \\ rm \\ # falsealarm } } \\ \\ \n",
              " \t & { \\ rm xxup xxunk \\ frac { { \\ rm \\ # falsealarm } } { { \\ rm \\ # xxunk { \\ rm \\ # falsealarm } } \\ \\ \n",
              " \t & { \\ rm xxup xxunk \\ frac { { \\ rm \\ # hit } } { { \\ rm \\ # xxunk { \\ rm \\ # miss } } \\ \\ \n",
              " \t & { \\ rm xxunk \\ frac { \\ sum_{i , j } { { \\ rm xxup cr \\ _ xxmaj p}_{i , j } \\ times { \\ rm xxup cr \\ _ xxmaj xxunk , j } } } { \\ sqrt { ( \\ sum_{i , j } { { \\ rm xxup cr \\ _ xxmaj p}_{i , j}^2 } ) ( \\ sum_{i , j } { { \\ rm xxup cr \\ _ xxmaj xxunk , xxunk \\ epsilon } } \n",
              " \t  \\ end{align } \n",
              " \t where $ { \\ rm xxup cr \\ _ xxup p}$ is the predicted xxup cr image and $ { \\ rm xxup cr \\ _ xxmaj p}_{i , j}$ is the 0 / 1 value of position ( i , j ) in the xxup cr image . $ { \\ rm xxup cr \\ _ xxup l}$ is the ground - truth xxup cr image , i.e. the label . \n",
              " \t \n",
              " \t xxmaj the models take 5 xxup cr images as input and predict 5 future images . xxmaj this is not a long sequence , so we do not adopt the xxup ltsc scheme . xxup stsgd is utilized in the deep xxup scs network . xxmaj with a higher initial $ p$ , the model achieves better performance ( see details in xxmaj tab.~ \\ ref{tab : precipitationresult } ) , which indicates the important role of xxup stsgd for xxup scs . xxmaj the detailed comparison results are shown in xxmaj tab.~ \\ ref{tab : precipitationresult } . \n",
              " \t \n",
              " \t \n",
              " \t \n",
              " \t  \\ subsection{optimization } \n",
              " \t xxmaj the hyper - parameters are selected from grid searches and are listed in xxmaj tab.~ \\ ref{tab : hyperparameter } . xxmaj for all the experiments , the xxup cnn layer is initialized with the ` ` xxmaj xavier initialization \" method followed by xxmaj batch xxmaj normalization layer~ \\ xxunk } . xxmaj all networks are trained using xxmaj adam optimizer~ \\ cite{kingma2014adam } and the xxunk are pre - trained on imagenet . xxmaj for the huge memory consumption of the long sequential vision tasks , the batch size of each training step is relative small and we accumulate the parameters ' gradients of several training steps , then update the parameters together , which can speed up the training process to some extent . xxmaj in the process of back - propagation - through - time ( xxup xxunk \\ xxunk } , the gradients of xxup rnn parameters was clipped to the range [ -5 , 5 ] . xxunk \\ section{data availability } \n",
              " \t xxmaj the data that support the plots within this paper are available from the corresponding author upon reasonable request . \n",
              " \t \n",
              " \t  \\ xxunk availability } \n",
              " \t a public version of the experiment codes will be made available with this paper , linked to from our website \\ href{http : / / xxunk : / / xxunk } and \\ href{https : / / github.com / xxunk / xxmaj semi - xxmaj coupled - xxmaj structure - for - visual - xxunk - xxunk website } . \n",
              " \t \n",
              " \t  \\ xxunk } \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup d. , xxmaj ling , xxup h. , xxmaj xxunk , a \\ & xxmaj xxunk , xxup s. \n",
              " \t\t xxmaj efficient xxmaj interactive xxmaj annotation of xxmaj segmentation xxmaj datasets xxmaj with xxmaj polygon - xxup rnn++ . \n",
              " \t\t xxmaj in \\ textit{ieee xxmaj conf . xxmaj comp . xxmaj vision and xxmaj pattern xxmaj recog . } xxunk - xxunk ( 2018 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup l. , xxmaj xxunk , xxup xxunk , \\ & xxmaj xxunk , xxup j. \n",
              " \t\t xxmaj optimization methods for large - scale machine learning . \n",
              " \t\t  \\ xxunk xxmaj review } \\ xxunk } , 223 - xxunk ( 2018 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup j. \\ & xxmaj zisserman , xxup a. \n",
              " \t\t xxmaj quo xxunk , action recognition ? a new model and the kinetics dataset . \n",
              " \t\t xxmaj in \\ textit{ieee xxmaj conf . xxmaj comp . xxmaj vision and xxmaj pattern xxmaj recog . } xxunk - xxunk ( 2017 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup l. , xxmaj xxunk , xxup k. , xxmaj xxunk , xxup r. \\ & xxmaj xxunk , xxup s. \n",
              " \t\t xxmaj annotating xxmaj object xxmaj instances with a xxmaj polygon - xxup rnn . \n",
              " \t\t xxmaj in \\ textit{ieee xxmaj conf . xxmaj comp . xxmaj vision and xxmaj pattern xxmaj recog . } 2 ( 2017 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj chen , xxup y. et al . \n",
              " \t\t xxmaj lidar - video driving dataset : xxmaj learning driving policies effectively . \n",
              " \t\t xxmaj in \\ textit{ieee xxmaj conf . xxmaj comp . xxmaj vision and xxmaj pattern xxmaj recog . } xxunk - xxunk ( 2018 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup m. et al . \n",
              " \t\t xxmaj the cityscapes dataset for semantic urban scene understanding . \n",
              " \t\t xxmaj in \\ textit{ieee xxmaj conf . xxmaj comp . xxmaj vision and xxmaj pattern xxmaj recog . } xxunk - xxunk ( 2016 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup i. et al . \n",
              " \t\t a novel brain partition highlights the modular skeleton shared by structure and function . \n",
              " \t\t  \\ xxunk reports } \\ textbf{5 } , xxunk ( 2015 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup j. et al . \n",
              " \t\t xxmaj long - term recurrent convolutional networks for visual recognition and description . \n",
              " \t\t xxmaj in \\ textit{ieee xxmaj conf . xxmaj comp . xxmaj vision and xxmaj pattern xxmaj recog . } xxunk - xxunk ( 2015 ) . \n",
              " \t\t \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup c. , xxmaj fan , xxup h. , xxmaj malik , xxup j. \\ & xxmaj he , xxup k. \n",
              " \t\t slowfast networks for video recognition . \n",
              " \t\t xxmaj in \\ textit{ieee xxmaj int . xxmaj conf . xxmaj comp . xxmaj vision } xxunk - xxunk ( 2019 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxunk , xxup a. \\ & xxmaj zisserman , xxup a. \n",
              " \t\t xxmaj convolutional two - stream network fusion for video action recognition . \n",
              " \t\t xxmaj in \\ textit{ieee xxmaj conf . xxmaj comp . xxmaj vision and xxmaj pattern xxmaj recog . } xxunk - xxunk ( 2016 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup r. , xxmaj xxunk , xxup j. , xxmaj xxunk , xxup c. \\ & xxmaj zisserman , xxup a. \n",
              " \t\t xxmaj video action transformer network . \n",
              " \t\t xxmaj in \\ textit{ieee xxmaj conf . xxmaj comp . xxmaj vision and xxmaj pattern xxmaj recog . } 244 - xxunk ( 2019 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj graves , xxup a. \n",
              " \t\t xxmaj generating sequences with recurrent neural networks . \n",
              " \t\t xxmaj preprint at https : / / arxiv.org / abs / xxunk ( 2013 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj gu , xxup c. et al . \n",
              " \t\t xxup ava : a video dataset of spatio - temporally localized atomic visual actions . \n",
              " \t\t xxmaj in \\ textit{ieee xxmaj conf . xxmaj comp . xxmaj vision and xxmaj pattern xxmaj recog . } xxunk - xxunk ( 2018 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj he , xxup k. , xxmaj xxunk , xxup g. , xxmaj xxunk { \\ ' xxunk , xxup p. \\ & xxmaj xxunk , xxup r. \n",
              " \t\t xxmaj mask r - cnn . \n",
              " \t\t xxmaj in \\ textit{ieee xxmaj int . xxmaj conf . xxmaj comp . xxmaj vision } xxunk - xxunk ( 2017 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj he , xxup k. , xxmaj zhang , xxup x. , xxmaj ren , xxup s. \\ & xxmaj sun , xxup j. \n",
              " \t\t xxmaj deep residual learning for image recognition . \n",
              " \t\t xxmaj in \\ textit{ieee xxmaj conf . xxmaj comp . xxmaj vision and xxmaj pattern xxmaj recog . } xxunk - xxunk ( 2016 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup s. \\ & xxmaj schmidhuber , xxup j. \n",
              " \t\t xxmaj long short - term memory . \n",
              " \t\t  \\ xxunk xxmaj computation } \\ xxunk } , xxunk - xxunk ( 1997 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup r. , xxmaj chen , xxup c. \\ & xxmaj shah , xxup m. \n",
              " \t\t xxmaj tube convolutional neural network ( t - xxup cnn ) for action detection in videos . \n",
              " \t\t xxmaj in \\ textit{ieee xxmaj int . xxmaj conf . xxmaj comp . xxmaj vision } xxunk - xxunk ( 2017 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup s. \\ & xxmaj xxunk , xxup c. \n",
              " \t\t xxmaj batch normalization : xxmaj accelerating deep network training by reducing internal covariate shift . \n",
              " \t\t xxmaj in \\ textit{int . xxmaj conf . xxmaj machine xxmaj learning } xxunk - xxunk ( 2015 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj ji , xxup s. , xxmaj xu , xxup w. , xxmaj yang , xxup m. \\ & xxmaj yu , xxup k. \n",
              " \t\t xxup 3d convolutional neural networks for human action recognition . \n",
              " \t\t  \\ textit{ieee xxmaj trans . xxmaj pattern xxmaj analysis and xxmaj machine xxmaj intel . } \\ xxunk } , 221 - xxunk ( 2013 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj karpathy , xxup a. et al . \n",
              " \t\t xxmaj large - scale video classification with convolutional neural networks . \n",
              " \t\t xxmaj in \\ textit{ieee xxmaj conf . xxmaj comp . xxmaj vision and xxmaj pattern xxmaj recog . } xxunk - xxunk ( 2014 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj kim , xxup j. , xxmaj el - xxmaj xxunk , xxup m. \\ & xxmaj lee , xxup j. \n",
              " \t\t xxmaj residual xxup lstm : xxmaj design of a deep recurrent architecture for distant speech recognition . \n",
              " \t\t xxmaj in \\ xxunk . xxmaj int . xxmaj speech xxmaj xxunk . xxmaj xxunk . } xxunk - xxunk ( 2017 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj kingma , xxup d. \\ & xxmaj ba , xxup j. \n",
              " \t\t xxmaj adam : a method for stochastic optimization . \n",
              " \t\t xxmaj in \\ textit{int . xxmaj conf . xxmaj learning xxmaj representations } ( 2015 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup t. et al . \n",
              " \t\t xxmaj xxunk cortical xxunk cells encode specific contexts and drive context - specific fear memory . \n",
              " \t\t  \\ xxunk } \\ xxunk } , xxunk - xxunk ( 2015 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup a. , xxmaj sutskever , xxup i. \\ & xxmaj hinton , xxup g. \n",
              " \t\t xxmaj imagenet classification with deep convolutional neural networks . \n",
              " \t\t xxmaj in \\ textit{ann . xxmaj conf . xxmaj neural xxmaj inform . xxmaj proc . xxmaj sys . } xxunk - xxunk ( 2012 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup h. , xxmaj xxunk , xxup h. , xxmaj xxunk , xxup e. , xxmaj poggio , xxup t. \\ & xxmaj xxunk , xxup t. \n",
              " \t\t xxup xxunk : a large video database for human motion recognition . \n",
              " \t\t xxmaj in \\ textit{ieee xxmaj int . xxmaj conf . xxmaj comp . xxmaj vision } xxunk - xxunk ( 2011 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj levine , xxup s. , xxmaj finn , xxup c. , xxmaj darrell , xxup t. \\ & xxmaj abbeel , xxup p. \n",
              " \t\t xxmaj end - to - end training of deep visuomotor policies . \n",
              " \t\t  \\ xxunk xxmaj machine xxmaj learning xxmaj research } \\ xxunk } , 1334 - xxunk ( 2016 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj lucas , xxup xxunk \n",
              " \t\t  \\ xxunk image matching by the method of differences } ( 1986 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup s. , xxmaj xxunk , xxup l. \\ & xxmaj malik , xxup j. \n",
              " \t\t xxmaj action recognition from a distributed representation of pose and appearance . \n",
              " \t\t xxmaj in \\ textit{ieee xxmaj conf . xxmaj comp . xxmaj vision and xxmaj pattern xxmaj recog . } xxunk - xxunk ( 2011 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup m. , xxmaj xxunk , xxup g. \\ & xxmaj xxunk , xxup c. \n",
              " \t\t xxmaj spatial -- temporal interactions in the human brain . \n",
              " \t\t  \\ xxunk xxmaj brain xxmaj research } \\ xxunk } , xxunk - xxunk ( 2009 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup b. , xxmaj zha , xxup k. , xxmaj cao , xxup h. , xxmaj shi , xxup c. \\ & xxmaj lu , xxup c. \n",
              " \t\t xxmaj deep xxup rnn xxmaj framework for xxmaj visual xxmaj sequential xxmaj applications . \n",
              " \t\t xxmaj in \\ textit{ieee xxmaj conf . xxmaj comp . xxmaj vision and xxmaj pattern xxmaj recog . } 423 - xxunk ( 2019 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup xxunk et al . \n",
              " \t\t xxmaj learning representations by back - propagating errors . \n",
              " \t\t  \\ textit{cognitive modeling } \\ textbf{5 } 1 ( 1988 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup e. \\ & xxmaj xxunk , xxup g. \n",
              " \t\t xxmaj learning a driving simulator . \n",
              " \t\t xxmaj preprint at https : / / arxiv.org / abs / xxunk ( 2016 ) . \n",
              " \t\t \n",
              " \t\t  \\ bibitem{schulman2015trust } \n",
              " \t\t xxmaj schulman , xxup j. , xxmaj levine , xxup s. , xxmaj abbeel , xxup p. , xxmaj jordan , xxup m. \\ & xxmaj moritz , xxup p. \n",
              " \t\t xxmaj trust xxmaj region xxmaj policy xxmaj optimization . \n",
              " \t\t xxmaj in \\ textit{int . xxmaj conf . xxmaj machine xxmaj learning } 1889 - -1897 ( 2015 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj simonyan , xxup k. \\ & xxmaj zisserman , xxup a. \n",
              " \t\t xxmaj two - stream convolutional networks for action recognition in videos . \n",
              " \t\t xxmaj in \\ textit{ann . xxmaj conf . xxmaj neural xxmaj inform . xxmaj proc . xxmaj sys . } 568 - xxunk ( 2014 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj simonyan , xxup k. , xxmaj zisserman , xxup a. \n",
              " \t\t xxmaj very deep convolutional networks for large - scale image recognition . \n",
              " \t\t xxmaj in \\ textit{int . xxmaj conf . xxmaj learning xxmaj representations } ( 2015 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj song , xxup s. , xxmaj lan , xxup c. , xxmaj xxunk , xxup j. , xxmaj zeng , xxup w. \\ & xxmaj liu , xxup j. \n",
              " \t\t xxmaj an end - to - end spatio - temporal attention model for human action recognition from skeleton data . \n",
              " \t\t xxmaj in \\ xxunk xxmaj conf . xxmaj art . xxmaj intel . } xxunk - xxunk ( 2017 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup k. , xxmaj xxunk , xxup xxunk \\ & xxmaj shah , xxup m. \n",
              " \t\t xxup xxunk : a dataset of 101 human actions classes from videos in the wild . \n",
              " \t\t xxmaj preprint at https : / / arxiv.org / abs / xxunk ( 2012 ) . \n",
              " \t\t \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup n. , xxmaj xxunk , xxup e. \\ & xxmaj xxunk , xxup r. \n",
              " \t\t xxmaj unsupervised learning of video representations using lstms . \n",
              " \t\t xxmaj in \\ textit{int . xxmaj conf . machine learning } 843 - xxunk ( 2015 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj sutskever , xxup i. , xxmaj vinyals , xxup o. \\ & xxmaj le , xxup xxunk \n",
              " \t\t xxmaj sequence to sequence learning with neural networks . \n",
              " \t\t xxmaj in \\ textit{ann . xxmaj conf . xxmaj neural xxmaj inform . xxmaj proc . xxmaj sys . } xxunk - xxunk ( 2014 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup c. et al . \n",
              " \t\t xxmaj going deeper with convolutions . \n",
              " \t\t xxmaj in \\ textit{ieee xxmaj conf . xxmaj comp . xxmaj vision and xxmaj pattern xxmaj recog . } 1 - -9 ( 2015 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj wang , xxup h. , xxmaj xxunk , xxup a. , xxmaj schmid , xxup c. \\ & xxmaj liu xxup c. \n",
              " \t\t xxmaj action recognition by dense trajectories . \n",
              " \t\t xxmaj in \\ textit{ieee xxmaj conf . xxmaj comp . xxmaj vision and xxmaj pattern xxmaj recog . } xxunk - xxunk ( 2011 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj wang , xxup h. , xxmaj xxunk , xxup a. , xxmaj schmid , xxup c. \\ & xxmaj liu , xxup c. \n",
              " \t\t xxmaj dense trajectories and motion boundary descriptors for action recognition . \n",
              " \t\t  \\ textit{int . xxup j. xxmaj comp . xxmaj vision } \\ textbf{103 } , 60 - xxunk ( 2013 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj wang , xxup l. , xxmaj xxunk , xxup y. , xxmaj tang , xxup x. \\ & xxmaj van xxup xxunk \n",
              " \t\t xxmaj xxunk estimation using hybrid fully convolutional networks . \n",
              " \t\t  \\ textit{ieee xxmaj conf . xxmaj comp . xxmaj vision and xxmaj pattern xxmaj recog . } xxunk - xxunk ( 2016 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup p. , xxmaj xxunk , xxup z. \\ & xxmaj schmid , xxup c. \n",
              " \t\t xxmaj learning to track for spatio - temporal action localization . \n",
              " \t\t xxmaj in \\ textit{ieee xxmaj int . xxmaj conf . xxmaj comp . xxmaj vision } xxunk - xxunk ( 2015 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup xxunk et al . \n",
              " \t\t xxmaj backpropagation through time : what it does and how to do it . \n",
              " \t\t  \\ textit{proceedings of the xxup ieee } \\ xxunk } , xxunk - xxunk ( 1990 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj williams , xxup xxunk \\ & xxmaj peng , xxup j. \n",
              " \t\t xxmaj an efficient gradient - based algorithm for on - line training of recurrent network trajectories . \n",
              " \t\t  \\ xxunk xxmaj computation } \\ textbf{2 } , 490 - xxunk ( 1990 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup d. \n",
              " \t\t a xxunk of two halves . \n",
              " \t\t  \\ xxunk } \\ xxunk } , 260 - xxunk ( 2012 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj wu , xxup c. et al . \n",
              " \t\t xxmaj long - term feature banks for detailed video understanding . \n",
              " \t\t xxmaj in \\ textit{ieee xxmaj conf . xxmaj comp . xxmaj vision and xxmaj pattern xxmaj recog . } 284 - xxunk ( 2019 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj wu , xxup z. , xxmaj wang , xxup x. , xxmaj jiang , xxup y. , xxmaj ye , xxup h. \\ & xxmaj xxunk , xxup x. \n",
              " \t\t xxmaj modeling spatial - temporal clues in a hybrid deep learning framework for video classification . \n",
              " \t\t xxmaj in \\ xxunk xxmaj int . xxmaj conf . xxmaj multimedia } xxunk - xxunk ( 2015 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj shi , xxup x. et al . \n",
              " \t\t xxmaj convolutional xxup lstm network : a machine learning approach for precipitation xxunk . \n",
              " \t\t xxmaj in \\ textit{ann . xxmaj conf . xxmaj neural xxmaj inform . xxmaj proc . xxmaj sys . } xxunk - xxunk ( 2015 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj yue - xxmaj xxunk xxup xxunk et al . \n",
              " \t\t xxmaj beyond short snippets : xxmaj deep networks for video classification . \n",
              " \t\t xxmaj in \\ textit{ieee xxmaj conf . xxmaj comp . xxmaj vision and xxmaj pattern xxmaj recog . } xxunk - xxunk ( 2015 ) . xxunk \\ end{thebibliography } xxunk \\ xxunk contributions } \n",
              " \t xxup b.p. and xxup c.l. conceived the idea . xxup b.p. , xxup xxunk and xxup c.l. designed the experiments . xxup b.p. , xxup xxunk , xxup xxunk , xxup xxunk and xxup xxunk carried out programming , adjustment , and data analysis . xxup b.p. and xxup c.l. wrote the manuscript . xxup b.p. , xxup xxunk , xxup xxunk and all other authors contributed to the results analysis and commented on the manuscript . \n",
              " \t \n",
              " \t  \\ xxunk xxmaj interests } \n",
              " \t xxmaj the authors declare no competing interests . \n",
              "  \\ end{document } \n",
              " ,xxbos \\ documentclass{article } \n",
              "  \\ usepackage{fontenc , xxunk , calc , indentfirst , xxunk , graphicx , xxunk , ifthen , lineno , float , amsmath , xxunk , xxunk , booktabs , xcolor , microtype , tikz , amsthm , hyperref , url , geometry , xxunk , caption } \n",
              "  \\ usepackage[square , numbers]{natbib } \n",
              "  \\ usepackage{subcaption , bm } \n",
              "  \\ usepackage{xcolor } \n",
              " \n",
              "  \\ xxunk - xxmaj directed xxmaj planning for xxmaj habituated xxmaj agents by xxmaj active xxmaj inference xxmaj using a xxmaj variational xxmaj recurrent xxmaj neural xxmaj network } \n",
              " \n",
              "  \\ xxunk xxmaj xxunk $ \\ and xxmaj jun xxmaj xxunk } \n",
              " \n",
              "  \\ date { \\ small $ xxunk xxmaj institute of xxmaj science and xxmaj technology , \\ xxunk } \\ \\ \n",
              "  $ xxunk xxmaj institute of xxmaj science and xxmaj technology , \\ xxunk } \\ \\ \n",
              "  $ xxunk author } \n",
              " \n",
              "  \\ begin{document } \n",
              "  \\ maketitle \n",
              "  xxrep 42 % \n",
              "  \\ section*{abstract } \n",
              "  xxmaj it is crucial to ask how agents can achieve goals by generating action plans using only partial models of the world acquired through habituated sensory - motor experiences . xxmaj although many existing robotics studies use a forward model framework , there are generalization issues with high degrees of freedom . xxmaj the current study shows that the predictive coding ( xxup pc ) and active inference ( xxup aif ) frameworks , which employ a generative model , can develop better generalization by learning a prior distribution in a low dimensional latent state space representing probabilistic structures extracted from well habituated sensory - motor trajectories . xxmaj in our proposed model , learning is carried out by inferring optimal latent variables as well as synaptic weights for maximizing the evidence lower bound , while goal - directed planning is accomplished by inferring latent variables for maximizing the estimated lower bound . xxmaj our proposed model was evaluated with both simple and complex robotic tasks in simulation , which demonstrated sufficient generalization in learning with limited training data by setting an intermediate value for a regularization coefficient . xxmaj furthermore , comparative simulation results show that the proposed model outperforms a conventional forward model in goal - directed planning , due to the learned prior xxunk the search of motor plans within the range of habituated trajectories . \n",
              " \n",
              "  \\ xxunk : goal directed planning ; active inference ; predictive coding ; variational xxmaj bayes ; recurrent neural network } \n",
              " \n",
              "  xxrep 42 % \n",
              "  \\ section{introduction } \n",
              "  xxmaj it is generally assumed that agents can never access or acquire complete models of the world which they are interacting with \\ xxunk , xxunk } . xxmaj this is because the amount of experience accumulated by interacting with the world in a finite time is limited , and usually the world itself is also dynamically changing . xxmaj under such conditions , agents with higher cognitive capability , such as humans , seem to be able to generate feasible goal - directed actions by mentally imaging possible behavioral plans using only partially developed models of the world , learning from limited experiences of interaction with the world . \n",
              " \n",
              "  xxmaj how is this possible ? xxmaj in addressing this problem , the current paper proposes a novel model for goal - directed plan generation referred to as goal - directed latent variable inference ( glean ) , based on learning by leveraging two related frameworks , \\ emph{predictive coding } ( xxup pc ) \\ xxunk , xxunk , xxunk , xxunk , xxunk , xxunk , xxunk } and \\ emph{active inference } ( xxup aif ) \\ xxunk , xxunk , xxunk , xxunk , xxunk , xxunk } . xxmaj in particular , we attempt to show that agents can generate adequate goal - directed behaviors based on learning in the habituated range of the world by conducting simulation studies on the proposed model . \n",
              " \n",
              "  xxmaj in brain modeling studies , it has long been considered that the brain uses an internal generative model to predict sensory outcomes of its own actions . xxmaj in this scenario , the fit between the model 's prediction and the actual sensation can be improved in two ways . xxmaj the first is by adapting belief or intention represented by the internal state of the generative model so that the reconstruction error can be minimized \\ xxunk , xxunk , xxunk , xxunk } . xxmaj this corresponds to perception . xxmaj the second approach is by acting on the environment in a manner such that the resultant sensation can better fit with the model 's prediction \\ xxunk , xxunk , xxunk } . xxmaj the former idea has been formulated in terms of xxup pc and the latter by xxup aif . xxmaj however , these two frameworks should be considered in xxunk as perception and action are effectively two sides of the same coin in xxunk cognition . \n",
              " \n",
              "  xxmaj originally , the idea of an internal model for sensory - motor systems was investigated in the study of the forward model ( xxup fm ) \\ xxunk , xxunk , xxunk } ( see xxmaj figure \\ ref{fig : xxunk } ) . xxmaj although both xxup fm and xxup pc can predict the next latent state and associated sensory inputs , different types of conditioning on the prediction were considered . xxmaj in xxup fm , the predicted sensory state is conditioned by the current motor commands and the current latent state , while in xxup pc it is conditioned only by the current latent state . xxmaj in theory , it is possible to infer optimal motor commands for achieving desired states using xxup fm by considering additional cost functions such as xxunk minimization , torque minimization , trajectory distance minimization etc . \\ xxunk } . xxmaj in practice , however , this inference tends to produce erroneous solutions unless the predictive model learns the outcomes for all possible motor combinations , which is intractable when the motor component has a high degree of freedom . \n",
              " \n",
              "  \\ begin{figure}[!htbp ] \n",
              "  \\ centering \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.4 \\ textwidth]{figures / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : pcaif_s } } { \\ includegraphics[width=0.4 \\ textwidth]{figures / xxup pcaif_s } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ vspace{1em } \n",
              "  \\ caption { \\ textbf{(a ) } xxmaj the forward model and \\ textbf{(b ) } the predictive coding and active inference framework where $ xxunk and $ xxunk represent the current latent state and prediction of the next sensory state in terms of the exteroception and proprioception . xxmaj the predicted proprioception can then be converted into a motor control signal as necessary , such as by using an inverse model as depicted in \\ textbf{(b ) } . } \n",
              "  \\ end{figure } \n",
              " \n",
              "  xxmaj however , this may not be the case if the xxup pc and xxup aif frameworks are used in combination as shown in xxmaj figure \\ ref{fig : pcaif_s } . xxmaj in the xxup pc component , an internal model predicts both the latent state and sensory inputs in terms of the exteroception and proprioception in the next timestep by receiving the current latent state . xxmaj it can be considered that the sensory sequences are embedded in the latent state space through iterative predictive learning . xxmaj in the xxup aif component , an inverse model can be used to map the predicted sensory inputs to motor commands which can realize the predicted sensation . xxmaj such an inverse model can be implemented in a straightforward manner by , for example , a xxup pid controller wherein the necessary motor torque to generate expected movements in terms of position and velocity can be computed through error feedback between the predicted proprioception ( for e.g. , joint angles in a robot ) and the outcome . \n",
              " \n",
              "  xxmaj given a desired state to be achieved , the optimal motor command at the next timestep can be obtained by first inferring an optimal latent state in the current timestep which can generate the best fit with the desired state with the minimal error . xxmaj the obtained latent state in the current timestep is mapped to the sensory state of the proprioception and exteroception expected in the next timestep , and the proprioception is finally mapped to a motor command by the inverse model . \n",
              " \n",
              "  xxmaj if we assume that agents act on their environment not through all possible combinations of motor command sequences but only a subset of them in terms of habituated trajectories , the effective dimensionality of the sensory space can be reduced drastically . xxmaj this also results in significant reduction in the required dimensionality of the latent state space which embeds the sensory sequences through learning . \n",
              " \n",
              "  xxmaj consequently , the problem of motor planning for achieving a desired state could become tractable when the inference for an optimal latent state can be limited in its relatively low dimensional space . xxmaj the same , however , can not be applied in the case of xxup fm as the search for an optimal motor plan can not be constrained within the range of habituated motor trajectories , as explained previously . \n",
              " \n",
              "  \\ begin{figure}[!htbp ] \n",
              "  \\ centering \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : predcoding0 } } { \\ xxunk \\ textwidth]{figures / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ vspace{1em } \n",
              "  \\ caption{three different models for learning - based goal - directed motor planning . \\ textbf{(a ) } xxmaj the forward model implemented in an xxup rnn , \\ textbf{(b ) } xxup pc and xxup aif frameworks implemented in an xxup rnn using initial sensitivity by latent random variables at the initial step , either by the stochastic $ \\ xxunk or the deterministic $ \\ bm{d}_t$ , and \\ textbf{(c ) } the proposed glean scheme based on the xxup pc and xxup aif framework implemented in a variational xxup rnn . xxmaj in each case , the horizontal axis indicates progression through time ( left to right ) . xxmaj the black arrows represent computation in the forward pass , while the red arrows represent prediction error being propagated during backpropagation through time ( xxup xxunk ) . \\ label{fig : modelcompare } } \n",
              "  \\ end{figure } \n",
              " \n",
              "  xxmaj the glean scheme proposed in this paper implements the aforementioned considerations using a variational recurrent neural network ( xxup rnn ) model and tests it in learning - based robot motor planning tasks . xxmaj in the following , we briefly review how models of learning - based goal - directed planning have been studied and how such prior studies have been extended to the current work . xxmaj tani \\ xxunk } proposed a goal - directed planning scheme for a robot navigation task based on xxup fm ( see xxmaj figure \\ ref{fig : xxunk } ) . xxmaj in this model , the latent state was represented by the activity of the context units in a xxmaj jordan - type xxup rnn \\ xxunk } . xxmaj during action planning , a sequence of discrete actions $ xxunk ... xxunk such as branching or not branching at each encountered branching point in a maze environment can be inferred by minimizing the error between predicted sensory inputs at distal step $ xxunk and the sensory inputs associated with the given goal $ \\ xxunk \n",
              " \n",
              "  xxmaj xxunk et al . \\ xxunk } developed a model of learning - based planning analogous to the xxup pc and xxup aif frameworks ( see xxmaj figure \\ ref{fig : predcoding0 } ) . xxmaj in this model , the initial sensitivity characteristics of deterministic dynamic systems is used wherein diverse sensory - motor sequences experienced are embedded into a distribution of the initial latent state of an xxup rnn model through iterative learning . xxmaj as such , learning a set of sensory - motor sequences is conducted by means of adapting two different types of variables --- connectivity weights of the xxup rnn which are shared by all sequences , and the initial state which is individually adapted for each sequence . xxmaj after learning with a given initial latent state $ \\ bm{d}_0 $ , the corresponding sequence consisting of the exteroception $ v_{1 ... t}$ and the proprioception $ p_{1 ... t}$ is generated . xxmaj by feeding the predicted proprioception at each timestep $ p_t$ as the target body posture to the inverse model , the corresponding motor command $ m_t$ can be generated . xxmaj in planning mode , the initial state is inferred such that the distal state in a generated sensory - motor sequence can agree with the desired goal state with minimal error . xxmaj the inferred initial state represents an intention or belief to generate a motor program reaching the goal state . \n",
              " \n",
              "  xxmaj similar work by xxmaj choi et al . \\ xxunk } employed a deterministic xxup rnn architecture to accomplish goal - directed motor planning with visual predictions for robotic tasks by searching in this initial state space . xxmaj in this case , while the network was able demonstrate adequate generalization for simple tasks such as touching a point with a robot arm , the success rate was considerably reduced in a more complex grasp and place task . xxmaj recently , xxmaj xxunk et al . \\ cite{jung19 } extended this model by allowing random variables $ \\ xxunk $ with mean and variance to represent the initial states for the purpose of extracting a probabilistic distribution among trained sensory - motor sequences ( see xxmaj figure \\ ref{fig : predcoding0 } ) . xxmaj the experimental results using this model for a task of stacking multiple objects by a robot arm showed that this scheme of using random variables for the initial latent state is beneficial in terms of generalization in both training and motor plan generation . \n",
              " \n",
              "  xxmaj in this current paper , we propose a further development of the aforementioned model using the framework of xxup pc and xxup aif to tackle the issue of learning - based goal - directed motor planning by expanding upon the variational xxmaj bayes approach . xxmaj the main purpose of our proposed glean scheme is to enable the network to learn to extract the transition probability distribution of the latent state at each timestep as a sequence prior \\ xxunk } and to utilize it for generating goal - directed plans with improved generalization . xxmaj for this purpose , we utilize a recently proposed variational xxup rnn known as the predictive - coding inspired variational xxup rnn ( xxup pv - xxup rnn ) \\ cite{ahmadi19 } for implementing the xxup pc and xxup aif frameworks such that the latent state at each timestep is represented by both a deterministic variable $ \\ bm{d}_t$ and a random variable $ \\ xxunk as shown in xxmaj figure \\ ref{fig : xxunk } . xxmaj learning of the model is accomplished by maximizing the evidence lower bound , whereas the estimated lower bound is maximized for goal - directed motor plan generation . xxmaj both lower bounds are computed as xxunk of the accuracy term and the complexity term . a formal description of the model is given in xxmaj section \\ ref{sec : model } . \n",
              " \n",
              "  xxmaj the proposed model also uses ideas considered in development of the so - called xxmaj multiple xxmaj timescale rnns ( xxup mtrnn ) \\ xxunk } , which is built on multiple layers of xxmaj continuous xxmaj time rnns ( xxup xxunk ) \\ xxunk } wherein higher layers have slower timescale dynamics and lower layers have faster dynamics ( note that xxmaj figure \\ ref{fig : modelcompare } shows only a single layer for simplicity ) . xxmaj it has been shown that xxup mtrnn enhances development of functional hierarchy among layers . xxmaj it does so by using the timescale difference by which more abstract representations of action plans are developed in the higher layers while a more detailed representation of sensory - motor patterns develop in the lower layers \\ xxunk } . \n",
              " \n",
              "  xxmaj in xxmaj section \\ ref{sec : experiments } we evaluate glean by conducting two sets of simulated experiments . xxmaj using a minimal task set , the first experiment examines essential characteristics of the proposed model in learning to generate goal - directed plans . xxmaj in particular , we investigate the effects that regulating the strength of the complexity term in the lower bound has upon learning performance as well as goal - directed motor plan generation . xxmaj furthermore , we compare the difference in planning performance between more habituated goal states and less habituated goal states in order to examine the effect of habituation in learning on goal - directed plan generation . \n",
              " \n",
              "  xxmaj the second simulation experiment uses a more realistic robotic task employing a model of a real robot and compares the performance between three models depicted in xxmaj figure \\ ref{fig : modelcompare } : xxup fm , xxup pc + xxup aif with initial state sensitivity , and the proposed glean scheme . xxmaj these experiments will clarify how glean can generate feasible goal - directed plans and the resultant actions . xxmaj it does so by developing regions of habituation in terms of the sequence prior in the latent state space by means of learning from a limited amount of sensory - motor experiences . \n",
              " \n",
              "  xxrep 5 % \n",
              "  \\ section{model } \\ label{sec : model } \n",
              "  xxmaj in this section , we will first present an overview of the xxup pv - xxup rnn model followed by a more detailed explanation of training and planning , including formulation of the evidence lower bound and approximate lower bound used in training and planning respectively . xxmaj we do not attempt to make an exhaustive derivation of xxup pv - xxup rnn in this paper , rather we focus on the salient points and changes compared to the originally proposed model in \\ cite{ahmadi19 } . \n",
              " \n",
              "  \\ subsection{overview of xxup pv - xxup rnn } \n",
              "  xxmaj figure \\ ref{fig : gp } shows a graphical representation of xxup pv - xxup rnn as implemented in this paper . xxmaj note that for generality we denote all the output of the model as $ \\ bm{x}$. xxmaj compared to the original xxup pv - xxup rnn , we have made three key changes to the model . xxmaj the first is at $ t=1 $ , the prior distribution is fixed as a unit xxmaj gaussian ( depicted as $ \\ xxunk ) , which acts as a weighted regularization on initial state sensitivity of the network . xxmaj this is primarily to improve the stability of learning in certain edge conditions . xxmaj note that the deterministic variables are always initialized at zero at $ xxunk xxmaj in practice , the deterministic variables will tend to learn the mean of the training sequence while the stochastic variables will learn the deviations from the mean . \n",
              " \n",
              "  xxmaj secondly , bottom - up connections from lower layers to higher layers have been removed in order to simplify the model . xxmaj prediction error from lower layers is still conveyed to higher layers during back - propagation . xxmaj additionally , connections between $ \\ bm{z}$ and the output $ \\ bm{x}$ have been removed . xxmaj preliminary testing has not shown any degradation of planning performance due to this change . \n",
              " \n",
              "  xxmaj finally , connections between $ \\ bm{d}_t$ and the posterior distribution $ \\ xxunk have been removed . xxmaj thus information from the previous timestep flows between stochastic units only by how close the prior and posterior distributions are , which is regulated by the meta - prior setting . xxmaj while this change could impact learning performance , it makes inference of the adaptation variables $ \\ bm{a}$ simpler . \n",
              " \n",
              "  \\ begin{figure}[!htbp ] \n",
              "  \\ centering \n",
              "  \\ includegraphics[width=0.4 \\ textwidth]{figures / xxunk } \n",
              "  \\ caption{graphical representation of xxup pv - xxup rnn as implemented in this paper } \n",
              "  \\ label{fig : gp } \n",
              "  \\ end{figure } \n",
              " \n",
              "  xxmaj as noted previously , xxup pv - xxup rnn is a variational xxup rnn comprised of deterministic variables $ \\ bm{d}$ and stochastic variables $ \\ bm{z}$. xxmaj the model infers an approximate posterior distribution $ q$ by the prior distribution $ p$ by means of error minimization on the generated output $ \\ bm{x}$. xxmaj the parameterized prior generative model $ p _ \\ theta$ is factorized as shown in xxmaj equation \\ ref{eq : genp } . \n",
              " \n",
              "  \\ begin{equation } \\ label{eq : genp } \n",
              "  p _ \\ theta ( \\ bm{x}_{1 : t } , \\ xxunk : t } , \\ bm{z}_{1 : t } | \\ bm{d}_0 ) = \\ prod_{t=1}^t p _ { \\ theta_x } ( \\ bm{x}_t | \\ bm{d}_t ) p _ { \\ theta_d } ( \\ bm{d}_t | \\ bm{d}_{t-1 } , \\ bm{z}_t ) p _ { \\ theta_z } ( \\ bm{z}_t | \\ bm{d}_{t-1 } ) \n",
              "  \\ end{equation } \n",
              " \n",
              "  xxmaj note that unlike in the original implementation of xxup pv - xxup rnn , $ \\ bm{x}$ is not conditioned directly on $ \\ bm{z}$ , only through $ \\ bm{d}$ , which is a xxmaj dirac delta function as defined in xxmaj equation \\ ref{eq : d } . \n",
              " \n",
              "  \\ begin{equation } \\ label{eq : d } \n",
              "  \\ bm{d}_t = \n",
              "  \\ begin{cases } \n",
              "  0 & \\ text{if } t = 0 \\ \\ \n",
              "  f _ { \\ theta_d } ( \\ bm{d}_{t-1 } , \\ bm{z}_t ) & \\ text{if } t > 0 \n",
              "  \\ end{cases } \n",
              "  \\ end{equation } \n",
              " \n",
              "  $ f _ { \\ xxunk is a neural network --- xxup mtrnn is used in this paper . $ \\ bm{d}$ is then the output of the xxup mtrnn , which is the internal state $ \\ bm{h}$ after activation . xxmaj for a multi - layer xxup mtrnn in this model , $ \\ bm{h}$ is calculated as a sum of the value of the stochastic variable $ \\ bm{z}$ , the previous timestep output of the current level $ l$ and previous timestep output of the next higher level $ l+1 $ as shown in xxmaj equation \\ ref{eq : cell } . \n",
              " \n",
              "  \\ begin{equation } \\ label{eq : cell } \n",
              "  \\ begin{aligned } \n",
              "  \\ xxunk & = \\ text{tanh } ( \\ xxunk ) \\ \\ \n",
              "  \\ xxunk & = \\ left(1 - \\ frac{1 } { \\ xxunk } \\ right ) \\ xxunk } + \\ frac{1 } { \\ xxunk } \\ left ( \\ bm{w}^{l , l}_{d , d } \\ xxunk } + \\ bm{w}^{l , xxunk , d } \\ xxunk + \\ xxunk , d } \\ xxunk } \\ right ) \n",
              "  \\ end{aligned } \n",
              "  \\ end{equation } \n",
              " \n",
              "  $ \\ xxunk represent connectivity weight matrices , in this case between layers and between deterministic and stochastic units . xxmaj note that at the top layer , $ \\ xxunk , d } \\ xxunk is omitted . \n",
              " \n",
              "  xxmaj the prior distribution $ p$ of $ \\ bm{z}$ is a xxmaj gaussian distribution which depends on $ \\ xxunk , except at $ t=1 $ which does not depend on $ \\ bm{d}_0 $ and is fixed as a unit xxmaj gaussian . $ \\ bm { \\ mu}$ and $ \\ bm { \\ sigma}$ for the prior distribution are obtained from $ \\ bm{d}$ as shown in xxmaj equation \\ ref{eq : p } . \n",
              " \n",
              "  \\ begin{equation } \\ label{eq : p } \n",
              "  \\ begin{aligned } \n",
              "  p ( \\ bm{z}_1 ) & = \\ mathcal{n}(0 , i ) \\ \\ \n",
              "  p ( \\ bm{z}_t | \\ bm{d}_{t-1 } ) & = \\ mathcal{n } ( \\ bm { \\ xxunk , ( \\ bm { \\ xxunk ) \\ text { where $ xxunk $ } \\ \\ \n",
              "  \\ bm { \\ xxunk & = \\ text{tanh } ( \\ bm{w}^{l , l}_{d , z , \\ xxunk } \\ bm{d}_{t-1 } ) \\ \\ \n",
              "  \\ bm { \\ xxunk & = \\ exp ( \\ bm{w}^{l , l}_{d , z , \\ sigma^p } \\ bm{d}_{t-1 } ) \n",
              "  \\ end{aligned } \n",
              "  \\ end{equation } \n",
              " \n",
              "  xxmaj based on the reparameterization trick proposed by xxmaj kingma and xxmaj xxunk \\ cite{kingma14 } , the latent value $ \\ bm{z}$ for both prior and posterior distributions is a function of $ \\ mu$ and $ \\ sigma$ and a noise sample $ \\ epsilon \\ sim \\ mathcal{n}(0 , xxup i)$. \n",
              " \n",
              "  \\ begin{equation } \n",
              "  \\ bm{z}_t = \\ bm { \\ xxunk + \\ bm { \\ xxunk \\ times \\ epsilon \n",
              "  \\ end{equation } \n",
              " \n",
              "  xxmaj since computing the true posterior distribution is intractable , the model infers an approximate posterior $ q$ of $ \\ bm{z}$ as described in xxmaj equation \\ ref{eq : q } . xxmaj in xxup pv - xxup rnn , while sensory information $ \\ overline { \\ xxunk is not directly available to the network , an adaptation variable $ \\ bm{a}$ is used , so for each training sequence $ \\ overline { \\ xxunk : xxup t}$ there is a corresponding $ \\ xxunk : xxup t}$. $ \\ bm{a}$ is learned together with the other network parameters during training based on the prediction errors $ \\ xxunk between $ \\ bm{x}$ and $ \\ bm { \\ xxunk \n",
              " \n",
              "  \\ begin{equation } \\ label{eq : q } \n",
              "  \\ begin{aligned } \n",
              "  q ( \\ bm{z}_t | \\ bm{e}_{t : t } ) & = \\ mathcal{n } ( \\ bm { \\ xxunk , ( \\ bm { \\ xxunk ) \\ \\ \n",
              "  \\ bm { \\ xxunk & = \\ text{tanh } ( \\ bm{a}^ \\ mu_t ) \\ \\ \n",
              "  \\ bm { \\ xxunk & = \\ exp ( \\ bm{a}^ \\ sigma_t ) \n",
              "  \\ end{aligned } \n",
              "  \\ end{equation } \n",
              " \n",
              "  % % \n",
              "  \\ subsection{learning with evidence lower bound } \n",
              "  xxmaj following from xxmaj equation \\ ref{eq : genp } , we can express the marginal likelihood ( evidence ) as shown in xxmaj equation \\ ref{eq : xxunk } . xxmaj as the value of $ \\ bm{d}$ is deterministic , if we let $ \\ bm { \\ xxunk be the value of $ \\ xxunk as described by xxmaj equation \\ ref{eq : d } , then $ p _ { \\ theta_d } ( \\ bm{d}_t | \\ bm{d}_{t-1 } , \\ xxunk is equivalent to a xxmaj dirac distribution given by $ \\ delta ( \\ bm{d}_t - \\ bm { \\ xxunk , which allows the integral over $ \\ bm{d}$ to be eliminated . \n",
              "  \\ begin{equation } \\ label{eq : xxunk } \n",
              "  \\ begin{aligned } \n",
              "  p _ \\ theta ( \\ bm{x}_{1 : t } | \\ bm{d}_0 ) & = \\ int \\ int \\ prod_{t=1}^t p _ { \\ theta_x } ( \\ bm{x}_t | \\ bm{d}_t ) p _ { \\ theta_d } ( \\ bm{d}_t | \\ bm{d}_{t-1 } , \\ bm{z}_t ) p _ { \\ theta_z } ( \\ bm{z}_t | \\ bm{d}_{t-1 } ) d \\ xxunk \\ xxunk } \\ \\ \n",
              "  & = \\ int \\ int \\ prod_{t=1}^t p _ { \\ theta_x } ( \\ bm{x}_t | \\ bm { \\ tilde{d}}_t ) \\ delta ( \\ bm{d}_t - \\ bm { \\ tilde{d}}_t ) p _ { \\ theta_z } ( \\ bm{z}_t | \\ bm { \\ tilde{d}}_{t-1 } ) d \\ xxunk \\ xxunk } \\ \\ \n",
              "  & = \\ int \\ prod_{t=1}^t p _ { \\ theta_x } ( \\ bm{x}_t | \\ bm { \\ tilde{d}}_t ) p _ { \\ theta_z } ( \\ bm{z}_t | \\ bm { \\ tilde{d}}_{t-1 } ) d \\ bm{z } \n",
              "  \\ end{aligned } \n",
              "  \\ end{equation } \n",
              " \n",
              "  xxmaj factoring the integral , taking the logarithm and refactoring with the parameterized posterior distribution produces an expectation on the posterior distribution as shown in xxmaj equation \\ ref{eq : xxunk } . \n",
              " \n",
              "  \\ begin{equation } \\ label{eq : xxunk } \n",
              "  \\ begin{aligned } \n",
              "  \\ log p _ \\ theta ( \\ bm{x}_{1 : t } | \\ bm{d}_0 ) & = \\ log \\ prod_{t=1}^t \\ int p _ { \\ theta_x } ( \\ bm{x}_t | \\ bm { \\ tilde{d}}_t ) p _ { \\ theta_z } ( \\ bm{z}_t | \\ bm { \\ tilde{d}}_{t-1 } ) d \\ bm{z}_t \\ \\ \n",
              "  & = \\ sum_{t=1}^t \\ log \\ int p _ { \\ theta_x } ( \\ bm{x}_t | \\ bm { \\ tilde{d}}_t ) p _ { \\ theta_z } ( \\ bm{z}_t | \\ bm { \\ tilde{d}}_{t-1 } ) d \\ bm{z}_t \\ \\ \n",
              "  & = \\ sum_{t=1}^t \\ log \\ int p _ { \\ theta_x } ( \\ bm{x}_t | \\ bm { \\ tilde{d}}_t ) \\ frac{p _ { \\ theta_z } ( \\ bm{z}_t | \\ bm { \\ xxunk _ \\ phi ( \\ bm{z}_t | \\ bm{e}_{t : t } ) } q _ \\ phi ( \\ bm{z}_t | \\ bm{e}_{t : t } ) d \\ bm{z}_t \n",
              "  \\ end{aligned } \n",
              "  \\ end{equation } \n",
              " \n",
              "  xxmaj finally , by applying xxmaj jensen 's inequality $ \\ log xxmaj xxunk ] \\ geq e [ \\ log x]$ , the variational evidence lower bound ( xxup elbo ) $ l ( \\ theta , \\ phi)$ is given in xxmaj equation \\ ref{eq : elbo } . \n",
              " \n",
              "  \\ begin{equation } \\ label{eq : elbo } \n",
              "  l ( \\ theta , \\ phi ) = \\ sum_{t=1}^t \\ int \\ log \\ xxmaj bigg [ p _ { \\ theta_x } ( \\ bm{x}_t | \\ bm { \\ tilde{d}}_t ) \\ frac{p _ { \\ theta_z } ( \\ bm{z}_t | \\ bm { \\ xxunk _ \\ phi ( \\ bm{z}_t | \\ bm{e}_{t : t } ) } \\ xxmaj bigg ] q _ \\ phi ( \\ bm{z}_t | \\ bm{e}_{t : t } ) d \\ bm{z}_t \n",
              "  \\ end{equation } \n",
              " \n",
              "  xxmaj following the concept of free energy minimization \\ xxunk } , xxup elbo is rewritten in terms of expected log likelihood under the posterior distribution ( \\ xxunk } ) and the xxmaj kullback - xxmaj leibler divergence ( xxup kld ) between the posterior and prior distributions ( \\ emph{complexity } ) in xxmaj equation \\ ref{eq : xxunk } . xxmaj the deterministic value in the expected log likelihood is substituted with all previous stochastic variables by xxmaj equation \\ ref{eq : d } in order to allow optimization of the posterior adaptive values against the training data . xxmaj for simplicity , we omit the summation over each layer of the xxup rnn and over each training sample . \n",
              " \n",
              "  \\ begin{equation } \\ label{eq : xxunk } \n",
              "  \\ begin{aligned } \n",
              "  l ( \\ theta , \\ phi ) & = \\ sum_{t=1}^t xxmaj e_{q _ \\ phi ( \\ bm{z}_t | \\ bm{z}_{1 : t-1 } , \\ bm{e}_{t : t } ) } \\ big [ p _ { \\ theta_x } ( \\ bm{x}_t | \\ bm { \\ tilde{d}}_t ) \\ big ] - xxup d_{kl } \\ big [ q _ \\ phi ( \\ bm{z}_t | \\ bm{e}_{t : t } ) || p _ { \\ theta_z } ( \\ bm{z}_t | \\ bm { \\ tilde{d}}_{t-1 } ) \\ big ] \\ \\ \n",
              "  & = \\ underbrace { \\ sum_{t=1}^t xxmaj e_{q _ \\ phi ( \\ bm{z}_t | \\ bm{z}_{1 : t-1 } , \\ bm{e}_{t : t } ) } \\ big [ p _ { \\ theta_x } ( \\ bm{x}_t | \\ bm{z}_{1 : t } ) \\ big ] } _ \\ xxunk } - \\ xxunk } \\ big [ q _ \\ phi ( \\ bm{z}_t | \\ bm{e}_{t : t } ) || p _ { \\ theta_z } ( \\ bm{z}_t | \\ bm{z}_{1 : t-1 } ) \\ big ] } _ \\ xxunk } \n",
              "  \\ end{aligned } \n",
              "  \\ end{equation } \n",
              " \n",
              "  xxmaj intuitively , the accuracy term is calculated by the distance between the predicted output $ \\ bm{x}$ and the sensory state or ground truth $ \\ bm { \\ xxunk xxmaj in practice , this is a standard measure such as mean squared error ( xxup mse ) or xxup kld . \n",
              " \n",
              "  xxmaj in xxup pv - xxup rnn , the meta - prior $ w$ is a hyperparameter which affects the degree of regularization ( or the tendency to overfit ) . xxmaj it is similar to the $ \\ beta$ parameter in xxup vae \\ cite{kingma14 } although the effect is reversed , that is , in models that assume a prior normal distribution , a larger regularization constant implies a stronger pull toward the normal distribution , reducing complexity and reducing the tendency to overfit . xxmaj however , as xxup pv - xxup rnn the prior is conditioned on the output of previous timesteps , a larger meta - prior causes the complexity to rise as the output becomes deterministic , resulting in a tendency to overfit training samples . xxmaj during learning , the meta - prior will affect the approximate posterior distribution and cause it to deviate from the true posterior , while during inference the meta - prior will control how much the prior and approximate posterior will deviate . xxmaj we explore this effect in the following xxmaj section \\ ref{sec : experiments } . \n",
              " \n",
              "  xxmaj in this implementation of xxup pv - xxup rnn , the complexity term at $ t=1 $ is a special case where the prior distribution is a unit xxmaj gaussian $ \\ xxunk , and the initial xxmaj gaussian weight $ w_i$ controls how closely the posterior follows . xxmaj this has two effects --- firstly , the xxup rnn can be made more or less sensitive to the initial state at $ t=1 $ by adjusting the degree of regularization with a unit xxmaj gaussian . xxmaj secondly , as it is independent of the meta - prior , it avoids degenerate cases where learning of a probabilistic training set is unsuccessful due to the meta - prior forcing deterministic behavior . xxmaj from preliminary testing , we found settings of either $ w_i = 0.01 $ or $ w_i = 0.001 $ appropriate depending on the data . xxmaj additionally , in this implementation of xxup pv - xxup rnn , we use different values of $ w$ per layer $ l$. xxmaj for simplicity , summation over timesteps is omitted in xxmaj equation \\ ref{eq : lz } . \n",
              " \n",
              "  \\ begin{equation } \\ label{eq : lz } \n",
              "  \\ sum^l_{l=1 } xxunk \\ cdot xxup d_{kl } \\ big [ q _ \\ phi ( \\ bm{z}_t | \\ bm{e}_{t : t } ) || p _ { \\ theta_z } ( \\ bm{z}_t | \\ bm { \\ tilde{d}}_{t-1 } ) \\ big ] = \n",
              "  \\ begin{cases } \n",
              "  \\ sum^l_{l=1 } w_i \\ sum _ { \\ bm { \\ sigma } , \\ bm { \\ mu } \\ in \\ bm{z } } \\ log \\ frac{1 } { \\ bm { \\ sigma}^{q , l}_t } + \\ xxunk \\ bm { \\ xxunk , l}_t)^2 + ( \\ bm { \\ sigma}^{q , xxunk } - \\ frac{1}{2 } & \\ text{if } t = 1 \\ \\ \n",
              "  \\ sum^l_{l=1 } xxunk \\ sum _ { \\ bm { \\ sigma } , \\ bm { \\ mu } \\ in \\ bm{z } } \\ log \\ frac { \\ bm { \\ sigma}^{p , l}_t } { \\ bm { \\ sigma}^{q , l}_t } + \\ frac { ( \\ bm { \\ sigma}^{p , l}_t - \\ bm { \\ xxunk , l}_t)^2 + ( \\ bm { \\ sigma}^{q , xxunk ( \\ bm { \\ sigma}^{p , l}_t)^2 } - \\ frac{1}{2 } & \\ text{if } t > 1 \n",
              "  \\ end{cases } \n",
              "  \\ end{equation } \n",
              " \n",
              "  xxmaj in practice , all parameters are optimized by gradient descent , using the xxmaj adam optimizer provided by tensorflow . xxmaj we note the conditions used in our experiments in xxmaj section \\ ref{sec : experiments } . \n",
              "  % xxmaj no detail on the update steps are given , since these are handled by automatic differentiation in xxup tf \n",
              " \n",
              "  % % \n",
              "  \\ xxunk generation with glean and the estimated lower bound } \n",
              "  xxmaj plan generation uses a variation of error regression \\ xxunk } in order to infer the latent variables that minimize the error . xxmaj however , recent works that utilize error regression \\ cite{ahmadi19 , xxunk } employ a regression window in which error is minimized in order to improve future prediction ( see xxmaj figure \\ ref{fig : xxunk } ) . glean attempts to minimize the errors at the initial timestep and the goal timestep ( see xxmaj figure \\ ref{fig : gdp } ) by maximizing the \\ xxunk lower bound } , shown in xxmaj equation \\ ref{eq : xxunk } . \n",
              " \n",
              "  \\ begin{figure}[!htbp ] \n",
              "  \\ centering \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.45 \\ textwidth]{figures / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : gdp } } { \\ includegraphics[width=0.45 \\ textwidth]{figures / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ vspace{1em } \n",
              "  \\ xxunk in how error regression is employed in \\ textbf{(a ) } future sequence prediction and \\ textbf{(b ) } goal - directed planning . xxmaj solid black lines represent the forward generative model while the dashed red lines represent back - propagation through time used to update $ xxup a^ \\ emptyset$. } \n",
              "  \\ end{figure } \n",
              " \n",
              "  xxmaj compared to xxup elbo shown in xxmaj equation \\ ref{eq : elbo } , the accuracy term is now calculated as the summation of prediction error in the initial ( $ t=1 $ ) and distal ( $ t = xxup t$ ) steps . xxmaj in this work , we assume that the distal step is at a fixed point in time ; in practice , if the goal is reached early , the agent should remain stationary until the final timestep . xxmaj the complexity term is also modified such that , except for the first timestep , the posterior distribution is conditioned only on the prediction error at the goal . \n",
              " \n",
              "  \\ begin{multline } \\ label{eq : xxunk } \n",
              "  xxmaj xxunk ( \\ theta , \\ phi ) = xxmaj e_{q _ \\ phi ( \\ bm{z}_1 | \\ xxunk , \\ bm{e}_t ) } \\ big [ p _ { \\ theta_x } ( \\ bm{x}_1 | \\ bm{z}_1 ) \\ big ] + xxmaj e_{q _ \\ phi ( \\ bm{z}_t | \\ bm{e}_t ) } \\ big [ p _ { \\ theta_x } ( \\ bm{x}_t | \\ bm{z}_{1 : t } ) \\ big ] \\ \\ \n",
              "  - \\ xxmaj big ( xxup d_{kl } \\ big [ q _ \\ phi ( \\ bm{z}_1 | \\ xxunk ) || p _ { \\ theta_z } ( \\ bm{z}_1 ) \\ big ] + \\ xxunk xxup d_{kl } \\ big [ q _ \\ phi ( \\ bm{z}_t | \\ bm{e}_t ) || p _ { \\ theta_z } ( \\ bm{z}_t | \\ bm{z}_{1 : t-1 } ) \\ big ] \\ xxmaj big ) \n",
              "  \\ end{multline } \n",
              " \n",
              "  xxmaj note that while the trained model is loaded before plan generation , the adaptive variable $ \\ bm{a}$ is reset to zero ( denoted as $ \\ bm{a}^ \\ emptyset$ ) . xxmaj during plan generation , only the adaptive variable $ \\ xxunk \\ xxunk is updated , while all other parameters remain fixed . xxmaj the implementation of plan generation is largely similar to training , although for practical reasons the number of epochs is significantly reduced . xxmaj the learning rate , which we refer to as \\ xxunk adaptation rate } in the context of plan generation , is raised to compensate for this . xxmaj in addition , noise sampling is employed by having multiple $ \\ xxunk \\ xxunk sequences and selecting for plans with the highest lower bound . \n",
              " \n",
              "  \\ section{experiments } \\ label{sec : experiments } \n",
              "  xxmaj in order to test glean , we conducted two experiments with simulated agents . xxmaj the first experiment was carried out with a virtual mobile agent in a xxup 2d space in order to examine the impact of the meta - prior on learning as well as plan generation outputs . xxmaj the second experiment used a simulated 8 xxup dof arm robot carrying out a goal - directed object moving task , and compared glean to two previously mentioned models --- a forward model and a stochastic initial state xxup rnn . \n",
              " \n",
              "  xxmaj due to the computational workload of generating long sequences , particularly when executing error regression for plan generation , all plans were generated in an offline manner . xxmaj this allowed the work to be run in batches on a computer cluster . xxmaj similarly , using a simulator to collect data and test the outcomes allowed greater efficiency and automation compared to using real robots . xxmaj however , in the future , we plan to extend this work to real - time trajectory planning using a physical robot . \n",
              " \n",
              "  xxmaj as mentioned previously , we implemented xxup pv - xxup rnn and glean using tensorflow . xxmaj the xxmaj adam optimizer was used with default parameters , except for learning rate and $ \\ hat { \\ varepsilon}$ which was set to $ 1 / 10 $ of learning rate . xxmaj additionally we used random dropout of the error signal ( i.e. the prediction error $ \\ xxunk can either be $ \\ bm{x}- \\ overline { \\ xxunk or $ 0 $ ) . \n",
              " \n",
              "  xxmaj the source code for glean is publicly available at \\ url{https : / / github.com / xxunk - xxunk / glean } for both xxmaj python 2.7 + tensorflow xxunk ( as tested in this paper ) and xxmaj python xxunk + tensorflow xxunk . xxmaj the tested datasets are also included , together with instructions on how to use the software . \n",
              " \n",
              "  xxmaj for these two simulation experiments , we prepared datasets of possible trajectories wherein a portion of the trajectories were used for training of the model and the remaining held back for testing . xxmaj this provides the ground truth under various conditions including non - goal - directed and goal - directed generation . xxmaj to evaluate the performance of trajectory generation after the training , we provide both plots of trajectories for qualitative evaluation as well as tables of qualitative measures . xxmaj for goal - directed plan generation , we judge the quality of the generated outputs by comparing the trajectory to the ground truth trajectory and calculating an average root mean squared error ( xxup rmse ) value . xxmaj the error at the final timestep is also given separately as goal deviation ( xxup gd ) . xxmaj the average xxup kld between prior and posterior ( $ kld_{pq}$ ) is stated as an indication of how closely the network is following its trained prior distribution . xxmaj note this is equivalent to the complexity term without weighting by the meta - prior . \n",
              " \n",
              "  \\ subsection{experiment 1 : simulated mobile agent in a xxup 2d space } \\ xxunk } \n",
              "  xxmaj to gain a better understanding of the generative capabilities of our model , we first conduct an experiment using a simple simulated agent moving in a xxup 2d space as shown in xxmaj figure \\ ref{fig : xxunk } . xxmaj the agent 's position at a given timestep is given by xxup xy coordinates in the range $ [ 0,1]$. xxmaj the training data consists of hand drawn trajectories resampled to 30 timesteps , starting at $ [ xxunk , moving to a central ` branch point ' at approximately $ ( 0.38 , xxunk , and then proceeding with a 50 / 50 chance to one of two goal areas --- the top left centered around $ ( 0.2 , xxunk and the bottom right centered around $ ( xxunk without colliding with obstacles shown as grey areas in xxmaj figure \\ ref{fig : xxunk } , ideally while maintaining a smooth trajectory . \n",
              " \n",
              "  xxmaj the branch point is reached at approximately $ t=10 $ , with the goal reached between $ xxunk $ and $ xxunk xxmaj as the trajectories are hand drawn with a mouse , there is a varying amount of noise in each trajectory and the goal points are also distributed in a fairly uniform distribution . xxmaj the result is that while the task itself is simple ( going from start to one of goal areas ) , a habituated path of sorts is generated out of the bundle of trajectories drawn . \n",
              " \n",
              "  \\ begin{figure}[!htbp ] \n",
              "  \\ centering \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp1 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp1 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp1 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ vspace{1em } \n",
              "  \\ caption{plots of the trajectories prepared for a mobile agent generating goal - directed behaviors in xxup 2d space . \\ textbf{(a ) } xxup xy plot showing the initial position of the agent , the branch point , and the two goal areas , \\ textbf{(b ) } the plot of the x position over time , and \\ textbf{(c ) } the plot of the y position over time . xxmaj the branch point is visible at around $ xxunk \\ label{fig : xxunk } } \n",
              "  \\ end{figure } \n",
              " \n",
              "  xxmaj as noted previously , we use xxup pv - xxup rnn which itself is built on xxup mtrnn . xxmaj in this experiment , we configure the network to have two layers ( note that layer 1 is the bottom layer ) with parameters as shown in xxmaj table \\ ref{tbl : xxunk } . xxmaj neurons refer to the number of deterministic variables , while z - units refer to the number of stochastic variables . xxmaj these are kept in a xxunk ratio as in \\ cite{ahmadi19 } . $ \\ tau$ is the xxup mtrnn time constant , with shorter time constants used in the lower layers which should be more responsive , and longer time constants in the higher layers . xxmaj the network was trained for 50,000 epochs with a learning rate of 0.001 . \n",
              " \n",
              "  \\ begin{table}[!htbp ] \n",
              "  \\ xxunk - xxup rnn parameters for xxmaj experiment 1 } \\ label{tbl : xxunk } \n",
              "  \\ centering . \n",
              "  \\ begin{tabular}{ccc } \n",
              "  \\ toprule \n",
              "  & \\ xxunk layer } \\ \\ \n",
              " \t  & \\ textbf{1 } \t & \\ textbf{2 } \\ \\ \n",
              "  \\ midrule \n",
              "  xxmaj neurons $ | \\ bm{d}^l|$ \t  & 20 \t\t\t & 10 \\ \\ \n",
              "  z - units \t $ | \\ bm{z}^l|$ \t  & 2 \t\t\t & 1 \\ \\ \n",
              "  $ \\ tau$ & 4 & 8 \\ \\ \n",
              "  \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  \\ end{table } \n",
              " \n",
              "  xxmaj in order to explore how the meta - prior affects the output in terms of trajectory generation after learning , we prepared three networks trained with different meta - prior values that we have labeled ` weak ' , ` intermediate ' and ` strong ' as shown in xxmaj table \\ ref{tbl : exp1w } . \n",
              " \n",
              "  \\ begin{table}[!htbp ] \n",
              "  \\ caption{meta - prior settings for the xxup 2d experiment } \\ label{tbl : exp1w } \n",
              "  \\ centering \n",
              "  \\ begin{tabular}{ccc } \n",
              "  \\ toprule \n",
              "  & \\ xxunk layer } \\ \\ \n",
              "  \\ textbf{meta - prior setting $ w$ } & \\ textbf{1 } \t & \\ textbf{2 } \\ \\ \n",
              "  \\ midrule \n",
              "  xxmaj weak \t\t  & 0 . xxrep 4 0 1 \t\t & 0 . xxrep 5 0 5 \\ \\ \n",
              "  xxmaj intermediate & 0.01 \t\t & 0.005 \\ \\ \n",
              "  xxmaj strong & 0.2 & 0.1 \\ \\ \n",
              "  \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  \\ end{table } \n",
              " \n",
              "  \\ xxunk generation } \n",
              "  xxmaj to evaluate the ability of the network to learn to extract the probabilistic characteristics latent in the training data , we test prior generation of trajectories using the prior distribution as illustrated in xxmaj figure \\ ref{fig : xxunk } . xxmaj since there are no target outputs given and $ \\ bm{z}_1 $ is a unit xxmaj gaussian and $ \\ bm{d}_0 = 0 $ , the network is not influenced to go to a particular goal direction . xxmaj ideally , the distribution of trajectories generated in this manner should match the training data in terms of distribution between left and right goal areas as the prior generation should represent the distribution of habituated trajectories . \n",
              " \n",
              "  \\ begin{figure}[!htbp ] \n",
              "  \\ centering \n",
              "  \\ includegraphics[width=0.5 \\ textwidth]{figures / xxunk } \n",
              "  \\ caption{generation using a stochastic initial state ( unit xxmaj gaussian ) } \n",
              "  \\ label{fig : xxunk } \n",
              "  \\ end{figure } \n",
              " \n",
              "  xxmaj table \\ ref{tbl : xxunk } shows the distributions between left and right goal areas for the three networks trained with different meta - priors in comparison to the training data ( ground truth ) . xxmaj we observed that a weaker meta - prior tended to allow slightly more skew in one direction , however by inspecting the plots in xxmaj figure \\ ref{fig : priorgenw } , it is apparent that there is a large amount of noise in the trajectories generated by the weak meta - prior network ( xxmaj figure \\ ref{fig : xxunk } ) . xxmaj in particular , there are large deviations and the overall shape of the trajectories does not follow the training data accurately . \n",
              " \n",
              "  \\ begin{table}[!htbp ] \n",
              "  \\ caption{distribution of goals reached by networks with different meta - priors , after 60 prior generation sequences \\ label{tbl : xxunk } } \n",
              "  \\ centering \n",
              "  \\ begin{tabular}{ccc } \n",
              "  \\ toprule \n",
              "  \\ textbf{training meta - prior } & \\ textbf{left goal \\ % } & \\ textbf{right goal \\ % } \\ \\ \n",
              "  \\ midrule \n",
              "  xxmaj weak & xxunk & 61.7 \\ \\ \n",
              "  xxmaj intermediate & 46.7 & 53.3 \\ \\ \n",
              "  xxmaj strong & 55.0 & xxunk \\ \\ \n",
              "  \\ emph{ground truth } & \\ xxunk } & \\ xxunk } \\ \\ \n",
              "  \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  \\ end{table } \n",
              " \n",
              "  xxmaj in contrast , with a large meta - prior ( xxmaj figure \\ ref{fig : xxunk } ) , there appears to have been a failure to learn the spread of goals , particularly in the right goal area , resulting in some unexpected trajectories . xxmaj in this test , an intermediate meta - prior was best at learning the probabilistic structure of the training data . \n",
              " \n",
              "  \\ begin{figure}[!htbp ] \n",
              "  \\ centering \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp1 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              " \n",
              "  \\ vspace{1em } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp1 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp1 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp1 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ vspace{1em } \n",
              "  \\ caption{trajectory plots showing \\ textbf{(a ) } the training data ( ground truth ) , \\ textbf{(b ) } prior generation with a weak meta - prior , \\ textbf{(c ) } with an intermediate meta - prior , and \\ textbf{(d ) } with a strong meta - prior . xxmaj each plot contains 60 trajectories . \\ label{fig : priorgenw } } \n",
              "  \\ end{figure } \n",
              " \n",
              "  \\ xxunk regeneration } \n",
              "  xxmaj as described previously , xxup pv - xxup rnn learns the probabilistic structure of trajectories by embedding in either initial state sensitive deterministic dynamics or stochastic dynamics based on the meta - prior value . xxmaj this suggests that trajectories for goal - directed behaviors with multiple goals , including decision branching points , can be generated either in an initial state sensitive manner based on deterministic dynamics or in a noise - driven manner based on stochastic dynamics . \n",
              " \n",
              "  xxmaj for the purpose of examining such properties of the trained networks , we conduct a test for target regeneration of the trained trajectories in a manner similar to that originally used in \\ cite{ahmadi19 } . xxmaj in this test , we attempt to regenerate a particular target sequence from the training dataset by using the information of the latent state in the initial step . xxmaj this information was a result of the training process . \n",
              " \n",
              "  xxmaj more specifically , as illustrated in xxmaj figure \\ ref{fig : xxunk } , the prior generation is computed but with the posterior adaptation variable at $ t=1 $ , $ \\ bm{a}_1 $ , fixed to the value obtained after training on the sequence . xxmaj this results in the setting of the initial latent state values of $ xxup z_1 $ and $ d_1 $ with values for the trained sequence . \n",
              " \n",
              "  \\ begin{figure}[!htbp ] \n",
              "  \\ centering \n",
              "  \\ includegraphics[width=0.5 \\ textwidth]{figures / xxunk } \n",
              "  \\ caption{generation using a given posterior adaptation variable $ \\ bm{a}_1 $ } \n",
              "  \\ label{fig : xxunk } \n",
              "  \\ end{figure } \n",
              " \n",
              "  xxmaj in this test , we load a particular $ \\ bm{a}_1 $ adaptation value for a single training sequence that ends in the left goal ( shown in xxmaj figure \\ ref{fig : xxunk } ) as an initial state , and allow the network to generate the trajectory 60 times from the same initial state with different noise sampling in the z - units . xxmaj if the information in the initial state is sufficient to regenerate the trajectory , and the network is deterministic , the generated trajectory should always match the ground truth . xxmaj we refer to this condition as ` initial state sensitive ' . \n",
              " \n",
              "  \\ begin{table}[!htbp ] \n",
              "  \\ centering \n",
              "  \\ caption{distribution of goals reached by networks with different meta - priors , after 60 target regeneration sequences \\ label{tbl : tgtdist } } \n",
              "  \\ begin{tabular}{ccc } \n",
              "  \\ toprule \n",
              "  \\ textbf{training meta - prior } & \\ textbf{left goal \\ % } & \\ textbf{right goal \\ % } \\ \\ \n",
              "  \\ midrule \n",
              "  xxmaj weak & 56.7 & 43.3 \\ \\ \n",
              "  xxmaj intermediate & xxunk & 30.0 \\ \\ \n",
              "  xxmaj strong & 100.0 & 0.0 \\ \\ \n",
              "  \\ emph{target } & \\ xxunk } & \\ xxunk } \\ \\ \n",
              "  \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  \\ end{table } \n",
              " \n",
              "  xxmaj results obtained after 60 target regeneration runs are summarized in xxmaj table \\ ref{tbl : tgtdist } and xxmaj figure \\ ref{fig : tgtregenw } . xxmaj table \\ ref{tbl : tgtdist } shows that the weaker meta - prior networks tend to ignore the target and retain the prior distribution seen previously . xxmaj as the meta - prior increases , the distribution of goals reached xxunk towards the target . xxmaj from this , we can xxunk that a strong training meta - prior creates a network that is initial state sensitive , while networks with a weaker meta - prior do not show such a tendency . \n",
              " \n",
              "  xxmaj visually inspecting the plots in xxmaj figure \\ ref{fig : tgtregenw } shows that in comparison to the prior generation results in xxmaj figure \\ ref{fig : priorgenw } , while the overall distribution of the output from the weak and intermediate meta - prior networks have not been affected by the initial state $ \\ bm{a}_1 $ the trajectories are not as stable . xxmaj we also note that while a strong meta - prior produces a network with a strong initial state sensitivity , the result is not completely deterministic as there is still a noise component in the posterior distribution . \n",
              " \n",
              "  \\ begin{figure}[!htbp ] \n",
              "  \\ centering \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp1 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              " \n",
              "  \\ vspace{1em } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp1 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp1 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp1 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ vspace{1em } \n",
              "  \\ caption{trajectory plots showing \\ textbf{(a ) } the target ( ground truth ) , \\ textbf{(b ) } target regeneration with a weak meta - prior , \\ textbf{(c ) } target regeneration with an intermediate meta - prior , and \\ textbf{(d ) } target regeneration with a strong meta - prior . xxmaj each plot contains 60 trajectories . \\ label{fig : tgtregenw } } \n",
              "  \\ end{figure } \n",
              " \n",
              "  xxmaj to better illustrate the activity of the networks in regenerating a particular sequence given $ \\ bm{a}_1 $ at each timestep , xxmaj figure \\ ref{fig : lz } shows plots of the xxup kld at both layers while xxmaj figure \\ ref{fig : xxunk } shows plots of the $ x$ coordinates over time . \n",
              " \n",
              "  xxmaj with a strong meta - prior , a large spike in xxup kld at $ t=2 $ followed by a rapid drop to near zero is visible at both layers , due to the posterior taking a particular mean with negligible variance to reconstruct the trajectory in an initial sensitive manner . xxmaj note that at $ t=1 $ , xxup kld is regulated independently by $ w_i$ so all the networks show identical behavior . xxmaj this suggests the branching decision is taken early with a strong meta - prior in order to minimize average xxup kld . \n",
              " \n",
              "  \\ begin{figure}[!htbp ] \n",
              "  \\ centering \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp1 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp1 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp1 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ vspace{1em } \n",
              "  \\ caption{plots of xxup kld during target regeneration given a particular $ \\ bm{a}_1 $ adaptation value . \\ textbf{(a ) } xxmaj shows xxup kld for weak , intermediate and strong meta - prior in the bottom layer , \\ textbf{(b ) } shows xxup kld for weak , intermediate and strong meta - prior in the top layer . \\ textbf{(c ) } xxmaj adjusts the scale of ( b ) so the intermediate meta - prior result can be more clearly seen . xxmaj the peak in xxup kld in the intermediate meta - prior network is visible around $ xxunk xxmaj the shaded areas indicate the standard deviation of xxup kld over 60 generated trajectories . \\ label{fig : lz } } \n",
              "  \\ end{figure } \n",
              " \n",
              "  xxmaj the case with an intermediate meta - prior shows a more moderate peak in xxup kld around $ xxunk $ or $ xxunk $ , just before the branch point at $ t=10 $ , with xxup kld remaining flat toward the end . xxmaj this suggests that uncertainty in the prior increases slowly until the branch point while uncertainty in the posterior is kept smaller in order to minimize the reconstruction error . xxmaj therefore , it is considered that the branch decision is built up by slowly accumulating sampled noise in the z - units until the branch point . \n",
              " \n",
              "  xxmaj in xxmaj figure \\ ref{fig : xxunk } , we can clearly see the branch point at approximately $ xxunk xxmaj the spread of the trajectories is relatively low until the branch , after which is a larger spread of trajectories until the goal points are reached . \n",
              " \n",
              "  \\ begin{figure}[!htbp ] \n",
              "  \\ centering \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp1 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp1 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp1 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ vspace{1em } \n",
              "  \\ caption{plots of the $ x$ coordinate over time , target regeneration given a particular $ \\ bm{a}_1 $ adaptation value with \\ textbf{(a ) } a weak meta - prior , \\ textbf{(b ) } an intermediate meta - prior , and \\ textbf{(c ) } a strong meta - prior . xxmaj the branch point is visible around $ t=10 $ , except in \\ textbf{(c ) } which does not exhibit any branching behavior . \\ label{fig : xxunk } } \n",
              "  \\ end{figure } \n",
              " \n",
              "  xxmaj with a weak meta - prior , xxup kld behaves slightly differently in the two layers . xxmaj in the top layer , the xxup kld of the weak meta - prior network behaves similarly to the intermediate meta - prior network until the branch point , after which the xxup kld does not decline --- rather it continues to rise and the spread of xxup kld values also increases significantly . xxmaj in the bottom layer , xxup kld remains low until around $ xxunk $ , where there is a sudden rise in xxup kld . \n",
              " \n",
              "  xxmaj in this case , we xxunk that uncertainty in the prior continues to build even after the branch point . xxmaj this is visible in xxmaj figure \\ ref{fig : xxunk } with a number of trajectories suddenly switching from one goal to the other after the branch point . xxmaj note that due to weighting of xxup kld by the weak meta - prior , the complexity term remains small , resulting in little pressure to follow learned priors . xxmaj in addition , the high uncertainty toward the end of the sequences is likely the reason why in the following test the weak meta - prior network is able to generate trajectories that end closer to untrained goals than other networks . \n",
              " \n",
              "  \\ subsubsection{plan generation } \\ xxunk } \n",
              "  xxmaj to evaluate glean , we first took the three networks previously trained with different meta - priors and then ran plan generation to evaluate the impact of meta - prior during training on the generated motor plans . xxmaj plan generation was conducted using a test dataset containing 20 untrained sequences , with the initial xxup xy and goal xxup xy coordinates of each test sequence used to generate 20 motor plans . xxmaj the goal coordinates of the test data are taken from the same distribution as in the training data . glean was allowed to run for 500 epochs , with a plan adaptation rate ( equivalent to learning rate in training ) of 0.05 . xxmaj the generated motor plans were then compared against the ground truth sequences . \n",
              " \n",
              "  xxmaj in the following results , we present quantitative results in a table , along with the meta - prior setting for training and planning . xxmaj as plan generation using glean is by necessity a non - deterministic process , plan generation was repeated 10 times for each network , with the result being averaged over the 10 runs . xxmaj average root mean squared error ( xxup rmse ) represents how closely the generated plans match the ground truth trajectories for each goal , while the average goal deviation ( xxup gd ) represents the final distance to the goal . xxmaj for both xxup rmse and xxup gd , the standard deviation over 10 runs is given , and the lowest result is highlighted as the best . xxmaj average $ kld_{pq}$ represents the xxup kl - divergence between the prior and posterior distributions , unweighted by the meta - prior . a low average $ kld_{pq}$ indicates the generated plans follow the learned prior distribution closely , while a high average $ kld_{pq}$ indicates significant deviation from learned patterns . xxmaj qualitative results are shown in trajectory plots that show all 20 generated trajectories and can be visually compared to the training data in xxmaj figure \\ ref{fig : xxunk } . \n",
              " \n",
              "  \\ begin{table}[!htbp ] \n",
              "  \\ centering \n",
              "  \\ xxunk generation results on the 20 trajectory test set with varying meta - prior . xxmaj best result highlighted in bold \\ label{tbl : plan1 } } \n",
              "  \\ begin{tabular } { xxrep 4 c } \n",
              "  \\ toprule \n",
              "  \\ textbf{meta - prior } & \\ textbf{average $ \\ bm{kld_{pq}}$ } & \\ textbf{average xxup rmse$ \\ bm { \\ pm \\ sigma}$ } & \\ textbf{average xxup gd$ \\ bm { \\ pm \\ sigma}$ } \\ \\ \n",
              "  \\ midrule \n",
              "  xxmaj weak & xxunk & $ xxunk \\ pm xxunk $ & $ \\ xxunk \\ times xxunk } \\ pm 2.1 \\ times xxunk \\ \\ \n",
              "  xxmaj intermediate & 3.36 & $ \\ xxunk \\ pm xxunk & $ 7.8 \\ times 10^{-5 } \\ pm 1.9 \\ times 10^{-5}$ \\ \\ \n",
              "  xxmaj strong & 0.17 & $ xxunk \\ pm xxunk $ & $ 6.7 \\ times xxunk } \\ pm 8.8 \\ times 10^{-5}$ \\ \\ \n",
              "  \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  \\ end{table } \n",
              " \n",
              "  xxmaj when conducting plan generation with the three networks trained with different meta - prior values , xxmaj table \\ ref{tbl : plan1 } shows that while the intermediate meta - prior network has the lowest average xxup rmse , the weak meta - prior network has the lowest goal deviation . xxmaj as expected , the average xxup kld increases as the meta - prior weight is reduced , although we note that while the increase in xxup kld between strong and intermediate is inversely proportional to the change in meta - prior , the average xxup kld increase from intermediate to weak does not follow the same relationship . xxmaj in addition , while it appears that the weak meta - prior trades a factor of 2 reduction of average xxup rmse for a factor of 10 improvement in goal deviation , the plots in xxmaj figure \\ ref{fig : plan1 } show that the trajectories generated by the weak meta - prior network are very noisy compared to the output from the other two networks . \n",
              " \n",
              "  \\ begin{figure}[!htbp ] \n",
              "  \\ centering \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp1 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              " \n",
              "  \\ vspace{1em } \n",
              "  \\ centering \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp1 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp1 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp1 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ vspace{1em } \n",
              "  \\ caption{plots showing motor plans of the 20 test sequences . \\ textbf{(a ) } xxmaj shows the ground truth for untrained test data set , with the remaining plots generated with a \\ textbf{(b ) } weak meta - prior , \\ textbf{(c ) } intermediate meta - prior , and \\ textbf{(d ) } strong meta - prior as described in xxmaj table \\ ref{tbl : exp1w } . \\ label{fig : plan1 } } \n",
              "  \\ end{figure } \n",
              " \n",
              "  xxmaj from visual inspection of the trajectory plots compared to the ground truth ( xxmaj figure \\ ref{fig : plan1 } ) , we can additionally see that the intermediate meta - prior network tends to average the trajectories more than the strong meta - prior network that is following the training data more strongly and as a result tends to miss the goal . \n",
              "  xxmaj in summary , plans were generated with highest generalization in the case of an intermediate value for meta - prior , whereas the planned trajectories became significantly more noisy in the case with a weak meta - prior , and in the case with a strong meta - prior the trajectories could not reach the specified goals well . xxmaj in xxmaj section \\ ref{sec : discussion } , we discuss further the implications of the meta - prior setting in plan generation . \n",
              " \n",
              "  \\ subsubsection{plan generation for goals set in xxunk regions } \n",
              "  xxmaj the following test examines whether glean can achieve goals set outside of the trained regions . xxmaj figure \\ ref{fig : xxunk } shows 10 ground truth trajectories reaching goals in an untrained region which is in the middle of the left and right trained goal regions . \n",
              " \n",
              "  \\ begin{figure}[!htbp ] \n",
              "  \\ centering \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp1 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp1 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ vspace{1em } \n",
              "  \\ caption{plots showing motor plans of the 10 test sequences with goals set in an untrained region . \\ textbf{(a ) } xxmaj shows the ground truth test trajectories , and \\ textbf{(b ) } shows the results of plan generation . \\ label{fig : xxunk } } \n",
              "  \\ end{figure } \n",
              " \n",
              "  xxmaj figure \\ ref{fig : xxunk } shows the results of plan generation performed by the network trained with the intermediate meta - prior , where it is apparent that glean is not able to reach the specified goals . xxmaj in particular , it can be observed that the trajectories can not go straight at the branching point . xxmaj instead , they branch left and head towards the left goal region . xxmaj this is likely because the learned prior strongly prefers either turning left or right but not going straight at the branching point . xxmaj this result implies that glean is more likely to generate goal - directed plan trajectories within well habituated areas . \n",
              " \n",
              "  \\ subsection{experiment 2 : simulated robotic object manipulation task } \\ label{sec : xxunk } \n",
              "  xxmaj in order to test the performance of glean in a robotic environment , we prepared a simulated environment in the v - xxup rep simulator with a model of a real 8 xxup dof arm robot ( a xxmaj tokyo xxmaj robotics xxmaj xxunk xxmaj arm ) with a gripper end effector ( see xxmaj figure \\ ref{fig : exp2 } ) . xxmaj in front of the robot is a workspace of approximately 30 cm square , with two cube blocks ( 5 cm / side ) and two circles ( 5 cm diameter ) . xxmaj the robot always starts in a set home position with the gripper between and above the four objects , the blocks placed in front and behind the gripper , and the circles placed left and right of the gripper . xxmaj the positions of the objects are randomized following a xxmaj gaussian distribution , with $ \\ sigma \\ simeq xxunk . xxmaj the task is to generate a motor plan to grasp one of the blocks and place it on a disc , as well as predict the coordinates of the gripper and the two blocks . \n",
              " \n",
              "  \\ begin{figure}[!htbp ] \n",
              "  \\ setlength { \\ fboxsep}{0pt } \n",
              "  \\ centering \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox * { } { \\ fbox { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp2 / xxunk } } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox * { } { \\ fbox { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp2 / xxunk } } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox * { } { \\ fbox { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp2 / xxunk } } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ caption{simulated robot executing the grasp and place task . xxmaj in the workspace in front of the robot , there are two graspable blocks and two goal circles . xxmaj xxunk markers show the predicted positions of the gripper and the two blocks . \\ label{fig : exp2 } } \n",
              "  \\ end{figure } \n",
              " \n",
              "  xxmaj in order to achieve this , the robot is trained with 120 trajectories that involve the robot arm ( 1 ) moving forward or backward to grasp the appropriate object , then ( 2 ) carry the object to the desired goal . xxmaj figure \\ ref{fig : xxunk } shows the trajectories of the gripper in two dimensions , overlaid with an illustration of the gripper and objects . xxmaj the training data is generated by a custom kinematic routine that converts the workspace coordinates to a series of pre - recorded movements taken from our previous work with this robot . xxmaj the recorded trajectories are resampled to 80 timesteps , with padding at the end as necessary . \n",
              " \n",
              "  \\ begin{figure}[!htbp ] \n",
              "  \\ centering \n",
              "  \\ includegraphics[width=0.5 \\ textwidth]{figures / xxmaj exp2 / xxunk } \n",
              "  \\ xxunk of the gripper in two dimensions , with the mean positions of the blocks and goal circles overlaid . xxmaj dashed circles represent the standard deviation of the positions . \\ label{fig : xxunk } } \n",
              "  \\ end{figure } \n",
              " \n",
              "  xxmaj the initial state of the environment is given as the joint angles of the robot as well as the xxup 3d $ ( x , y , z)$ coordinates of the gripper and blocks ( xxunk 17 dimensions ) , while the goal is given as only the coordinates of the gripper and blocks . xxmaj using glean , a motor plan to grasp the appropriate block and take it to the correct goal is generated , along with predictions of the coordinates of the gripper and both blocks at each timestep . xxmaj at the end of the generated sequence , the robot releases the block and the control program records the distance between the centers of the block and goal circle . xxmaj if the block and goal circle overlap , the trial is considered successful . \n",
              " \n",
              "  \\ begin{figure}[!htbp ] \n",
              "  \\ centering \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxup fw } } { \\ includegraphics[width=0.4 \\ textwidth]{figures / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxup si } } { \\ includegraphics[width=0.4 \\ textwidth]{figures / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ vspace{1em } \n",
              "  \\ caption{graphical representations of \\ textbf{(a ) } the forward model ( xxup fm ) and \\ textbf{(b ) } the stochastic initial state ( xxup si ) model as implemented in this paper } \n",
              "  \\ end{figure } \n",
              " \n",
              "  xxmaj in order to compare the performance of glean against other typical trajectory planning approaches , we have implemented a forward model with xxup mtrnn ( see xxmaj figure \\ ref{fig : xxup fw } ) and a stochastic initial state xxup mtrnn ( see xxmaj figure \\ ref{fig : xxup si } ) . xxup fm , as mentioned previously , is commonly used in robotic trajectory planning and is able to predict the next sensory state given the current sensory and motor states . xxmaj for this paper , it is implemented using the same xxup mtrnn as used by glean , but with no stochastic units . xxup si is implemented similarly , although using a xxunk ratio of deterministic and stochastic units at $ t=1 $ and no stochastic units at $ xxunk $ ( as in \\ cite{jung19 } ) . xxmaj table \\ ref{tbl : xxunk } shows an overview of the network parameters for glean , xxup fm , and xxup si . \n",
              " \n",
              "  \\ begin{table}[!htbp ] \n",
              "  \\ caption{network parameters used for the simulated robot experiment for 3 different models --- glean , xxup fm , and xxup si . } \\ label{tbl : xxunk } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ begin{subtable}{0.3 \\ textwidth } \n",
              "  \\ xxunk } \n",
              "  \\ centering \n",
              "  \\ begin{tabular } { xxrep 4 c | } \n",
              "  \\ toprule \n",
              "  & \\ xxunk layer } \\ \\ \n",
              " \t  & \\ textbf{1 } \t & \\ textbf{2 } & \\ textbf{3 } \\ \\ \n",
              "  \\ midrule \n",
              "  xxmaj neurons $ | \\ bm{d}^l|$ \t  & 30 & 20 \t\t  & 10 \\ \\ \n",
              "  z - units \t $ | \\ bm{z}^l|$ & 3 & 2 \t\t  & 1 \\ \\ \n",
              "  $ \\ tau$ & 2 & 4 & 8 \\ \\ \n",
              "  \\ bottomrule \n",
              "  \\ multicolumn{4}{l } { } \\ \\ \n",
              "  \\ end{tabular } \n",
              "  \\ end{subtable } \n",
              "  % \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ begin{subtable}{0.3 \\ textwidth } \n",
              "  \\ xxunk } \n",
              "  \\ centering \n",
              "  \\ begin{tabular } { xxrep 4 c | } \n",
              "  \\ toprule \n",
              "  & \\ xxunk layer } \\ \\ \n",
              " \t  & \\ textbf{1 } \t & \\ textbf{2 } & \\ textbf{3 } \\ \\ \n",
              "  \\ midrule \n",
              "  xxmaj neurons $ | \\ bm{d}^l|$ \t  & 30 & 20 \t\t  & 10 \\ \\ \n",
              "  z - units \t $ | \\ bm{z}^l|$ & 0 & 0 \t\t  & 0 \\ \\ \n",
              "  $ \\ tau$ & 2 & 4 & 8 \\ \\ \n",
              "  \\ bottomrule \n",
              "  \\ multicolumn{4}{l } { } \\ \\ \n",
              "  \\ end{tabular } \n",
              "  \\ end{subtable } \n",
              "  % \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ begin{subtable}{0.3 \\ textwidth } \n",
              "  \\ xxunk } \n",
              "  \\ centering \n",
              "  \\ begin{tabular } { xxrep 4 c } \n",
              "  \\ toprule \n",
              "  & \\ xxunk layer } \\ \\ \n",
              " \t  & \\ textbf{1 } \t & \\ textbf{2 } & \\ textbf{3 } \\ \\ \n",
              "  \\ midrule \n",
              "  xxmaj neurons $ | \\ bm{d}^l|$ \t  & 30 & 20 \t\t  & 10 \\ \\ \n",
              "  z - units \t $ | \\ bm{z}^l|$ & 30 * & 20 * & 10 * \\ \\ \n",
              "  $ \\ tau$ & 2 & 4 & 8 \\ \\ \n",
              "  \\ bottomrule \n",
              "  \\ xxunk z - units only at $ t=1 $ } \\ \\ \n",
              "  \\ end{tabular } \n",
              "  \\ end{subtable } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ end{table } \n",
              " \n",
              "  xxmaj both xxup fm and xxup si are trained in a partially closed loop manner to improve their generative ability , blending the ground truth sensory state $ \\ bm { \\ xxunk and the predicted sensory state $ \\ xxunk as in \\ cite{jung19 } . xxmaj for xxup si , we use global norm gradient clipping with a setting of 50 to ensure the network remains stable . xxmaj note that while the forward model has thus far been depicted as operating on the motor space directly , in this comparison the forward model operates in proprioception space to match the other models . \n",
              " \n",
              "  \\ begin{equation } \n",
              "  \\ bm { \\ xxunk } = 0.9 \\ xxunk } + 0.1 \\ bm { \\ xxunk } \n",
              "  \\ end{equation } \n",
              " \n",
              "  xxmaj for this experiment , we have adjusted the meta - prior settings as shown in xxmaj table \\ ref{tbl : xxunk } . xxmaj the range of meta - prior values has been reduced significantly as this task is much more sensitive to this setting , as shown in the following results . \n",
              " \n",
              "  \\ begin{table}[!htbp ] \n",
              "  \\ caption{meta - prior settings for the simulated robot experiment } \\ label{tbl : xxunk } \n",
              "  \\ centering \n",
              "  \\ begin{tabular } { xxrep 4 c } \n",
              "  \\ toprule \n",
              "  & \\ xxunk layer } \\ \\ \n",
              "  \\ textbf{meta - prior setting $ w$ } & \\ xxunk } \t & \\ xxunk } & \\ xxunk } \\ \\ \n",
              "  \\ midrule \n",
              "  xxmaj weak \t\t  & 0.0004 & 0.0002 \t\t & 0.0001 \\ \\ \n",
              "  xxmaj intermediate & xxunk \t\t & 0.0004 & 0.0002 \\ \\ \n",
              "  xxmaj strong & 0.002 & 0.001 & 0.0005 \\ \\ \n",
              "  \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  \\ end{table } \n",
              " \n",
              "  \\ subsubsection{plan generation } \n",
              "  xxmaj as in plan generation results with the xxup 2d dataset in xxmaj section \\ xxunk } , here we use a test set of 20 untrained trajectories , with the results being averaged over 10 plan generation runs . glean was allowed to run for 1000 epochs , with a plan adaptation rate of 0.1 . xxmaj in xxmaj table \\ ref{tbl : exp2 } , we compare generated trajectories to ground truth trajectories , and here it can be xxunk again that finding an intermediate setting of the meta - prior gives the best result --- not only in terms of being close to the ground truth but in terms of success rate in accomplishing the grasp and place task in the simulator . \n",
              " \n",
              "  xxmaj in xxmaj table \\ ref{tbl : xxunk } , we summarize the results of executing the generated plans using the robot simulator --- comprising of success rate at the task as well as the average distance of the final block position from the goal , the latter only being counted in successful attempts . xxmaj as in our previous work with a similar grasping task , succeeding in this task requires high accuracy at the grasp point in the middle of the trajectory . xxmaj thus , even though the differences in the generated trajectories are relatively small , the outcomes in simulation are significantly altered . \n",
              " \n",
              "  xxmaj note that despite the weak meta - prior offering a theoretically lower goal deviation , the actual measured error at the goal is higher than the intermediate meta - prior network . xxmaj this is due to the average distance from the goal measuring from the block center to the goal center , and if the block was off - center when it was grasped , it would likely be off - center when it is placed on the goal . xxmaj due to the weak meta - prior network being less accurate during the intermediate steps , higher errors at the grasp point is likely . \n",
              " \n",
              "  \\ begin{table}[!htbp ] \n",
              "  \\ centering \n",
              "  \\ xxunk generated plans with networks trained with different meta - priors , compared with ground truth . xxmaj note that in order for the results in the following tables to be comparable to the previous experiment , the output values were rescaled to $ [ 0,1]$. xxmaj only the sensory states are compared between generated and ground truth trajectories . xxmaj best result highlighted in bold \\ label{tbl : exp2 } } \n",
              "  \\ begin{tabular } { xxrep 4 c } \n",
              "  \\ toprule \n",
              "  \\ textbf{meta - prior } & \\ textbf{average $ \\ bm{kld_{pq}}$ } & \\ textbf{average xxup rmse$ \\ pm \\ sigma$ } & \\ textbf{average xxup gd$ \\ pm \\ sigma$ } \\ \\ \n",
              "  \\ midrule \n",
              "  xxmaj weak & 12.48 & $ xxunk \\ pm xxunk $ & $ \\ xxunk \\ times 10^{-5 } \\ pm 7.4 \\ xxunk \\ \\ \n",
              "  xxmaj intermediate & 4.64 & $ \\ xxunk \\ pm xxunk & $ 6.9 \\ times 10^{-5 } \\ pm 8.6 \\ times10^{-6}$ \\ \\ \n",
              "  xxmaj strong & 2.35 & $ xxunk \\ pm xxunk $ & $ 1.3 \\ times xxunk } \\ pm 1.4 \\ times 10 xxunk \\ \\ \n",
              "  \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  \\ end{table } \n",
              " \n",
              "  \\ begin{table}[!htbp ] \n",
              "  \\ centering \n",
              "  \\ caption{simulation results of executing glean generated plans with networks trained with different meta - priors . xxmaj best result highlighted in bold \\ label{tbl : xxunk } } \n",
              "  \\ begin{tabular}{ccc } \n",
              "  \\ toprule \n",
              "  \\ textbf{meta - prior } & \\ textbf{success rate } & \\ textbf{average error at xxunk \\ pm \\ sigma$ } \\ \\ \n",
              "  \\ midrule \n",
              "  xxmaj weak & xxunk \\ % & $ 1.74 \\ pm xxunk \\ \\ \n",
              "  \\ xxunk } & \\ xxunk \\ % } & $ \\ xxunk \\ pm xxunk \\ xxunk } \\ \\ \n",
              "  xxmaj strong & 60.5 \\ % & $ 2.02 \\ pm xxunk \\ \\ \n",
              "  \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  \\ end{table } \n",
              " \n",
              "  xxmaj as an illustrative example , xxmaj figure \\ ref{fig : xxunk } shows generated plans consisting of predicted sensory and motor states given the initial environmental state and the goal sensory image . xxmaj as suggested by the overall results , glean trained with an intermediate meta - prior appears to generate trajectories that most resemble the ground truth trajectory . xxmaj while in some other tasks it is possible that the trajectory between the start and the goal is not critical , in order for the robot to successfully complete the task in this experiment accuracy is required at the point where the robot grasps the block . \n",
              " \n",
              "  \\ begin{figure}[!htbp ] \n",
              "  \\ centering \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox * { \\ label{fig : xxunk } } { \\ includegraphics[width=0.24 \\ textwidth]{figures / xxmaj exp2 / plangen / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox * { \\ label{fig : xxunk } } { \\ includegraphics[width=0.24 \\ textwidth]{figures / xxmaj exp2 / plangen / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox * { \\ label{fig : xxunk } } { \\ includegraphics[width=0.24 \\ textwidth]{figures / xxmaj exp2 / plangen / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox * { \\ label{fig : xxunk } } { \\ includegraphics[width=0.24 \\ textwidth]{figures / xxmaj exp2 / plangen / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk m } } { \\ includegraphics[width=0.24 \\ textwidth]{figures / xxmaj exp2 / plangen / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk m } } { \\ includegraphics[width=0.24 \\ textwidth]{figures / xxmaj exp2 / plangen / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk m } } { \\ includegraphics[width=0.24 \\ textwidth]{figures / xxmaj exp2 / plangen / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.24 \\ textwidth]{figures / xxmaj exp2 / plangen / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ vspace{1em } \n",
              "  \\ caption{plots showing the predicted sensory states ( top row ) and the motor plans ( bottom row ) for a given goal . xxmaj the colored lines within each plot represent a sequence of predictions for one sensory or proprioception dimension . xxmaj the columns of plots correspond to \\ textbf{(a ) } weak meta - prior , \\ textbf{(b ) } intermediate meta - prior , \\ textbf{(c ) } strong meta - prior , and \\ textbf{(d ) } ground truth . xxmaj an arrow indicates the grasp point , where the robot attempts to pick up the block . xxmaj while the exact timestep of the grasp point can vary , if the relationship between the predicted dimensions is not maintained the grasping attempt is more likely to fail . \\ label{fig : xxunk } } \n",
              "  \\ end{figure } \n",
              " \n",
              "  \\ subsection{comparison between glean , xxup fm , and xxup si } \n",
              "  xxmaj finally , we compare the plan generation performance of glean against the stochastic initial state ( xxup si ) model and the forward model ( xxup fm ) . glean in this test is represented by the intermediate meta - prior network from the previous test . xxmaj results from xxup si are averaged over 10 runs , as with glean . xxup fm is deterministic and thus some statistics such as $ kld_{pq}$ and $ \\ sigma$ are omitted . \n",
              " \n",
              "  \\ begin{table}[!htbp ] \n",
              "  \\ centering \n",
              "  \\ xxunk generation results of glean , xxup fm , and xxup si . xxmaj best result highlighted in bold \\ label{tbl : xxunk } } \n",
              "  \\ begin{tabular } { xxrep 4 c } \n",
              "  \\ toprule \n",
              "  \\ textbf{model } & \\ textbf{average $ \\ bm{kld_{pq}}$ } & \\ textbf{average xxup rmse$ \\ pm \\ sigma$ } & \\ textbf{average xxup gd$ \\ pm \\ sigma$ } \\ \\ \n",
              "  \\ midrule \n",
              "  xxmaj forward model & -- & $ xxunk $ & $ 6.8 \\ times 10^{-3}$ \\ \\ \n",
              "  xxmaj stochastic initial state & 3.32 & $ xxunk \\ pm xxunk $ & $ 7.8 \\ times 10^{-5 } \\ pm 3.3 \\ times10^{-6}$ \\ \\ \n",
              "  \\ xxunk } & 4.64 & $ \\ xxunk \\ pm xxunk & $ \\ xxunk \\ times 10^{-5 } \\ pm 8.6 \\ xxunk \\ \\ \n",
              "  \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  \\ end{table } \n",
              " \n",
              "  xxmaj from xxmaj table \\ ref{tbl : xxunk } , which evaluates the three algorithms ' planning performance compared to the ground truth , we can observe that xxup fm is the worst performer , with xxup rmse an order of magnitude and xxup gd two orders of magnitude worse than either glean or xxup si . xxmaj on the other hand , glean and xxup si are relatively close in this theoretical planning performance . xxmaj however , as summarized in xxmaj table \\ ref{tbl : xxunk } , executing the generated plans in the robot simulator demonstrates a significant advantage for glean . xxup fm is unable to generate any plausible motor plans and thus achieved no successful runs . \n",
              " \n",
              "  \\ begin{table}[!htbp ] \n",
              "  \\ centering \n",
              "  \\ caption{simulation results of executing plans generated by glean , xxup fm , and xxup si . xxmaj best result highlighted in bold \\ label{tbl : xxunk } } \n",
              "  \\ begin{tabular}{ccc } \n",
              "  \\ toprule \n",
              "  \\ textbf{model } & \\ textbf{success rate } & \\ textbf{average error at xxunk \\ pm \\ sigma$ } \\ \\ \n",
              "  \\ midrule \n",
              "  xxmaj forward model ( xxup fm ) & 0.0 \\ % & -- \\ \\ \n",
              "  xxmaj stochastic initial state ( xxup si ) & 68.0 \\ % & $ 2.02 \\ pm xxunk \\ \\ \n",
              "  \\ xxunk } & \\ xxunk \\ % } & $ \\ xxunk \\ pm xxunk \\ xxunk } \\ \\ \n",
              " \n",
              "  \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  \\ end{table } \n",
              " \n",
              "  xxmaj given that glean and xxup si were able to generate plans with successful outcomes while xxup fm had no successful plans , it is apparent that the forward model in this condition is not capable of generating goal - directed plans . xxmaj this is visible in xxmaj figure \\ ref{fig : exp2compare } , showing a comparison between generated sensory predictions and ground truth sensory states , where unlike glean and xxup si , xxup fm is unable to find any motor plan in order to generate a plausible sensory prediction . \n",
              "  % \n",
              "  \\ begin{figure}[!htbp ] \n",
              "  \\ setlength { \\ fboxsep}{0pt } \n",
              "  \\ centering \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ xxunk \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp2 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ xxunk \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp2 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ xxunk \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp2 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ vspace{1em } \n",
              "  \\ caption{comparison between the generated sensory predictions ( solid lines ) and the ground truth sensory states ( dashed lines ) for \\ textbf{(a ) } forward model , \\ textbf{(b ) } stochastic initial state , and \\ textbf{(c ) } glean \\ label{fig : exp2compare } } \n",
              "  \\ end{figure } \n",
              "  % \n",
              "  xxmaj naturally , we may ask whether the observed failure of plan generation by xxup fm is due to insufficient sensory prediction capability . xxmaj in order to examine this , one - step look ahead prediction capability in the three models were compared . xxmaj in xxup fm , one - step look ahead prediction was generated at each current timestep by providing the ground truth sensory - motor sequence inputs up to the current timestep . xxmaj the resultant sensory prediction was compared with the ground truth sensory inputs . xxmaj for glean and xxup si , one - step look ahead prediction was generated analogously . xxmaj specifically , with glean , this was done by using error regression for inferring the latent state at each timestep until the current timestep . xxmaj with xxup si , the latent state is inferred at the initial timestep only . \n",
              " \n",
              "  % \n",
              "  \\ begin{table}[!htbp ] \n",
              "  \\ caption{comparison of average errors in sensory predictions generated by glean , xxup fm , and xxup si when provided with the ground truth motor states } \\ label{tbl : exp2compare } \n",
              "  \\ centering \n",
              "  \\ begin{tabular}{cc } \n",
              "  \\ toprule \n",
              "  \\ textbf{model } & \\ textbf{average xxup rmse } \\ \\ \n",
              "  \\ midrule \n",
              "  xxmaj forward model ( xxup fm ) & xxunk \\ \\ \n",
              "  xxmaj stochastic initial state ( xxup si ) & xxunk \\ \\ \n",
              "  glean & xxunk \\ \\ \n",
              "  \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  \\ end{table } \n",
              " \n",
              "  xxmaj table \\ ref{tbl : exp2compare } shows the result of comparison among those three models . xxmaj it can be observed that the prediction capabilities of these three models are relatively similar . xxmaj in particular , by looking at a comparison of one - step ahead prediction for an example trajectory among the models as shown in xxmaj figure \\ ref{fig : xxunk } , we observe that xxup fm is able to generate adequate sensory predictions in a similar manner to xxup si and glean . xxmaj this result suggests that the failure of motor plan generation by xxup fm is not due to lack of sensory prediction capability but due to other reasons . xxmaj we speculate that this is caused by the fact that no prior knowledge or constraints exist for generating motor sequences in xxup fm . xxmaj we discuss this issue in xxmaj section \\ ref{sec : discussion } . \n",
              " \n",
              "  \\ begin{figure}[!htbp ] \n",
              "  \\ setlength { \\ fboxsep}{0pt } \n",
              "  \\ centering \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ xxunk \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp2 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ xxunk \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp2 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ xxunk \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp2 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ vspace{1em } \n",
              "  \\ caption{comparison of one - step look ahead sensory prediction ( solid lines ) and the ground truth ( dashed lines ) among three different xxunk \\ textbf{(a ) } forward model , \\ textbf{(b ) } stochastic initial state , and \\ textbf{(c ) } glean \\ label{fig : xxunk } } \n",
              "  \\ end{figure } \n",
              " \n",
              "  xxrep 42 % \n",
              "  \\ section{conclusion and xxmaj discussion } \\ label{sec : discussion } \n",
              "  xxmaj the current study proposed glean as a novel goal - directed planning scheme to investigate the problem of how agents can generate effective goal - directed plans based on learning using limited amount and range of sensory - motor experiences . glean was developed using the frameworks of predictive coding ( xxup pc ) and active inference ( xxup aif ) . xxmaj with these frameworks , learning is conducted by inferring optimal latent variables and synaptic weights for maximizing the evidence lower bound . xxmaj in a similar manner , glean accomplishes goal - directed planning by inferring optimal latent variables for maximizing the estimated lower bound . xxmaj actual implementation of glean was achieved by using the predictive coding inspired variational recurrent neural network ( xxup pv - xxup rnn ) previously proposed by our group \\ cite{ahmadi19 } . \n",
              " \n",
              "  xxmaj the model was evaluated using a simple virtual agent in xxup 2d environment and a more complex simulated robotic pick and place task . xxmaj the analysis based on the results from the first experiment revealed that the prior distribution developed initial state sensitive deterministic dynamics by increasing the complexity with a strong meta - prior . xxmaj meanwhile , it developed noisy stochastic dynamics by reducing the complexity with a weaker meta - prior . \n",
              " \n",
              "  xxmaj both experiments showed that glean produces the best performance in goal - directed planning by achieving sufficient generalization in learning when setting the meta - prior to an adequate intermediate value between the two extremes of weak and strong during the learning phase . xxmaj furthermore , it was shown that motor plans can not be generated for those goals set in xxunk regions . xxmaj this is because the learned prior tends to prevent the motor trajectory from going beyond the learned region . \n",
              " \n",
              "  xxmaj the performance of glean in goal - directed planning was compared against the forward model ( xxup fm ) and stochastic initial state model ( xxup si ) using the robotic pick and place task . xxmaj the results showed that glean outperforms the other two models , especially when considering the simulation results . xxmaj moreover , it was shown that xxup fm can not generate corresponding motor plans at all even with sufficient capability for predicting next timestep sensory inputs when provided with the current motor commands . xxmaj this outcome can be accounted for by the fact that in xxup fm the motor plan search is carried out without any learned priors for constraining generation of hypothetical motor sequences , since xxup fm does not facilitate any functions for probabilistically predicting next motor commands . \n",
              " \n",
              "  xxmaj in this circumstance , xxunk trajectories that seemingly reach given goals can be generated by arbitrarily combining motor states in sequences that happen to minimize the distal goal error . xxmaj on the other hand , in the case of glean a generative model is learned as a probabilistic mapping from the latent state in the current timestep to the proprioception in terms of the joint angles as well as the exteroception in terms of sensory state . xxmaj in this case , motor sequence plans can be inferred under the constraints of the learned prior by which goal - directed plans can be generated within the boundary of well - habituated trajectories . \n",
              " \n",
              "  xxmaj the aforementioned idea aligns well with the concept of ` ` niche construction ' ' of agents discussed in \\ xxunk } . xxmaj it is argued that agents should not attempt to learn complete global models of the world , and instead should learn local models of habituated patterns which should be feasible given that the amount of possible experiences in the world is certainly limited . xxmaj the free energy minimization principle \\ xxunk } naturally realizes this as its inherent drive for minimizing surprise places limits on plan generation as well as actions beyond the boundary of habituated space . \n",
              " \n",
              "  xxmaj another similar line of research that we have recently become aware of is model - based reinforcement learning for plan generation \\ xxunk , xxunk } . xxmaj an agent learns either deterministic \\ xxunk } or stochastic \\ xxunk } latent dynamics for predicting the sensation and reward in a similar manner to xxup fm . xxmaj the agent after learning can generate actions not by using an action policy network as is the case in model - free reinforcement learning but by planning in the latent space using an evolutionary search for maximizing the reward accumulation in the future . \n",
              " \n",
              "  xxmaj the aforementioned studies , however , could suffer from the problem of generating faulty action plans because the planning process can not be constrained by a learned action prior for preventing action space search from going beyond the learned region , as the current paper has discussed . xxmaj this problem could be solved if the model - based learning and the model - free learning components could be sufficiently combined as the latter could provide the action prior to be former . \n",
              " \n",
              "  xxmaj the current study has potential to be extended in various directions in future study . xxmaj one significant drawback in the current study is that an optimal value for meta - prior which results in the best generalization in learning and planning can be obtained only though trial and error . xxmaj although our preliminary study showed that generalization is less sensitive to the setting of the meta - prior when an ample amount of training data is used , the meta - prior should still be set within a reasonable range . xxmaj future study should explore possible measures for adapting meta - prior automatically depending the training data . \n",
              " \n",
              "  xxmaj one interesting possibility is that shifts of the meta - prior during planning could affect the quality of motor plan generation analogously to the choking effect \\ xxunk , xxunk } . xxmaj the choking effect is the tendency of xxunk experts to show performance disruption such as drops in the quality and precision of generated sensorimotor behavior . xxmaj xxunk et al . \\ xxunk } proposed that this effect can be accounted for by imprecise precision modulation during active inference for generating motor plans . xxmaj this imprecise precision modulation could take place during the inference of the latent variable , if the meta - prior in our model is set with different values during the plan generation phase compared to the optimal values used during the learning phase . xxmaj future study should explore such mechanisms in detail . \n",
              " \n",
              "  xxmaj another drawback is that the current investigation is limited to an offline plan generation processes . xxmaj extended studies should investigate how the model could deal with the problem of online planning , which requires the model to be responsive to dynamically changing environments in real time . xxmaj for this purpose , the model should be extended such that all three processes of ( 1 ) recognizing the current situation by maximizing the evidence lower bound , ( 2 ) updating current goal - directed plans based on currently recognized situation by maximizing the estimated lower bound , and ( 3 ) acting on the environment by executing the plan , to be carried out in real time , as has been demonstrated by a simulation study on the retrospective and prospective inference scheme ( xxup xxunk ) \\ xxunk } . \n",
              " \n",
              "  xxmaj in such a situation , an interesting problem to be considered is how to dynamically allocate cognitive computational resources required for real time computation of these multiple cognitive processes by adapting to the on - going situation under a resource bounded condition . xxmaj it is also important to investigate how agents can assure the minimum cognitive and behavioral competency for their survival when the optimization involved with these cognitive processes can not be guaranteed under real time constraints . xxmaj these research problems are left for future studies . \n",
              " \n",
              "  xxmaj although the current study employed supervised training schemes for acquiring the generative models , it may also be interesting if self - exploration - based learning can be introduced to the scheme . xxmaj one possible scenario for achieving this would be to incorporate the idea of intrinsic motivation \\ cite{oudeyer07 , xxunk } into the model . xxmaj with intrinsic motivation , agents tend to explore particular goals more frequently for which the success rate of achievement improves more rapidly or other goals \\ xxunk } . xxmaj the exploration can switch to other goals when the exploration of the current goal hits a plateau in its improvement . xxmaj in order to incorporate such a mechanism into glean , glean should be extended to facilitate a mechanism for learning a meta - policy \\ xxunk } to generate its own goals , some more frequently than others , by monitoring the improvement rate for successful achievement of each goal . xxmaj it may be worthwhile to examine what sort of development in generating various goal - directed behaviors , from simple to more complex , can be observed by using this scheme . \n",
              " \n",
              "  xxrep 42 % \n",
              " \n",
              "  \\ section*{acknowledgments } \n",
              "  xxmaj the authors are grateful for the help and support provided by xxmaj dr. xxmaj xxunk xxmaj ahmadi , as well as the xxmaj scientific xxmaj computing section of xxmaj research xxmaj support xxmaj division at xxup xxunk . \n",
              " \n",
              "  xxrep 42 % \n",
              " \n",
              "  \\ bibliographystyle{abbrvnat } \n",
              "  \\ xxunk } \n",
              " \n",
              "  \\ end{document } \n",
              " ,xxbos \\ documentclass{ios - xxmaj book - xxmaj article } \n",
              "  \\ xxunk } \n",
              " \n",
              "  \\ usepackage[utf8]{inputenc } \n",
              "  \\ usepackage{hyperref } \n",
              "  \\ xxunk } \n",
              " \n",
              "  \\ usepackage{mathptmx } \n",
              " \n",
              "  \\ usepackage{graphicx } \n",
              "  \\ usepackage{url } \n",
              "  \\ usepackage{amssymb } \n",
              "  % \\ usepackage{pifont}% http : / / ctan.org / pkg / pifont \n",
              "  % \\ xxunk } % for the verbatim indent \n",
              "  % \\ usepackage{framed } \n",
              "  \\ usepackage[dvipsnames]{xcolor } \n",
              "  \\ usepackage{enumerate } \n",
              "  \\ usepackage{algpseudocode , algorithm } \n",
              "  % \\ usepackage{wrapfig } \n",
              " \n",
              " \n",
              "  \\ usepackage{caption } \n",
              "  \\ usepackage{subcaption } \n",
              "  % \\ usepackage{booktabs } % xxmaj for professional looking tables \n",
              "  \\ usepackage{multirow } \n",
              "  % \\ usepackage{rotating } \n",
              "  % \\ usepackage{multicol } \n",
              "  % \\ usepackage{longtable } \n",
              "  % \\ usepackage{tabularx } \n",
              "  % \\ xxunk } \n",
              "  % \\ usepackage{tablefootnote } \n",
              " \n",
              " \n",
              " \n",
              "  \\ def \\ hb { \\ hbox to 10.7 cm { } } \n",
              " \n",
              "  \\ begin{document } \n",
              " \n",
              "  \\ pagestyle{headings } \n",
              "  \\ def \\ thepage { } \n",
              " \n",
              "  \\ begin{frontmatter } % xxmaj the preamble begins here . \n",
              " \n",
              "  % \\ xxunk } \n",
              "  \\ xxunk is this xxmaj explanation for ? \\ \\ xxmaj human xxmaj intelligence and xxmaj knowledge xxmaj graphs for explainable xxup ai } \n",
              " \n",
              "  \\ xxunk 2020 \\ xxunk 2020 \\ hb } \n",
              "  % \\ subtitle{subtitle } \n",
              " \n",
              "  \\ author { \\ xxunk } \\ xxunk } } \\ xxunk - print version of the xxmaj book xxmaj chapter accepted in : xxmaj ilaria xxmaj xxunk , xxmaj xxunk xxmaj xxunk , xxmaj pascal xxmaj xxunk ( eds . ) , xxmaj knowledge xxmaj graphs for explainable xxup ai -- xxmaj foundations , xxmaj applications and xxmaj challenges . xxmaj studies on the xxmaj semantic xxmaj web , xxmaj volume 47 , xxup ios xxmaj press , xxmaj amsterdam , xxunk \n",
              "  % \\ author[a ] { \\ xxunk } \\ xxunk \n",
              "  % \\ xxunk this if needed . } , \n",
              "  % \\ author[b ] { \\ xxunk } \\ xxunk } } \n",
              "  % and \n",
              "  % \\ author[b ] { \\ xxunk } \\ xxunk } } \n",
              " \n",
              "  \\ xxunk xxmaj xxunk } \n",
              "  \\ xxunk -- xxmaj politecnico di xxmaj milano \\ \\ xxmaj xxunk xxmaj xxunk 226 , xxunk xxmaj milano -- xxmaj italy } \n",
              "  % \\ xxunk -- xxmaj politecnico di xxmaj milano } \n",
              "  % \\ xxunk xxmaj affiliation of xxmaj second xxmaj author and xxmaj third xxmaj author } \n",
              " \n",
              "  \\ begin{abstract } \n",
              "  % \\ xxunk abstract here . } \n",
              "  explainable xxup ai focuses on generating explanations for the output of an xxup ai algorithm to a user , usually a decision - maker . xxmaj such user needs to interpret the xxup ai system in order to decide whether to trust the machine outcome . xxmaj when addressing this challenge , therefore , proper attention should be given to produce explanations that are \\ xxunk } by the target community of users . \n",
              " \n",
              "  xxmaj in this chapter , we claim for the need to better investigate what constitutes a \\ emph{human explanation } , i.e. a justification of the machine behaviour that is interpretable and actionable by the human decision makers . xxmaj in particular , we focus on the contributions that \\ emph{human xxmaj intelligence } can bring to explainable xxup ai , especially in conjunction with the exploitation of xxmaj knowledge xxmaj graphs . \n",
              " \n",
              "  xxmaj indeed , we call for a better interplay between xxmaj knowledge xxmaj representation and xxmaj reasoning , xxmaj social xxmaj sciences , xxmaj human xxmaj computation and xxmaj human - xxmaj machine xxmaj cooperation research -- as already explored in other xxup ai branches -- in order to support the goal of explainable xxup ai with the adoption of a \\ emph{human - in - the - xxmaj loop } approach . \n",
              "  \\ end{abstract } \n",
              " \n",
              "  \\ begin{keyword } \n",
              "  xxmaj explainability \\ sep xxmaj human xxmaj intelligence \\ sep xxmaj human xxmaj computation \\ sep xxmaj human - in - the - xxmaj loop \\ sep xxmaj human - xxmaj machine xxmaj cooperation \\ sep xxmaj knowledge xxmaj graphs \n",
              "  \\ end{keyword } \n",
              "  \\ end{frontmatter } \n",
              " \n",
              "  \\ xxunk 2020 \\ xxunk 2020 \\ hb } \n",
              "  % \\ thispagestyle{empty } \n",
              "  % \\ pagestyle{empty } \n",
              " \n",
              "  xxrep 96 % \n",
              "  \\ section{introduction } \\ label{sec : intro } \n",
              " \n",
              "  % xxmaj modeling ( as in xxup ml ) needs humans ( slide 23 ) \n",
              "  xxmaj the recent xxunk of xxmaj machine xxmaj learning and xxmaj artificial xxmaj intelligence approaches brought a new wave of interest in such methods and technologies . xxmaj autonomous agents and automatic systems are now available and more affordable than before , but , if we relied only on popular news and communication , we would tend to think that they completely got rid of human intervention both in their setup and in their operation . xxmaj any practitioner , however , knows very well that human contributions are indispensable in order to set up , train , optimise and operate such systems . \n",
              " \n",
              "  xxmaj referring to the xxup ai systems that more strongly rely on data and in particular to predictive xxmaj machine xxmaj learning , human knowledge is still required in all phases to answer relevant questions that are not necessarily targeted to the xxup ai experts : \n",
              "  \\ begin{itemize } \n",
              " \t  \\ item \\ xxunk creating a model } : \n",
              " \t\t % \\ begin{itemize } \n",
              " \t\t % \\ item \n",
              " \t\t during training set creation ( ` ` what data can i use to build a model ? ' ' ) \n",
              " \t % \\ end{itemize } \n",
              " \t  \\ item at \\ emph{model building time } : \n",
              " \t % \\ begin{itemize } \n",
              " \t\t % \\ item \n",
              " \t\t during model validation ( ` ` is my model correct ? ' ' , ` ` is my model good enough ? ' ' ) and \n",
              " \t\t % \\ item \n",
              " \t\t during model refinement ( ` ` what additional training data / features would improve my model performance ? ' ' ) \n",
              " \t % \\ end{itemize } \n",
              " \t  \\ item \\ xxunk the model in production } : \n",
              " \t % \\ begin{itemize } \n",
              " \t\t % \\ item \n",
              " \t\t to ensure algorithmic transparency ( ` ` should i trust the way my model gave such a prediction ? ' ' ) and \n",
              " \t\t % \\ item \n",
              " \t\t to provide explainability ( ` ` why did my model give such an outcome / prediction ? ' ' ) \n",
              " \t % \\ end{itemize } \n",
              "  \\ end{itemize } \n",
              " \n",
              " \n",
              "  oindent xxmaj in this chapter , we focus on the role that xxmaj human xxmaj intelligence and ( human - generated ) xxmaj knowledge xxmaj graphs play to answer the above questions . xxmaj we also claim that , with special reference to explainability , humans are only partially considered in explainable xxup ai research , while they should , because the required explanations should be useful for human comprehension . \n",
              " \n",
              "  xxmaj the remainder of the chapter is structured as follows : related work is illustrated in xxmaj section \\ ref{sec : related } , and xxmaj section \\ ref{sec : explanation } clarifies what we mean by explanation and why humans are needed in their generation ; opportunities for ( human ) explainable xxup ai coming from the employment of xxmaj human xxmaj intelligence and xxmaj knowledge xxmaj graphs are outlined in xxmaj section \\ ref{sec : xxunk } , and xxmaj section \\ ref{sec : concl } presents some conclusions and traces some possible future work . % \\ xxunk } \n",
              " \n",
              "  xxrep 96 % \n",
              "  \\ section{related xxmaj work } \\ label{sec : related } \n",
              " \n",
              "  xxmaj in the context of xxmaj artificial xxmaj intelligence and xxmaj machine xxmaj learning , several research trends investigate the role and interplay between humans and machines . \n",
              " \n",
              "  a new emerging process of scientific inquiry is shown in~ \\ xxunk } : different people beyond scientists are now involved in such a process , because xxunk participate both in the creation / collection of information ( via user - generated content ) and in the coding / labelling / validation phases ( e.g. through xxmaj crowdsourcing or xxmaj citizen xxmaj science ) ; the authors call for a new data analytics paradigm with user involvement , and demonstrate experimental results to show the effect of interface design on how users transform information . \n",
              " \n",
              "  xxmaj indeed , the power of the ` ` crowd ' ' is often leveraged to create large - scale training sets for xxmaj machine xxmaj learning , by adopting xxmaj crowdsourcing~ \\ xxunk } , xxmaj human xxmaj computation~ \\ xxunk } and xxmaj citizen xxmaj xxunk \\ xxunk } approaches . \n",
              "  % \n",
              "  xxmaj moreover , knowledge in human cognitive processes may assist the design and implementation of xxmaj machine xxmaj learning , as claimed in~ \\ xxunk } ; however , the current popularity of black - box models hinders an effective human intervention because those approaches negatively impact on trustworthiness , interpretability and the discovery of hidden rules . \n",
              " \n",
              "  xxmaj user trust is indeed an important indicator because it correlates with system accuracy : humans are able to dynamically adjust their reliance based on a system perceived accuracy and they even show acceptance xxunk \\ xxunk } : this implies the need to correctly design an xxup ai system to xxunk the desired level of user trust . \n",
              "  % \n",
              "  xxmaj the validation phase of xxmaj machine xxmaj learning algorithms also benefits from the integration of user - centred evaluation : the authors of~ \\ xxunk } advocate adopting user - centred design ( iterative ) approaches for xxmaj machine xxmaj learning , in model optimisation , selection and validation . \n",
              " \n",
              "  xxmaj different families of methods explicitly aim to improve learned models based on human knowledge . xxmaj active xxmaj learning~ \\ xxunk } is based on the idea that a xxmaj machine xxmaj learning algorithm can achieve greater accuracy with fewer labeled training instances if it is allowed to ` ` choose ' ' the data from which it learns , by asking queries to an ` ` oracle ' ' which usually is a human annotator . xxmaj transfer xxmaj learning~ \\ xxunk } emerged to fulfill the need to build real world applications in which it is expensive or impossible to re - collect the training data required and xxunk the models ; in such cases knowledge transfer is attempted by adapting a model already trained on some domain ( with the help of human annotators ) to a different domain . \n",
              " \n",
              "  xxmaj human - xxmaj machine xxmaj cooperation is at the heart of xxmaj interactive xxmaj machine xxmaj learning~ \\ xxunk } , in which a human operator and a machine collaborate to achieve a task ; while coupling algorithm - centred analysis with human - centred evaluation seems to yield better results than a fully automated or fully manual approach , research is still needed to explore to what extent this mix can provide xxunk \\ xxunk } : participatory design with end - users could help incorporating human expertise in algorithms and models ; visualisation techniques could facilitate user feedback ; creativity , lateral thinking and exploration can also support , if suitable tools and objective and subjective metrics are developed . \n",
              " \n",
              "  xxmaj in general , in order to improve and optimise the interaction between humans and machines , a perspective shift should be adopted , for example by walking away from a purely technical optimisation and embracing a designer xxunk , like the one proposed in~ \\ xxunk } , in which the author xxunk to stop seeing technologies as a collection of tools and xxunk and instead start seeing them as an evolutionary flow around human problems , whose parts ultimately integrate to create a new category of things named xxunk technologies or ` ` xxup ai that works for people ' ' . \n",
              " \n",
              "  % \\ begin{itemize } \n",
              " \t % \\ item \\ xxunk } : process of scientific enquiry ( xxunk ) , claim on new data analytics paradigm for user involvement , results on effect of user interface on results \n",
              " \t % \\ item \\ xxunk } : how knowledge in human cognitive processes may assist he design and implementation of xxmaj machine xxmaj learning ( however with claims against black box ... ) \n",
              " \t % \\ item \\ xxunk } : user trust correlate with system accuracy and users develop acceptance thresholds \n",
              " \t % \\ item \\ xxunk } : integration of user - centred evaluation in ml algorithm design process ( model optimisation , selection and validation ) \n",
              " \t % \\ item \\ xxunk } : coupling algorithm - centred analysis with human - centred evaluation ; implications for research \n",
              " \t % \\ item crowdsourcing / human computation / citizen science as a way to create training sets [ xxunk xxunk ? ] \n",
              " \t % \\ item active learning \\ xxunk } and transfer learning \\ xxunk } as ways to improve modeling based on ( human ) knowledge \n",
              " \t % \\ item \\ xxunk } : stop seeing technologies as a collection of tools and xxunk and instead see it as an evolutionary flow around human problems , whose parts ultimately integrate to become a new category of thing % https : / / xxunk / xxunk = xxunk = xxunk = xxunk = xxunk = xxunk = xxunk # v = xxunk = xxunk = false \n",
              " \t % in xxunk xxunk 58 e xxunk ! ! ! \n",
              "  % \\ end{itemize } \n",
              " \n",
              "  xxrep 96 % \n",
              "  \\ section{what is an explanation for humans } \\ label{sec : explanation } \n",
              " \n",
              "  xxmaj the rationale behind explainable xxup ai research is that xxmaj artificial xxmaj intelligence systems should not only display an intelligent behaviour , but they also should be able to explain such behaviour . xxmaj the naturally raising question is what an explanation is and how to generate it . xxmaj in this section , we attempt at illustrating the characteristics of explanations and we justify the need for ` ` xxmaj human xxmaj intelligence ' ' and ` ` xxmaj human - in - the - xxmaj loop ' ' approaches also in relation to explainable xxup ai . \n",
              " \n",
              "  % xxrep 62 - \n",
              "  \\ subsection{a working definition of explanation } \\ label{sub : def - expl } \n",
              " \n",
              "  xxmaj let us consider the simple example of email categorisation between spam and non - spam . xxmaj here the task is binary classification ( i.e. , the output of a xxmaj machine xxmaj learning classifier is the labeling of each mail as spam or non - spam ) . \n",
              " \n",
              "  xxmaj an explanation consists in a set of hints to understand the relationship between the characteristics of an individual ( e.g. an email ) and the model prediction on that individual ( e.g. this email is spam ) . xxmaj the explanation is used by a human decision - maker , who should decide whether to trust the system ( e.g. accept or reject the prediction of the spam xxunk \\ cite{ribeiro2016whytrust } . \n",
              " \n",
              "  xxmaj user trust can happen at different levels : on the individual prediction , when the user requires an explanation about a specific instance ( e.g. why \\ xxunk } mail is spam ) or on an entire model , when the user needs to decide whether to trust the system altogether . xxmaj in the latter case , an explanation could require selecting a representative sample of individuals ( e.g. a set of spam / non - spam emails ) and explaining each individual in the sample . \n",
              " \n",
              "  xxmaj the main characteristics that an explanation should display ( again according to~ \\ cite{ribeiro2016whytrust } ) are fidelity , model - independence and interpretability . \\ emph{local fidelity } or local faithfulness means that a prediction should be valid in the vicinity of the individual ; global fidelity would of course be desirable , but it could be challenging for complex models . xxmaj the explanation should also be \\ emph{model - agnostic } , in that it should be independent on the specific type of xxup ai model . xxmaj finally , \\ xxunk } is the qualitative understanding of the relationship between the input variables and the response ( e.g. the relation between the words contained in an email and the email categorisation as spam / non - spam ) . \n",
              " \n",
              "  xxmaj interpretability is the key aspect for an explanation to be accepted by a user ; in our example of an email classifier , an interpretable explanation could rely on a list of words ( e.g. the system thinks this email is spam because it contains the following words ) rather that be based on opaque clues ( e.g. word embeddings ) which are not easily understandable by a human . xxmaj the level of interpretability of an explanation of course depends on the audience , because humans use their previous knowledge about the application domain to interpret an explanation and accept / reject a prediction based on their understanding . \n",
              " \n",
              "  % \\ cite{ribeiro2016whytrust } ( slide 25 ) \n",
              "  % \n",
              "  % \\ begin{itemize } \n",
              " \t % \\ item xxmaj explanation = set of hints to understand the relationship between the characteristics of an individual ( e.g. an email ) and the model prediction on that individual ( e.g. this email is spam ) \n",
              " \t % \\ item xxmaj different levels of prediction trust \n",
              " \t % \\ begin{itemize } \n",
              " \t\t % \\ item xxmaj on individual prediction : it requires explanation about the individual ( e.g. why this mail is spam ) \n",
              " \t\t % \\ item xxmaj on entire model : it requires ( 1 ) selecting a representative sample of individuals ( e.g. a set of spam / non - spam emails ) + ( 2 ) explaining each individual in the sample \n",
              " \t % \\ end{itemize } \n",
              " \t % \\ item xxmaj characteristics of explanations \n",
              " \t % \\ begin{itemize } \n",
              " \t\t % \\ item xxmaj local fidelity : valid in the vicinity of the individual ( but non necessarily globally ) \n",
              " \t\t % \\ item xxmaj model agnostic : independent on the specific black box model \n",
              " \t\t % \\ item xxmaj interpretability : quantitative understanding of the explanation ( e.g. words , not word embeddings ) ; this depends on the audience , because humans use their previous knowledge to interpret an explanation \n",
              " \t % \\ end{itemize } \n",
              "  % \\ end{itemize } \n",
              " \n",
              "  % xxrep 59 - \n",
              "  \\ subsection{explanation from a human point of view } \\ label{sub : xxunk - expl } \n",
              " \n",
              "  xxmaj the latest point on interpretability clarifies that proper attention should be given to the different kinds of explanations that could be generated , in particular by distinguishing ` ` machine ' ' explanations from ` ` human ' ' explanations . \n",
              " \n",
              "  xxmaj indeed , most xxup xai research has been focusing on generating \\ emph{machine explanations } , i.e. justifications of what / how the machine ` ` thinks ' ' . xxmaj in other words , machine explanations try to explain the scientific theory behind a model , to allow for phenomena comprehension . xxmaj in case of interpretable models ( like linear regression or decision trees ) , the machine explanation consists in making explicit the mathematical / logical relation between inputs and outputs ( e.g. tree model of decisions ) . xxmaj in case of black - box models , especially for deep learning and other complex approaches , the machine explanation may be based on ` ` compressed ' ' models or other approximation techniques that still use an explicit representation of the relation between inputs and outputs . \n",
              " \n",
              "  xxmaj instead , \\ emph{human explanations } focus on what a human user wants to know in order to interpret a model and make subsequent decisions . xxmaj the user may be xxunk in the internal functioning of an algorithm , as she may even be unable to understand a potentially complex mathematical formulation of the function that transforms the input parameters in the output prediction . xxmaj on the contrary , the user is interested in getting useful clues on why a specific output is given , in order to evaluate if such output is ` ` reliable ' ' from a human understanding point of view . \n",
              " \n",
              "  xxmaj as a consequence , in order to be useful , a human explanation needs to display some specific characteristics~ \\ xxunk } . xxmaj an explanation should be \\ xxunk } : it should not provide all possible reasons , but convey only the ` ` relevant ' ' causes ; indeed , people usually do not expect an explanation to consist of a complete cause of an event , also to let the explanation itself being reduced to a cognitively manageable size ; moreover , an explanation should not contain useless information , like xxunk or beliefs that the user already holds . xxmaj humans xxunk prefer \\ xxunk } explanations , in that they are used to reason according to counter - factual causality ( i.e. people do not ask why an event a happened , but rather why an event a happened instead of some other event b ) , especially in case of an anomaly or an abnormal event . xxmaj another characteristic of human explanations is that they are usually \\ emph{social } , involving the interaction between ( multiple ) explainers and explainees ; also with respect to explainable xxup ai , explanations should be seen as an interactive process , including interaction and dialogue with a mix of human and machine participants . \n",
              " \n",
              "  xxmaj from all the above considerations , it is apparent that explainable xxup ai research should go well beyond automatic methods to generate explanations ; it is of utmost importance to keep the \\ emph{human - in - the - xxmaj loop } . xxmaj there are at least two main reasons to advocate for the active involvement of people in explainable xxup ai~ \\ xxunk } : on the one hand , if explanation formulation is delegated to ` ` computer scientists ' ' , the risk is that such explanations are too close to the model and too far from human understanding , especially that of domain / business users who need to interpret such information ; on the other hand , there is a large body of knowledge about explanations from the social sciences ( philosophy , psychology , cognitive science ) , which could bring tangible benefits to explainable xxup ai research in terms of getting to a ` ` good ' ' explanation from a human point of xxunk \\ xxunk } . \n",
              " \n",
              "  % \\ xxunk , xxunk } ( slide 26 ) \n",
              " \n",
              "  % \\ begin{itemize } \n",
              " \t % \\ item xxmaj two meaning of explanation \n",
              " \t % \\ begin{itemize } \n",
              " \t\t % \\ item ` ` xxmaj machine ' ' explanation = what the machine thinks ( scientific theory , phenomena comprehension ) \n",
              " \t\t % \\ item ` ` xxmaj human ' ' explanation = what the human wants to know to interpret a model \n",
              " \t % \\ end{itemize } \n",
              " \t % \\ item xxmaj characteristics of explanations from the human point of view \n",
              " \t % \\ begin{itemize } \n",
              " \t\t % \\ item xxmaj selective explanations ( not all possible reasons , but only ` ` relevant ' ' causes , not including pre - existing beliefs / assumptions ) \n",
              " \t\t % \\ item xxmaj contrastive explanations ( counterfactual causality , ` ` why p and not q ? ' ' ) \n",
              " \t\t % \\ item xxmaj social explanations ( dialogue / conversation , interaction , iteration ) \n",
              " \t % \\ end{itemize } \n",
              " \t % \\ item xxmaj why human - in - the - loop is needed for xxmaj explainable xxup ai \n",
              " \t % \\ begin{itemize } \n",
              " \t\t % \\ item xxmaj do n't let computer scientists decide how to formulate explanations , because otherwise explanations are too close to the model and too far from human understanding \n",
              " \t\t % \\ item xxmaj there is a large body of knowledge about explanations from social sciences \n",
              " \t % \\ end{itemize } \n",
              "  % \\ end{itemize } \n",
              " \n",
              "  xxrep 96 % \n",
              "  \\ xxunk xxmaj intelligence and xxmaj knowledge xxmaj graphs to support explainable xxup ai } \\ label{sec : xxunk } % why / how can humans and kg help xai \n",
              " \n",
              "  xxmaj the xxmaj semantic xxmaj web has always relied on humans , since most of its tasks are knowledge - intensive and context - specific and , as such , they require user engagement for their solution ( e.g. , conceptual modelling , multi - language resource labelling , content annotation with ontologies , concept / entity similarity recognition ) . xxmaj with the rise of xxmaj knowledge xxmaj graphs and their popularity , new opportunities have emerged to exploit them for xxup ai in general and specifically for explainable xxup ai~ \\ xxunk } . \n",
              " \n",
              "  xxmaj without the claim of being exhaustive , in the following we illustrate a set of approaches that can bring xxmaj human xxmaj intelligence and xxmaj knowledge xxmaj graphs to the benefit of explainable xxup ai , with specific reference to xxmaj machine xxmaj learning . xxmaj we distinguish between two main types of opportunities , those related to the exploitation of ( human - generated ) xxmaj knowledge xxmaj graphs and those that xxunk on the direct involvement of people ; we depict them in xxmaj figure~ \\ ref{fig : approaches } along two axes , representing whether xxmaj human xxmaj intelligence is employed in data / knowledge representation or for explanations . % in relation to data preparation / manipulation and with respect to model explanation . \n",
              " \n",
              "  % \\ textcolor{red}{todo : fare xxunk xxunk xxunk e in xxunk ( 1 ) xxunk a xxunk serve per xxup xai e ( 2 ) xxunk xxunk xxunk xxunk xxunk / xxunk } \n",
              " \n",
              "  \\ begin{figure}[htb ] \n",
              " \t  \\ centering \n",
              " \t\t  \\ includegraphics[width=0.95 \\ textwidth]{img / xxunk } \n",
              " \t  \\ caption{graphical representation of xxmaj human xxmaj intelligence approaches } \n",
              " \t  \\ label{fig : approaches } \n",
              "  \\ end{figure } \n",
              " \n",
              " \n",
              "  % xxunk \n",
              "  \\ xxunk ) xxmaj knowledge xxmaj graphs for xxup xai } \n",
              "  xxmaj the first set of approaches exploits xxmaj knowledge xxmaj graphs to support explanation generation . xxmaj we specifically focus on the role of human - generated information to directly and indirectly support xxup xai . \n",
              " \n",
              "  % xxrep 59 - \n",
              "  \\ subsubsection{dataset metadata } \n",
              "  xxmaj structured data represents an invaluable input for any xxmaj machine xxmaj learning approach . xxmaj consequently , linked data and xxmaj knowledge xxmaj graphs represent as such a rich and xxunk contribution . xxmaj an important role can even be played by simple metadata : descriptive metadata about datasets , in the form of xxup xxunk \\ xxunk - v2 } and related vocabularies , can be exploited to improve data sourcing . xxmaj the information about where some data comes from can also be re - used for explanations : users can better judge the reliability or the meaningfulness of a machine output if they are given also the detail about the original sources . \n",
              " \n",
              "  xxmaj for example , the opportunities to facilitate dataset reuse in the development of chatbots are illustrated by the xxunk - xxup ap xxunk \\ xxunk } , an extension of the xxmaj data xxmaj xxunk ( xxup xxunk ) xxmaj application xxmaj profile . xxunk - xxup ap enables the description of intents ( i.e. , the actions users want to accomplish by interacting with a chatbot ) and entities ( i.e. , individual information units associated to an intent ) supported by a dataset and the method to access it ; as such , it enables and fosters xxunk of datasets ( including xxmaj knowledge xxmaj graphs ) across chatbot systems . xxmaj it could also be exploited further to support the generation of explanations for the chatbot ` ` replies ' ' in terms of recognised intents / entities and used datasets . \n",
              " \n",
              "  % xxrep 59 - \n",
              "  \\ xxunk - specific semantics } \n",
              "  xxmaj different users may have different interests or skills and , as a consequence , they may need different explanations . xxmaj user - generated data often implicitly contains hints on \\ emph{what people care about } ; this can be an opportunity to exploit when providing explanations on systems trained on such data . \n",
              " \n",
              "  xxmaj for example , spatial data analytics of xxunk manual tagging showed to be beneficial for geo - ontology engineering , by surfacing latent semantic differences in concepts by different xxunk \\ xxunk } : the same ` ` concept ' ' of spatial object ( e.g. , a pub ) may have slightly diverging meanings in different places ( e.g. , a place to xxunk in xxup uk , a bar to have a drink in xxmaj italy ) . xxmaj this implicit semantics , when extracted and made explicit , can be exploited also for explanation generation , because it can contribute to convey the right ` ` semantics ' ' to the right community . \n",
              " \n",
              "  % xxrep 59 - \n",
              "  \\ xxunk of user - generated data } \n",
              "  xxmaj providing better data for training in turn leads to better models , as well as to more interpretable explanations . xxmaj when data is user - generated , quality assurance is an important step , for example to aggregate inputs from multiple contributors ( cf . ` ` truth inference ' ' in xxmaj crowdsourcing~ \\ xxunk } ) . xxmaj provenance metadata about human contributions often contain important clues that can be exploited both for quality improvement and for generating explanations . \n",
              " \n",
              "  % xxmaj when data is user - generated , provenance information can be exploited to improve data quality , as \n",
              "  xxmaj for example , in the case of the xxmaj human xxmaj computation - powered volunteered geographic information ( xxup vgi ) illustrated in~ \\ xxunk } , the involvement of a crowd of volunteers , potentially untrained or non - experts , implies that xxup vgi can be of varying quality ; tracing xxup vgi provenance enables the recording of the collection activity : the information about who gathered what , where and when is then employed to compute and judge the xxup vgi quality . xxmaj the same provenance information can be offered to users of systems trained on such user - generated data , to explain where some prediction comes from . \n",
              " \n",
              "  % xxrep 59 - \n",
              "  \\ subsubsection{knowledge graphs as explanation content } \n",
              "  xxmaj structured knowledge and xxmaj knowledge xxmaj graphs can be used as basis for explanations , because they may already contain the rationale behind the relationship between inputs and outputs of a system . xxmaj whenever a predictive system is based on a knowledge base , the relevant part of it that motivates a system output can be directly used as explanation . \n",
              " \n",
              "  % , in terms of resources and properties connecting them , \n",
              "  xxmaj for example , graph traversal information is used to explain the suggestions of a knowledge - based recommender system in~ \\ xxunk } : the logical path connecting a user ( e.g. , xxmaj john loves hard rock music ) and a recommended item ( e.g. , x is a xxmaj web - radio broadcasting rock music ) provides a xxunk account of the reasons behind the recommendation ( e.g. , xxmaj john is recommended to listen to x , because xxmaj john \\ xxunk } hard rock music , hard rock \\ emph{is a kind of } rock music , x \\ xxunk } rock music ) . xxmaj the chain of relevant connected resources / properties ( i.e. , the set of triples composing a path between the user and the recommended item ) already constitutes a human explanation for the recommendation . \n",
              " \n",
              " \n",
              "  % xxunk \n",
              "  \\ subsection{human xxmaj intelligence for xxup xai } \n",
              "  xxmaj the second set of approaches directly focuses on the active involvement of people to the benefit of xxup xai . \n",
              " \n",
              "  % xxrep 59 - \n",
              "  \\ subsubsection{user engagement for data quality } \n",
              "  xxmaj as claimed in xxmaj section \\ ref{sec : explanation } , in order to provide human explanations , we should turn to social sciences , which may help in the involvement and engagement of people also during the phase of explanation generation for xxup ai systems . xxmaj engaging humans is a challenge by itself , therefore explainable xxup ai could reuse the research results in relation to designing and exploiting behaviours , personal motivations and incentive mechanisms . \n",
              " \n",
              "  xxmaj for example , the evaluation and improvement of data quality can be achieved through an analysis of contributions : % the unconscious contributions of users as well as by improving user experience xxmaj it is xxunk that people can display varied levels of attention when performing a task , due to attitude or contextual conditions ; therefore , \n",
              "  user behaviour influences data quality and should be taken into account , to evaluate the reliability of user - generated information , to better design data collection systems and to generate explanations . xxmaj as demonstrated in~ \\ xxunk } , the presence of tangible rewards , leveraging extrinsic motivation , affects quantity and quality of collected data ; moreover , an analysis of accuracy and participation of contributors highlights different engagement profiles , which should be taken into account when aggregating user - generated data and should be xxunk for explainability . \n",
              " \n",
              "  % xxrep 59 - \n",
              "  \\ subsubsection{user interaction and user experience } \n",
              "  xxmaj lessons learned and best practices from user experience design can also inform human - powered explanation generation , because they can help in designing suitable tools and data value chains that involve and engage people to bring benefit to xxup ai in general and explainable xxup ai specifically . \n",
              " \n",
              "  xxmaj indeed , a carefully designed user interaction with digital tools proves to be key in raising attention and improving data quality , as shown in~ \\ xxunk } with respect to survey data collection : an improvement on user experience , making questionnaire compilation more enjoyable , leads also to higher - quality information , because it reduces the satisficing effect and increases response quality . xxmaj therefore , involving users for the generation or validation of explanations , for example by adopting a social and interactive pattern guided by a design thinking approach , can maximise user attention and ease user experience , thus making sure that the result is a \\ xxunk } explanation from a human point of view . \n",
              " \n",
              "  % xxrep 59 - \n",
              "  \\ subsubsection{human and machine confidence } \n",
              "  xxmaj predictive xxmaj machine xxmaj learning modelling aims at building a trustworthy system able to provide prediction on unknown cases ; to evaluate model confidence , different metrics are usually employed to give quantitative estimates of a prediction reliability . xxmaj reporting confidence metrics to support prediction explanation is a means to increase user trust , but again those quantitative hints should be interpretable from a human point of view . \n",
              " \n",
              "  xxmaj human intervention can be also employed to support a model evaluation and , consequently , a model explanation through confidence metrics . xxmaj indeed , it can happen that what is ` ` difficult ' ' to predict for an algorithm ( i.e. predictions with low confidence metrics ) is also difficult for humans to judge ; the case of questionable image classification is illustrated in~ \\ xxunk } , where the correspondence exists between low - confidence machine classifications and user disagreement . xxmaj the correlation between human and machine predictions and their respective confidence / reliability can be exploited to understand the reasons behind a model and can therefore improve both the modelling phase ( by incorporating additional human knowledge in training ) and the generation of explanations ( which can be closer to human understanding ) . \n",
              " \n",
              "  % xxrep 59 - \n",
              "  \\ xxunk as a means to improve user involvement } \n",
              "  xxmaj the most challenging aspect of xxmaj human - xxmaj machine xxmaj cooperation is the effective involvement of people in the various phases of modelling . xxmaj while users are already employed in data collection and model validation , further opportunities lie in a more xxunk interaction between human steps and automatic steps . xxmaj therefore , explanations are not only an objective as such , but they can be an instrument to further involve and motivate human participants in the xxup ai system life - cycle . \n",
              " \n",
              "  xxmaj for example , in order to identify and reduce bias in knowledge representation and modelling , the involved users should not only be exposed to potential biased information , but should also be given an explanation for such an identified bias , to understand the reasons behind a questionable piece of information or prediction . a xxmaj human - in - the - xxmaj loop approach to identify and resolve implicit bias in xxmaj knowledge xxmaj graphs is illustrated in~ \\ xxunk } : users are involved not only to accept / reject an identified bias , but they are also engaged as decision - makers to evaluate if further actions should be taken to solve such bias . \n",
              " \n",
              "  % xxrep 59 - \n",
              "  % \\ subsection { } \n",
              " \n",
              "  % xxrep 59 - \n",
              "  % \\ xxunk related to xxmaj data for xxmaj explanation } \\ label{sub : data } \n",
              "  % \\ begin{itemize } \n",
              " \t % \\ item metadata to improve data sourcing ( reusable for explanations ? ) \\ xxunk } : xxunk i dataset per xxunk il xxunk ? ? \n",
              " \t % \\ item provenance to evaluate and improve data quality \\ xxunk } : xxrep 4 ? \n",
              " \t % \\ item xxunk to understand what people care about \\ xxunk } : crowdsourced data give information in an implicit way ? ? \n",
              " \t % \\ item user behaviour to evaluate and improve data quality \\ xxunk } : xxunk degli xxunk influenza i xxunk \n",
              " \t % \\ item user engagement to improve data quality \\ xxunk } : engagement degli xxunk xxunk i xxunk ? \n",
              "  % \\ end{itemize } \n",
              " \n",
              "  % xxrep 59 - \n",
              "  % \\ xxunk related to xxmaj model xxmaj explanation } \n",
              "  % \\ begin{itemize } \n",
              " \t % \\ item xxunk to evaluate model confidence \\ xxunk } : xxunk che e ' xxunk per xxunk e ' xxunk xxunk per la xxunk ( xxunk ) \n",
              " \t % \\ item kg as explanation \\ xxunk } : path in the kg as en explanation for recommendations \n",
              " \t % \\ item provenance as explanation \\ xxunk } : bias degli input xxunk e xxunk xxunk xxunk / provenance \n",
              "  % \\ end{itemize } \n",
              " \n",
              "  xxrep 96 % \n",
              "  \\ section{conclusions } \\ label{sec : concl } \n",
              " \n",
              "  explainable xxup ai aims at generating explanations to justify the output of an algorithm to a user , usually a decision - maker . xxmaj those explanations need to be interpretable by the intended target users and , therefore , can not be restricted to the ` ` scientific modelling ' ' ( i.e. , the explanation of the scientific / mathematical law or theory behind an artificial model ) , but should be focused on addressing the needs of the decision makers , which exploit such explanations and decide whether to trust an xxup ai system . \n",
              " \n",
              "  xxmaj therefore , a better understanding of \\ emph{human xxmaj intelligence } is needed to make sure that the generated explanations are ` ` good enough ' ' to be used in practice : a certain help can come from social sciences , but even within the xxup ict community , we identify several opportunities . xxmaj on the one hand , xxmaj knowledge xxmaj representation and xxmaj reasoning ( xxup krr ) research has always been addressing the open issue of human knowledge formalisation ; in this context , therefore , explainable xxup ai can leverage all the experience related to the involvement of human annotators and crowdsourced knowledge bases and xxmaj knowledge xxmaj graphs ( e.g. xxunk \\ xxunk } and xxmaj xxunk \\ xxunk } ) : indeed , the same xxmaj human xxmaj intelligence that supports xxup krr tasks can be similarly exploited for explainable xxup ai . \n",
              " \n",
              "  xxmaj on the other hand , xxmaj human xxmaj computer xxmaj interaction ( xxup hci ) research has been focusing on improving and optimizing user experience with digital tools ; in this context , explainable xxup ai can leverage the approaches and methods to support the ` ` interaction ' ' between a human user and a digital explanation , improving interpretability and promote trust . xxup ai system should be designed to allow and facilitate the exchange with the relevant user communities : while people are already heavily involved in data collection , their engagement in other steps of the xxup ai life - cycle is still to be fully explored , especially with respect to explainability . \n",
              " \n",
              "  xxmaj the big challenge is to define flexible and complex human - computer cooperative systems , able to guide in the preparation , building and production of data processing pipelines involving xxmaj artificial xxmaj intelligence technologies . xxmaj human xxmaj intelligence and xxmaj knowledge xxmaj graphs should become first - order citizens of such data value chains , not only to improve the performance of such artificial systems , but also -- and foremost -- to assure that xxup ai outcomes are relevant and usable by human decision makers . \n",
              " \n",
              " \n",
              "  \\ section*{acknowledgments } \n",
              "  xxmaj the presented research was partially supported by the xxup action project ( grant agreement number xxunk ) , co - funded by the xxmaj european xxmaj commission under the xxmaj horizon 2020 xxmaj framework xxmaj programme . xxmaj we would like to thank xxmaj xxunk xxmaj re xxmaj xxunk and xxmaj ilaria xxmaj xxunk for their feedback and revision on this chapter . \\ emph { } \n",
              " \n",
              "  \\ xxunk } \n",
              "  \\ bibliography{biblio } \n",
              " \t \n",
              "  % \\ begin{thebibliography}{99 } \n",
              "  % \n",
              "  % \\ xxunk } \n",
              "  % xxup xxunk xxmaj xxunk , xxmaj xxunk hoc et xxunk et xxunk xxunk xxunk , \n",
              "  % \\ xxunk } \\ xxunk } ( 1993 ) , xxunk - xxunk . \n",
              "  % \n",
              "  % \\ end{thebibliography } \n",
              "  \\ end{document } \n",
              " ,xxbos \\ xxunk } % xxmaj include author names \n",
              "  % \\ xxunk } % xxmaj anonymized submission \n",
              " \n",
              "  % xxmaj the following packages will be automatically loaded : \n",
              "  % jmlr , amsmath , amssymb , natbib , graphicx , url , algorithm2e \n",
              "  % xxunk , xxunk and probably more \n",
              "  % make sure they are installed with your latex distribution \n",
              "  \\ usepackage{amsmath } \n",
              "  \\ def \\ xxmaj inf { \\ xxunk \\ xxunk } } } \n",
              "  \\ usepackage{graphicx } \n",
              "  % \\ usepackage{subfig } \n",
              " \n",
              "  \\ usepackage{caption } \n",
              "  % \\ usepackage{subcaption } \n",
              " \n",
              "  \\ xxunk xxunk xxmaj imaging with xxmaj deep xxmaj learning 2020 } \n",
              "  \\ xxunk { } \n",
              "  \\ xxunk { } \n",
              "  \\ xxunk 2020 -- xxmaj short xxmaj paper } \n",
              "  \\ editors { } \n",
              " \n",
              " \n",
              "  \\ xxunk } % to get dummy images \n",
              "  \\ usepackage{amssymb } \n",
              "  % \\ xxunk xxmaj under xxmaj review } \n",
              "  % \\ xxunk xxmaj review for xxup xxunk 2020 } \n",
              "  \\ xxunk xxmaj space xxmaj variation xxunk xxmaj space xxmaj variational xxmaj inference for xxmaj uncertainty xxmaj estimation in xxmaj computer xxmaj aided xxmaj diagnosis } \n",
              " \n",
              "  % xxmaj use \\ name{author xxmaj name } to specify the name . \n",
              "  % xxmaj if the surname contains spaces , enclose the surname \n",
              "  % in braces , e.g. \\ name{john { xxmaj smith xxmaj jones } } similarly \n",
              "  % if the name has a \" von \" part , e.g \\ xxunk { de xxmaj winter } } . \n",
              "  % xxmaj if the first letter in the xxunk is a diacritic \n",
              "  % enclose the diacritic in braces , e.g. \\ xxmaj name { { \\ ' xxmaj xxunk xxmaj smith } \n",
              " \n",
              "  % xxmaj two authors with the same address \n",
              "  % \\ xxunk { \\ name{author xxmaj name1 } \\ xxmaj xxunk } \\ and \n",
              "  % \\ name{author xxmaj name2 } \\ xxmaj xxunk } \\ \\ \n",
              "  % \\ addr xxmaj address } \n",
              " \n",
              "  % xxmaj three or more authors with the same address : \n",
              "  % \\ xxunk { \\ name{author xxmaj name1 } \\ xxmaj xxunk } \\ \\ \n",
              "  % \\ name{author xxmaj name2 } \\ xxmaj xxunk } \\ \\ \n",
              "  % \\ name{author xxmaj xxunk } \\ xxmaj xxunk } \\ \\ \n",
              "  % \\ addr xxmaj address } \n",
              " \n",
              " \n",
              "  % xxmaj authors with different addresses : \n",
              "  % \\ xxunk { \\ name{author xxmaj name1 } \\ xxmaj xxunk } \\ \\ \n",
              "  % \\ addr xxmaj address 1 \n",
              "  % \\ xxup and \n",
              "  % \\ name{author xxmaj name2 } \\ xxmaj xxunk } \\ \\ \n",
              "  % \\ addr xxmaj address 2 \n",
              "  % } \n",
              " \n",
              "  % \\ xxunk equally } \n",
              " \n",
              "  % xxmaj more complicate cases , e.g. with dual affiliations and joint authorship \n",
              "  \\ xxunk { \\ xxunk xxmaj xxunk { } \n",
              "  ametag { } } \\ xxmaj xxunk } \\ \\ \n",
              "  % \\ addr $ xxunk xxmaj address 1 \\ \\ \n",
              "  % \\ addr $ xxunk xxmaj address 2 \\ xxup and \n",
              "  \\ xxunk xxmaj xxunk \n",
              "  ametag { } } \\ xxmaj xxunk } \\ \\ \n",
              "  \\ xxunk xxmaj sethi \n",
              "  ametag { } } \\ xxmaj xxunk } \\ \\ \n",
              "  \\ addr xxmaj department of xxmaj electrical xxmaj engineering , xxmaj indian xxmaj institute of xxmaj technology , xxmaj xxunk \\ xxup and \n",
              "  } \n",
              " \n",
              "  \\ begin{document } \n",
              " \n",
              "  \\ maketitle \n",
              " \n",
              "  \\ begin{abstract } \n",
              "  xxmaj deep neural networks have xxunk medical image analysis and disease diagnosis . xxmaj despite their impressive performance , it is difficult to generate well - calibrated probabilistic outputs for such networks , which makes them uninterpretable black boxes . xxmaj bayesian neural networks provide a principled approach for modelling uncertainty and increasing patient safety , but they have a large computational overhead and provide limited improvement in calibration . xxmaj in this work , by taking skin lesion classification as an example task , we show that by shifting xxmaj bayesian inference to the functional space we can craft meaningful priors that give better calibrated uncertainty estimates at a much lower computational cost . \n",
              "  % xxmaj despite their impressive performance , they have been criticized for being non - interpretable black box . xxmaj standard approach for uncertainty estimation in neural networks is by approaching problem from a xxmaj bayesian view , by placing a prior on the parameters and approximating the posterior . xxmaj in this work we show that by shifting to the functional space we can craft more meaningful prior 's https : / / www.overleaf.com / project / xxunk in turn give us far better calibrated uncertainty estimates at a significantly lower computational cost . \n",
              "  \\ end{abstract } \n",
              " \n",
              "  \\ begin{keywords } \n",
              "  xxmaj bayesian approximation , uncertainty estimates , calibration , skin xxunk \n",
              "  \\ end{keywords } \n",
              " \n",
              "  \\ section{introduction } \n",
              " \n",
              "  xxmaj in computer - aided diagnosis , xxup ai models must not only be accurate , but they should also indicate when they are likely to be incorrect . xxmaj for instance , control should be passed on to human doctors when the confidence of a neural network for disease diagnosis is low . xxmaj model calibration is the degree to which a model ‚Äôs predicted probabilities reflect the true correctness likelihood . xxmaj calibrated confidence estimates are also important for model interpretability and they provide a valuable extra bit of information to establish trustworthiness with the user . xxmaj this is important for deep neural networks , whose classification decisions are often and difficult to interpret . \n",
              " \n",
              "  xxmaj it is well known that popular neural network frameworks only provide a point estimate of the true underlying distribution . xxmaj furthermore , the typical classification setting of training the softmax output layer using cross - entropy loss typically gives ‚Äú over - confident ‚Äù ( low entropy ) class probability mass distributions , even when there is a classification error . xxmaj this is especially concerning for training on medical datasets that are often relatively smaller and suffer from severe class imbalance \\ xxunk } . xxmaj in other words , the popular deep learning models give poorly calibrated uncertainty estimates for cases that are ambiguous , or difficult , or \\ xxunk - of - distribution } ( xxup ood ) , including those from a new class . \n",
              " \n",
              "  % xxmaj recently deep learning methods have received significant attention for computer aided diagnosis in a variety of medical imaging domains \\ xxunk } . xxmaj they outperform former methods on performance metrics such as accuracy , xxup f1 score , or xxup roc - xxup auc etc . xxmaj however care has to be taken before deploying deep neural networks to support medical diagnosis . xxmaj this is because it is known that neural networks are only a point estimate of the true underlying distribution , and the softmax output layer that is used to get a probability score is typically ‚Äú over - confident ‚Äù for one class . xxmaj this issue causes most deep learning models to be poorly calibrated and give over - confident estimates for ambiguous or unknown cases . \n",
              " \n",
              "  xxmaj bayesian modelling offers a set of tools to reason about uncertainty . xxmaj existing xxmaj bayesian approaches involve approximate inference using either xxmaj markov xxmaj chain xxmaj monte xxmaj carlo \\ xxunk } or variational inference methods , such as dropout \\ xxunk } . xxmaj this idea has attracted attention of the medical community to ensure that difficult cases for computer - aided diagnosis are xxunk flagged for review \\ xxunk } . xxmaj since most xxmaj bayesian neural networks ( bnns ) have their prior defined on the weight space , the regularization caused by these prior is not able to xxunk the network output , nor do these priors explicitly make the model under - confident on the xxup ood samples . xxmaj we show that by performing variational inference on the functional space we can craft a prior that is able to simultaneously xxunk the network as well as ensure the the recognition of xxup ood samples as more uncertain . xxmaj our method is also significantly less computationally expensive as compared to xxmaj bayesian or frequentist approaches . xxmaj although our method shares some similarities with xxmaj xxunk xxmaj deep xxmaj learning ( xxup xxunk ) \\ xxunk } , it has been derived from a variational xxmaj bayesian framework and it can distinguish distributional versus data uncertainties ( shift in distribution versus class confusion , respectively ) , unlike xxup xxunk . \n",
              " \n",
              "  % xxunk show the advantage of our method on the xxup xxunk xxrep 4 0 dataset for skin lesion classification . \n",
              " \n",
              "  % xxmaj in order to craft such a prior we need to shift to the functional space , and we show the advantage of our method on the xxup xxunk xxrep 4 0 dataset for skin lesion classification . xxmaj our method is also significantly less computational expensive as compared to xxmaj dropouts , xxmaj deep xxmaj ensembles etc . as we do not have to rely on the expensive xxmaj monte - xxmaj carlo samples on test time to approximate the output distribution . \n",
              " \n",
              " \n",
              " \n",
              "  % xxmaj deep neural networks ( dnns ) have emerged as powerful image analysis and prediction tools , especially so for medical image analysis and disease diagnosis . xxmaj thus although they provide super - human performance on tasks like skin cancer xxunk from xxunk images \\ xxunk } etc . they still have a fatal weakness which prevents them from being deployed on real world tasks safely . xxmaj that is dnns do not generally generate well - calibrated reliable uncertainty estimates regarding their decisions \\ xxunk } , \\ xxunk } , \\ xxunk } . \n",
              "  % \\ par \n",
              "  % xxmaj in most medical domains where there is abundance of data , reaching impressive scores on performance metrics , such as accuracy , sensitivity , xxunk , xxup f1 score , or xxup roc - xxup auc is no longer an issue , rather the major challenges of the upcoming era , are likely to lie elsewhere . xxmaj for example are current models able to detect shifts in the data distribution ? xxmaj this is important because cancer patients from a different ethnicity or locality may not have the same distribution as each , also natural mutations in the disease may cause shift in the data over long period of time , making it imperative for our model to not only be accurate but also well calibrated , while still having the capability of saying \" i do not know \" in unseen scenarios . \n",
              " \n",
              " \n",
              "  \\ section{proposed xxmaj method } \n",
              " \n",
              "  xxmaj for classification among $ xxup k$ classes , deep neural networks represent a function $ f _ { \\ xxunk \\ rightarrow \\ textbf{p } \\ in [ xxup xxunk , where $ xxup x$ represents the input , and $ \\ xxunk represents a probability mass function such that $ \\ xxunk = 1$. xxmaj the output distribution $ p(y|x , \\ theta ) = \\ xxunk \\ xxunk a prior on $ \\ theta$ implicitly defines a prior measure on the space of $ f(x)$ , denoted as $ xxunk xxmaj priors of convenience on $ \\ theta$ , such as a fully factorized xxmaj gaussian , are often used , and it is difficult to formulate a prior on the weight space that is informative in the sense that it leads to high uncertainty on xxup ood examples . xxmaj we therefore define a uniform prior on the $ xxmaj xxunk unit simplex for the functional space , such that $ xxunk ) = d ( \\ xxunk \\ xxunk , \\ xxunk \\ xxunk ( completely uncertain prior ) . xxmaj while it seems intuitively satisfying to have a model that is not biased towards ` ` over - confident \" outputs ( towards which the usual cross - entropy loss is severely biased ) , we also empirically show that such a uniform prior gives well - calibrated outputs . % xxmaj completely uncertain prior is added \n",
              " \n",
              "  xxmaj given the training data $ d = ( xxup xxunk , xxunk and the test points $ ( xxunk we have : \n",
              "  \\ begin{equation } \n",
              "  xxunk ) = \\ int xxunk \\ textbf{p } ) \\ , p ( \\ xxunk ) \\ , d \\ textbf{p } \n",
              "  \\ end{equation } \n",
              "  xxmaj we assume $ xxunk \\ textbf{p } ) = \\ xxunk \\ xxunk xxmaj we further assume that the neural network estimates a xxmaj dirichlet distribution $ \\ xxunk } ( \\ xxunk \\ alpha)$ with $ \\ alpha>0 $ , as done by \\ xxunk } , because of its analytical tractability . \n",
              "  xxmaj in other words , unlike for a standard neural network where $ \\ textbf{p } = f _ { \\ xxunk is the point estimate output , in our case $ \\ xxunk } ( \\ xxunk \\ alpha ) = q _ { \\ xxunk is the marginal functional distribution . xxmaj this is similar to how a xxmaj gaussian process has a multivariate xxmaj gaussian as its marginal distribution . \n",
              " \n",
              "  xxmaj the true functional posterior $ xxunk is intractable , but it can be approximated by minimizing the functional evidence lower bound ( xxunk ) as done by \\ xxunk } : \n",
              "  % such that the objective is : \n",
              " \n",
              "  \\ begin{equation } \n",
              "  \\ label{eq : xxunk } \n",
              "  \\ xxunk ) = - \\ mathbb{e } _ { xxunk ) } [ \\ log xxunk ) ) ] + \\ xxunk ) ] \n",
              "  \\ end{equation } \n",
              " \n",
              "  xxmaj the second term in xxmaj equation~ \\ ref{eq : xxunk } is the functional xxup kl divergence , which is hard to estimate . xxmaj therefore , we shift to a more familiar metric , the xxup kl divergence between the marginal distributions of function values at finite sets of points $ \\ xxunk : n}$. \\ xxunk } has shown : \n",
              "  \\ begin{equation } \n",
              "  \\ xxunk \\ smash { \\ displaystyle \\ sup _ { \\ xxunk : n } } } \\ mathop { \\ mathbb { \\ text{kl } } } \\ left [ xxunk ( \\ xxunk : xxunk ( \\ xxunk : n } ) \\ right ] = \\ sum_{i=1}^n \\ text{kl } [ \\ xxunk } ( \\ xxunk \\ xxunk \\ xxunk } ( \\ xxunk \\ langle 1 , \\ dots 1 \\ rangle ) ] \n",
              "  \\ end{equation } \n",
              "  a more relaxed way of sampling these ‚Äú measure points \" $ \\ xxunk : n}$ , is to assume $ \\ xxunk : k } \\ sim xxup xxunk ( training distribution ) and $ \\ xxunk : n } \\ sim c$ where $ c$ is a distribution having the same support as the training distribution , which could be xxup ood samples , that can be forced to be more uncertain . xxmaj this approach is similar to \\ xxunk } , \\ xxunk } . \n",
              "  % xxmaj note $ y$ is assumed to be a one - hot vector , such that if the true label is $ j$ then $ y_j = 1 $ and $ y_i = 0 $ for all $ i \n",
              "  eq j$. xxmaj so now we can get the closed form solution of the first term in loss function as - \n",
              " \n",
              "  xxmaj we get a closed form solution for the first part in xxmaj equation~ \\ ref{eq : xxunk } by assuming $ y$ to be a one - hot vector as follows : \n",
              "  \\ begin{equation } \n",
              "  \\ mathcal{l}_1 = \\ int \\ left [ \\ sum_{i=1}^k xxunk \\ log p_i \\ right ] \\ frac{1}{b ( \\ alpha ) } \\ prod_{i=1}^k xxunk { \\ xxunk } d \\ textbf{p } = \\ sum_{i=1}^k y_i \\ left ( \\ xxunk ( \\ xxunk \\ xxunk \\ xxunk ( \\ alpha_i ) \\ right ) \n",
              "  \\ end{equation } \n",
              "  % where $ \\ xxunk ( . ) $ is the xxunk function . xxmaj thus , both parts of xxmaj equation~ \\ ref{eq : xxunk } have analytically closed forms , which helps in smooth training as we do not have to rely on the noisy xxmaj monte xxmaj carlo estimates , unlike previously proposed xxmaj bayesian neural networks . \n",
              " \n",
              "  $ \\ xxunk is the xxunk function . xxmaj to measure calibration of the proposed model we group predictions $ p \\ in [ 0,1]$ into $ xxup m$ bins each of size $ \\ xxunk , and let $ xxmaj xxunk be the set of indices of samples whose prediction confidence falls into the interval $ ( \\ xxunk } , \\ xxunk for $ m \\ in \\ { 1 , \\ dots , m \\ } $ . xxmaj now we define accuracy of $ xxmaj xxunk as xxunk $ \\ xxunk } \\ sum_{i \\ in xxup b_m } 1 _ { \\ { \\ xxunk = y_i \\ } } $ , where $ \\ hat{y}$ is the predicted outcome with confidence $ p$ , and $ y$ is the true label . xxmaj similarly , we define the average confidence as xxunk ) = $ \\ xxunk } \\ sum_{i \\ in xxmaj b_m } p_i$. xxmaj for perfect calibration we expect xxunk ) = xxunk ) . xxmaj in order to quantify how well calibrated our networks are , we use xxmaj expected xxmaj calibration xxmaj error ( xxup ece ) $ = \\ sum_{i=1}^m \\ xxunk \\ xxunk ) - \\ xxunk as the metric . xxmaj note xxup ece = 0 for perfect calibration . \n",
              " \n",
              "  \\ section{results } \n",
              "  % xxmaj we apply our method to the problem of skin lesion xxunk , using the xxup xxunk xxrep 4 0 dataset \\ xxunk xxrep 4 0 } . xxmaj this dataset contains xxunk images of common xxunk skin xxunk , divided over seven classes . xxmaj similar to other medical datasets , this dataset is heavily imbalanced . xxmaj the images are down - scaled to xxunk pixels , and normalized . xxmaj we randomly split the full dataset into a training set ( xxunk images ) , a validation set , and a hold - out test set ( both 501 images ) . xxmaj we use the training and validation set to train a deep neural network architecture and optimize hyperparameters . xxmaj for training we use the resnet18 \\ xxunk } architecture and the trainable parameters are optimized using the xxmaj adam , with an initial learning rate of 0.0001 . \n",
              "  % \\ par \n",
              "  xxmaj we applied our method to the problem of skin lesion classification , using the xxup xxunk xxrep 4 0 dataset \\ xxunk xxrep 4 0 } . resnet 50 architecture optimized by xxmaj adam was used . \n",
              "  % xxmaj we trained a resnet50 architecture using the xxmaj adam optimizer , with an initial learning rate of 0.0001 . \n",
              " \n",
              "  % xxmaj for example , if we have a well calibrated weather prediction model that predicts xxunk event with 80 \\ % probability for 100 days then , any deviation from 80 xxunk days and 20 non - xxunk days will imply a poorly calibrated model . a poorly calibrated model is hard to interpret and is too unreliable to be deployed in the real world . xxmaj this is especially true when a classification model is not trained for its own sake but instead for the purpose of passing on such probabilities to some other decision - making component , which is often the case in medical domain . \n",
              " \n",
              "  xxmaj from xxmaj table 1 we can see that although standard xxmaj bayesian approaches do help xxunk the model , our method has a significantly lower xxup ece . xxmaj that too at a much lower computational cost , approximately xxunk less computationally expensive than xxmaj dropouts ( monte carlo approximation ) and xxunk more memory efficient than xxmaj ensembles ( ensemble size ) . \n",
              "  % , with only a marginal compromise in test accuracy . \n",
              " \n",
              "  % xxmaj because minimizing a cross entropy loss does not ensure calibration , and even tends to over - fit classification accuracy \\ xxunk } , it ‚Äôs imperative to xxunk any model where probabilities are passed on to some other decision making system , which is often the case in practical medical applications . xxmaj regular xxmaj bayesian xxmaj neural xxmaj networks like xxmaj bayes by xxmaj backprop ( xxup xxunk ) \\ xxunk } , xxmaj dropouts \\ xxunk } etc . tend to be better calibrated than the standard xxmaj neural xxmaj networks but are far from satisfactory , since the regular prior used in these cases are not able to prevent under - estimation or over - estimation of class probabilities . \n",
              " \n",
              "  % \\ begin{table}[!htb ] \n",
              "  % \\ caption{comparison of classification accuracy and xxup ece on xxup xxunk xxrep 4 0 dataset for the proposed and the other xxmaj bayesian approaches } \n",
              "  % \\ xxunk } \n",
              "  % \\ centering \n",
              "  % \\ begin{tabular}{|l|l|l| } \n",
              "  % \\ toprule \n",
              "  % \\ hline \n",
              "  % xxmaj method & xxmaj test xxmaj accuracy & xxup ece \\ \\ \n",
              "  % \\ midrule \n",
              "  % \\ hline \n",
              "  % xxmaj standard xxup nn & xxunk \\ % & 7.73 \\ % \\ \\ \n",
              "  % \\ hline \n",
              "  % xxmaj concrete xxmaj dropout & \\ xxunk \\ % } & 6.39 \\ % \\ \\ \n",
              "  % \\ hline \n",
              "  % xxmaj deep xxmaj ensemble & xxunk \\ % & 3.12 \\ % \\ \\ \n",
              "  % \\ hline \n",
              "  % xxmaj bayes - xxmaj by - xxmaj backprop & xxunk \\ % & xxunk \\ % \\ \\ \n",
              "  % \\ hline \n",
              "  % xxmaj functional xxmaj space xxup vi & xxunk \\ % & \\ xxunk } \\ % \\ \\ \n",
              "  % \\ hline \n",
              "  % \\ bottomrule \n",
              "  % \\ end{tabular } \n",
              "  % \\ end{table } \n",
              " \n",
              " \n",
              " \n",
              "  \\ begin{table}[h ! ] \n",
              "  \\ caption{comparison of classification accuracy and xxup ece on xxup xxunk xxrep 4 0 dataset } \n",
              "  \\ xxunk } \n",
              "  \\ centering \n",
              "  \\ begin{tabular}{| xxwrep 2 l| } \n",
              "  % \\ toprule \n",
              "  \\ hline \n",
              "  xxmaj method & xxmaj standard xxup nn & xxmaj dropout & xxmaj deep xxmaj ensemble & xxmaj functional xxmaj space xxup vi \\ \\ \n",
              "  % \\ midrule \n",
              "  \\ hline \n",
              "  xxmaj test xxmaj accuracy & xxunk \\ % & \\ xxunk } \\ % & xxunk \\ % & xxunk \\ % \\ \\ \n",
              "  \\ hline \n",
              "  xxup ece ( m = 15 ) & 7.73 \\ % & 6.39 \\ % & 3.12 \\ % & \\ xxunk } \\ % \\ \\ \n",
              "  % \\ hline \n",
              "  % xxmaj deep xxmaj ensemble & xxunk \\ % & 3.12 \\ % \\ \\ \n",
              "  % \\ hline \n",
              "  % xxmaj bayes - xxmaj by - xxmaj backprop & xxunk \\ % & xxunk \\ % \\ \\ \n",
              "  % \\ hline \n",
              "  % xxmaj functional xxmaj space xxup vi & xxunk \\ % & \\ xxunk } \\ % \\ \\ \n",
              "  \\ hline \n",
              "  % \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  \\ end{table } \n",
              " \n",
              "  \\ par \n",
              "  % \\ textbf{experiment to show benefits of uncertainty yet to think of \n",
              "  % } \n",
              "  % xxmaj refer to the xxmaj appendix for our work on quantifying different types of uncertainty . \n",
              "  % xxmaj in the xxmaj appendix we show how our model can distinguish distributional uncertainty from data uncertainty , allowing it distinguish xxup ood samples much better than the previous xxmaj bayesian approaches , while also detecting samples within the distribution that are overlapping . \n",
              "  xxmaj the entropy $ \\ xxunk , xxup xxunk is a measure of total uncertainty , whereas differential entropy $ \\ xxunk ( \\ xxunk \\ alpha ) ] $ is a measure of the distributional xxunk xxmaj appendix a for more xxunk , both of which have an analytically closed form . \n",
              "  \\ section{conclusions } \n",
              "  % xxmaj our method shares similarity with xxmaj xxunk xxmaj deep xxmaj learning ( xxup xxunk ) \\ xxunk } , but has been derived completely from a xxmaj variational xxmaj bayesian xxmaj framework , also unlike xxup xxunk our model can distinguish xxmaj distributional xxmaj uncertainty from xxmaj data xxmaj uncertainty . \n",
              "  xxmaj we proposed a novel xxmaj bayesian xxup nn framework whose prior explicitly forces xxup ood samples to become xxunk as well as allow us to estimate uncertainty analytically at test time , without needing approximate or expensive algorithms . xxmaj we have also shown that our model gives well - calibrated uncertainty outputs , which can increase patient safety and assist a transfer of xxup ai systems into clinical settings by including trustworthiness as a design factor in machine learning models for medical diagnosis . xxmaj our method is also significantly more computationally efficient making it a more viable option for resource - constrained problems . \n",
              "  % xxmaj we observe that our model 's xxunk uncertainty correlates negatively with the number of training examples it has seen , and that it remains highly uncertain on \\ xxunk - of - distribution } samples . \n",
              " \n",
              " \n",
              "  % xxmaj the practical effectiveness of bnns is limited by our ability to specify meaningful prior distributions and by the intractability of posterior inference . xxmaj choosing a meaningful prior distribution over network weights is xxunk because the weights have a complicated relationship to the function computed by the network . xxmaj here , we propose to perform variational inference directly on the distribution of functions , where a xxup bnn is trained to produce a distribution of functions with small xxup kl divergence to the true posterior over functions . xxmaj to do so we define \n",
              " \n",
              " \n",
              " \n",
              "  % xxmaj this is where the content of your paper goes . xxmaj some random \n",
              "  % notes \\ xxunk footnote are xxunk } : \n",
              "  % \\ begin{itemize } \n",
              "  % \\ item xxmaj you should use \\ latex \\ xxunk : xxmaj xxunk } . \n",
              "  % \\ item xxup jmlr / xxup pmlr uses natbib for references . xxmaj for simplicity , here , \\ verb| \\ xxunk defaults to \n",
              "  % xxunk citations , i.e. \\ verb| \\ citep| . xxmaj you can of course also \n",
              "  % use \\ verb| \\ citet| for textual citations . \n",
              "  % \\ item xxmaj you should follow the guidelines provided by the conference . \n",
              "  % \\ item xxmaj read through the xxup jmlr template documentation for specific \\ latex \n",
              "  % usage questions . \n",
              "  % \\ item xxmaj note that the xxup jmlr template provides many handy functionalities \n",
              "  % such as \\ verb| \\ xxunk to refer to a figure , \n",
              "  % e.g. \\ figureref{fig : example } , \\ verb| \\ xxunk to refer to a table , \n",
              "  % e.g. \\ xxunk : example } and \\ verb| \\ xxunk to refer to an equation , \n",
              "  % e.g. \\ xxunk : example } . \n",
              "  % \\ end{itemize } \n",
              " \n",
              "  % \\ begin{table}[htbp ] \n",
              "  % % xxmaj the first argument is the label . \n",
              "  % % xxmaj the caption goes in the second argument , and the table contents \n",
              "  % % go in the third argument . \n",
              "  % \\ floatconts \n",
              "  % { tab : xxunk \n",
              "  % { \\ caption{an xxmaj example xxmaj xxunk \n",
              "  % { \\ begin{tabular}{ll } \n",
              "  % \\ bfseries xxmaj dataset & \\ bfseries xxmaj result \\ \\ \n",
              "  % xxmaj xxunk & xxunk \\ \\ \n",
              "  % xxmaj xxunk & xxunk \\ \\ \n",
              "  % xxmaj xxunk & xxunk \\ \\ \n",
              "  % xxmaj xxunk & xxunk \n",
              "  % \\ end{tabular } } \n",
              "  % \\ end{table } \n",
              " \n",
              "  % \\ begin{figure}[htbp ] \n",
              "  % % xxmaj caption and label go in the first argument and the figure contents \n",
              "  % % go in the second argument \n",
              "  % \\ floatconts \n",
              "  % { fig : example } \n",
              "  % { \\ caption{example xxmaj image } } \n",
              "  % { \\ includegraphics[width=0.5 \\ xxunk - image } } \n",
              "  % \\ end{figure } \n",
              " \n",
              "  % \\ xxunk } \n",
              "  % \\ xxunk xxmaj net xxmaj activation } \n",
              "  % \\ label{alg : net } \n",
              "  % % older versions of algorithm2e have \\ dontprintsemicolon instead \n",
              "  % % of the following : \n",
              "  % % \\ dontprintsemicolon \n",
              "  % % older versions of algorithm2e have \\ linesnumbered instead of the \n",
              "  % % following : \n",
              "  % % \\ linesnumbered \n",
              "  % \\ xxunk , \\ ldots , x_n , w_1 , \\ ldots , xxunk } \n",
              "  % \\ xxunk , the net activation } \n",
              "  % $ y \\ leftarrow 0 $ \\ ; \n",
              "  % \\ xxmaj for{$i \\ leftarrow 1 $ \\ kwto $ n$ } { \n",
              "  % $ y \\ leftarrow y + xxunk \\ ; \n",
              "  % } \n",
              "  % \\ end{algorithm2e } \n",
              " \n",
              "  % % xxmaj acknowledgments --- xxmaj will not appear in anonymized version \n",
              "  % \\ xxunk thank xxmaj nvidia for its xxunk of gpus . } \n",
              " \n",
              " \n",
              "  \\ xxunk - xxunk } \n",
              " \n",
              " \n",
              "  \\ appendix \n",
              " \n",
              "  ewpage \n",
              "  \\ xxunk xxmaj uncertainty } \n",
              " \n",
              "  xxmaj we use two measures to estimate uncertainty -- differential entropy and output entropy . xxmaj the output entropy is a measure of the total uncertainty , where as the differential entropy is a good measure of distributional uncertainty . xxmaj output entropy is high whenever we encounter overlap between classes or we encounter samples from xxup ood . xxmaj on the other hand , the differential entropy is high only when we encounter xxup ood samples and remains low even in case of data uncertainty \\ xxunk } . \n",
              " \n",
              "  xxmaj output entropy is defined as : \n",
              "  \\ begin{equation } \\ label{eq : example } \n",
              "  \\ xxunk , d ) ] = - \\ sum_{i=1}^k xxunk , d ) \\ xxunk , d ) ) \n",
              "  \\ end{equation } \n",
              "  where \n",
              "  \\ begin{equation } \\ label{eq : example } \n",
              "  xxunk , d ) = \\ int p(y_i| \\ textbf{p } ) \\ xxunk } ( \\ xxunk \\ alpha ) d \\ textbf{p } = \\ frac { \\ alpha_i } { \\ xxunk \\ alpha_j } \n",
              "  \\ end{equation } \n",
              " \n",
              " \n",
              "  xxmaj differential entropy is maximized when all categorical distributions are xxunk . i.e. when posterior $ q _ { \\ xxunk ) ) = d ( \\ xxunk \\ xxunk , \\ xxunk \\ xxunk , and it is defined as : \n",
              "  \\ begin{equation } \\ label{eq : example } \n",
              "  \\ xxunk ( \\ xxunk \\ alpha ) ] = \\ log b ( \\ alpha ) + ( \\ sum_{i=1}^k \\ alpha_i - k ) \\ xxunk ( \\ sum_{i=1}^k \\ alpha_i ) - \\ sum_{i=1}^k ( \\ alpha_i - 1 ) \\ xxunk ( \\ alpha_i ) \n",
              "  \\ end{equation } \n",
              " \n",
              "  % \\ begin{figure } \n",
              "  % \\ begin{subfigure}[b]{0.25 \\ textwidth } \n",
              "  % \\ centering \n",
              "  % \\ xxunk . xxup png } \n",
              "  % \\ caption{high xxmaj data xxmaj uncertainty } \n",
              "  % \\ label{fig : xxunk } \n",
              "  % \\ end{subfigure}% \n",
              "  % \\ begin{subfigure}[b]{0.25 \\ textwidth } \n",
              "  % \\ xxunk . xxup png } \n",
              "  % \\ caption{high xxmaj distributional xxmaj uncertainty } \n",
              "  % \\ label{fig : xxunk } \n",
              "  % \\ end{subfigure}% \n",
              "  % \\ xxunk ( a ) implies high data uncertainty so we will have low differential entropy \\ \\ xxmaj fig ( b ) has high distributional uncertainty so both uncertainty metrics will be high } \n",
              "  % \\ end{figure } \n",
              " \n",
              " \n",
              "  % \\ xxunk \n",
              "  % \\ centering \n",
              "  % \\ xxunk xxmaj data xxmaj uncertainty ] { \\ xxunk . xxup png } } % \n",
              "  % \\ qquad \n",
              "  % \\ xxunk xxmaj distributional xxmaj uncertainty ] { \\ xxunk . xxup png } } % \n",
              "  % \\ xxunk ( a ) implies high data uncertainty so we will have low differential entropy \\ \\ xxmaj fig ( b ) has high distributional uncertainty so both uncertainty metrics will be xxunk \n",
              "  % \\ label{fig : xxunk \n",
              "  % \\ end{figure } \n",
              " \n",
              "  \\ begin{figure}[htbp ] \n",
              "  \\ floatconts \n",
              "  { fig : xxunk } \n",
              "  { \\ caption{(a ) implies high data uncertainty so we will have low differential entropy \\ \\ ( b ) has high distributional uncertainty so both uncertainty metrics will be high } } \n",
              "  { % \n",
              "  \\ xxunk xxmaj data xxmaj uncertainty ] { \\ label{fig : xxunk \n",
              "  \\ xxunk . xxup xxunk \n",
              "  \\ qquad \n",
              "  \\ xxunk xxmaj distributional xxmaj uncertainty ] { \\ label{fig : xxunk \n",
              "  \\ xxunk . xxup png } } \n",
              "  } \n",
              "  \\ end{figure } \n",
              " \n",
              "  xxmaj from xxmaj figure 1 it becomes clear that our method allows us to easily distinguish between xxmaj data and xxmaj distributional xxmaj uncertainty . \n",
              " \n",
              "  ewpage \n",
              "  \\ section{additional xxmaj experiment } \n",
              "  \\ begin{figure}[htbp ] \n",
              "  \\ centering \n",
              "  \\ xxunk } \n",
              "  \\ end{figure } \n",
              "  xxmaj we observe our model is very confident on xxmaj xxunk ( xxup xxunk ) class , which is expected since it make majority of the dataset , this reinforces the importance of well balanced data for learning . xxmaj we can also see our xxup ood samples can be distinctly separated from the in - class samples . xxmaj the xxup ood sample used for training and testing are from different distributions . xxmaj for simplicity we used xxmaj gaussian xxmaj distribution for training xxup ood samples and xxmaj uniform xxmaj distribution for testing xxup ood samples . xxmaj ideally more complex techniques should be used for generating xxup ood samples on the decision boundary \n",
              "  \\ xxunk } . \n",
              "  \\ end{document } \n",
              " ,xxbos \\ xxunk } \n",
              " \n",
              "  % xxrep 8 xxunk xxmaj user 's xxmaj packages xxrep 7 xxunk \n",
              "  \\ usepackage{amsmath } \n",
              "  % \\ usepackage{arydshln } % dashed lines \n",
              "  % \\ usepackage{amsfonts } \n",
              "  \\ usepackage{array } % new column type \n",
              "  \\ usepackage{amssymb } % for using \\ varnothing \n",
              "  \\ usepackage{bm } \n",
              "  \\ xxunk } \n",
              "  \\ usepackage{booktabs } % nice tables \n",
              "  \\ usepackage{calc } \t  % calculations over tikz coordinates \n",
              "  \\ usepackage{caption } \n",
              "  % \\ xxunk } % crossing \n",
              "  \\ usepackage{enumitem } \n",
              "  \\ usepackage{diagbox } \n",
              "  % \\ usepackage{fancyvrb } % xxunk verbatim \n",
              "  \\ usepackage{float } \n",
              "  \\ usepackage{graphicx } % % % for including graphics \n",
              "  \\ xxunk } \n",
              "  \\ usepackage[colorlinks = true , allcolors = xxunk , xxunk } % ( cross ) referencing \n",
              "  % \\ usepackage{latexsym } \n",
              "  \\ usepackage{listings } % for amr \n",
              "  \\ xxunk } % xxup user xxup define xxup macros \n",
              "  \\ usepackage{multicol } % multicolumn structure \n",
              "  \\ usepackage{multirow } % nice tables \n",
              "  \\ usepackage{nicefrac } \n",
              "  \\ usepackage{natbib } % xxunk citation xxunk \n",
              "  \\ usepackage{pifont } % arrow in amr to clausal form translation \n",
              "  % \\ usetikzlibrary{positioning } \n",
              "  \\ usepackage{ragged2e } % xxunk \n",
              "  \\ usepackage{subcaption } \n",
              "  \\ xxunk } \n",
              "  \\ xxunk } \n",
              "  \\ usepackage{textcomp } % xxunk text < and > \n",
              "  \\ usepackage{times } % times font \n",
              "  \\ usepackage{tcolorbox } % for colored boxes \n",
              "  \\ usepackage{colortbl } % coloured columns \n",
              "  % \\ usepackage[dvipsnames]{xcolor } \n",
              "  \\ xxunk } % xxunk notes for communication \n",
              "  % \\ usepackage{times } \n",
              "  \\ usepackage[normalem]{ulem } % underline and xxunk \n",
              "  \\ usepackage{url } % % % for including urls \n",
              "  \\ usepackage{pifont}% for xxunk \n",
              " \n",
              "  % \\ setlength { \\ xxunk mm } % ! ! ! xxup remove xxup before xxup submission \n",
              " \n",
              "  % uncomment below if xxmaj error \" \\ xxunk ended up in ... \" occurs \n",
              "  % \\ xxunk } \n",
              " \n",
              "  % xxrep 10 xxunk xxmaj user 's xxmaj macros xxrep 11 xxunk \n",
              "  % \n",
              "  ewcommand { \\ xxunk ] { } % xxunk it to get rid of notes \n",
              " \n",
              "  ewcommand { \\ xxunk ] { \\ xxunk \\ tiny ] { # 1 } { } } % comment it out to get rid of notes \n",
              "  % \n",
              "  ewcommand { \\ xxunk ] { } % for multiline comments \n",
              " \n",
              "  ewcommand { \\ xxunk ] { \\ textcolor{red } { # 1 } } \n",
              "  % \n",
              "  ewcommand { \\ xxunk ] { # 1 } % uncomment to remove alerts \n",
              "  % \\ xxunk } \n",
              " \n",
              "  ewcommand { \\ xxunk ] { \\ textbf { # 1 } } \n",
              " \n",
              "  ewcommand { \\ xxunk ] { \\ texttt { # 1 } } \n",
              " \n",
              "  ewcommand { \\ xxunk ] { \\ sout { \\ mbox { # 1 } } } \n",
              " \n",
              "  ewcommand { \\ xxunk } { \\ xxunk mm } } \n",
              " \n",
              "  ewcommand { \\ xxunk ] { # 1 \\ xxunk . \\ xxunk # 2 } \n",
              " \n",
              "  ewcommand { \\ xxunk ] { \\ xxunk } { # 1 } } \n",
              " \n",
              "  ewcommand { \n",
              "  xxunk ] { \\ xxunk } { # 1 } } \n",
              " \n",
              "  ewcommand { \n",
              "  xxunk ] { \\ xxunk [ # 1 ] { \\ texttt { # 2 } } } \n",
              " \n",
              "  ewcommand { \\ xxunk ] { \\ ensuremath { \\ langle # 1 \\ rangle } } \n",
              "  \\ xxunk } \n",
              " \n",
              "  ewcommand { \\ xxunk ] { \\ mbox{$ \\ langle$ \n",
              "  tt [ # 1 ] { # 2}$ \\ rangle$ } } \n",
              " \n",
              "  ewcommand { \\ cross } { \\ textcolor{red } { \\ xxunk } } } \n",
              " \n",
              "  ewcommand { \\ cmark } { \\ textcolor{green } { \\ xxunk } } } \n",
              " \n",
              "  ewcommand { \\ xxunk ] { \\ textcolor{red } { \\ textbf { # 1 } } } \n",
              " \n",
              "  ewcommand { \\ xxunk ] { \\ textcolor{red } { \\ ensuremath { \\ bm { # 1 xxrep 4 } \n",
              " \n",
              "  \\ xxunk } \n",
              " \n",
              "  xxunk } \n",
              "  \\ xxunk } \n",
              " \n",
              " \n",
              "  ewcommand { \\ xxunk } { \\ catcode ` \\ _ = 11 } \n",
              " \n",
              "  ewcommand { \\ xxunk } { \\ catcode ` \\ _ = \\ active } \n",
              " \n",
              "  ewcommand { \\ xxunk } { \\ xxunk \\ hbox{$ \\ scriptstyle \\ mathtt { \\ xxunk } } \n",
              " \n",
              "  % xxrep 10 xxunk xxmaj abbreviations xxrep 11 xxunk \n",
              " \n",
              "  ewcommand { \\ xxunk } { \\ xxunk } } \n",
              " \n",
              "  ewcommand { \\ xxunk } { \\ mbox { \\ xxunk } } } \n",
              " \n",
              "  ewcommand { \\ xxunk } { \\ xxunk } } \n",
              " \n",
              "  ewcommand { \\ xxunk } { \\ xxunk } } \n",
              " \n",
              "  ewcommand { \\ xxunk } { \\ xxunk et xxunk } } \n",
              " \n",
              "  ewcommand { \\ xxunk } { \\ xxunk et xxunk } } \n",
              " \n",
              "  ewcommand { \\ xxunk } { \\ xxunk et al . } } \n",
              " \n",
              "  ewcommand { \\ xxunk } { \\ xxunk et al . } } \n",
              " \n",
              "  ewcommand { \\ xxunk } { \\ xxunk } } \n",
              " \n",
              "  ewcommand { \\ tacl } { \\ xxunk } } \n",
              " \n",
              "  ewcommand { \\ xxunk } { \\ xxunk } } \n",
              " \n",
              "  ewcommand { \\ liu } { \\ xxunk } } \n",
              " \n",
              "  ewcommand { \\ xxunk } { \\ xxunk } } \n",
              " \n",
              "  ewcommand { \\ xxunk } { \\ xxunk } } \n",
              " \n",
              "  \\ title{the xxmaj first xxmaj shared xxmaj task on \\ \\ xxmaj discourse xxmaj representation xxmaj structure xxmaj parsing } \n",
              "  \\ date { } \n",
              "  \\ xxunk xxmaj xxunk \\ qquad xxmaj xxunk van xxmaj xxunk \\ qquad xxmaj xxunk xxmaj xxunk \\ qquad xxmaj xxunk xxmaj xxunk \\ \\ \n",
              "  xxup xxunk , xxmaj university of xxmaj groningen \\ \\ \n",
              "  \\ texttt { \\ { xxunk , \\ , r \\ ! xxunk \\ ! xxunk , \\ , xxunk , \\ , xxunk \\ } xxunk } \n",
              "  } \n",
              " \n",
              "  % xxrep 21 xxunk xxup main xxrep 20 xxunk \n",
              "  \\ begin{document } \n",
              "  \\ xxunk \n",
              "  \\ maketitle \n",
              "  \\ thispagestyle{empty } \n",
              "  \\ pagestyle{empty } \n",
              " \n",
              "  \\ begin{abstract } \n",
              "  xxmaj the paper presents the xxup xxunk 2019 shared task on semantic parsing where the goal is to produce xxmaj discourse xxmaj representation xxmaj structures ( xxunk ) for xxmaj english sentences . \n",
              "  xxunk originate from xxmaj discourse xxmaj representation xxmaj theory and represent xxunk meaning representations that capture the semantics of negation , xxunk , quantification , and presupposition triggers . \n",
              "  xxmaj additionally , concepts and event - participants in xxunk are described with wordnet synsets and the thematic roles from xxunk . \n",
              "  xxmaj to measure similarity between two xxunk , they are represented in a clausal form , i.e. as a set of tuples . \n",
              "  xxmaj participant systems were expected to produce xxunk in this clausal form . \n",
              "  xxmaj taking into account the rich lexical information , explicit scope marking , a high number of shared variables among clauses , and highly - constrained format of valid xxunk , all these makes the xxup xxunk parsing a challenging xxup nlp task . \n",
              "  xxmaj the results of the shared task displayed improvements over the existing state - of - the - art parser . \n",
              "  \\ end{abstract } \n",
              " \n",
              "  % xxrep 27 xxunk \n",
              "  \\ section{introduction } \n",
              "  \\ label{sec : intro } \n",
              " \n",
              " \n",
              "  xxmaj semantic parsing has been gaining in popularity in the last few years . \n",
              "  xxmaj there have been a series of shared tasks in semantic parsing organized , where each task requires to generate meaning representations of specific types : \n",
              "  xxmaj broad - xxmaj coverage xxmaj broad - coverage xxmaj semantic xxmaj dependencies \\ xxunk - xxunk , xxunk - xxunk } , \n",
              "  xxmaj abstract xxmaj meaning xxmaj representation \\ xxunk - xxup xxunk , semeval - xxup xxunk } , \n",
              "  or xxmaj universal xxmaj conceptual xxmaj cognitive xxmaj annotation \\ xxunk } . \n",
              " \n",
              "  xxmaj the xxmaj discourse xxmaj representation xxmaj structure ( xxup xxunk ) parsing task extends this development by aiming at producing meaning representations that ( i ) come with more expressive power than existing ones and ( ii ) are easily xxunk into formal logic , thereby opening the door to applications that require automated forms of inference \\ xxunk } . \n",
              "  xxunk are meaning representations employed by xxmaj discourse xxmaj representation xxmaj theory ( xxup xxunk , \\ xxunk : xxunk } ) . \n",
              "  xxmaj they have been successfully applied for wide - coverage semantic representations \\ xxunk : xxunk } , xxmaj natural xxmaj language xxmaj inference \\ xxunk , xxunk } , and xxmaj natural xxmaj language xxmaj generation \\ xxunk } . \n",
              "  xxmaj to the best of our knowledge , there has never been a shared task on xxunk meaning representations . \n",
              " \n",
              "  xxmaj the aim of the task is to compare semantic parsing methods and the performance of systems that take as input an xxmaj english text and provide as output the xxunk meaning representation of that text % ( see \\ autoref{fig : xxunk : afraid } ) . \n",
              "  xxmaj since a xxup xxunk combines logical ( negation , quantification and xxunk ) , pragmatic ( xxunk ) and lexical ( word senses and thematic roles ) components of semantics in a single meaning representation , \n",
              "  the xxup xxunk parsing task shares parts of the following xxup nlp tasks : semantic role labeling , reference resolution , scope detection , named entity tagging , word sense disambiguation , predicate - argument structure prediction , and presupposition projection . \n",
              " \n",
              "  xxmaj there are only a few previous approaches to xxup xxunk parsing . xxmaj traditionally , due to the complexity of the task , it has been the domain of symbolic and statistical approaches \\ xxunk : xxunk , xxunk , xxunk } . xxmaj recently , however , neural sequence - to - sequence systems achieved impressive performance on the task \\ xxunk , xxunk } , without relying on any external linguistic resources . \n",
              " \n",
              "  xxmaj in the first shared task on xxup xxunk parsing , taking into account the information - rich and complex structure of the target meaning representation , we tested participant systems mainly on short , open - domain xxmaj english texts . \n",
              "  xxmaj in this way , we lowered the threshold for participation to encourage higher results in the shared task and mitigate challenges associated to semantic parsing long texts . \n",
              "  xxmaj in total five systems participated in the shared task . \n",
              "  xxmaj the top - ranked systems outperformed the existing state - of - the - art system in xxup xxunk parsing . \n",
              "  xxmaj the shared task was hosted on xxunk \n",
              "  \\ footnote { \\ url{https : / / xxunk / competitions / xxunk } } . \n",
              " \n",
              " \n",
              " \n",
              "  % xxrep 7 xxunk 2 xxup xxunk xxrep 7 xxunk \n",
              "  \\ begin{figure } \n",
              "  \\ centering \n",
              "  % xxrep 5 xxunk xxup xxunk xxrep 5 xxunk \n",
              "  \\ xxunk \\ textwidth } \n",
              "  \\ centering \n",
              "  \\ xxunk } { \n",
              "  \\ begin{tabbing } \n",
              "  12 \\ = xxunk \\ = \\ kill \n",
              "  { \\ sc system input } : \\ \\ [ 0pt ] \n",
              "  \\ > \\ > xxmaj tom is n't afraid of anything . \n",
              "  \\ \\ [ 1 mm ] \n",
              "  { \\ sc system output } : \\ \\ [ 0pt ] \n",
              "  \\ > \\ > \\ xxunk ] { \\ xxunk \n",
              "  \\ xxunk { \\ , } l } \n",
              "  % \\ toprule \n",
              "  \\ xxunk } xxup ref \\ xxunk } \\ \\ \n",
              "  \\ xxunk } male \" \\ xxunk } \" \\ xxunk } \\ \\ \n",
              "  \\ xxunk } xxmaj name \\ xxunk } \" tom \" \\ \\ \n",
              "  \\ xxunk } xxup ref \\ xxunk } \\ \\ \n",
              "  \\ xxunk } xxup xxunk \\ xxunk } \" now \" \\ \\ \n",
              "  \\ xxunk } time \" \\ xxunk } \" \\ xxunk } \\ \\ \n",
              "  \\ xxunk } xxup not \\ xxunk } \\ \\ \n",
              "  \\ xxunk } xxup ref \\ xxunk } \\ \\ \n",
              "  \\ xxunk } xxmaj time \\ xxunk } \\ xxunk } \\ \\ \n",
              "  \\ xxunk } xxmaj xxunk \\ xxunk } \\ xxunk } \\ \\ \n",
              "  \\ xxunk } afraid \" \\ xxunk } \" \\ xxunk } \\ \\ \n",
              "  \\ xxunk } xxmaj stimulus \\ xxunk } \\ xxunk } \\ \\ \n",
              "  \\ xxunk } xxup ref \\ xxunk } \\ \\ \n",
              "  \\ xxunk } entity \" \\ xxunk } \" \\ xxunk } \\ \\ \n",
              "  % \\ bottomrule \n",
              "  \\ end{tabular } } } \n",
              "  \\ \\ [ 1 mm ] \n",
              "  { \\ sc box format } : \\ \\ [ 3pt ] \n",
              "  \\ xxunk mm } \n",
              "  [ { \\ xxunk $ } { \n",
              "  \\ xxunk \n",
              "  eg$ } \n",
              "  \\ xxunk $ ~ $ x_2 $ } { \n",
              "  xxunk \\ xxunk \\ \\ \n",
              "  \\ xxunk \\ xxunk , xxunk \\ \\ \n",
              "  \\ xxunk \\ xxunk , xxunk \\ \\ \n",
              "  \\ xxunk \\ xxunk , xxunk \\ \\ \n",
              "  xxunk \\ xxunk } \\ \\ \n",
              "  $ \\ xxunk \\ \\ \n",
              "  \\ xxunk = \\ xxunk \n",
              "  } } \n",
              "  [ { \\ xxunk $ } { \n",
              "  $ \\ xxunk \\ \\ \n",
              "  \\ xxunk \\ xxunk , \\ xxunk } } \n",
              "  ] \n",
              "  ] \n",
              "  \\ xxunk } \n",
              "  \\ end{tabbing } \n",
              "  } \\ vspace{-7 mm } \n",
              "  \\ caption{the xxup xxunk parsing task : the ~ system input is a short text ( the xxup pmb document \\ href{http : / / xxunk / explorer / xxunk / xxunk } ) , and the expected output is a xxup xxunk in clausal form . xxmaj its standard visualisation in box - notation , following xxup xxunk , is presented below . } \n",
              "  \\ label{fig : xxunk : afraid } \n",
              "  \\ end{minipage}% \n",
              "  \\ qquad \n",
              "  % xxrep 5 xxunk xxup xxunk xxrep 5 xxunk \n",
              "  \\ xxunk \\ textwidth } \n",
              "  \\ xxunk mm } \n",
              "  \\ xxunk } { \\ xxunk } \n",
              "  \\ mbox { \\ href{http : / / xxunk / explorer / xxunk / xxunk } } : \n",
              "  xxmaj he played the xxunk and she xxunk . \n",
              "  \\ \\ [ -1 mm ] \n",
              "  \\ xxunk ] { \\ texttt { \n",
              "  \\ renewcommand * { \\ arraystretch}{1.1 } \n",
              "  \\ xxunk { \\ xxunk { } } \\ toprule \n",
              "  \\ xxunk } xxup xxunk \\ xxunk } & \n",
              "  \\ xxunk } xxup xxunk \\ xxunk } \\ \\ \n",
              "  \\ xxunk } xxup ref \\ xxunk } & \n",
              "  \\ xxunk } xxup ref \\ xxunk } \\ \\ \n",
              "  \\ xxunk } male \" \\ xxunk } \" \\ xxunk } & \n",
              "  \\ xxunk } female \" \\ xxunk } \" \\ xxunk } \\ \\ \n",
              "  \\ xxunk } xxup ref \\ xxunk } & \n",
              "  \\ xxunk } xxup ref \\ xxunk } \\ \\ \n",
              "  \\ xxunk } play \" \\ xxunk } \" \\ xxunk } & \n",
              "  \\ xxunk } xxunk \" \\ xxunk } \" \\ xxunk } \\ \\ \n",
              "  \\ xxunk } xxmaj agent \\ xxunk } \\ xxunk } & \n",
              "  \\ xxunk } xxmaj agent \\ xxunk } \\ xxunk } \\ \\ \n",
              "  \\ xxunk } xxmaj theme \\ xxunk } \\ xxunk } & \n",
              "  \\ xxunk } xxmaj time \\ xxunk } \\ xxunk } \\ \\ \n",
              "  \\ xxunk } xxup ref \\ xxunk } & \n",
              "  \\ xxunk } xxup ref \\ xxunk } \\ \\ \n",
              "  \\ xxunk } xxunk \" \\ xxunk } \" \\ xxunk } & \n",
              "  \\ xxunk } xxup tpr \\ xxunk } \" now \" \\ \\ \n",
              "  \\ xxunk } xxup ref \\ xxunk } & \n",
              "  \\ xxunk } time \" \\ xxunk } \" \\ xxunk } \\ \\ \n",
              "  \\ xxunk } time \" \\ xxunk } \" \\ xxunk } & \n",
              "  \\ xxunk } xxup continuation \\ xxunk } \\ xxunk } \\ \\ \n",
              "  \\ xxunk } xxup tpr \\ xxunk } \" now \" & \n",
              "  \\ xxunk } xxmaj time \\ xxunk } \\ xxunk } \\ \\ \n",
              "  \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  } } \n",
              "  \\ \\ \n",
              "  xxunk mm } \n",
              "  \\ xxunk } { \n",
              "  \\ xxunk mm } \n",
              "  [ { \\ xxunk } { } { \n",
              "  \\ xxunk $ ~ $ t_1 $ } { \n",
              "  xxunk \\ xxunk \\ \\ \n",
              "  \\ xxunk \\ xxunk , xxunk \\ \\ \n",
              "  \\ xxunk \\ xxunk , xxunk \\ \\ \n",
              "  \\ xxunk \\ xxunk , xxunk \\ \\ \n",
              "  $ \\ xxunk \\ \\ \n",
              "  \\ xxunk \\ prec \\ xxunk } \n",
              "  \\ xxunk $ ~ $ t_2 $ } { \n",
              "  xxunk \\ xxunk \\ \\ \n",
              "  \\ xxunk \\ xxunk , xxunk \\ \\ \n",
              "  \\ xxunk \\ xxunk , xxunk \\ \\ \n",
              "  $ \\ xxunk \\ \\ \n",
              "  \\ xxunk \\ prec \\ xxunk } } \n",
              "  { $ \\ xxunk } } \n",
              "  [ { \\ xxunk $ } { \n",
              "  xxunk \\ xxunk } } \n",
              "  ] \n",
              "  [ { \\ xxunk $ } { \n",
              "  xxunk \\ xxunk } } \n",
              "  ] \n",
              "  [ { \\ xxunk $ } { \n",
              "  xxunk \\ xxunk } } \n",
              "  ] \n",
              "  ] \n",
              "  \\ xxunk } \n",
              "  } \n",
              "  \\ end{tabular } \n",
              "  } \n",
              "  % from dev - set \n",
              "  \\ caption{the segmented box \\ xxunk } consists of a set of labelled boxes , i.e. the discourse segments \\ xxunk } and \\ xxunk } , and a single discourse condition . \n",
              "  xxmaj in the condition , discourse relation holds between two discourse segments and is formatted in uppercase . \n",
              "  xxmaj the definite noun phrase and the pronouns are presupposition ( \\ xxunk } , \\ xxunk } , and \\ xxunk } ) triggers . \n",
              "  } \n",
              "  \\ label{fig : xxunk : xxunk } \n",
              "  \\ end{minipage } \n",
              "  \\ vspace{-0.4 cm } \n",
              "  \\ end{figure } \n",
              " \n",
              "  % xxrep 27 xxunk \n",
              "  \\ section{task xxmaj description } \n",
              "  \\ label{sec : task } \n",
              " \n",
              "  xxmaj the xxup xxunk parsing in a nutshell is presented in \\ autoref{fig : xxunk : afraid } . \n",
              "  xxmaj here , the input , a short xxmaj english sentence , needs to be mapped to the output , a xxunk meaning representation in clausal form . \n",
              "  xxmaj concepts , states and events are represented by the word senses ( male \\ xxunk } , entity \\ xxunk } , afraid \\ xxunk } ) from wordnet 3.0 \\ xxunk } and relations are modeled with thematic roles ( \\ xxunk } , \\ xxunk } , \\ xxunk } ) drawn from an extended version of xxunk \\ xxunk } . \n",
              " \n",
              "  xxmaj each entity needs to introduce a discourse referent , i.e. a variable , in the right scope , form an instance of the right concepts , and be connected to other entities via thematic roles or comparison operators . \n",
              "  xxmaj for example , in \\ autoref{fig : xxunk : afraid } , \\ xxunk } introduces a discourse referent $ x_2 $ in the scope \\ xxunk } with the help of the clause \\ xxunk xxup ref x2 } . \n",
              "  xxmaj the clause \\ xxunk entity \" \\ xxunk } \" x2 } makes $ x_2 $ an instance of entity \\ xxunk } . \n",
              "  xxmaj finally , the clause \\ xxunk xxmaj stimulus s1 x2 } connects $ x_2 $ to the event entity $ s_1 $ of \\ xxunk } via the \\ xxunk } thematic role . \n",
              " \n",
              "  xxmaj the xxunk of negation , implication , modal operators or propositional arguments need to be correctly identified . \n",
              "  xxmaj proper names , pronouns , definite descriptions and xxunk \n",
              "  are treated as xxunk and get their own box if they can not be resolved by the local context . xxmaj tense is locally accommodated . \n",
              "  xxmaj for example , \\ autoref{fig : xxunk : afraid } shows how the negation operator introduces the scope ( \\ xxunk } ) and how the named entity \\ xxunk } gives rise to the presupposition ( \\ xxunk } ) . \n",
              "  \\ autoref{fig : xxunk : xxunk } demonstrates how discourse segments get their own scope ( \\ xxunk } and \\ xxunk } ) and how definite noun phrases and pronouns trigger xxunk ( \\ xxunk } , \\ xxunk } , and \\ xxunk } ) . \n",
              "  xxmaj finally , \\ autoref{fig : xxunk : xxunk } depicts an implication with two xxunk ( \\ xxunk } and \\ xxunk } ) , modeling semantics of a universal quantifier , and nested xxunk ( \\ xxunk } and \\ xxunk } ) due to a xxunk pronoun . \n",
              " \n",
              "  xxmaj given the aforementioned nuances of the fine - grained xxunk meaning representations , the xxup xxunk parsing task represents a challenge for machine learning methods . \n",
              " \n",
              " \n",
              " \n",
              " \n",
              "  % xxrep 27 xxunk \n",
              "  \\ xxunk xxmaj representation xxmaj structure } \\ label{sec : xxunk } \\ label{ssec : boxes } \n",
              " \n",
              "  xxmaj the meaning representations used in this shared task are based on \n",
              "  the xxunk put forward in xxup xxunk \\ xxunk : xxunk } and derived from the xxmaj parallel xxmaj meaning xxmaj bank \\ xxunk } . xxmaj there are some important extensions to the theory , though . \n",
              "  xxmaj first , the xxunk are language - neutral , and all non - logical symbols are disambiguated to wordnet synsets or xxunk roles . xxmaj furthermore , xxunk are explicitly represented following \n",
              "  \\ xxunk } and xxmaj xxunk xxup xxunk \\ xxunk } . xxmaj discourse structure is analysed following by xxmaj segmented xxup xxunk \\ xxunk } . xxmaj as in the original xxup xxunk , xxunk are displayed in box format for reading convenience ( xxunk xxunk are displayed with outgoing arrows of the boxes that triggered them ) . xxunk are recursive structures , and for the purpose of evaluation , they are translated into clauses , flattening down the recursion by reification . \n",
              " \n",
              " \n",
              "  \\ xxunk ! ] \n",
              "  \\ centering \n",
              "  \\ caption{a xxup bnf of xxunk : ( possibly empty ) sets are denoted with curly brackets as \\ { $ \\ langle$ xxunk \\ rangle$ \\ } . \n",
              "  xxmaj the string elements for operators and punctuation are in red . } \n",
              "  \\ label{def : bnf } \n",
              "  \\ xxunk \\ textwidth } \n",
              "  \\ xxunk \n",
              "  \\ setlength { \\ xxunk mm plus 1pt minus 1pt } % increase separation between rules \n",
              "  \\ setlength { \\ xxunk mm } % increase separation between xxup lhs / xxup rhs \n",
              "  \\ footnotesize \n",
              "  \\ xxunk } \n",
              "  < xxup xxunk > : : = \\ { < xxup xxunk > \\ } < labelled xxup box > \n",
              " \n",
              "  < labelled xxup box > : : = < label > < xxup box > \n",
              " \n",
              "  < xxup box > : : = < simple xxup box > | < segmented xxup box > \n",
              " \n",
              "  < simple xxup box > : : = \\ { < discourse referent > \\ } \\ { < condition > \\ } \n",
              " \n",
              "  < condition > : : = < basic condition > | < complex condition > \n",
              " \n",
              "  < term > : : = < discourse referent > | < constant > \n",
              " \n",
              "  < basic condition > : : = < semantic role > \\ xxunk > \\ xxunk { , } < term > \\ xxunk { ) } \\ alt < term > < comparison operator > < term > \n",
              "  \\ alt < concept > \\ xxunk \\ _ sense \\ _ number > \\ xxunk > \\ xxunk { ) } \n",
              " \n",
              "  < complex condition > : : = \\ xxunk { \\ xxunk xxup box > | \\ xxunk { \\ xxmaj xxunk xxup box > | \\ xxunk { \\ xxmaj xxunk xxup box > \\ alt < labelled xxup box > \\ xxunk { \\ xxmaj xxunk xxup box > \n",
              "  \\ alt < discourse referent > \\ xxunk xxup box > \n",
              " \n",
              "  < segmented xxup box > : : = \\ { < labelled xxup box > \\ } \\ { < discourse condition > \\ } \n",
              " \n",
              "  < discourse condition > : : = < discourse relation > \\ xxunk > \\ xxunk { , } < label > \\ xxunk { ) } \n",
              " \n",
              "  \\ xxunk } \n",
              "  \\ xxunk \n",
              "  \\ end{minipage } \n",
              "  \\ xxunk } \n",
              " \n",
              "  % xxrep 12 xxunk \n",
              " \n",
              "  a xxup xxunk always contains a main labelled box along with an optional set of presupposition xxunk ( see xxmaj definition \\ , \\ ref{def : bnf } ) . \n",
              "  xxmaj for example , the main labelled box in \\ autoref{fig : xxunk : afraid } is \\ xxunk } while \\ xxunk } is a presupposition . \n",
              "  a box can be simple ( e.g. , the box labelled with \\ xxunk } in \\ autoref{fig : xxunk : afraid } ) or segmented ( e.g. , the box labelled with \\ xxunk } in \\ autoref{fig : xxunk : xxunk } ) . \n",
              "  a simple box consists of a set of discourse referents and a set of conditions . xxmaj conditions can be basic or complex . \n",
              "  xxmaj basic conditions are concept predicates or relations over discourse referents and constants . \n",
              "  xxmaj xxunk are treated as constants , not as discourse referents \\ xxunk } , for example , { \\ em now } is one of such xxunk ( see \\ autoref{fig : xxunk : afraid } ) . \n",
              "  xxmaj complex conditions are those involving labelled boxes . \n",
              "  xxmaj the examples of complex conditions are $ \n",
              "  eg \\ xxunk in \\ autoref{fig : xxunk : afraid } and $ \\ xxunk } \\ xxmaj rightarrow \\ xxunk in \\ autoref{fig : xxunk : xxunk } . \n",
              "  xxmaj finally , a segmented box contains a set of labelled boxes ( \\ xxunk } and \\ xxunk } in \\ autoref{fig : xxunk : xxunk } ) and discourse conditions . \n",
              "  a discourse condition is a discourse relations over box labels , e.g. , $ \\ xxunk in \\ autoref{fig : xxunk : xxunk } . \n",
              " \n",
              "  % xxrep 12 xxunk \n",
              "  % \n",
              "  % \\ xxunk format } \n",
              "  \\ label{ssec : clauses } \n",
              " \n",
              "  xxmaj the clausal form and the box - notation are two different forms of displaying xxunk meaning representations \\ xxunk } . \n",
              "  xxmaj we consider the clausal form a machine - readable format that is suitable for the evaluation with a continuous score between 0 and 1 ( see xxmaj section \\ , \\ ref{sec : evaluation } ) . \n",
              "  xxmaj on the other hand , the box - notation is a human - readable format and originates from xxmaj discourse xxmaj representation xxmaj theory . \n",
              "  xxmaj conversion from the box - notation to the clausal form and vice versa is transparent : each box gets a label , and discourse referents and conditions in the clausal form are preceded by the label of the box they occur in . \n",
              " \n",
              " \n",
              " \n",
              "  % xxrep 5 xxunk xxup xxunk xxrep 5 xxunk \n",
              "  \\ begin{figure}[t ! ] \n",
              "  \\ centering \n",
              "  \\ begin{tabular}{c } \n",
              "  \\ href{https : / / xxunk / explorer / xxunk / xxunk } : xxmaj he put all his money in the box . \n",
              "  \\ \\ [ -2 mm ] \n",
              "  \\ xxunk ] { \\ xxunk \n",
              "  \\ xxunk { \\ , } l l @ { \\ xxunk mm } } l xxunk { \\ , } } \n",
              "  \\ toprule \n",
              "  \\ xxunk } xxup ref \\ xxunk } & \n",
              "  \\ xxunk { \\ % xxmaj he [ 0 ... 2 ] his [ 11 ... 14 ] } \n",
              "  & \\ xxunk } xxup imp \\ xxunk } \\ xxunk } & \n",
              "  \\ xxunk { \\ % all [ 7 ... 10 ] } \n",
              "  \\ \\ \n",
              "  \\ xxunk } male \" \\ xxunk } \" \\ xxunk } & \n",
              "  \\ xxunk { \\ % xxmaj he [ 0 ... 2 ] his [ 11 ... 14 ] } \n",
              "  & \\ xxunk } xxup ref \\ xxunk } & \n",
              "  \\ xxunk { \\ % all [ 7 ... 10 ] } \n",
              "  \\ \\ \n",
              "  \\ xxunk } xxup ref \\ xxunk } & \n",
              "  \\ xxunk { \\ % put [ 3 ... 6 ] } \n",
              "  & \\ xxunk } xxunk \\ xxunk } \\ xxunk } & \n",
              "  \\ xxunk { \\ % all [ 7 ... 10 ] } \n",
              "  \\ \\ \n",
              "  \\ xxunk } xxup tpr \\ xxunk } \" now \" & \n",
              "  \\ xxunk { \\ % put [ 3 ... 6 ] } \n",
              "  & \\ xxunk } entity \" \\ xxunk } \" \\ xxunk } & \n",
              "  \\ xxunk { \\ % all [ 7 ... 10 ] } \n",
              "  \\ \\ \n",
              "  \\ xxunk } time \" \\ xxunk } \" \\ xxunk } & \n",
              "  \\ xxunk { \\ % put [ 3 ... 6 ] } \n",
              "  & \\ xxunk } xxup ref \\ xxunk } & \n",
              "  \\ xxunk { \\ % his [ 11 ... 14 ] } \n",
              "  \\ \\ \n",
              "  \\ xxunk } xxup ref \\ xxunk } & \n",
              "  \\ xxunk { \\ % put [ 3 ... 6 ] } \n",
              "  & \\ xxunk } xxmaj owner \\ xxunk } \\ xxunk } & \n",
              "  \\ xxunk { \\ % his [ 11 ... 14 ] } \n",
              "  \\ \\ \n",
              "  \\ xxunk } xxmaj agent \\ xxunk } \\ xxunk } & \n",
              "  \\ xxunk { \\ % put [ 3 ... 6 ] } \n",
              "  & \\ xxunk } money \" \\ xxunk } \" \\ xxunk } & \n",
              "  \\ xxunk { \\ % money [ 15 ... 20 ] } \n",
              "  \\ \\ \n",
              "  \\ xxunk } xxmaj theme \\ xxunk } \\ xxunk } & \n",
              "  \\ xxunk { \\ % put [ 3 ... 6 ] } \n",
              "  & \\ xxunk } xxmaj destination \\ xxunk } \\ xxunk } & \n",
              "  \\ xxunk { \\ % in [ 21 ... 23 ] } \n",
              "  \\ \\ \n",
              "  \\ xxunk } xxmaj time \\ xxunk } \\ xxunk } & \n",
              "  \\ xxunk { \\ % put [ 3 ... 6 ] } \n",
              "  & \\ xxunk } xxup ref \\ xxunk } & \n",
              "  \\ xxunk { \\ % the [ 24 ... 27 ] } \n",
              "  \\ \\ \n",
              "  \\ xxunk } put \" \\ xxunk } \" \\ xxunk } & \n",
              "  \\ xxunk { \\ % put [ 3 ... 6 ] } \n",
              "  & \\ xxunk } box \" \\ xxunk } \" \\ xxunk } & \n",
              "  \\ xxunk { \\ % box [ 28 ... 31 ] } \n",
              "  \\ \\ \n",
              "  \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  } } \n",
              "  \\ \\ \n",
              "  xxunk mm } \n",
              "  \\ xxunk mm } \n",
              "  [ { \\ xxunk $ } { \n",
              "  xxunk \\ xxunk \\ \\ \n",
              "  \\ xxunk \\ prec \\ xxunk \\ \\ \n",
              "  xxunk } \n",
              "  \\ xxunk $ } { \n",
              "  xxunk \\ xxunk \\ \\ \n",
              "  \\ xxunk \\ xxunk , xxunk } \n",
              "  \\ xxunk \\ xxmaj rightarrow$ } \n",
              "  \\ xxunk $ } { \n",
              "  xxunk \\ xxunk \\ \\ \n",
              "  \\ xxunk \\ xxunk , xxunk \\ \\ \n",
              "  \\ xxunk \\ xxunk , xxunk \\ \\ \n",
              "  \\ xxunk \\ xxunk , xxunk \\ \\ \n",
              "  \\ xxunk \\ xxunk , xxunk } } } \n",
              "  [ { \\ xxunk $ } { \n",
              "  xxunk \\ xxunk \\ \\ \n",
              "  \\ xxunk \\ xxunk , xxunk } } \n",
              "  [ { \\ xxunk $ } { \n",
              "  xxunk \\ xxunk } } \n",
              "  ] \n",
              "  ] \n",
              "  [ { \\ xxunk $ } { \n",
              "  box$ \\ xxunk } } \n",
              "  ] \n",
              "  ] \n",
              "  \\ xxunk } \n",
              "  \\ end{tabular } \n",
              "  % from xxup pmb - test \n",
              "  \\ caption{the xxup xxunk contains the example of nested xxunk triggered by the xxunk pronoun \\ xxunk } . \n",
              "  xxmaj the main box \\ xxunk } of the xxup xxunk xxunk a set of two xxunk . \n",
              "  xxmaj at the same time , one of the xxunk xxunk , namely $ \\ pair { \\ { \\ xxunk } \\ } , \\ xxunk , itself carries the presupposition \\ xxunk } . \n",
              "  xxmaj note that the xxunk about a male discourse referent , triggered by \\ xxunk } and \\ xxunk } separately , are merged into a single presupposition box \\ xxunk } . xxmaj the clauses are accompanied with aligned tokens . \n",
              "  } \n",
              "  \\ label{fig : xxunk : xxunk } \n",
              "  \\ end{figure } \n",
              " \n",
              " \n",
              "  % xxrep 27 xxunk \n",
              "  \\ section{data } \n",
              "  \\ label{sec : data } \n",
              "  % xxrep 12 xxunk \n",
              "  \\ xxunk xxmaj data } \n",
              "  \\ label{ssec : xxunk } \n",
              " \n",
              "  xxmaj for the shared task we released the training , development , and test data , taken from the xxmaj parallel xxmaj meaning xxmaj bank ( xxup pmb , \\ xxunk } ) . xxmaj the xxup pmb is a parallel corpus annotated with formal meaning xxunk \n",
              "  \\ footnote{a part of the corpus can be viewed online via the xxup pmb explorer : \\ url{http : / / xxunk / explorer } } \n",
              "  xxmaj these representations capture the most probable interpretation of a sentence ; no ambiguities or under - specification techniques are employed . \n",
              "  xxmaj the formal meaning representations are automatically constructed and manually corrected . xxmaj completely correct representations are flagged as \\ xxunk } . \n",
              "  xxmaj representations that are partly manually corrected are marked as \\ xxunk } , while the rest is marked \\ xxunk } . \n",
              " \n",
              " \n",
              "  xxmaj the xxup pmb release number used for the shared task is xxunk % \n",
              "  \\ footnote { \\ url{https : / / xxunk / xxunk } } , of which some statistics are shown in \\ xxunk : stats } . xxmaj note that xxup xxunk tokens and types are underrepresented in the silver and xxunk data compared to the gold data . \n",
              "  xxmaj this is because the gold data contains more manual corrections on the token level than the silver and xxunk data . \n",
              "  xxmaj for the example of multi - word expressions see \n",
              "  \\ autoref{fig : xxunk } . \n",
              "  xxmaj in the shared task , participants were allowed to use the silver and xxunk data , this would especially make sense in the case of data - hungry neural models , though there is no guarantee that those representations resemble the gold standard . \n",
              " \n",
              "  \\ begin{table}[t ] \n",
              "  \\ centering \n",
              "  \\ caption{statistics for the xxup pmb release xxunk and the shared task evaluation set . } \n",
              "  \\ label{tab : stats } \n",
              "  \\ begin{tabular } { l | xxwrep 6 r } \n",
              "  \\ toprule \n",
              "  \\ bf xxmaj data splits & \\ bf xxmaj docs & \\ bf xxmaj tokens & \\ bf xxmaj word types & \\ bf xxup xxunk tokens & \\ bf xxup xxunk types \\ \\ \n",
              "  \\ midrule \n",
              "  xxup pmb xxunk gold train & xxunk & xxunk & xxunk & xxunk & xxunk \\ \\ \n",
              "  xxup pmb xxunk gold dev & xxunk & xxunk & xxunk & 71 & 61 \\ \\ \n",
              "  xxup pmb xxunk gold test & 650 & xxunk & xxunk & 108 & 100 \\ \\ \n",
              "  xxup pmb xxunk silver & xxunk & xxunk & xxunk & xxunk & xxunk \\ \\ \n",
              "  xxup pmb xxunk xxunk & xxunk & xxunk & xxunk & xxunk & 699 \\ \\ \n",
              "  \\ midrule \n",
              "  xxmaj evaluation set & 600 & xxunk & xxunk & 92 & 79 \\ \\ \n",
              "  \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  \\ vspace{-0.4 cm } \n",
              "  \\ end{table } \n",
              " \n",
              " \n",
              " \n",
              "  xxmaj the data provided to the shared task participants consists of pairs of a raw natural language text and its corresponding xxunk meaning representation in clausal xxunk \n",
              "  \\ footnote { \\ url{https : / / github.com / xxunk / xxunk / tree / master / data / xxunk } } \n",
              "  xxmaj whether the meaning representation is of gold , silver or xxunk standard is explicitly indicated . \n",
              "  xxmaj to facilitate automatic learning of xxunk meaning representations , we also provided automatically induced alignments between clauses and tokens , where token positions are provided with character xxunk . \n",
              "  xxmaj the examples of clause - token alignments are give in \\ autoref{fig : xxunk : xxunk } and \\ autoref{fig : xxunk } . \n",
              "  xxmaj the latter represents an exact formatting of the text and clausal form pair provided in the shared task . \n",
              " \n",
              " \n",
              " \n",
              "  % xxrep 7 xxunk xxup begin samples of training data \n",
              "  \\ xxunk ] \n",
              "  \\ centering \n",
              "  % \\ lstset { \n",
              "  % frame = single , \n",
              "  % xxunk , \n",
              "  % xxunk mm , \n",
              "  % xxunk mm \n",
              "  % } \n",
              "  % \\ begin{subfigure } { \\ textwidth } \n",
              "  % \\ xxunk mm , xxunk mm } \n",
              "  \\ begin{tabular}{c } \n",
              "  \\ xxunk { \\ ttfamily \\ small } , xxunk \\ $ ] \n",
              "  xxmaj xxunk xxmaj xxunk was xxunk for collapse of xxmaj xxunk xxmaj bank xxup xxunk . \n",
              " \n",
              "  b1 xxup ref x1 % xxmaj xxunk \\ xxunk [ 0 ... 11 ] \n",
              "  b1 xxmaj name x1 \" xxunk \\ xxunk \" % xxmaj xxunk \\ xxunk [ 0 ... 11 ] \n",
              "  b1 male \" xxunk \" x1 % xxmaj xxunk \\ xxunk [ 0 ... 11 ] \n",
              "  b2 xxup ref t1 % was [ 12 ... 15 ] \n",
              "  b2 xxup tpr t1 \" now \" % was [ 12 ... 15 ] \n",
              "  b2 xxmaj time e1 t1 % was [ 12 ... 15 ] \n",
              "  b2 time \" xxunk \" t1 % was [ 12 ... 15 ] \n",
              "  b2 xxup ref e1 % xxunk [ 16 ... 24 ] \n",
              "  b2 xxmaj patient e1 x1 % xxunk [ 16 ... 24 ] \n",
              "  b2 arrest \" xxunk \" e1 % xxunk [ 16 ... 24 ] \n",
              "  b2 xxmaj theme e1 x2 % for [ 25 ... 28 ] \n",
              "  b2 xxup ref x2 % collapse [ 29 ... 37 ] \n",
              "  b2 collapse \" xxunk \" x2 % collapse [ 29 ... 37 ] \n",
              "  b2 xxmaj patient x2 xxunk % of [ 38 ... 40 ] \n",
              "  xxunk xxup ref xxunk % \n",
              "  xxunk xxmaj name xxunk \" xxunk \\ xxunk \\ xxunk \" % xxmaj xxunk \\ xxunk \\ xxunk [ 41 ... 57 ] \n",
              "  xxunk company \" xxunk \" xxunk % xxmaj xxunk \\ xxunk \\ xxunk [ 41 ... 57 ] \n",
              "  % . [ 57 ... 58 ] \n",
              "  \\ end{lstlisting } \n",
              "  \\ end{tabular } \n",
              "  % \\ xxunk translation and the corresponding clausal form with xxmaj english word senses } \n",
              "  % \\ xxunk : en } \n",
              "  % \\ end{subfigure } \n",
              "  \\ xxunk mm } \n",
              "  \\ caption{a sample of a training document ( \\ href{http : / / xxunk / explorer / xxunk / xxunk } ) . \n",
              "  xxmaj for each document there is a pair of raw text and the corresponding clausal form . \n",
              "  xxmaj clausal forms incorporate automatically induced clause - token alignment . } \n",
              "  \\ label{fig : xxunk } \n",
              "  \\ end{figure } \n",
              " \n",
              "  % xxrep 27 xxunk \n",
              " \n",
              "  \\ subsection{evaluation set } \n",
              "  \\ label{ssec : xxunk } \n",
              " \n",
              "  xxmaj the official evaluation set contains 600 instances that were not released previously . xxmaj they will not be released publicly , but are still available for ( blind ) scoring via the shared task xxunk \n",
              "  \\ footnote { \\ url{https : / / xxunk / competitions / xxunk } } \n",
              "  xxmaj however , during the evaluation phase , we asked the participants to provide xxunk for a set of xxunk short texts . \n",
              "  xxmaj in addition to the raw texts ( 600 ) from the evaluation split , this set contained the train ( xxunk ) , development ( xxunk ) , and test ( 650 ) data from the xxup xxunk release and the sentences ( xxunk ) from the xxup sick dataset \\ xxunk } . \n",
              "  xxmaj the reason for providing the xxunk set of raw texts was three - fold : \n",
              "  ( i ) xxmaj xxunk the raw texts of the evaluation set to make it hard to tune models on them ; \n",
              "  ( ii ) xxmaj obtain the complete information about the performance of the systems on the provided training , development and test sets ; \n",
              "  ( iii ) xxmaj carry out extrinsic evaluation of the participant systems on the natural language inference task . \n",
              " \n",
              " \n",
              "  % xxrep 27 xxunk \n",
              "  \\ section{evaluation xxmaj metrics and xxmaj baselines } \n",
              "  % xxup la : we agreed on to make the section for this \n",
              "  \\ label{sec : evaluation } \n",
              " \n",
              "  xxmaj before comparing a system produced clausal form to the gold one , the produced form is checked on validity --- whether it represents a xxup xxunk . xxmaj if the clausal form is invalid , it is replaced by a single non - matching clause . \n",
              "  xxmaj in the shared task , we include three baseline systems . \n",
              "  xxmaj the evaluation and validation scripts and the baselines are publicly xxunk \n",
              "  \\ footnote { \\ url{http : / / github.com / xxunk / xxunk } } \n",
              " \n",
              " \n",
              "  % xxrep 12 xxunk \n",
              "  \\ xxunk } \n",
              "  \\ label{ssec : xxunk } \n",
              " \n",
              "  xxmaj not all sets of clauses correspond to a well - formed xxup xxunk , e.g. , discourse referents found in the conditions should be explicitly introduced in the boxes , or there should exist labelled boxes for the labels used in the discourse conditions . \n",
              "  xxmaj we employ the validator \\ xxunk } \\ xxunk } to automatically check a set of clauses on well - xxunk . \n",
              "  \\ xxunk } does several checks for validity checking . \n",
              "  xxmaj for example , first it scans each clause separately in a clausal form and identifies the types of variables based on the operators . \n",
              "  xxmaj for each discourse referent variable , it checks the existence of the binding discourse referent . \n",
              "  xxmaj during this procedure , \\ xxunk } also detects positions of the boxes in the xxup xxunk ( i.e. , so - called the subordinate relation ) . \n",
              "  xxmaj based on this information , it is checked that nested boxes do not create loops and there is a unique main box in the xxup xxunk . \n",
              " \n",
              "  xxmaj all the released clausal forms of the xxunk are valid . \n",
              "  xxmaj we provided the participants with \\ xxunk } in order to help them identify the ill - formed clausal forms produced by their systems . \n",
              " \n",
              " \n",
              "  % xxrep 12 xxunk \n",
              "  \\ subsection{evaluation } \n",
              "  \\ label{ssec : xxunk } \n",
              " \n",
              "  xxmaj the evaluation defines to what degree a system output clausal form is similar to the corresponding gold one . \n",
              "  xxmaj to compare the system output and gold representations , we compute the xxmaj f1-score over the clauses , following \\ xxunk : xxunk } . \n",
              "  xxmaj we use the tool \\ xxunk } \\ xxunk } , which is specifically designed to evaluate xxunk . xxmaj it is based on the \\ xxunk } \\ xxunk } tool that is used to evaluate xxup amr parsers . xxmaj it is essentially a hill - climbing algorithm that finds the best variable mapping between the produced xxup xxunk and the gold standard . xxmaj to avoid local optima , we restart the procedure 10 times . xxmaj in order to prevent an xxunk f - score , before searching the maximal matching , \\ xxunk } discards those { \\ tt xxunk which are deemed redundant . \n",
              "  a { \\ tt xxunk \\ mbox{$ \\ langle$ \n",
              "  xxunk xxup ref x}$ \\ rangle$ } is redundant if and only if its discourse referent \n",
              "  xxunk } occurs with a concept predicate in a basic condition of the same box \n",
              "  xxunk } -- in other words , there exists a clause of the form \\ mbox{$ \\ langle$ \n",
              "  xxunk $ xxunk \" $ xxunk \" x}$ \\ rangle$ } . \\ footnote{in \\ autoref{fig : xxunk - match } redundant { \\ tt xxunk are xxunk through . } \n",
              " \n",
              " \n",
              "  % xxrep 5 xxunk match clausal forms xxrep 5 xxunk \n",
              "  \\ xxunk ! ] \n",
              "  \\ centering \n",
              "  \\ begin{tabular}{c c c } \n",
              "  xxmaj sample system output & xxmaj optimal mapping & xxmaj gold representation \\ \\ \n",
              "  \\ xxunk ] { \\ texttt { \n",
              "  \\ xxunk { \\ , } xxunk { \\ , } } \\ toprule \n",
              "  \\ matched { \\ xxunk } xxup imp \\ xxunk } \\ xxunk } } \\ \\ \n",
              "  \\ xxunk { \\ xxunk } xxup ref \\ xxunk } } \\ \\ \n",
              " \n",
              "  xxunk { \\ xxunk } every \" \\ xxunk } \" \\ xxunk } } \\ \\ \n",
              "  \\ xxunk { \\ xxunk } xxup ref \\ xxunk } } \\ \\ \n",
              " \n",
              "  xxunk { \\ xxunk } xxmaj agent \\ xxunk } \\ xxunk } } \\ \\ \n",
              "  \\ matched { \\ xxunk } new \" \\ xxunk } \" \\ xxunk } } \\ \\ \n",
              "  \\ matched { \\ xxunk } xxmaj time \\ xxunk } \\ xxunk } } \\ \\ \n",
              "  \\ xxunk { \\ xxunk } xxup ref \\ xxunk } } \\ \\ \n",
              " \n",
              "  xxunk { \\ xxunk } time \" \\ xxunk } \" \\ xxunk } } \\ \\ \n",
              " \n",
              "  xxunk { \\ xxunk } xxup ref \\ xxunk } } \\ \\ \n",
              "  \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  } } \n",
              "  & \n",
              "  \\ xxunk ] { \\ texttt { \n",
              "  \\ renewcommand \\ arraystretch{1.2 } \n",
              "  \\ xxunk } \n",
              " \n",
              "  xxunk mm } \n",
              "  \\ xxunk } $ \\ xxunk \\ xxunk } \\ \\ \n",
              "  \\ xxunk } $ \\ xxunk \\ xxunk } \\ \\ \n",
              "  \\ xxunk } $ \\ xxunk \\ xxunk } \\ \\ \n",
              "  \\ xxunk } $ \\ xxunk \\ xxunk } \\ \\ \n",
              "  \\ xxunk } $ \\ xxunk \\ xxunk } \\ \\ \n",
              "  \\ xxunk } $ \\ xxunk \\ xxunk } \\ \\ \n",
              "  \\ xxunk } $ \\ xxunk \\ xxunk } \\ \\ \n",
              "  \\ xxunk } $ \\ xxunk \\ textnormal { \\ xxunk / a } } \n",
              "  \\ end{tabular } \n",
              "  } } \n",
              "  & \n",
              "  \\ xxunk ] { \\ texttt { \n",
              "  \\ xxunk { \\ , } xxunk { \\ , } } \\ toprule \n",
              "  \\ matched { \\ xxunk } xxup imp \\ xxunk } \\ xxunk } } \\ \\ \n",
              "  \\ xxunk { \\ xxunk } xxup ref \\ xxunk } } \\ \\ \n",
              " \n",
              "  xxunk { \\ xxunk } entity \" \\ xxunk } \" \\ xxunk } } \\ \\ \n",
              "  \\ xxunk { \\ xxunk } xxup ref \\ xxunk } } \\ \\ \n",
              " \n",
              "  xxunk { \\ xxunk } xxmaj theme \\ xxunk } \\ xxunk } } \\ \\ \n",
              "  \\ matched { \\ xxunk } new \" \\ xxunk } \" \\ xxunk } } \\ \\ \n",
              "  \\ matched { \\ xxunk } xxmaj time \\ xxunk } \\ xxunk } } \\ \\ \n",
              "  \\ xxunk { \\ xxunk } xxup ref \\ xxunk } } \\ \\ \n",
              " \n",
              "  xxunk { \\ xxunk } time \" \\ xxunk } \" \\ xxunk } } \\ \\ \n",
              " \n",
              "  xxunk { \\ xxunk } xxup xxunk \\ xxunk } \" now \" } \\ \\ \n",
              "  \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  } } \n",
              "  \\ end{tabular } \n",
              "  \\ \\ [ 3 mm ] \n",
              " \n",
              "  \\ xxunk mm } \n",
              "  \\ begin{tabular}{@{}cc@ { } } \n",
              "  \\ xxunk } \n",
              "  \\ xxunk mm } \n",
              "  [ { \\ xxunk $ } { \n",
              "  xxunk } \n",
              "  \\ xxunk $ } { \n",
              "  xxunk \\ xxunk } \n",
              "  \\ xxunk \\ xxmaj rightarrow$ } \n",
              "  \\ xxunk $ } { \n",
              "  xxunk \\ xxunk \\ \\ \n",
              "  \\ xxunk \\ xxunk , xxunk \\ \\ \n",
              "  \\ xxunk \\ xxunk , xxunk } } } \n",
              "  [ { \\ xxunk $ } { \n",
              "  $ \\ xxunk } } \n",
              "  ] \n",
              "  ] \n",
              "  \\ xxunk } \n",
              "  & \n",
              "  \\ xxunk } \n",
              "  \\ xxunk mm } \n",
              "  [ { \\ xxunk \\ xxunk \\ \\ \n",
              "  \\ xxunk = \\ xxunk \\ \\ \n",
              " \n",
              "  xxunk } \n",
              "  \\ xxunk $ } { \n",
              "  xxunk \\ xxunk } \n",
              "  \\ xxunk \\ xxmaj rightarrow$ } \n",
              "  \\ xxunk $ } { \n",
              "  xxunk \\ xxunk \\ \\ \n",
              "  \\ xxunk \\ xxunk , xxunk \\ \\ \n",
              "  \\ xxunk \\ xxunk , xxunk } } } \n",
              "  ] \n",
              "  \\ xxunk } \n",
              "  \\ end{tabular } \n",
              "  \\ caption{an optimal mapping of variables which maximizes overlap between the system output and gold clausal forms for the sentence ( xxup pmb document \\ href{http : / / xxunk / explorer / xxunk / xxunk } ) \\ xxunk is new } . \n",
              "  xxmaj the maximal overlap yields an f - score of $ xxunk \n",
              "  xxmaj matching , non - matching and redundant clauses are in green , red , and xxunk through , respectively . \n",
              "  xxmaj the box - notation of xxunk meaning representations is not available during the comparison of clausal forms . } \n",
              "  \\ label{fig : xxunk - match } \n",
              "  \\ vspace{-0.4 cm } \n",
              "  \\ end{figure * } \n",
              " \n",
              " \n",
              "  xxmaj an example of comparing the clausal forms of two xxunk meaning representations is shown in \\ autoref{fig : xxunk - match } . \n",
              "  xxmaj with respect to the optimal mapping , both , the sample system output and gold clauses , include three clauses that could not be matched with each other while four clauses are matched . \n",
              "  xxmaj the optimal mapping gives us a precision and recall of $ \n",
              "  xxunk , resulting in an f - score of $ xxunk xxmaj similarly to xxup amr , we use micro - averaged f - score when evaluating a set of xxunk . \n",
              " \n",
              "  xxmaj an aspect that is different from the xxup amr evaluation system is that we generalize over synonyms . \n",
              "  xxmaj in a preprocessing step of the evaluation , all word senses are converted to its wordnet 3.0 synset xxup id . \n",
              "  xxmaj for example , fox \\ xxunk } and xxunk \\ xxunk } both get normalized to xxunk \\ xxunk } and are thus able to match . \n",
              " \n",
              "  xxmaj to calculate whether two systems differ significantly , we perform approximate randomization \\ xxunk - xxunk } , with $ \\ alpha$ = $ 0.05 $ , \\ xxunk } = $ 1000 $ and $ xxmaj xxunk } ) > xxmaj xxunk as test statistic for each individual xxup xxunk pair . \n",
              " \n",
              "  \\ subsection{baselines } \n",
              " \n",
              "  xxmaj we provide three baseline parsers : \\ xxunk } , \\ xxunk - xxunk } and \\ xxunk } . \\ xxunk } simply outputs a default xxup xxunk , which is a xxup xxunk that is the most similar to the xxunk in our training set . \\ footnote{for xxup pmb release xxunk this is the xxup xxunk for \\ xxunk xxunk for himself . } } \n",
              "  \\ xxunk - xxunk } outputs the xxup xxunk of the most similar sentence in the training set , based on the cosine distance of the average word - embedding vector , calculated using glove \\ xxunk } . \n",
              "  \\ xxunk } is a script that converts the output of an xxup amr parser to a valid xxup xxunk by applying a set of rules , described in \\ xxunk } and \\ xxunk } . \n",
              "  xxmaj we will provide scores on the development , test and evaluation sets by using the xxup amr parser of \\ xxunk } . \n",
              " \n",
              " \n",
              " \n",
              "  % xxrep 27 xxunk \n",
              "  \\ xxunk xxmaj systems } \n",
              " \n",
              "  xxmaj we received a total of five submissions in the shared task out of 32 registered participants . \n",
              "  xxmaj three out of five submitted a system paper . \n",
              "  xxmaj the general characteristics of the participating systems are give in \\ xxunk : systems } . \n",
              "  xxmaj following \\ xxunk } , we explicitly encouraged the participants to include ablation experiments and negative results ( if any ) . \n",
              "  xxmaj note that the authors of the systems \\ xxunk { } and \\ xxunk { } are from the organizers . \n",
              "  xxmaj below , we provide a short description of each system . \n",
              " \n",
              "  \\ xxunk ] \n",
              "  % \\ vspace{-0.4 cm } \n",
              "  \\ centering \n",
              "  \\ caption{overview of the participating systems } \n",
              "  \\ label{tab : systems } \n",
              "  \\ begin{tabular}{ll xxrep 4 c } \n",
              "  \\ toprule \n",
              "  & \\ textbf{model } & \\ textbf{input } & \\ xxunk } & \\ xxunk } & \\ xxunk } \\ \\ \n",
              "  \\ midrule \n",
              "  \\ xxunk & xxmaj transformer & char & \\ cross & \\ cmark & \\ cmark \\ \\ \n",
              "  \\ xxunk & seq2seq & char & \\ cross & \\ cmark & \\ cross \\ \\ \n",
              "  \\ xxunk & seq2seq & char & \\ cross & \\ cmark & \\ cross \\ \\ \n",
              "  \\ xxunk & stack - lstms & word & \\ cmark & \\ cross & \\ cross \\ \\ \n",
              "  \\ xxunk & bi - xxup lstm & word & \\ cmark & \\ cross & \\ cross \\ \\ \n",
              "  \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  \\ vspace{-0.4 cm } \n",
              "  \\ end{table } \n",
              " \n",
              "  % xxrep 10 xxunk \n",
              "  \\ subsection { \\ xxunk } } \n",
              " \n",
              "  \\ xxunk { } , the parser described in \\ xxunk } , uses a character - level neural sequence - to - sequence model to produce xxunk . xxmaj they apply a number of methods to improve performance , such as rewriting the variables to a more general format , introducing a feature for uppercase letters and \\ emph{not } using character - level representation for xxup xxunk roles and operators . xxmaj moreover , they show that performance can be substantially improved by first pre - training on gold and silver data , after which the parser is fine - tuned on only the gold standard data . \n",
              "  \\ vspace{-0.1 cm } \n",
              "  % xxrep 10 xxunk \n",
              "  \\ subsection { \\ xxunk : xxunk } } \n",
              "  xxmaj the system of \\ xxunk { } is the parser described in \\ xxunk } and \\ xxunk : xxunk } , which follows up on their work previously described in \\ xxunk } . xxmaj they improve on this work in two ways : ( i ) by switching their sequence - to - sequence framework from opennmt \\ xxunk } to xxmaj xxunk \\ xxunk } and ( ii ) by providing the encoder with linguistic information ( lemmas , semantic tags \\ xxunk - xxunk } , xxup pos - tags , dependency parses and xxup xxunk xxunk ) that are encoded in a separate encoder . \n",
              "  \\ vspace{-0.1 cm } \n",
              " \n",
              "  % xxrep 10 xxunk \n",
              "  \\ subsection { \\ xxunk : liu } } \n",
              "  \\ xxunk { } also follow the approach of \\ xxunk } in terms of pre- and postprocessing the data , but they improve on it by using the xxmaj transformer model \\ citep{vaswani2017attention } , instead of a sequence - to - sequence xxup rnn . xxmaj also , they show that employing the xxunk standard in addition to the gold and silver standard leads to improved performance . \n",
              "  \\ vspace{-0.1 cm } \n",
              " \n",
              "  % xxrep 10 xxunk \n",
              "  \\ subsection { \\ xxunk : xxunk } } \n",
              "  \\ xxunk { } aim to find a middle - ground between traditional symbolic approaches and the recent neural ( sequence - to - sequence ) models . xxmaj they employ a transition - based parser that relies on explicit word - meaning pairs that are found in the training set . xxmaj parsing decisions are made based on vector representations of parser states , which are encoded using stack - lstms . \n",
              "  \\ vspace{-0.1 cm } \n",
              " \n",
              "  % xxrep 10 xxunk \n",
              "  \\ subsection { \\ xxunk \\ protect \\ footnotemark } \n",
              "  \\ xxunk full list of authors : xxmaj xxunk xxmaj xxunk , xxmaj xxunk xxmaj xxunk , xxmaj adam xxmaj xxunk and xxmaj xxunk xxmaj xxunk ( xxmaj university of xxmaj edinburgh ) . \n",
              "  xxmaj since the authors xxunk from submitting a system paper due to the xxup acl policy for submission , we include a slightly extended summary of their system , xxunk provided by them . } \n",
              "  % \n",
              "  \\ xxunk { } propose a graph decoder that given an input sentence encoded via a bidirectional xxup lstm generates a xxup dag ( xxmaj directed xxmaj acyclic xxmaj graph ) as a sequence of fragments from a graph grammar . \n",
              "  xxmaj these fragments are \\ xxunk } ; predicate names , synset and information on whether the predicate is xxunk or not are predicted in a second step , conditioned on the fragment and the decoding history . \n",
              "  xxmaj two are the main features of the graph parser : 1 ) it is agnostic to the underlying semantic formalism and does not need any preprocessing step to deal with variable binding ; \n",
              "  2 ) fragments are aware of the overall graph structure and the graph is built incrementally via a process of non - terminal rewriting . \n",
              "  ( 1 ) sets this method apart from the graph parser of \\ xxunk } where a grammar is extracting via an elaborate pre - processing step , tailored to a specific formalism , whereas ( 2 ) allows to leverage neural sequential decoding \\ xxunk } . \n",
              "  xxmaj the only preprocessing step required is to convert xxunk in clause format into single - rooted , fully instantiated dags ; \n",
              "  we do so by treating both variables and boxes as nodes and semantic roles , operators and discourse relations as edges between those ( where each binary operator or relation gives rise to two edges ) . \n",
              "  xxmaj similarly , the only postprocessing step lies in converting the graph back to clause format . xxmaj this last step can inject errors in the parse and it is the reason why some of the output graphs can be ill - formed . \n",
              " \n",
              "  % xxrep 27 xxunk \n",
              "  \\ section{results } \n",
              " \n",
              "  \\ begin{table}[t ] \n",
              "  \\ centering \n",
              "  \\ xxunk results of the shared task for the participating systems } \n",
              "  \\ begin{tabular } { l | c c c | c c c } \n",
              "  \\ toprule \n",
              "  % \\ multirow{2 } { * } { \\ xxunk \\ xxunk mm } { \\ xxunk mm xxmaj sets } } \n",
              "  & \\ xxunk xxunk ( f \\ % ) } & \\ xxunk set ( \\ % ) } \\ \\ \n",
              "  % \\ cline{2 - 7 } \n",
              "  & xxmaj train & xxmaj dev & xxmaj test & xxmaj prec . & xxmaj rec . & f \\ \\ \n",
              "  \\ midrule \n",
              "  \\ xxunk } & xxup na & xxunk & 40.1 & \\ xxunk } & \\ xxunk } & 38.8 \\ \\ \n",
              "  \\ xxunk } & xxup na & 40.0 & xxunk & \\ xxunk } & \\ xxunk } & xxunk \\ \\ \n",
              "  \\ xxunk - xxunk } & xxup na & 53.3 & 57.7 & \\ xxunk } & \\ xxunk } & xxunk \\ \\ \n",
              "  \\ midrule \n",
              "  \\ xxunk & 91.1 & 69.9 & 73.3 & \\ xxunk } & \\ xxunk } & xxunk \\ \\ \n",
              "  \\ xxunk & 84.2 & xxunk & xxunk & \\ xxunk } & \\ xxunk } & 70.9 \\ \\ \n",
              "  \\ xxunk { } & 88.5 & 81.2 & xxunk & \\ xxunk } & \\ xxunk } & 79.7 \\ \\ \n",
              "  \\ xxunk { } & 94.9 & 86.5 & 86.8 & \\ xxunk } & \\ xxunk } & xxunk \\ \\ \n",
              "  \\ xxunk & 96.9 & 85.5 & xxunk & \\ xxunk } & \\ xxunk } & 84.8 \\ \\ \n",
              "  \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  \\ label{tab : results } \n",
              "  \\ end{table } \n",
              " \n",
              "  \\ xxunk : results } shows the official results of the shared task . xxmaj the system of \\ xxunk \\ achieved the best performance , though there is no significant difference with the work of \\ xxunk \\ ( $ p = 0.23 $ ) . xxmaj the systems of \\ xxunk \\ and \\ xxunk , though clearly outperforming the baselines , are a bit behind the best three systems . xxmaj however , they can likely improve performance by incorporating silver and xxunk standard data . xxmaj no systems seem to have overfit on the provided dev and test sets . xxmaj the work of \\ xxunk \\ is perhaps overfit on the training set , given their high score on train compared to the test sets . \n",
              " \n",
              "  \\ xxunk : xxunk } shows a more detailed overview of the results . xxmaj all teams produced a substantial amount of perfect xxunk , but only 31 xxunk of them were perfectly produced by each system . \n",
              "  \\ xxunk { } is the only system with a substantial number of ill - formed xxunk . xxmaj this hurts their performance , since they get an f - score of 0.0 in evaluation . xxmaj if we ignore xxunk and score their ill - formed xxunk as if they were valid , their score increases to 72.1 . xxmaj on the other hand , calculating an f - score for \\ xxunk } the ill - formed xxunk ( without xxunk ) gives us an f - score of $ xxunk $ , suggesting that the model would not have scored very well in either way . \n",
              " \n",
              "  xxmaj similar as was observed in \\ xxunk } , word sense disambiguation is problematic for the xxup xxunk parsers . xxmaj when assuming oracle sense numbers , all systems obtain a substantially higher f - score ( increases of $ 1.8 $ to $ 3.6 $ ) . \\ xxunk { } propose a simple method to improve on this sub - problem by taking the most frequent sense in the training set for a concept , though this only increased their f - scores by $ 0.2 $ to $ 0.4 $ on the dev and test sets . xxmaj nouns are the easiest for all models to correctly produce ( possibly due to the frequent \\ xxunk } ) , while adverbs are the hardest , though there are only 12 such clauses in the evaluation set . \n",
              " \n",
              "  \\ begin{table}[t ] \n",
              "  \\ centering \n",
              "  % \\ xxunk } { \n",
              "  \\ xxunk - scores of fine - grained evaluation of the participating systems on the evaluation set . ` ` xxmaj winner out of 5 ' ' counts only those instances for which the parser obtained a higher score than all the rest , while ` ` xxmaj highest out of 5 ' ' allows ties . } \n",
              "  \\ begin{tabular}{l xxrep 5 c } \n",
              "  \\ toprule \n",
              "  & \\ liu { } & \\ xxunk { } & \\ tacl { } & \\ xxunk { } & \\ xxunk { } \\ \\ \\ midrule \n",
              "  \\ textbf{all clauses } & 84.8 & xxunk & 79.7 & 70.9 & xxunk \\ \\ \\ midrule \n",
              "  \\ xxunk xxmaj operators } & 93.9 & 94.2 & xxunk & 75.2 & 76.3 \\ \\ \n",
              "  \\ xxunk roles } & xxunk & xxunk & 78.1 & 72.4 & 66.4 \\ \\ \n",
              "  \\ xxunk synsets } & 83.8 & 82.3 & xxunk & xxunk & xxunk \\ \\ \n",
              "  \\ textbf { \\ quad nouns } & 89.2 & 87.5 & xxunk & xxunk & xxunk \\ \\ \n",
              "  \\ textbf { \\ quad verbs } & 69.5 & 68.9 & xxunk & xxunk & 58.3 \\ \\ \n",
              "  \\ textbf { \\ quad adjectives } & xxunk & xxunk & xxunk & 61.5 & xxunk \\ \\ \n",
              "  \\ textbf { \\ quad adverbs } & xxunk & xxunk & 33.3 & 0.0 & xxunk \\ \\ \\ midrule \n",
              "  \\ xxunk sense numbers } & xxunk & xxunk & xxunk & xxunk & xxunk \\ \\ \n",
              "  \\ xxunk synsets } & xxunk & 90.7 & 87.5 & xxunk & xxunk \\ \\ \n",
              "  \\ xxunk roles } & 88.4 & 88.5 & xxunk & xxunk & xxunk \\ \\ \n",
              "  \\ midrule \n",
              "  \\ textbf { \\ # of perfect xxunk } & 214 & 210 & 160 & 95 & 104 \\ \\ \n",
              "  \\ textbf { \\ # highest out of 5 } & 383 & xxunk & 261 & 171 & xxunk \\ \\ \n",
              "  \\ textbf { \\ # winner out of 5 } & 100 & 77 & 26 & 18 & 18 \\ \\ \n",
              "  \\ textbf { \\ # of ill - formed xxunk } & 1 & 0 & 1 & 37 & 5 \\ \\ \n",
              "  \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  % } \n",
              "  \\ label{tab : xxunk } \n",
              "  \\ end{table } \n",
              " \n",
              " \n",
              " \n",
              "  % xxrep 27 xxunk \n",
              "  \\ section{analysis } \n",
              " \n",
              "  xxmaj longer sentences are probably harder to parse , but which systems behave well on longer sentences ? \n",
              "  \\ autoref{fig : xxunk } shows the performance of the systems plotted over sentence length . xxmaj as expected , all systems show a clear drop in performance for longer sentences . xxmaj the work of \\ xxunk { } is based on the xxmaj transformer model \\ citep{vaswani2017attention } , which claims that performance should not degrade for longer sentences . xxmaj however , for xxup xxunk parsing this does not seem to be the case , as \\ xxunk { } shows a similar decrease in performance as the neural models of \\ xxunk { } and \\ xxunk { } . \n",
              " \n",
              "  \\ begin{figure}[!t ] \n",
              "  \\ centering \n",
              "  \\ includegraphics[width=0.75 \\ xxunk } \n",
              "  \\ caption { \\ label{fig : xxunk of the systems per sentence length ( punctuation are counted as tokens ) . } \n",
              "  \\ end{figure } \n",
              " \n",
              "  xxmaj how similar were the outputs of the participating systems to each other ? \n",
              "  \\ xxunk : comp } shows pairwise comparison of the outputs of the systems on the evaluation set . \n",
              "  xxmaj the only system that has a substantially higher similarity to one of the systems than their official f - score is \\ xxunk { } compared to \\ xxunk { } , which tells us the models make similar mistakes . xxmaj this makes sense given that they are both character - level sequence - to - sequence models trained on the same data . \n",
              "  xxmaj additionally , the output of \\ xxunk { } comes closest to the output of \\ xxunk { } when compared to other systems ' outputs . \n",
              "  xxmaj similarly , \\ xxunk { } is most similar to \\ xxunk { } than to any other systems . \n",
              " \n",
              " \n",
              "  \\ begin{table}[t ] \n",
              "  \\ centering \n",
              "  \\ caption { \\ label{tab : xxunk - scores of all systems compared to each other . } \n",
              "  \\ begin{tabular}{l| xxrep 5 c } \n",
              "  \\ toprule \n",
              "  & ~ ~~ \\ xxunk ~ & \\ xxunk & \\ tacl & ~~ \\ xxunk & \\ xxunk \\ \\ \\ midrule \n",
              "  \\ liu & \\ xxunk { } & 83.4 & xxunk & xxunk & xxunk \\ \\ \n",
              "  \\ xxunk & 83.4 & \\ xxunk { } & xxunk & 70.9 & 68.1 \\ \\ \n",
              "  \\ tacl & xxunk & xxunk & \\ xxunk { } & xxunk & 67.1 \\ \\ \n",
              "  \\ xxunk & xxunk & 70.9 & xxunk & \\ xxunk { } & 61.3 \\ \\ \n",
              "  \\ xxunk & xxunk & 68.1 & 67.1 & 61.3 & \\ xxunk { } \\ \\ \n",
              "  \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  \\ end{table } \n",
              " \n",
              "  xxmaj how complementary were the participating systems to each other ? xxmaj if we had an ensemble system , with an oracle component that selected the best xxup xxunk for each sentence out of the participants submissions , it would obtain an f - score of xxunk . xxmaj when only combining the submissions of \\ xxunk { } and \\ xxunk , it would already result in an f - score of 89.1 . xxmaj this suggests that the neural models in fact do learn different things , though there is still a significant portion that both methods could not learn . \n",
              " \n",
              " \n",
              " \n",
              "  xxmaj finally , are there phenomena that are especially hard for all participating systems ? xxmaj this is not an easy question to answer , and here we show just a first step to such an analysis . \n",
              "  \\ xxunk : worst } shows sentences for which systems , on average , performed badly . xxmaj some of them show non - standard use of xxmaj english , others are phenomena that are relatively rare , such as xxunk , multi - word expressions , and coordination . \n",
              " \n",
              " \n",
              "  \\ begin{table}[htb ] \n",
              "  \\ centering \n",
              "  \\ xxunk for which participating systems , on average , produced the worst xxunk } \n",
              "  \\ label{tab : worst } \n",
              "  \\ xxunk } \n",
              "  \\ toprule \n",
              "  \\ xxunk } & \\ xxunk . f } & \\ xxunk } \\ \\ \n",
              "  \\ midrule \n",
              "  xxmaj thou xxunk . & 21.4 & xxunk xxmaj english \\ \\ \n",
              "  i xxunk ken . & 21.8 & xxmaj xxunk \\ \\ \n",
              "  xxmaj my fault . & 24.2 & noun phrase \\ \\ \n",
              "  a cat has two ears . & xxunk & generic \\ \\ \n",
              "  i look down on xxunk and xxunk . & xxunk & coordination , xxup xxunk \\ \\ \n",
              "  xxmaj get me the number of this young xxunk . & 41.8 & imperative \\ \\ \n",
              "  xxmaj she attends school at night . & xxunk & temporal xxunk \\ \\ \n",
              "  xxmaj the union of xxmaj xxunk and xxmaj england took place in xxunk . & 46.4 & coordination , xxup xxunk \\ \\ \n",
              "  xxmaj something i had n't anticipated happened . & 47.0 & reduced relative clause \\ \\ \n",
              "  xxmaj charles i had his head cut off . & xxunk & ordinal , xxup xxunk \\ \\ \n",
              "  \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  \\ end{table } \n",
              " \n",
              "  % xxrep 27 xxunk \n",
              "  \\ section{conclusion } \n",
              " \n",
              "  xxmaj the first shared task on xxup xxunk parsing was successful . xxmaj it improved the state - of - the - art in xxup xxunk parsing , and the variety in methods used ( models based on recursive neural networks , transformer models , models based on transition - based parsing , graph decoders ) gives inspiration for future research . xxmaj in the future xxup xxunk parsing will be made more challenging by moving to longer sentences and texts ( where we expect simple seq2seq models to have a harder time ) , more complex phenomena ( xxunk , xxunk , multi - word expressions ) , and to languages other than xxmaj english . \n",
              " \n",
              "  \\ section*{acknowledgements } \n",
              " \n",
              "  xxmaj we would like to thank the xxup xxunk organizers , xxmaj xxunk xxmaj xxunk , xxmaj xxunk xxmaj xxunk , xxmaj simon xxmaj xxunk \n",
              "  and xxmaj xxunk xxmaj xxunk , for hosting the shared task in xxmaj xxunk . \n",
              "  xxmaj we also would like to thank all participants for their feedback on the task . \n",
              "  xxmaj this work was funded by the xxup nwo - xxup xxunk grant ` ` xxmaj lost in xxmaj translation -- xxmaj found in xxmaj meaning ' ' ( 288 - 89 - 003 ) . \n",
              " \n",
              " \n",
              "  \\ xxunk } \n",
              "  \\ xxunk } \n",
              " \n",
              " \n",
              "  \\ end{document } \n",
              " \n",
              "y: CategoryList\n",
              "peer_reviewed,peer_reviewed,peer_reviewed,peer_reviewed,peer_reviewed\n",
              "Path: /content/gdrive/My Drive/fastai-v3/SCIgan/clean;\n",
              "\n",
              "Valid: LabelList (79 items)\n",
              "x: TextList\n",
              "xxbos xxrep 8 % xxup icml 2020 xxup example xxup latex xxup submission xxup file xxrep 17 % \n",
              " \n",
              "  \\ documentclass{article } % xxmaj for latex2e \n",
              " \n",
              "  % xxmaj recommended , but optional , packages for figures and better typesetting : \n",
              "  \\ usepackage{microtype } \n",
              "  \\ usepackage{epsfig } \n",
              "  \\ usepackage{graphicx } \n",
              "  \\ usepackage{wrapfig } \n",
              "  % \\ usepackage{subfigure } \n",
              "  \\ usepackage{caption } \n",
              "  \\ usepackage{subcaption } \n",
              " \n",
              "  % table management \n",
              "  \\ usepackage{multirow } \n",
              "  \\ usepackage{rotating } \n",
              "  \\ usepackage{booktabs } \n",
              " \n",
              "  % hyperref makes hyperlinks in the resulting xxup pdf . \n",
              "  % xxmaj if your build breaks ( sometimes temporarily if a hyperlink spans a page ) \n",
              "  % please comment out the following usepackage line and replace \n",
              "  % \\ usepackage{icml2020 } with \\ usepackage[nohyperref]{icml2020 } above . \n",
              "  \\ usepackage{hyperref } \n",
              " \n",
              "  % xxmaj attempt to make hyperref and algorithmic work together better : \n",
              " \n",
              "  ewcommand { \\ thehalgorithm } { \\ arabic{algorithm } } \n",
              " \n",
              " \n",
              "  ewcommand { \\ xxunk ] { \\ multicolumn { # 1 } { # 2 } { \\ rlap { \\ xxunk { # 3 } { # xxunk } } } \n",
              " \n",
              "  % xxmaj use the following line for the initial blind version submitted for review : \n",
              "  % \\ usepackage{icml2020 } \n",
              " \n",
              "  \\ xxunk - xxunk } \n",
              "  \\ usepackage{xspace } \n",
              "  \\ makeatletter \n",
              "  \\ declarerobustcommand \\ onedot { \\ futurelet \\ @let@token \\ @onedot } \n",
              "  \\ def \\ @onedot { \\ ifx \\ @let@token . \\ else . \n",
              "  ull \\ fi \\ xspace } \n",
              "  \\ def \\ eg { \\ emph{e.g } \\ onedot } \\ def \\ xxmaj eg { \\ emph{e.g } \\ onedot } \n",
              "  \\ def \\ ie { \\ emph{i.e } \\ onedot } \\ def \\ xxmaj ie { \\ emph{i.e } \\ onedot } \n",
              "  \\ def \\ xxunk \\ onedot } \\ def \\ xxmaj st { \\ xxunk } \\ onedot } \n",
              "  \\ def \\ cf { \\ emph{c.f } \\ onedot } \\ def \\ xxmaj cf { \\ emph{c.f } \\ onedot } \n",
              "  \\ def \\ etc { \\ xxunk } \\ onedot } \\ def \\ vs { \\ emph{vs } \\ onedot } \n",
              "  \\ def \\ wrt{w.r.t \\ onedot } \\ def \\ xxunk \\ onedot } \n",
              "  \\ def \\ etal { \\ emph{et al } \\ onedot } \n",
              "  \\ makeatother \n",
              " \n",
              " \n",
              "  % xxmaj if accepted , instead use the following line for the camera - ready submission : \n",
              "  \\ usepackage[accepted]{icml2020 } \n",
              " \n",
              "  % xxmaj the \\ icmltitle you define below is probably too long as a header . \n",
              "  % xxmaj therefore , a short form for the running title is supplied here : \n",
              "  \\ xxunk xxmaj emergent xxmaj semantics in xxmaj predictive xxmaj agents via xxmaj question xxmaj answering } \n",
              " \n",
              "  \\ begin{document } \n",
              " \n",
              "  \\ twocolumn [ \n",
              "  \\ xxunk xxmaj emergent xxmaj semantics in xxmaj predictive xxmaj agents via xxmaj question xxmaj answering } \n",
              " \n",
              "  % xxmaj it is xxup okay to include author information , even for blind \n",
              "  % submissions : the style file will automatically remove it for you \n",
              "  % unless you 've provided the [ accepted ] option to the icml2020 \n",
              "  % package . \n",
              " \n",
              "  % xxmaj list of affiliations : xxmaj the first argument should be a ( short ) \n",
              "  % identifier you will use later to specify author affiliations \n",
              "  % xxmaj academic affiliations should list xxmaj department , xxmaj university , xxmaj city , xxmaj region , xxmaj country \n",
              "  % xxmaj industry affiliations should list xxmaj company , xxmaj city , xxmaj region , xxmaj country \n",
              " \n",
              "  % xxmaj you can specify symbols , otherwise they are numbered in order . \n",
              "  % xxmaj ideally , you should not use this facility . xxmaj affiliations will be numbered \n",
              "  % in order of appearance and this is the preferred way . \n",
              "  \\ icmlsetsymbol{equal } { * } \n",
              " \n",
              "  \\ begin{icmlauthorlist } \n",
              "  \\ xxunk xxmaj xxunk } \n",
              "  \\ xxunk xxmaj xxunk } \n",
              "  \\ xxunk xxmaj xxunk } \n",
              "  \\ xxunk xxmaj xxunk } \n",
              "  \\ xxunk xxmaj xxunk } \n",
              "  \\ xxunk xxmaj xxunk } \n",
              "  \\ xxunk xxmaj xxunk } \n",
              "  \\ xxunk xxmaj xxunk } \n",
              "  \\ xxunk xxmaj xxunk } \n",
              "  \\ xxunk xxmaj xxunk } \n",
              "  \\ xxunk xxmaj xxunk } \n",
              "  \\ end{icmlauthorlist } \n",
              " \n",
              "  \\ xxunk xxmaj institute of xxmaj technology } \n",
              "  \\ xxunk } \n",
              " \n",
              "  \\ xxunk } \n",
              " \n",
              " \n",
              "  % xxmaj you may provide any keywords that you \n",
              "  % find helpful for describing your paper ; these are used to populate \n",
              "  % the \" keywords \" metadata in the xxup pdf but will not be shown in the document \n",
              "  \\ xxunk xxmaj learning , xxup icml } \n",
              " \n",
              "  \\ vskip 0.3 in \n",
              "  ] \n",
              " \n",
              " \n",
              "  % this must go after the closing bracket ] following \\ twocolumn [ ... \n",
              " \n",
              "  % xxmaj this command actually creates the footnote in the first column \n",
              "  % listing the affiliations and the copyright notice . \n",
              "  % xxmaj the command takes one argument , which is text to display at the start of the footnote . \n",
              "  % xxmaj the \\ icmlequalcontribution command is standard text for equal contribution . \n",
              "  % xxmaj remove it ( just { } ) if you do not need this facility . \n",
              " \n",
              "  \\ printaffiliationsandnotice { \\ icmlequalcontribution } % otherwise use the standard text . \n",
              " \n",
              "  \\ begin{abstract } \n",
              "  xxmaj recent work has shown how predictive modeling can endow \n",
              "  agents with rich knowledge of their surroundings , improving \n",
              "  their ability to act in complex environments . xxmaj we propose \n",
              "  question - answering as a general paradigm to decode and \n",
              "  understand the representations that such agents develop , applying \n",
              "  our method to two recent approaches to predictive modeling -- \n",
              "  action - conditional xxup xxunk \\ xxunk } and xxunk \\ xxunk } . \n",
              "  xxmaj after training agents with these predictive objectives in a \n",
              "  visually - rich , $ xxup xxunk environment with an xxunk of objects , colors , shapes , \n",
              "  and spatial configurations , we probe their internal state representations \n",
              "  with synthetic ( xxmaj english ) questions , without backpropagating gradients \n",
              "  from the question - answering decoder into the agent . xxmaj the performance of \n",
              "  different agents when probed this way reveals that they learn to \n",
              "  encode factual , and seemingly compositional , information about \n",
              "  objects , properties and spatial relations from their physical environment . \n",
              "  xxmaj our approach is intuitive , \\ ie ~ humans can easily interpret responses of the model \n",
              "  as opposed to inspecting continuous vectors , and \n",
              "  model - agnostic , \\ ie applicable to any modeling approach . \n",
              "  xxmaj by revealing the implicit knowledge of objects , quantities , properties and relations \n",
              "  acquired by agents as they learn , \\ xxunk - conditional agent probing } can \n",
              "  stimulate the design and development of stronger \n",
              "  predictive learning objectives . \n",
              "  \\ end{abstract } \n",
              " \n",
              "  \\ input{sections / intro } \n",
              "  \\ input{sections / related } \n",
              "  \\ input{sections / data } \n",
              "  \\ input{sections / approach } \n",
              "  \\ input{sections / results } \n",
              "  \\ input{sections / discussion } \n",
              " \n",
              "  % xxmaj acknowledgements should only appear in the accepted version . \n",
              "  % \\ section*{acknowledgements } \n",
              "  % \\ textbf{do not } include acknowledgements in the initial version of \n",
              "  % the paper submitted for blind review . \n",
              " \n",
              "  \\ bibliographystyle{icml2020 } \n",
              "  \\ bibliography{main } \n",
              " \n",
              "  \\ clearpage \n",
              " \n",
              "  \\ appendix \n",
              "  \\ input{sections / appendix } \n",
              " \n",
              "  \\ end{document } \n",
              " ,xxbos \\ documentclass{article } \n",
              " \n",
              "  % if you need to pass options to natbib , use , e.g. : \n",
              "  % \\ passoptionstopackage{numbers , compress}{natbib } \n",
              "  % before loading neurips_2020 \n",
              " \n",
              "  % ready for submission \n",
              "  % \\ usepackage{neurips_2020 } \n",
              " \n",
              "  % to compile a preprint version , e.g. , for submission to arxiv , add add the \n",
              "  % [ preprint ] option : \n",
              "  \\ usepackage[preprint]{neurips_2020 } \n",
              " \n",
              "  % to compile a camera - ready version , add the [ final ] option , e.g. : \n",
              "  % \\ usepackage[final]{neurips_2020 } \n",
              " \n",
              "  % to avoid loading the natbib package , add option nonatbib : \n",
              "  % \\ usepackage[nonatbib]{neurips_2020 } \n",
              " \n",
              "  \\ usepackage[utf8]{inputenc } % allow utf-8 input \n",
              "  \\ usepackage[t1]{fontenc } % use 8-bit xxup t1 fonts \n",
              "  \\ usepackage{hyperref } % hyperlinks \n",
              "  \\ usepackage{url } % simple xxup url typesetting \n",
              "  \\ usepackage{booktabs } % professional - quality tables \n",
              "  \\ usepackage{amsfonts } % blackboard math symbols \n",
              "  \\ usepackage{nicefrac } % compact symbols for 1 / 2 , etc . \n",
              "  \\ usepackage{microtype } % microtypography \n",
              "  \\ usepackage{amsmath } \n",
              "  \\ usepackage{amssymb } \n",
              "  \\ usepackage{graphicx } \n",
              "  % \\ graphicspath{{figures / } } \n",
              " \n",
              "  \\ declaremathoperator { \\ xxup ex } { \\ xxunk expected value \n",
              "  \\ declaremathoperator * { \\ argmax}{arg \\ , max } \n",
              "  \\ declaremathoperator * { \\ argmin}{arg \\ , min } \n",
              " \n",
              "  ewcommand { \\ pluseq } { \\ mathrel{+}= } \n",
              " \n",
              "  % \\ xxunk of observation costs with xxmaj active xxmaj measure xxmaj reinforcement xxmaj learning } \n",
              "  \\ title{active xxmaj measure xxmaj reinforcement xxmaj learning for xxmaj observation xxmaj cost xxmaj minimization } \n",
              "  % \\ title{active xxmaj measure xxmaj reinforcement xxmaj learning \\ \\ \n",
              "  % \\ large a framework for minimizing measurement costs in reinforcement learning } \n",
              "  % \\ large a framework for observation costs minimization } \n",
              " \n",
              "  % xxmaj the \\ author macro works with any number of authors . xxmaj there are two commands \n",
              "  % used to separate the names and addresses of multiple authors : \\ xxmaj and and \\ xxup and . \n",
              "  % \n",
              "  % xxmaj using \\ xxmaj and between authors leaves it to latex to determine where to break the \n",
              "  % lines . xxmaj using \\ xxup and forces a line break at that point . xxmaj so , if latex puts 3 of 4 \n",
              "  % authors names on the first line , and the last on the second line , try using \n",
              "  % \\ xxup and instead of \\ xxmaj and before the third author name . \n",
              " \n",
              "  \\ author{% \n",
              "  xxmaj xxunk xxmaj xxunk \\ \\ \n",
              "  xxmaj digital xxmaj technologies \\ \\ \n",
              "  xxmaj national xxmaj research xxmaj council of xxmaj canada \\ \\ \n",
              "  xxmaj ottawa , xxmaj canada \\ \\ \n",
              "  \\ xxunk } \\ \\ \n",
              "  \\ xxmaj and \n",
              "  xxmaj xxunk xxmaj xxunk \\ \\ \n",
              "  xxmaj department of \n",
              "  xxmaj university of xxmaj victoria \\ \\ \n",
              "  xxmaj victoria , xxmaj canada \\ \\ \n",
              "  \\ xxunk } \\ \\ \n",
              "  \\ xxup and \n",
              "  xxmaj mark xxmaj xxunk \\ \\ \n",
              "  xxmaj faculty of xxmaj engineering \\ \\ \n",
              "  xxmaj university of xxmaj waterloo \\ \\ \n",
              "  xxmaj waterloo , xxmaj canada \\ \\ \n",
              "  \\ xxunk } \\ \\ \n",
              "  \\ xxmaj and \n",
              "  xxmaj xxunk xxmaj xxunk \\ \\ \n",
              "  xxmaj security and xxmaj disruptive xxmaj technologies \\ \\ \n",
              "  xxmaj national xxmaj research xxmaj council of xxmaj canada \\ \\ \n",
              "  xxmaj ottawa , xxmaj canada \n",
              "  xxmaj vector xxmaj institute for xxmaj artificial xxmaj intelligence \\ \\ \n",
              "  xxmaj toronto , xxmaj canada \\ \\ \n",
              "  \\ xxunk } \\ \\ \n",
              "  } \n",
              " \n",
              " \n",
              "  % \\ xxunk xxmaj xxunk et al . } \n",
              " \n",
              "  % xxmaj first names are abbreviated in the running head . \n",
              "  % xxmaj if there are more than two authors , ' et al . ' is used . \n",
              "  % \n",
              " \n",
              "  \\ begin{document } \n",
              " \n",
              "  \\ maketitle \n",
              " \n",
              "  \\ begin{abstract } \n",
              " \n",
              "  xxmaj standard reinforcement learning ( xxup rl ) algorithms assume that the observation of the next state comes instantaneously and at no cost . xxmaj in a wide variety of sequential decision making tasks ranging from medical treatment to scientific discovery , however , multiple classes of state observations are possible , each of which has an associated cost . xxmaj we propose the active measure xxup rl framework ( xxmaj amrl ) as an initial solution to this problem where the agent learns to maximize the costed return , which we define as the discounted sum of rewards minus the sum of observation costs . xxmaj our empirical evaluation demonstrates that xxmaj amrl - q agents are able to learn a policy and state estimator in parallel during online training . xxmaj during training the agent naturally shifts from its reliance on costly measurements of the environment to its state estimator in order to increase its reward . xxmaj it does this without harm to the learned policy . xxmaj our results show that the xxmaj amrl - q agent learns at a rate similar to standard q - learning and xxmaj dyna - xxup q. xxmaj critically , by utilizing an active strategy , xxmaj amrl - q achieves a higher costed return . \n",
              "  \\ end{abstract } \n",
              " \n",
              "  \\ section{introduction } \n",
              " \n",
              "  % xxup suggest : xxmaj do we need an intro section here \n",
              " \n",
              "  xxmaj when seeing a patient concerned about a potentially xxunk skin xxunk , a doctor must decide which diagnostic assessments are required . xxmaj some measurements , such as touch and visual inspection , can easily be conducted during the initial xxunk , whilst others require sophisticated equipment , drawn - out lab analyses , and have higher costs associated with them . xxmaj the doctor must actively decide whether the higher cost assessment will provide information necessary in order to accurately and efficiently select the next treatment action . \n",
              " \n",
              "  xxmaj the above scenario describes a xxmaj markov xxmaj decision xxmaj process ( xxup mdp ) with observation classes and costs . xxmaj environments of this nature include the following properties : \n",
              "  \\ begin{itemize } \n",
              "  \\ item xxmaj one or more classes of observations ( measurements ) of the next state are possible ; \n",
              "  \\ item xxmaj the measurements have explicit associated costs ; and , \n",
              "  \\ item xxmaj the value of the measurement depends on time and space . \n",
              "  \\ end{itemize } \n",
              " \n",
              "  xxmaj indeed , a wide variety of sequential decision making tasks , such as materials design , public health planning during a pandemic and operational planning ( business decision making ) involve the choice of actions and classes of observations with associated costs . \n",
              " \n",
              "  xxmaj the xxup mdp formalism and the environments on which reinforcement learning ( xxup rl ) algorithms are developed and tested , however , are not designed to explore such settings \\ cite{brockman2016openai } . xxmaj in the canonical framework , observations of the state of the environment are produced automatically , instantaneously and have no explicit associated costs . xxmaj generally , agents are agnostic to the state observations provided by the environment in the sense that they learn from what they receive . xxmaj to the extent that the agent might try to improve the quality of observations , it is through deep feature representations \\ cite{mnih2015human } , maintaining a belief state for partially observable mdps \\ cite{kaelbling1998planning } , or taking actions to change the state of the environment in order to gain a better understanding of it \\ xxunk } . xxmaj thus prior work has considered observations , yet has not dealt with the selection of observation classes , nor minimizing observation costs . \n",
              " \n",
              "  xxmaj here , we frame mdps with observation classes and costs as an active learning problem . xxmaj active learning is typically applied to supervised machine learning with the aim of reducing the cost of labelling training data \\ xxunk } . xxmaj however , active learning has recently been applied to xxup rl in the context of determining reward from external experts \\ xxunk , xxunk , xxunk } . xxmaj conversely , we postulate that in some domains observations of the state of the environment , like supervised labels , are expensive to obtain . xxmaj in the context of this work , the active component is applied to learning which measurements to make in a given state at a particular time , or deciding not to make a measurement at all - thereby xxunk the additional information and cost associated with it . xxmaj the aim is to discounted sum of rewards minus observation costs , which we denote as the \\ xxunk return } . \n",
              " \n",
              "  xxmaj we propose the xxmaj active xxmaj measure xxmaj reinforcement xxmaj learning ( xxmaj amrl ) framework in which the agent learns a policy and a state estimator in parallel via online experience . xxmaj the agent chooses actions pairs that change the environment and dictate whether the next state is measured directly or estimated . xxmaj as the state estimator is refined over time , the agent smoothly shifts to increasingly rely on it thereby lowering its observations cost . xxmaj this enables the xxmaj amrl agents to achieve a higher costed return . \n",
              " \n",
              "  xxmaj we demonstrate an implementation of xxmaj amrl using q - learning and a statistical state estimator ( xxmaj amrl - q ) . xxmaj we compare xxmaj amrl - q to q - learning and xxmaj dyna - q on four benchmark learning environments , including a new chemistry motivated environment ; specifically , the junior scientist environment . xxmaj the results show that xxmaj amrl - q achieves a higher sum of rewards minus observation cost than q - learning and xxmaj dyna - q , whilst learning at an equivalent rate to q - learning and xxmaj dyna - xxup q. \n",
              " \n",
              "  % xxmaj amrl represents a new paradigm not described by xxup pomdp or model based xxup rl . < --- xxmaj do we need a sentence like this in the xxunk \n",
              " \n",
              "  \\ xxunk } \n",
              " \n",
              "  xxmaj the main contributions of this work are : \n",
              "  \\ begin{itemize } \n",
              "  \\ item xxmaj formalization of mdps with observation classes and costs \n",
              "  \\ item xxmaj definition of the xxmaj active xxmaj measure xxup rl framework ( xxmaj amrl ) \n",
              "  \\ item xxmaj initial implementation of a q - learning approach , the xxmaj amrl - q algorithm \n",
              "  \\ item xxmaj analysis of xxmaj amrl - q on benchmark xxup rl environments \n",
              "  \\ end{itemize } \n",
              " \n",
              "  \\ section{related xxmaj work } \n",
              " \n",
              "  xxmaj previous work on active reinforcement learning has focused on ameliorating the problem of defining a complete reward function over the state - action space \\ xxunk , xxunk , xxunk } . xxmaj in addition to selecting an action at each time step , the agents in these proposals actively decide to request a human expert to provide the reward for the state - action pair . xxmaj to minimize reliance on human experts , there is a cost assigned to requesting a human - specified reward . xxmaj the agent aims to minimize this cost whilst maximizing the discounted sum of rewards . xxmaj similarly , xxmaj amrl maximizes the discounted sum of rewards minus the sum of observations cost . xxmaj however , the xxmaj amrl agent differs in the sense that state observations are the bottleneck in the learning process rather than the rewards . xxmaj moreover , the xxmaj amrl agent may have multiple different measurements of the state of the environment available to it , each of which has a distinct cost . \n",
              " \n",
              "  xxmaj active perception relates to our work in that the agent takes actions to increase the information available \\ xxunk } . xxmaj the key distinction , however , is that in active adaptive perception applied to xxup rl , the agents employ self - modification and self - evaluation to improve its perception \\ xxunk } . xxmaj alternatively , the xxmaj amrl agent aims to judiciously select observation classes in order to have the necessary and sufficient amount of information to choose the next action in order to maximize costed return . \n",
              " \n",
              "  xxmaj recently , the authors in \\ xxunk , xxunk } proposed the extension of the concept of multi - view learning from supervised domains reinforcement learning . xxmaj they formulate this as an agent having multiple views of the state - space available to it . xxmaj this is the case , for example , for agents controlling autonomous vehicles equipped with multiple sensors . xxmaj this previous work , however , does not contain the concept of observation costs , which are fundamental in applications of xxmaj amrl . \n",
              "  xxmaj approximate dynamic programming ( xxup adp ) aims to ameliorate the ` ` curse - of - dimensionality ' ' in dynamic programming \\ xxunk } . xxmaj it is connected to our work in the sense that it introduces a new component , the post - decision state , to the interaction with the environment . xxmaj alternatively , our work , which is not focused on the curse - of - dimensionality , formulates an action pair that determines the process to be applied in the environment and the class observation to be made . \n",
              " \n",
              "  xxmaj the learning of the state transition dynamics of the xxmaj amrl framework is consistent with the techniques employed in model - based xxup rl \\ xxunk , xxunk , xxunk } . xxmaj the goal of model - based xxup rl , however , is to reduce the number of real - world training steps needed to obtain an optimal policy . xxmaj this does not solve our problem of selecting the observation class , nor minimizing associated observations . \n",
              " \n",
              "  % xxup suggest : xxmaj somewhere , we need to say xxup model based xxup rl wants less real world episodes , xxunk of whether some of those xxunk are \" cheap \" in terms of observation costs . xxmaj amrl only wants less observations in the real world . xxmaj that means it is xxup ok to do lots of real world runs , but you ca n't burn through your observation budget on them . xxmaj this is a more realistic setup for lots of problems . xxmaj e.g. talking to a patient is n't that expensive , but ordering and xxup mri , xxunk , etc etc is . xxup xxunk \n",
              " \n",
              "  % but the key point is that we are solving an xxup xxunk with observation costs where the agent can choose to operate in pseudo xxup pomdp mode in the interest of increasing its costed return \n",
              " \n",
              "  % xxup pomdp , the agent is always in a state of uncertainty . xxmaj the agent is keeping a history in order to try and narrow that uncertainty . \n",
              " \n",
              "  xxmaj learning algorithms for pomdps utilize a state estimator to xxunk the agent 's recent experience in order to reduce uncertainty in partially observable environments . xxmaj at each time step , the next action $ a_t$ is selected based on the the agent 's belief state $ b_t$ as determined by its state estimator , rather than the observation emitted from the environment $ o_t$ \\ cite{kaelbling1998planning } . xxmaj alternatively , in xxmaj amrl the agent is learning an optimal policy under a xxup mdp with observation costs . xxmaj the agent chooses between paying the cost to measure the true state of the environment $ s_t$ or estimating it $ \\ xxunk xxmaj thus , in xxmaj amrl the state estimator is a mechanism to increase the costed return , not manage partial observability . \n",
              " \n",
              "  % xxmaj critically , while uncertainty in pomdps is a consequence of the external environment , uncertainty in xxmaj amrl is a function of agent 's choice to xxunk measuring the state of the environment to lower its observation costs . a xxup pomdp agent can only indirectly affect uncertainty by choosing actions that change the environment thereby lowering its uncertainty . xxmaj alternatively , an xxmaj amrl agent can always opt to measure the state of the environment to removing uncertain at a cost . \n",
              " \n",
              " \n",
              "  \\ section{preliminaries } \n",
              " \n",
              "  xxmaj we define active measure reinforcement learning as a tuple : $ ( s , a , p , xxup s^ \\ prime , r , c , \\ gamma)$. xxmaj the components $ ( s , a , p , xxup s^ \\ prime , r , \\ gamma)$ make up a standard xxup mdp where $ xxup s$ is the state - space , $ xxup a$ is the action - space , $ xxmaj xxunk \\ prime | s , a)$ is the state transition probabilities , $ xxmaj r(s , a)$ is the reward function , and $ \\ gamma \\ in [ 0,1]$ is a discount factor . $ xxup p$ and $ xxup r$ are not known by the agent . $ xxmaj xxunk is the cost charged to the agent each time it decides to measure the state of the environment . xxmaj thus , for a state $ s$ , the environment returns the cost as follows : \n",
              "  \\ begin{equation } \n",
              "  xxmaj xxunk \n",
              "  \\ begin{cases } \n",
              "  c>0 , & \\ text{if } m = \\ xxunk the state } \\ \\ \n",
              "  0 , & \\ text{otherwise } . \n",
              "  \\ end{cases } \n",
              "  \\ end{equation } \n",
              " \n",
              "  xxmaj applications may have multiple observation classes $ \\ mathcal{m } = \\ { 0 , 1,2 , ... \\ } $ , such as different sensors that serve different purposes . xxmaj in this case , each measurement class $ m \\ in \\ mathcal{m}$ may have a different associated cost . xxmaj selecting $ m$ constitutes the active learning choice on the part of the agent . xxmaj the values of $ m>0 $ indicate a specific observation class ( such as a specific sensor ) to be used , whereas $ m=0 $ specifies that no measurement of the environment is to made \\ footnote{when $ m=0 $ , the agent uses its state estimator in place of a measurement of the environment . } . \n",
              " \n",
              "  % xxmaj as in \\ xxunk } , at each time step $ t$ the agent selects an action pair . xxmaj in xxmaj amrl , the action pair $ ( a_t , m_t)$ consists of an atomic process $ a_t \\ in xxup a$ ( \\ textit{e.g . } , move left ) and an observation class $ m_t \\ in \\ mathcal{m}$. \n",
              " \n",
              "  % xxmaj the value of $ m_t$ constitutes the active learning choice on the part of the agent . xxmaj choosing $ m_t>0 $ indicates which observation class ( such as a specific sensor ) of the environment should be used , whereas $ m_t=0 $ specifies that no measurement of the environment is to made at time $ t$ \\ footnote{when $ m_t=0 $ , the agent uses its state estimator in place of the measurement of the environment . } . \n",
              "  % xxmaj in the context of active learning , $ m_t>0 $ is analogous to using an oracle . xxmaj the oracle , however , need not be a human , but rather a sensor in the environment . xxmaj for $ m_t>0 $ , the xxmaj amrl agent utilizes its learned state estimator $ \\ xxunk xxmaj the state estimator is learned in parallel with the agent 's policy . \n",
              " \n",
              "  xxmaj as in \\ xxunk } , at each time step $ t$ the agent selects an action pair . xxmaj in xxmaj amrl , the action pair $ ( a_t , m_t)$ consists of an atomic process $ a_t \\ in xxup a$ ( \\ textit{e.g . } , move left ) and an observation class $ m_t \\ in \\ mathcal{m}$. xxmaj thus , if $ m_t>0 $ , the process $ a_t$ is applied to the environment , and the environment returns the reward $ xxunk and the next state observation $ s_{t+1}$ measured via $ m_t$ ( $ r_{t+1 } , s_{t+1 } = xxmaj xxunk , m_t)$ ) . xxmaj here , $ s_{t+1}$ results from the underlying , unknown transition dynamics $ xxmaj p(s_t , a_t)$. xxmaj for $ m_t=0 $ , the process $ a_t$ is applied to the environment , but the environment only returns the reward $ r_{t+1 } = xxmaj xxunk , xxunk xxmaj in this case , the xxmaj amrl agent estimates the next state $ \\ xxunk } \\ sim \\ xxunk , a_t)$ , and selects its next action pair $ ( a_{t+1 } , xxunk based on this estimate , $ \\ xxunk xxmaj this leads to an alternative agent - environment interaction sequence of the form : \n",
              "  \\ begin{equation } \n",
              "  xxunk ) , \\ xxunk ) , \\ xxunk ... , \n",
              "  \\ end{equation } \n",
              "  where the agent starts each episode with a true measurement of the environment 's current state , $ s_0 $ , and proceeds to sequentially select action pairs that determine the process $ a_t$ to be applied and whether to measure the next state $ s_{t+1}$ or estimate $ \\ xxunk instead . \n",
              " \n",
              "  xxmaj importantly , the reward emitted from the environment is always a function of the process $ a_{t}$ and the true state of the environment $ s_t$ xxunk of whether the agent selected $ a_t$ based on $ s_t$ or an estimate $ \\ xxunk xxmaj for simplicity and generalization , at times we drop the hat notation on the state estimates . \n",
              " \n",
              "  xxmaj in this work , we focus on episodic environments with discrete states , $ s = \\ { 1, ... xxup xxunk \\ } $ , and action sets $ a = \\ { 1, ... xxup xxunk \\ } $ , and stationary state - transition dynamics . xxmaj in an xxup mdp with measurement costs , the objective is to select a sequence of action pairs $ ( a_t , m_t)$ that maximize the costed return , which is defined as the discounted sum of rewards minus the sum of measurement costs : \n",
              "  \\ begin{equation } \n",
              "  v(s ) = \\ xxup ex \\ bigg [ \\ sum^ { \\ xxunk } \\ gamma^t \\ xxunk , a_t ) - xxmaj xxunk ) \\ big ) ~|~ s = s_0 \\ bigg ] . \n",
              "  \\ end{equation } \n",
              " \n",
              "  xxmaj in xxmaj amrl , a policy , $ \\ pi$ maps states $ xxup s$ and actions pairs $ xxup ap$ to a probability $ \\ pi : s \\ times xxup ap \\ rightarrow [ 0,1]$ , such that $ \\ pi(s , xxunk is the probability of selecting action pair $ ap \\ in xxup ap$ in state $ s \\ in xxup s$. xxmaj the value function associated with policy $ \\ pi$ is : \n",
              "  \\ begin{equation } \n",
              "  v _ \\ pi(s ) = \\ xxup ex \\ bigg [ \\ sum^ { \\ xxunk } \\ gamma^t \\ xxunk , a_t ) - xxmaj xxunk , a_t ) \\ big ) ~|~ s = s_0 \\ bigg ] , \n",
              "  \\ end{equation } \n",
              "  where the actions are selected according to $ \\ pi$. xxmaj since actions pairs can be though of as a higher - level class of action , the standard xxup rl theorems hold . xxmaj thus , there is at least one policy $ \\ pi^*$ such that $ xxup v^ { \\ pi}(s ) \\ ge xxup v^ { \\ xxunk , where $ \\ pi^*$ is an optimal policy and $ xxup v^*$ is the corresponding value function . \n",
              " \n",
              "  \\ xxunk - q } \\ label{sec : xxmaj xxunk } \n",
              " \n",
              "  xxmaj we propose an initial implementation of the xxmaj amrl framework for a tabular learning environment . xxmaj our proposed solution utilizes q - learning for the value function and a statistical state transition model . xxmaj we focus on tabular problems here for clarity in the demonstration and analysis . xxmaj our future work will implement xxmaj amrl solutions for continuous state and action spaces . \n",
              " \n",
              "  \\ subsection{overview } \n",
              " \n",
              "  xxmaj as previously stated , xxmaj amrl - q framework learns a value function $ xxup q$ , and a state estimator $ \\ xxunk , a_t)$ in parallel . xxmaj learning $ \\ hat{p}$ and $ xxup q$ is essential to the active learning based solution which enables the agent to reduce its the total number of times it requests a true measurement . xxmaj the theory behind this can be demonstrated with the xxmaj markov chain in xxmaj figure \\ ref{fig : markovchain } . \n",
              " \n",
              "  \\ begin{figure * } \n",
              "  \\ centering \n",
              "  \\ xxunk } \n",
              "  \\ caption{this figure illustrates a five state xxmaj markov chain . } \n",
              "  \\ label{fig : markovchain } \n",
              "  \\ end{figure * } \n",
              " \n",
              "  xxmaj this xxmaj markov chain forms a two action ( left , right ) episodic xxup rl problem where the agent starts in stage zero , and receives a reward of one upon entering the absorbing state , state four . xxmaj for temporal difference ( xxup td ) learning methods , such as q - learning , applied to episodic problems such as this , the value of states and actions is refined over episodes of training from the state closest to the absorbing state back to the start state . xxmaj the backup algorithm for q - learning is : \n",
              "  \\ begin{equation } \n",
              "  xxmaj q(s_t , a_t ) \\ leftarrow xxmaj q(s_t , a_t ) + \\ alpha \\ xxunk } ~ \\ gamma \\ max_a xxmaj q(s_{t+1},a ) - xxmaj q(s_t , a_t ) \\ bigg ] , \n",
              "  \\ end{equation } \n",
              "  where $ xxmaj q(s_t , a_t)$ is the value of action $ a$ in state $ s$ at time $ t$ , $ \\ alpha$ is the learning rate and $ \\ gamma$ is the discount factor . xxmaj if we assume a $ xxmaj q$-table initialized to zeros , after one episode of training is complete , only $ xxmaj xxunk \\ xxunk will have a value greater than zero ; after the second episode is complete , states 2 and 3 will have values greater than zero , and so on . xxmaj in general , for an $ xxunk chain of this nature , the agent will require $ n-1 $ episodes of training to start to improve the $ xxmaj q$-values associated with the start state , state 0 . \n",
              " \n",
              "  xxmaj the number of times the agent visits each state per episode indicates how many true measurements of the environment it will make . xxmaj we can estimate this by calculating the fundamental matrix $ xxup n$ of the absorbing xxmaj markov chain $ xxup p$ shown in xxmaj figure \\ ref{fig : markovchain } . xxmaj the fundamental matrix is defined as $ xxup xxunk - xxup xxunk , where $ xxup i$ is the identify matrix and $ xxup q$ is the $ t \\ times t$ matrix representing the transient states in $ xxup p$. xxmaj based on this , the expected number of state visits before absorbing for an agent starting in state 0 and following a random policy is xxunk and 2 , respectively . xxmaj thus , in the first four episodes of training , the q - agent is expected to take 46 measurements of the environment . \n",
              " \n",
              "  xxmaj if we consider the state estimator $ \\ hat{p}$ learned by xxmaj amrl , according to the calculations above , in the first episode of training the agent is expected to have tried both actions in each state 4 , 3 , 2 and 1 times , respectively . xxmaj since for a deterministic $ xxup p$ , the agent must try each state - action pair once to have an accurate $ \\ hat{p}$ , xxmaj amrl can safely switch from actively measuring the next state , to estimating it with $ \\ hat{p}$ after the first episode of training . xxmaj moreover , because the agent tries actions in states closer to the start sooner and more frequently , it can switch to using $ \\ hat{p}$ in these states even before the first episode of training ends . xxmaj in this way , xxmaj amrl is able to improve measurement efficiency well beyond what can be achieved by standard xxup rl methods and model - based xxup rl . \n",
              " \n",
              "  \\ xxunk } \n",
              " \n",
              "  xxmaj the xxmaj amrl - q algorithm maintains $ xxup |a|$ , $ xxup |s| \\ xxunk count - based statistics table for state transitions models $ \\ xxunk xxmaj in this initial presentation , we limit the agent to selecting from one observation class . xxmaj therefore , the agent maintains an $ xxup |s| \\ xxunk \\ xxunk \\ cdot 2)$ dimensional $ xxmaj q$-table , where $ | \\ xxunk \\ times 2 $ is the number of action pairs . xxmaj an environment with 2 action has 4 action pairs , and thus , a four column $ xxmaj q$-table . \n",
              " \n",
              "  xxmaj the q - table is update in the standard way as : \n",
              "  \\ begin{equation } \n",
              "  xxmaj q(s_t , a_t ) \\ leftarrow xxmaj q(s_t , a_t ) + \\ alpha \\ xxunk } ) ~ \\ gamma \\ max_a xxmaj q(s_{t+1},a ) - xxmaj q(s_t , a_t ) \\ bigg ] \n",
              "  \\ end{equation } \n",
              "  xxmaj the agent employs an $ \\ epsilon$-greedy strategy to pick action pairs from the q - table . xxmaj if the action pair at time $ t$ includes $ m_t = 1 $ , then the agent chooses to pay the cost $ c$ of measuring the next state from the environment . xxmaj otherwise , the agent estimates the next state from its model as $ s_{t+1 } \\ sim \\ xxunk xxmaj when the agent chooses to measure the true state , it updates $ \\ xxunk , s_{t+1})$ for the corresponding action $ a = a_t$ \n",
              " \n",
              "  xxmaj much like a human learning a new task , the first few times an agent enters a state it must measure the result of taking an action . xxmaj we produce this behaviour by initializing q - values for action pairs involving state measurements $ m=1 $ with small positive value , and zero for q - values related to measurements $ m=0 $ ( implications of initialization are discussed below ) . \n",
              " \n",
              "  xxmaj over successive visits to a state $ s$ and applications of a process $ a$ and measurement $ m=1 $ , the return for $ s$ will be less than the maximum possible return because the measurement cost $ xxmaj xxunk is subtracted from the reward $ xxmaj r(s , a)$. xxmaj since moving without measuring does not incur an additional measurement cost , in time and as the model improves , moving and relying on the learned model produces an increased reward and the agent shifts to this strategy . \n",
              " \n",
              "  xxmaj the outline of the algorithm is : \n",
              "  \\ begin{itemize } \n",
              "  \\ item xxmaj initialize a biased q - table of size $ xxup |s| \\ times xxup |a| \\ cdot 2 $ \n",
              "  \\ item xxmaj initialize xxup |a| state - transition statistic table of size $ xxup |s| \\ times xxup |s|$ to zeros \n",
              "  \\ item get the first state $ s = s_0 $ from the environment \n",
              "  \\ item repeat until done \n",
              "  \\ begin{itemize } \n",
              "  \\ item xxmaj select action pair $ ( a , m)$ with $ \\ epsilon$ greedy policy from q table for state $ s$ \n",
              "  \\ item xxmaj apply action $ a$ to environment \n",
              "  \\ item xxmaj if measure $ m=1 $ : \n",
              "  \\ begin{itemize } \n",
              "  \\ item xxmaj measure next state $ s^ \\ prime$ in environment \n",
              "  \\ item xxmaj update state transition model for action $ a$ $ \\ xxunk , s^ \\ prime ] \\ pluseq 1 $ \n",
              "  \\ end{itemize } \n",
              "  \\ item xxmaj else : \n",
              "  \\ begin{itemize } \n",
              "  \\ item xxmaj sample next state $ s^ \\ prime \\ sim \\ xxunk \n",
              "  \\ end{itemize } \n",
              "  \\ item xxmaj get reward $ r$ from environment \n",
              "  \\ item xxmaj get cost $ c$ from the environment \n",
              "  \\ item xxmaj update q table for state $ s$ with tuple $ ( s , a , r - c , s^ \\ prime)$ \n",
              "  \\ item xxmaj set $ s \\ leftarrow s^ \\ prime$ \n",
              "  \\ end{itemize } \n",
              "  \\ end{itemize } \n",
              " \n",
              " \n",
              "  \\ section{experimental xxmaj setup } \n",
              " \n",
              "  xxmaj the following experiments are conducted on episodic , discrete state and action problems . xxmaj our analysis involves three standard xxup rl environments ( xxmaj chain , xxmaj frozen xxmaj lake $ 8 \\ times 8 $ and xxmaj taxi ) and one new environment ( xxmaj junior xxmaj scientist ) . xxmaj each of these environments has the feature that the agent must actively decide if and when to measure the state of the environment . xxmaj in the case of the openai xxmaj gym environments ( xxmaj frozen xxmaj lake and xxmaj taxi ) , we have implemented a wrapper class in xxmaj python that adds the xxmaj amrl functionality . \n",
              " \n",
              "  \\ subsection{rl xxmaj environments } \n",
              " \n",
              "  \\ textbf { \\ xxunk environment } } : a chain of 11 states , $ s \\ in \\ { 0, ... xxunk \\ } $ , where the agent starts at $ s_0 $ and the episodes ends when the agent enters $ xxunk xxmaj upon entering goal state $ xxunk , the agent receives a reward of $ xxunk xxmaj the agent receives a reward of $ xxunk $ at each time step . xxmaj the agent is charged a measure cost of $ xxunk $ for measuring the state of the environment . xxmaj measuring the state results in the environment returning the current state in chain . xxmaj the action space is $ xxup a= \\ { \\ text{move left , move right } \\ } $ . xxmaj we evaluate the performance with both deterministic state transitions and stochastic state transitions . xxmaj in the stochastic setup , the environment has a probability $ p$ of the actions being swapped at each time step . \n",
              " \n",
              "  \\ textbf { \\ xxunk xxmaj lake $ 8 \\ times 8 $ environment } } : xxmaj in this environment , the agent learns to navigate from a start location to a goal in a frozen lake grid with holes in the ice . xxmaj each episode ends when the agent reaches the goal or falls through a hole in the ice . xxmaj the agent receives a reward of $ r=1 $ at the goal , $ r=0 $ otherwise . xxmaj the agent pays a cost of $ c=0.01 $ for measuring the state of the environment . xxmaj measuring the state results in the environment returning the current position in the 2-dimensional frozen lake grid . xxmaj the action - space in the environment is $ xxup a= \\ { \\ text{move left , move right , move up , move down } \\ } $ . xxmaj in this implementation , the agent is prevented from moving off the grid . xxmaj we evaluate the agents with both the predefined deterministic and slippery settings in the openai gym . \n",
              " \n",
              "  \\ textbf { \\ xxunk environment } } : xxmaj the agent learns to navigate a city grid world to pick up and drop off passengers at the appropriate location \\ xxunk } . xxmaj the agent receives a reward $ xxunk $ for dropping off at the correct location , $ xxunk $ for illegal pickup or drop - off and $ xxunk $ at each time step . xxmaj the agent is charged a cost of $ c=0.01 $ for measuring the state of the environment . xxmaj measuring the state results in the environment returning the current position in the city grid . xxmaj the action - space includes $ xxup a= \\ { \\ text{move left , move right , move up , move down , pickup , drop - off } \\ } $ . \n",
              " \n",
              "  \\ textbf { \\ xxunk xxmaj scientist environment } } : xxmaj this environment emulates a student learning to manipulate an energy source to produce a desired state change in a target material . xxmaj specifically , the agent starts with a xxunk container of water composed of an initial $ h_0 $ percent ice , $ l_0 $ percent water and $ g_0 $ percent gas ( $ xxunk $ ) . xxmaj the agent learns to sequentially and incrementally adjust a heat source in order to transition the ratio of ice , liquid , gas from $ ( xxunk to a goal ratio $ ( h , l , g)$. xxmaj the episode ends when the agent declares that it has reached the goal and it is correctly in the goal state . xxmaj the action - space includes $ xxup a= \\ { \\ xxunk , increase , done } \\ } $ , where \\ xxunk } and \\ emph{increase } are fixed incremental adjustments in the energy source . xxmaj the agent receives a reward of $ r=1 $ when it reaches the goal and it correctly declares that it is done , and receives a reward of $ xxunk $ at each time step . xxmaj the agent is charged $ c=0.01 $ for measuring the state of the environment . xxmaj measuring the state results in the environment returning the cumulative energy which has been added or removed from the system . \n",
              " \n",
              "  \\ subsection{rl xxmaj algorithms } \n",
              " \n",
              "  xxmaj we compare the relative performance of xxmaj amrl - q to non - active methods : q - learning \\ xxunk } and xxmaj dyna - q \\ xxunk } . xxmaj since neither q - learning nor xxmaj dyna - q are active xxup rl methods , they require a measurement of the environment at each time step . xxmaj as a result , they are charged the measurement cost $ xxup c$ at each time step . xxmaj the relative performance of these methods is assessed in terms of the sum of reward minus observation costs , along with the mean number of steps and measurements per episode . xxmaj to the best of our knowledge , we are proposing the first solution to the xxmaj amrl problems . xxmaj as such , q - learning and xxmaj dyna - q are a reasonable baseline for comparison in this introductory work . \n",
              " \n",
              "  \\ subsection{methodology } \n",
              " \n",
              "  xxmaj for each xxup rl algorithm in our evaluation , we utilize a discount factor of $ \\ xxunk $ and $ \\ epsilon$-greedy exploration $ \\ xxunk xxmaj the $ xxmaj xxunk for both q - learning and xxmaj dyna - q are initialized to zeros . xxmaj the columns of the $ xxmaj q$-table in xxmaj amrl - q associated with estimate ( $ m=0 $ ) are initialized to zeros and those associated with measure ( $ m=1 $ ) were set to a small positive , typically $ 0.1 $ ( we also explore the impact of larger values ) . xxmaj the results presented are mean performance averaged over 20 random trials , enough to be statistically significant . xxmaj we employ 5 planning steps , a reasonable baseline , in xxmaj dyna - q after each real step . \n",
              " \n",
              "  \\ section{results } \n",
              " \n",
              "  xxmaj we initially focus on the performance of each agent in the deterministic environments . xxmaj we highlight the impact of stochasticity in the xxmaj discussion . \n",
              " \n",
              "  \\ xxunk } \n",
              "  \\ begin{figure * } \n",
              "  \\ centering \n",
              "  \\ xxunk } \n",
              "  \\ xxunk } \n",
              "  \\ caption{left : xxmaj mean steps to the goal by episode in the deterministic xxmaj chain environment . xxmaj right : xxmaj mean costed return in the deterministic xxmaj chain environment . } \n",
              "  \\ label{fig : detchainstepsandsum } \n",
              "  \\ end{figure * } \n",
              " \n",
              "  xxmaj the mean performance of each agent is shown in xxmaj figure \\ ref{fig : detchainstepsandsum } . xxmaj the left plot displays the mean number of steps to the goal for q - learning , xxmaj dyna - q , and xxmaj amrl - xxup q. xxmaj all three methods learn a policy that takes a similar number of steps to the goal . xxmaj naturally , xxmaj dyna - q learns faster ( red line versus green and blue ) . xxmaj it worth noting that xxmaj dyna styled planning could easily be incorporated into xxmaj amrl - q as an enhancement , however , this is beyond the scope of this study . \n",
              " \n",
              "  xxmaj whilst q - learning and xxmaj dyna - q require a measurement after each action , xxmaj amrl - q actively decides whether to measure or estimate the next state . xxmaj the purple line in xxmaj figure \\ ref{fig : detchainstepsandsum } show the mean number of measurements per episode made by xxmaj amrl - xxup q. xxmaj in the very early episodes , the number of measurements is similar to xxmaj dyna - q , however , it quickly drops well below the alternatives . \n",
              " \n",
              "  xxmaj the cost savings resulting from fewer measurements for xxmaj amrl - q can be seen in the higher costed return presented in the plot on the right . xxmaj as in the previous analysis , xxmaj amrl - q is initially similar to xxmaj dyna - xxup q. xxmaj this holds while xxmaj amrl - q learns about state transition dynamics . xxmaj because xxmaj amrl - q dynamically shifts its measurement behaviour in each state as it learns about the transition dynamics , over episodes of training it reduces its measurement costs to acquire a higher costed return ( blue line ) . \n",
              " \n",
              "  \\ begin{figure * } \n",
              "  \\ centering \n",
              "  \\ xxunk } \n",
              "  \\ xxunk } \n",
              "  \\ xxunk } \n",
              "  \\ caption{bar plots comparing the state visit and measurement distribution for q - learning and xxmaj amrl - q on the xxmaj chain environment after 1 , 20 and 40 ( left , centre , right ) episodes of training . } \n",
              "  \\ label{fig : xxunk } \n",
              "  \\ end{figure * } \n",
              " \n",
              "  xxmaj figure \\ ref{fig : xxunk } summarizes the total number of visits and measurements made in each state after 1 , 20 and 40 episodes of training for q - learning \\ footnote{the state visits and measurements are equivalent for q - learning . } and xxmaj amrl - xxup q. xxmaj the plot on the left shows that initially xxmaj amrl - q ( blue bar ) visits most states slightly more frequently than q - learning ( red bar ) . xxmaj importantly , however , the purple bars show that it measures each state less frequently than q - learning . xxmaj thus , the measurement costs are lower from the outset . xxmaj after 20 and 40 episodes of training ( centre and right plots ) , the state visit frequency of xxmaj amrl - q is consistent with q - learning . xxmaj in these later episodes of training , however , xxmaj amrl - q requires significantly fewer state measurements than q - learning . xxmaj this highlights the advantage that the xxmaj amrl framework has in its ability to shift from measuring the state of the environment to estimating it as more experience ( episodes of training ) is gathered . xxmaj this behaviour is shown in greater detail in xxmaj figure \\ ref{fig : detchainmeasureanalysis } . \n",
              " \n",
              "  \\ begin{figure * } \n",
              "  \\ centering \n",
              "  \\ xxunk } \n",
              "  \\ caption{two - dimensional histograms comparing of the number of state visits and measurements made by q - learning versus xxmaj amrl - q on the xxmaj chain environment . } \n",
              "  \\ label{fig : detchainmeasureanalysis } \n",
              "  \\ end{figure * } \n",
              " \n",
              "  xxmaj figure \\ ref{fig : detchainmeasureanalysis } contains four 2-dimensional histograms . xxmaj these depict the number of visits to each state ( plots 1 and 2 ) and the number of measurements in each state ( plots 3 and 4 ) \\ xxunk - learning measures the state on each visit , therefore , plots 1 and 3 are the same . } as a function of episodes of training . xxmaj the $ x$-axis specifies the state in the chain and the $ y$-axis indicates the number of episodes of training completed . xxmaj the darker black cells indicate more visits / measurements , whilst white indicates a moderate number and red depicts a low number . xxmaj as a result of the learning behaviour of q - learning that was discussed in xxmaj section \\ ref{sec : xxmaj xxunk } , the lower diagonal of the state visit and measurement plots for q - learning , and the state visit plot for xxmaj amrl - q have a light red to black shading , with the xxunk black appearing in the lower left corner . xxmaj the upper diagonal , where the shading is uniformly dark red , shows the time at which the agent has learned a policy that enables it to directly transition from this current state to the goal . xxmaj this occurs within just a few episodes of training for q - learning in state 10 ( first plot , lower right ) , whereas it takes approximately 50 episodes of training for state 0 ( first plot , upper left ) . xxmaj whilst the state visit distributions are very similar for q - learning and xxmaj amrl - q , their state measurement distributions have an outstanding difference in magnitude . xxmaj the max state measurement value for xxmaj amrl - q ( right most plot ) is 6 , in comparison to 16 for for q - xxmaj learning . xxmaj moreover , in shading in the xxmaj amrl - q measurement plot quick shift from light red to dark red . xxmaj in fewer than 30 episodes of training , the agent is able to replace all measurements of the environment with its own estimate . \n",
              " \n",
              "  \\ xxunk xxmaj lake $ 8 \\ times 8 $ } \n",
              "  \\ begin{figure * } \n",
              "  \\ centering \n",
              "  \\ xxunk } \n",
              "  \\ xxunk } \n",
              "  \\ caption{left : xxmaj average number of steps to the goal by episode in the deterministic xxmaj frozen xxmaj lake environment . xxmaj right : xxmaj average costed return in the deterministic xxmaj frozen xxmaj lake environment . } \n",
              "  \\ label{fig : xxunk } \n",
              "  \\ end{figure * } \n",
              " \n",
              "  xxmaj figure \\ ref{fig : xxunk } shows the mean number of steps to the goal for each algorithm on the deterministic frozen lake . xxmaj similar to the deterministic chain , xxmaj amrl - q learns at the same rate as q - learning . xxmaj it takes approximately the same number of steps per episode ( green versus blue line ) . xxmaj dyna - q learns faster than the alternatives , but converges to a similar mean number of steps as q - learning and xxmaj amrl - q ( red line ) . xxmaj amrl - q requires fewer measurements on average ( purple line ) . xxmaj the mean number of steps per episode at the end of training for each method is : random agent = xxunk , q - xxmaj learning = 13.99 , xxmaj dyna - q = 15.45 , xxmaj amrl - q xxmaj steps = 18.52 . xxmaj importantly however , xxmaj amrl - q only takes a mean of xxunk measurements per episode . \n",
              " \n",
              " \n",
              "  \\ xxunk } \n",
              "  \\ begin{figure * } \n",
              "  \\ centering \n",
              "  \\ xxunk } \n",
              "  \\ xxunk } \n",
              "  \\ caption{left : xxmaj mean number of steps to the goal by episode in the xxmaj taxi environment . xxmaj right : xxmaj mean of the costed return in the xxmaj taxi environment . } \n",
              "  \\ label{fig : xxunk } \n",
              "  \\ end{figure * } \n",
              " \n",
              "  xxmaj figure \\ ref{fig : xxunk } depicts the mean number of steps to the goal for each algorithm on the xxmaj taxi environment . xxmaj this is a more challenging environment because it requires the agent to learn an intermediate goal . xxmaj nonetheless , the relative performance of the considered algorithms is consistent with our previous results . xxmaj amrl - q learns at a similar rate to q - learning , and takes approximately the same number of steps ( green versus blue line ) . xxmaj dyna - q learns faster ( red line ) , but converges to a similar average number of steps as q - learning and xxmaj amrl - xxup q. xxmaj amrl - q requires fewer measurements on average ( purple line ) . xxmaj the mean number of steps per episode are as follows : random agent = xxunk , q - xxmaj learning = 14.83 , xxmaj dyna - q = 14.67 , xxmaj amrl - q xxmaj steps = xxunk . xxmaj amrl - q take an average of 12.13 measurements per episode . \n",
              " \n",
              "  \\ xxunk xxmaj scientist } \n",
              " \n",
              "  \\ begin{figure * } \n",
              "  \\ centering \n",
              "  \\ xxunk } \n",
              "  \\ xxunk } \n",
              "  \\ caption{left : xxmaj mean steps per episode in the xxmaj junior xxmaj scientist environment . xxmaj right : xxmaj mean of the costed returns in the xxmaj junior xxmaj scientist environment . } \n",
              "  \\ label{fig : xxunk } \n",
              "  \\ end{figure * } \n",
              " \n",
              "  xxmaj figure \\ ref{fig : xxunk } shows the mean of the costed return for each algorithm on the xxmaj junior xxmaj scientist environment . xxmaj once again , xxmaj dyna - q learns slightly faster than q - learning and xxmaj amrl - xxup q. xxmaj the plot on the left clearly shows xxmaj amrl - q shifting away from measuring the state after approximately 2,000 episodes of training ( purple line ) . xxmaj the fact that the mean steps ( blue line ) is stable during this shift indicates that the agent is not becoming ` lost ' in the state space due to bad estimates . \n",
              " \n",
              "  \\ section{discussion } \n",
              "  % \\ subsection{evolution of the q - table in xxmaj xxunk - q } \n",
              "  \\ begin{figure * } \n",
              "  \\ centering \n",
              "  \\ xxunk } \n",
              "  \\ caption{evolution of the values of the q - table for xxmaj amrl - q on the deterministic xxmaj chain environment . } \n",
              "  \\ label{fig : xxunk } \n",
              "  \\ end{figure * } \n",
              " \n",
              "  xxmaj figure \\ ref{fig : xxunk } shows the evolution of the values of the q - table for xxmaj amrl - q over episodes of training on the deterministic chain environment . xxmaj the $ x$-axis shows the four action pairs [ ( \\ emph{move left , measure } ) , ( \\ emph{move right , measure } ) , ( \\ emph{move left , estimate } ) , ( \\ emph{move right estimate } ) ] that the agent chooses from . xxmaj the $ y$-axis shows each state , where 0 is the start state and 10 is the goal state . xxmaj from left to right , the first plot is the initialized q - table . xxmaj it is followed by the q - values after xxunk of 29 episodes of training . xxmaj in earlier episodes of training , the action pair ( \\ emph{move right , measure } ) has the highest values . xxmaj the sequence of plots demonstrates that over episodes of training , the action pair ( \\ emph{move right , estimate } ) comes to have the highest value . xxmaj thus , the agent shifts over time away from its reliance of more costly measurements . \n",
              " \n",
              "  xxmaj the shift to estimating the next state occurs naturally within the q - learning backup algorithm and sufficient exploration . xxmaj there is a clear trade - off in this evolution . xxmaj if an agent in state $ s$ relies on its state estimator $ \\ hat{p}$ before it is sufficiently accurate , it will be xxunk about its current location . xxmaj as a result , it is likely to select the wrong action and take more time to reach the goal . xxmaj moreover , the agent 's q updates will be applied to the wrong state . xxmaj alternatively , if an agent in state $ s$ utilizes measurements $ m=1 $ longer than is necessary ( \\ textit{i.e . } , when $ \\ hat{p}$ is sufficiently accurate ) , it xxunk pays the measurement cost which lowers its reward . xxmaj in xxmaj amrl - q , proper exploration and the initialization of the q - table serve to balance this trade - off . xxmaj however , more sophisticated solution using model confidence are expected to produce even better performance . xxmaj we leave the study of such methods to future work . \n",
              " \n",
              "  % \\ xxunk of q - xxmaj table xxmaj initialization on xxmaj measurement xxmaj frequency } \n",
              "  \\ begin{figure * } \n",
              "  \\ centering \n",
              "  \\ xxunk } \n",
              "  \\ caption{this figure demonstrates how the initialization of the q - values for \\ xxunk } affects the number of measurements made by the agent ( right column ) , and how it impacts the costed return in noisy environments . } \n",
              "  \\ label{fig : xxunk } \n",
              "  \\ end{figure * } \n",
              " \n",
              "  xxmaj the right column of xxmaj figure \\ ref{fig : xxunk } depicts how the initialization of the q - values associated with measure $ m=1 $ in xxmaj amrl - q shapes the number of measurements made by the agent . xxmaj the top plot depicts the number of steps on the deterministic chain and the bottom for the stochastic chain . xxmaj the episodes of training are plotted on the $ x$-axis and the mean number of measurements is plotted on the $ y$-axis . xxmaj this clearly shows that as the initialization is decreased towards zero , the number of measurements made by the agent reduces . \n",
              " \n",
              "  xxmaj the number of measurements per state - action pair has important implications on performance in the stochastic environments . xxmaj in the lower right plot , which applies to the stochastic environment , the difference between the initialization of 0.01 and 0.005 is much smaller than in the deterministic case . xxmaj in that case , the agent using the initialization of 0.005 shifts to using its state estimator before it is sufficiently accurate . xxmaj as result , the agent is operating from error prone estimates of is current state , and thus , requires more steps and more measurements on average . \n",
              " \n",
              "  xxmaj the column on the left shows how the initialization impacts the costed return . xxmaj the upper plot shows that given enough time , the agent overcomes the larger initialization to achieve an equivalent costed return as agents with smaller initial values . xxmaj the lower plot demonstrates the benefit of a large initial value in environments with stochastic transitions . xxmaj from early episodes of training the difference in mean performance ( shown without error bars in the embedded plot ) of the agents with different initialization is small . xxmaj in the large plot ( with error bars ) it is clear that the larger initial value leads to a notably lower standard deviation . xxmaj given the added robustness of the larger initial values , and the fact that the agent will converge to the same performance , we advise against setting it too close to zero . \n",
              " \n",
              "  % \\ xxunk of xxmaj stochastic xxmaj environments } \n",
              " \n",
              "  \\ begin{figure * } \n",
              "  \\ centering \n",
              "  \\ xxunk } \n",
              "  \\ xxunk } \n",
              "  \\ caption{left : xxmaj mean of the costed return on the stochastic xxmaj chain environment . xxmaj right : xxmaj mean of the costed return on the slippery xxmaj frozen xxmaj lake $ 8 \\ times 8 $ environment . } \n",
              "  \\ label{fig : xxunk } \n",
              "  \\ end{figure * } \n",
              " \n",
              "  xxmaj the plot on the left in xxmaj figure \\ ref{fig : xxunk } depicts the mean of the costed return for xxmaj amrl - q , q - learning and xxmaj dyna - q on the stochastic xxmaj chain . xxmaj in this case , the action pairs involving measure $ m=1 $ are initialized to 0.01 . xxmaj the results for xxmaj slippery xxmaj frozen xxmaj lake environment are plotted on the right . xxmaj this is much more complex than the stochastic chain because it involves a larger number of actions and more variability in the transition dynamics . xxmaj in this setting all methods have a high variance . xxmaj the actions pairs associated with measure $ m=1 $ must be set to a large value ( in this case 10.0 ) in order to provide $ \\ hat{p}$ time to stabilize . xxmaj the xxmaj amrl - q agent begins to slowly shift way from relying on measurements after approximately 1,000 episodes of training . \n",
              " \n",
              " \n",
              "  \\ section{conclusion } \n",
              " \n",
              "  xxmaj we introduced a sequential decision making framework , xxmaj amrl , in which the agent selects both an action and an observation class at each time step . xxmaj the observation classes have associated costs and provide information that depends on time and space . xxmaj we formulate our solution in terms of active learning , and empirically show that xxmaj amrl - q learns to shift from relying on costly measurements of the environment to using its state estimator via online experience . xxmaj amrl - q learns at a similar rate to q - learning and xxmaj dyna - q , and achieves a higher costed return . xxmaj amrl has the potential to expand the applicability of xxup rl to important applications in operational planning , scientific discovery , and medical treatments . xxmaj to achieve this , additional research is required to develop xxmaj amrl methods for continuous state and action environments , and function approximation methods , such as xxmaj gaussian processes and deep learning . \n",
              " \n",
              "  % \\ section*{broader xxmaj impact } \n",
              " \n",
              "  % xxmaj the recent successes of xxup rl at games and simulated environments has resulted in considerable interest and attention from new domains . \n",
              " \n",
              "  % \\ begin{ack } \n",
              " \n",
              "  % \\ end{ack } \n",
              " \n",
              " \n",
              "  \\ bibliographystyle{plain } \n",
              "  % \\ bibliographystyle{splncs04 } \n",
              "  \\ xxunk } \n",
              " \n",
              "  \\ end{document } \n",
              " ,xxbos \n",
              "  ewcommand { \\ xxunk cm } \n",
              " \n",
              "  ewcommand { \\ xxunk cm } \n",
              "  % \\ documentclass[journal , 10pt , xxunk } \n",
              "  \\ documentclass[journal , 10pt , xxunk } \n",
              "  \\ ieeeoverridecommandlockouts \n",
              "  \\ ifclassinfopdf \n",
              "  \\ usepackage[pdftex]{graphicx } \n",
              "  \\ else \n",
              "  \\ fi \n",
              "  \\ usepackage{amsmath } \n",
              "  \\ usepackage{array } \n",
              "  \\ ifclassoptioncompsoc \n",
              "  \\ usepackage[caption = false , font = normalsize , labelfont = sf , textfont = sf]{subfig } \n",
              "  \\ else \n",
              "  \\ usepackage[caption = false , font = footnotesize]{subfig } \n",
              "  \\ fi \n",
              "  \\ usepackage{fixltx2e } \n",
              "  \\ usepackage{stfloats } \n",
              "  \\ usepackage{cite } \n",
              "  \\ usepackage{url } \n",
              "  % \\ usepackage{hyperref } % xxmaj creates hyperlinks within document \n",
              "  % \\ hypersetup{colorlinks = true , linkcolor = blue , \n",
              "  % \t citecolor = blue , urlcolor = blue } \n",
              " \n",
              "  \\ usepackage{amssymb } \n",
              "  \\ usepackage{amsthm } \n",
              "  \\ usepackage{algpseudocode } \n",
              "  \\ usepackage{algorithm } \n",
              " \n",
              "  \\ usepackage{graphicx } \n",
              "  \\ usepackage{mathptmx } \n",
              "  \\ usepackage{amsmath } \n",
              "  \\ usepackage{xcolor } \n",
              "  \\ xxunk \n",
              "  \\ renewcommand { \\ xxunk \\ xxunk } \n",
              "  \\ xxunk } \n",
              "  \\ usepackage{multicol } \n",
              "  \\ declaremathoperator { \\ xxunk } \n",
              " \n",
              "  \\ usepackage{setspace } \n",
              " \n",
              " \n",
              "  \\ begin{document } \n",
              "  \\ xxunk } \t \n",
              "  \\ xxunk xxmaj intelligence xxmaj assisted xxmaj collaborative xxmaj edge xxmaj caching in xxmaj small xxmaj cell xxmaj networks } \n",
              " \n",
              "  \\ author { \\ xxunk xxmaj xxunk xxmaj xxunk \\ ieeeauthorrefmark{1 } , xxmaj le xxmaj thanh xxmaj tan \\ ieeeauthorrefmark{2 } and xxmaj rose xxmaj xxunk xxmaj hu \\ ieeeauthorrefmark{2 } } \\ \\ \n",
              "  \\ ieeeauthorblocka { \\ xxunk of xxmaj electrical and xxmaj computer xxmaj engineering , xxmaj north xxmaj carolina xxmaj state xxmaj university , xxmaj xxunk , xxup nc xxunk , xxup usa } \\ \\ \n",
              "  \\ ieeeauthorblocka { \\ xxunk of xxmaj electrical and xxmaj computer xxmaj engineering , xxmaj utah xxmaj state xxmaj university , xxmaj logan , xxup ut xxunk , xxup usa } \\ \\ \n",
              "  xxmaj email : \\ tt xxunk , \\ { xxunk , xxunk \\ } xxunk \\ vspace{-0.3 in } \n",
              " \n",
              "  \\ thanks{the work of xxup m. xxup f. xxmaj xxunk , xxup l. xxup t. xxmaj tan and xxup r. xxup q. xxmaj hu were supported in part by xxmaj national xxmaj science xxmaj foundation under grants nets xxunk and xxup ears xxunk as well as in part by the xxmaj intel xxmaj corporation . } } \n",
              " \n",
              "  \\ maketitle \n",
              "  \\ thispagestyle{empty } \n",
              "  \\ pagestyle{empty } \n",
              " \n",
              "  \\ begin{abstract } \n",
              "  xxmaj edge caching is a new paradigm that has been exploited over the past several years to reduce the load for the core network and to enhance the content delivery performance . \n",
              "  xxmaj many existing caching solutions only consider homogeneous caching placement due to the immense complexity associated with the heterogeneous caching models . \n",
              "  xxmaj unlike these legacy modeling paradigms , this paper considers heterogeneous ( 1 ) content preference of the users and ( 2 ) caching models at the edge nodes . \n",
              "  xxmaj besides , collaboration among these spatially distributed edge nodes is used aiming to maximize the cache hit ratio ( xxup chr ) in a two - tier heterogeneous network platform . \n",
              "  xxmaj however , due to complex combinatorial decision variables , the formulated problem is hard to solve in the polynomial time . \n",
              "  xxmaj moreover , there does not even exist a ready - to - use tool or software to solve the problem . \n",
              "  xxmaj thanks to artificial intelligence ( xxup ai ) , based on the methodologies of the conventional particle swarm optimization ( xxup pso ) , we propose a modified xxup pso ( m - xxup pso ) to efficiently solve the complex constraint problem in a reasonable time . \n",
              "  xxmaj using numerical analysis and simulation , we validate that the proposed algorithm significantly enhances the xxup chr performance when comparing to that of the existing baseline caching schemes . \n",
              "  \\ end{abstract } \n",
              " \n",
              "  \\ begin{ieeekeywords } \n",
              " \t xxmaj cache hit ratio , content delivery network , edge caching , particle swarm optimization , small cell network . \n",
              "  \\ end{ieeekeywords } \\ vspace{-0.1 in } \n",
              " \n",
              "  \\ ieeepeerreviewmaketitle \n",
              " \t \n",
              "  \\ section{introduction } \n",
              "  xxmaj owing to the ever growing requirements on the high data rates , good quality of service and low latency , wireless communication has evolved from generation to generation . \n",
              "  xxmaj with the exponential increase of the connected devices , existing wireless networks have already been experiencing performance bottleneck . \n",
              "  xxmaj while the general trends are shifting resources towards the edge of the network \\ xxunk , xxunk } , study shows that mobile video traffic is one of the dominant applications that cause this performance bottleneck \\ xxunk , xxunk , xxunk } . \n",
              "  xxmaj caching has become a promising technology to address this performance issue by storing popular contents close to the end users \\ xxunk } . \n",
              "  xxmaj therefore , during the network busy time , the requested contents can be delivered from these local nodes ensuring a xxunk pressure to the xxunk and the centralized core network and reducing the latency for content delivery . \n",
              "  xxmaj thus , the much - needed wireless spectrum and xxunk bandwidth can be better utilized in the cache - enabled network platform . \n",
              "  xxmaj in the ultra - dense network platform , caching at the edge nodes is therefore a powerful mechanism for delivering video traffic . \n",
              " \n",
              " \n",
              "  xxmaj while the caching solution can significantly benefit the next - generation wireless communication , various challenges need to be handled to ensure the xxunk performances of the cache - enabled network \\ xxunk , xxunk , xxunk , xxunk } . \n",
              "  xxmaj first of all , the content selection has an enormous impact on the cache - enabled platform \\ xxunk } . \n",
              "  % xxmaj the selection of the contents to store is critical in the edge caching . \n",
              "  xxmaj then , choosing at what node to store the contents needs to be answered . \n",
              "  xxmaj due to the broad combinatorial decision parameters , this is an immense challenge for any cache - enabled network platform . \n",
              "  xxmaj furthermore , owing to the necessity of the system performance metrics , the solution to this combinatorial decision problem may change . \n",
              "  xxmaj therefore , based on the performance metric , an efficient solution is demanded to handle the issue in a reasonable time . \n",
              "  xxmaj as such , under a practical system model in actual communication scenarios , a heterogeneous network platform needs to be adopted for evaluating the caching performance . \n",
              " \n",
              " \n",
              "  xxmaj there exist several caching solutions in the literature \\ xxunk } . \n",
              "  xxmaj caching policy and cooperative distance were designed in \\ xxunk } , by xxmaj lee \\ textit{et al . } , considering clustered device - to - device ( xxup d2d ) networks . \n",
              "  xxmaj while the authors showed some xxunk concepts for the caching policy design aiming to maximize ( a ) energy efficiency and ( b ) throughput , they only considered the collaboration among the xxup d2d users . \n",
              "  xxmaj lee \\ textit{et al . } also proposed a base station ( xxup bs ) assisted xxup d2d caching network in \\ xxunk } that maximizes the time - average service rate . \n",
              "  xxmaj however , the authors only considered a single xxup bs xxunk xxup d2d communication with homogeneous request probability modeling . \n",
              "  xxmaj tan \\ textit{et al . } \\ xxunk } adopted the collaboration based caching model in the heterogeneous network model . \n",
              "  a mobility aware probabilistic edge caching approach was explored in \\ cite{8667875 } . \n",
              "  xxmaj here , the proposed model considered the noble idea of collaboration by considering the spatial node distribution and the user - mobility . \n",
              "  xxmaj while some xxunk concept of relaying and collaboration was introduced in \\ xxunk } , only homogeneous caching placement strategies were incorporated . \n",
              " \n",
              " \n",
              "  xxmaj unlike these existing works , in this paper , we investigate heterogeneous content preference model leveraging heterogeneous cache placement strategy . \n",
              "  xxmaj particularly , in a small cell network ( xxup scn ) , we incorporate collaborations among spatially distributed full - duplex ( xxup fd ) enabled bss and half - duplex ( xxup hd ) operated xxup d2d users to maximize the average cache hit ratio ( xxup chr ) . \n",
              "  xxmaj however , the formulated problem contains hard combinatorial decision variables that are hard to determine in a polynomial time . \n",
              "  xxmaj therefore , we implement a modified particle swarm optimization ( m - xxup pso ) algorithm that effectively solves the grand probabilistic cache placement problem within a reasonable time . \n",
              "  % xxmaj our contributions are summarized as follows : \n",
              "  % \\ begin{itemize } \n",
              "  % \t  \\ item xxmaj to incorporate the goal of content caching in a content delivery network ( xxup cdn ) , we consider the collaborations among different heterogeneous edge nodes in proximity . \n",
              "  % \t  \\ item xxmaj we explore realistic spatial node distributions for the full - duplex ( xxup fd ) enabled bss and half - duplex ( xxup hd ) operated xxup d2d users . \n",
              "  % \t  \\ item xxmaj we consider the heterogeneous content preference and content placement considering the real world heterogeneous network . \n",
              "  % \t  \\ item xxmaj we propose the modified particle swarm optimization ( m - xxup pso ) to effectively solve our decision variables . \n",
              "  % \t  \\ item xxmaj we implement our m - xxup pso to maximize cache hit ratio ( xxup chr ) in a modern xxup scn . \n",
              "  % \\ end{itemize } \n",
              "  xxmaj to the best of our knowledge , this is the first work to consider heterogeneous user preference with a heterogeneous caching model in a practical xxup scn that uses collaborative content sharing among heterogeneous edge nodes to maximize the xxup chr . \n",
              " \n",
              "  xxmaj the outline of this paper is as follows . \n",
              "  xxmaj the system model and the proposed content access protocols are presented in xxmaj section~ \\ xxunk } , followed by the xxup chr analysis in xxmaj section~ \\ xxunk } . \n",
              "  xxmaj the optimization problem and the proposed m - xxup pso algorithm are described in xxmaj section~ \\ xxunk } . \n",
              "  xxmaj section~ \\ xxunk } gives the performance results , followed by the concluding remarks in xxmaj section~ \\ xxunk } . \n",
              " \n",
              " \n",
              "  \\ section{system xxmaj model and xxmaj content xxmaj access xxmaj protocols } \n",
              "  \\ xxunk } \n",
              "  xxmaj this section presents the node distributions and describes the caching properties , followed by the proposed content access protocols . \n",
              " \n",
              "  \\ xxunk xxmaj distributions } \n",
              " \n",
              "  xxmaj we consider a practical two - tier heterogeneous network , which consists of macro base stations ( xxup mbs ) and low - power sbss ( or xxunk ) with xxunk xxup d2d users . \n",
              "  xxmaj the nodes are distributed following an independent homogeneous xxmaj poisson point processes ( xxup xxunk ) model . \n",
              "  xxmaj let us denote the densities of the xxup d2d user , sbs and xxup mbs by $ \\ xxunk , $ \\ xxunk and $ \\ lambda_m$ , respectively . \n",
              "  xxmaj the sbss and mbss operate in the xxup fd mode whereas the xxup d2d users operate in the xxup hd mode . \n",
              "  xxmaj let us denote the set of xxup d2d users , sbss and mbss by $ \\ mathcal{u}$ , $ \\ mathcal{b}$ and $ \\ mathcal{m } $ , respectively . \n",
              "  xxmaj without any loss of generality , user , sbs and xxup mbs are denoted by $ u \\ in \\ { \\ mathcal{u } \\ } $ , $ b \\ in \\ { \\ mathcal{b } \\ } $ , and $ m \\ in \\ { \\ mathcal{m } \\ } $ , respectively . \n",
              "  xxmaj besides , the communication ranges of these nodes are denoted by $ xxmaj xxunk , $ xxmaj xxunk and $ xxmaj xxunk , respectively . \n",
              " \n",
              " \n",
              " \n",
              "  xxmaj the requesting user node is named as the tagged user node . \n",
              "  xxmaj while a user is always associated with the serving xxup mbs , it can also associate with a low powered sbs if the association rules are satisfied . xxmaj the main benefits of being connected to sbs over xxup mbs are higher data rate , less latency , less power consumption , more effective uses of radio resources , etc . \n",
              "  xxmaj we denote the associated sbs as the tagged sbs for that user . \n",
              "  xxmaj furthermore , if such a tagged sbs exists for the user , the user maintains its communication with the serving xxup mbs via the tagged sbs . \n",
              "  xxmaj in that case , the sbs can also use its xxup fd mode to deliver requested content from the other sbss or the cloud via the xxup mbs . \n",
              "  xxmaj if such a tagged sbs does not exist for the user , the user will have to rely on the neighbor sbs nodes and the serving xxup mbs for extracting the requested contents . \n",
              "  xxmaj as all the users may not place a content request at the same time , we assume that only $ \\ alpha$ portions of the users act as tagged users . \n",
              "  % xxmaj in other words , they can place content requests and serve as the xxunk , while the remaining $ \\ left(1- \\ alpha \\ right)$ portion of the users act as xxunk . \n",
              "  xxmaj without any loss of generality , the requesting user , the associated sbs , and the serving xxup mbs are denoted as $ u_0 $ , $ b_0 $ and $ xxunk $ , respectively . \n",
              " \n",
              " \n",
              " \n",
              " \n",
              "  \\ subsection{cache xxmaj storage , xxmaj caching xxmaj policy and xxmaj content xxmaj popularity } \n",
              " \n",
              "  xxmaj the cache storage of the users , sbss and mbss are denoted by $ \\ xxunk } , \\ xxunk and $ \\ xxunk , respectively . \n",
              "  xxmaj considering equal sized contents with a normalized size $ 1 $ \\ xxunk } , it is assumed that the users can make a content request from a content directory of $ \\ mathcal{f } = \\ { f_k \\ } $ , where $ k \\ in \\ { 1,2 , \\ dots , f \\ } $ . \n",
              "  xxmaj for the caching model , a probabilistic method is considered assuming a heterogeneous caching placement strategy . \n",
              "  xxmaj let $ \\ xxunk , $ \\ xxunk and $ \\ xxunk be the probabilities of storing a content $ f_k \\ in \\ { \\ mathcal{f } \\ } $ at the cache store of the user node $ u_i$ , the sbs $ b_j$ and the xxup mbs $ m_l$ , respectively . \n",
              "  xxmaj note that probabilistic caching is highly practical and adopted in many existing works \\ xxunk , xxunk , xxunk } . \n",
              " \n",
              "  xxmaj the content popularity is modeled by following the $ \\ xxunk distribution with the probability mass function $ \\ xxunk } = \\ xxunk \\ gamma } } { \\ sum_{k=1}^{f } xxunk \\ xxunk \n",
              "  xxmaj note that the skewness $ \\ gamma$ governs this distribution . \n",
              "  xxmaj it is assumed that each user has a different content preference . \n",
              "  xxmaj therefore , a random content preference order and a random skewness are chosen for each user . \n",
              "  xxmaj while the content order is chosen using random permutation , the parameter , $ \\ gamma$ , is chosen following $ \\ xxunk random distribution within a range of maximum $ \\ xxunk and minimum $ \\ gamma^{min}$ values . \n",
              "  % xxmaj this can be expressed as $ \\ xxunk } = \\ xxunk } \\ times \\ xxunk ) - \\ gamma^{min}$ , where $ \\ xxunk and $ \\ gamma^{min}$ are the maximum and minimum allowable values , respectively . \n",
              "  xxmaj without any loss of generality , the probability that user $ u_0 $ requests for content $ f_k$ is denoted by $ \\ xxunk \n",
              "  xxmaj this is modeled based on the $ \\ xxunk distribution . \n",
              " \n",
              " \n",
              " \n",
              " \n",
              " \n",
              "  \\ subsection{proposed xxmaj content xxmaj access xxmaj protocol } \n",
              "  \\ xxunk } \n",
              "  xxmaj for accessing the contents , the following practical cases are considered . \n",
              " \n",
              "  \\ textbf{case 1 - \\ textbf{local / self cache hit } } : xxmaj if a tagged user requests the content that is previously cached , the user can directly access the content from its own storage . \n",
              " \n",
              "  \\ textbf{case 2 - \\ xxunk cache hit } } : \n",
              "  xxmaj if the required content is not stored in its own storage , the tagged user sends the content request to the neighboring xxup d2d nodes . \n",
              "  xxmaj if any of the neighbors has the content , the user can extract the content from that neighboring user . \n",
              " \n",
              "  \\ textbf{case 3 - \\ xxunk cache hit } } : \n",
              "  xxmaj if the tagged user is under the communication range of any sbs , it maintains its communication via the tagged sbs . \n",
              "  xxmaj in this particular case , we have the following sub - cases : \n",
              " \n",
              "  \\ textit{case 3.1 } : xxmaj if the requested content is in the tagged sbs cache , it can access the content directly from there . \n",
              "  % xxmaj we denote this case as a direct cache hit from the tagged sbs . \n",
              " \t \n",
              "  \\ textit{case 3.2 } : xxmaj if the content is not stored in the tagged sbs cache but is available in one of the neighboring sbss , the tagged sbs extracts the content from the neighboring sbs via its xxup fd capability and delivers it to the tagged user . \n",
              "  % xxmaj we denote this term as soft - sbs ( xxunk ) cache hit . \n",
              " \n",
              "  \\ textit{case 3.3 } : xxmaj if the requested content is not available in any of the sbss , the tagged sbs forwards the request to the serving xxup mbs . \n",
              "  xxmaj if the content is in the serving xxup mbs , it is delivered to the tagged sbs and then to the user . \n",
              "  % xxmaj this case is denoted as the sbs - xxup mbs cache hit . \n",
              " \t \n",
              "  \\ textit{case 3.4 } : xxmaj if all of the above sub - cases fail , then the xxup mbs extracts the content from the cloud using its xxup fd capability . \n",
              "  xxmaj the sbs extracts the content from the xxup mbs using its own xxup fd capability and delivers it to the tagged user . \n",
              "  % xxmaj this case is denoted as the sbs cache miss . \n",
              " \n",
              " \t \n",
              "  \\ textbf{case 4 - \\ xxunk cache hit } } : \n",
              "  xxmaj if the tagged user is not in the communication range of any of the sbss , it has to rely on the serving xxup mbs for its communication . \n",
              "  xxmaj in this case , we consider the following sub - cases : \n",
              " \n",
              "  \\ textit{case 4.1 } : xxmaj if the requested content is available in the xxup mbs cache , the content is directly delivered to the tagged user . \n",
              "  % xxmaj this case is denoted as an xxup mbs cache hit . \n",
              " \n",
              "  \\ textit{case 4.2 } : xxmaj if the content is not available in the xxup mbs storage and the above case fails , the xxup mbs extracts the content from the cloud using its xxup fd capability . xxmaj then , the content is directly delivered to the user . \n",
              "  % xxmaj this case is referred as an xxup mbs cache miss . \n",
              " \n",
              "  xxmaj without loss of generality , \\ textit{case 3 } and \\ xxunk 4 ) } are denoted by the indicator function $ \\ xxunk and $ \\ xxunk , respectively . \n",
              "  xxmaj note that , in \\ textit{case 3 } , if the tagged user is in the communication ranges of multiple sbss , it gets connected to the one that provides the best received power . xxunk \\ xxunk xxmaj caching : xxmaj cache xxmaj hit xxmaj ratio xxmaj analysis } \t \n",
              "  \\ xxunk } \n",
              "  xxmaj in this section , we analyze and calculate the local cache hit probabilities . \n",
              "  % \\ vspace{-0.05 in } \n",
              "  \\ xxunk xxmaj probabilities } \n",
              "  xxmaj we now analyze the cache hit probability at different nodes for the cases mentioned in xxmaj section \\ xxunk } . \n",
              "  xxmaj note that a cache hit occurs at a node , if a requested content is available in that node . \n",
              " \n",
              "  \\ subsubsection{case 1 - xxmaj local / self cache hit } \n",
              "  xxmaj the local cache hit probability is denoted as $ \\ xxunk } = \\ xxunk , i.e. the probability of storing the content $ f$ at the self cache storage of the tagged user . \n",
              " \n",
              "  \\ subsubsection{case 2 - xxup d2d cache hit } \n",
              "  xxmaj the cache hit probability for the xxup d2d nodes can be calculated as follows : % \\ vspace{-0.05 in } \n",
              "  \\ begin{equation } \n",
              "  % \\ small \n",
              "  \\ xxunk } \n",
              " \t  \\ xxunk } = \\ left(1- \\ eta_{f_k}^{u_0 } \\ right ) \\ left[1 - \\ prod_{u_i \\ in \\ xxmaj phi_{u } \\ backslash u_0 } \\ left(1 - \\ eta_{f_k}^{u_i } \\ right ) \\ right ] , \n",
              "  \\ end{equation } % \\ vspace{-0.05 in } \n",
              "  where $ \\ prod_{u_i \\ in \\ xxmaj phi_{u } } \\ left(1 - \\ eta_{f_k}^{u_i } \\ right)$ means that none of the $ \\ xxmaj xxunk active neighbors ( xxup d2d nodes ) in its communication range have the content . \n",
              "  xxmaj thus , the complement of that is the probability that at least one of the users stores the content . \n",
              " \n",
              " \n",
              "  \\ subsubsection{case 3 - sbs cache hit } \n",
              "  xxmaj in this case , cache hit probabilities achieved via the tagged sbs for the respective sub - cases are calculated . \n",
              " \n",
              "  \\ textit{case 3.1 : } xxmaj the probability of getting a requested content from the tagged sbs is calculated as follows : % \\ vspace{-0.05 in } \n",
              "  \\ begin{equation } \n",
              "  % \\ small \n",
              "  \\ xxunk } \n",
              " \t  \\ xxunk } = \\ left(1- \\ eta_{f_k}^{u_0 } \\ right ) \\ prod_{u_i \\ in \\ xxmaj phi_{u } \\ backslash u_0 } \\ left(1 - \\ eta_{f_k}^{u_i } \\ right ) \\ eta_{f_k}^{b_0 } . \n",
              "  \\ end{equation } % \\ vspace{-0.05 in } \n",
              " \n",
              "  \\ textit{case 3.2 : } xxmaj the probability of getting a requested content from one of the neighbor sbss is considered in this sub - case . \n",
              "  xxmaj essentially , this case states that a cache miss occurs at the tagged sbs . xxmaj mathematically , this probability is expressed as % \\ vspace{-0.05 in } \n",
              "  \\ begin{equation } \n",
              "  % \\ small \n",
              "  \\ xxunk } \n",
              "  \\ begin{aligned } \n",
              " \t  \\ xxunk } & = \\ left(1- \\ eta_{f_k}^{u_0 } \\ right ) \\ prod_{u_i \\ in \\ xxmaj phi_{u } \\ backslash u_0 } \\ left(1 - \\ eta_{f_k}^{u_i } \\ right ) \\ left(1 - \\ eta_{f_k}^{b_0 } \\ right ) \\ \\ \n",
              " \t & \\ qquad \\ qquad \\ left(1 - \\ prod_{b_j \\ in \t\t  \\ xxmaj phi_{b } \\ backslash b_0 } \\ left ( 1 - \\ eta_{f_k}^{b_j } \\ right ) \\ right ) , \n",
              "  \\ end{aligned } \n",
              "  \\ end{equation } % \\ vspace{-0.05 in } \n",
              "  where $ \\ xxmaj xxunk is the set of active neighboring sbss that are in the communication range of the tagged sbs . \n",
              " \n",
              "  \\ textit{case 3.3 : } \n",
              "  xxmaj if sub - cases 3.1 and 3.2 fail , the content request is forwarded to the serving xxup mbs via the tagged sbs . \n",
              "  xxmaj the cache hit probability , for this case , is calculated as \n",
              "  \\ begin{equation } \n",
              "  \\ xxunk } \n",
              "  \\ begin{aligned } \n",
              " \t  \\ mathrm{p}_{m _ { \\ xxunk } & = \\ left(1- \\ eta_{f_k}^{u_0 } \\ right ) \\ prod_{u_i \\ in \\ xxmaj phi_{u } \\ backslash u_0 } \\ left(1 - \\ eta_{f_k}^{u_i } \\ right ) \\ left(1 - \\ eta_{f_k}^{b_0 } \\ right ) \\ \\ \n",
              " \t & \\ qquad \\ qquad \\ prod_{b_j \\ in \\ xxmaj phi_{b } \\ backslash xxunk } \\ left ( 1 - \\ eta_{f_k}^{b_j } \\ right ) \\ eta_{f_k}^{m_0 } . \n",
              "  \\ end{aligned } \n",
              "  \\ end{equation } \n",
              "  xxmaj when $ \\ mathbb{i}_s = 1 $ , i.e. the tagged user is in the communication range of at least one sbs , from the above cases and sub - cases , we calculate the total cache hit probability as \n",
              "  \\ begin{equation } \n",
              "  % \\ small \n",
              "  \\ xxunk } \n",
              "  \\ begin{aligned } \n",
              " \t  \\ mathrm{p}_{l}^ { \\ mathbb{i}_s } & % = \\ eta_{f_k}^{u_0 } + \\ xxunk } + \\ xxunk } + \\ xxunk } + \\ mathrm{p}_{m _ { \\ xxunk } \\ \\ & \n",
              " \t = 1 - \\ xxmaj bigg [ \\ left(1 - \\ eta_{f_k}^{u_0 } \\ right ) \\ prod_{u_i \\ in \\ xxmaj phi_{u } \\ backslash u_0 } \\ left(1 - \\ eta_{f_k}^{u_i } \\ right ) \\ left(1 - \\ eta_{f_k}^{b_0 } \\ right ) \\ \\ \n",
              " \t & \\ qquad \\ qquad \\ prod_{b_j \\ in \\ xxmaj phi_{b } \\ backslash b_0 } \\ left(1 - \\ eta_{f_k}^{b_j } \\ right ) \\ xxmaj bigg ] \\ left(1 - \\ eta_{f_k}^{m_0 } \\ right ) . \n",
              "  \\ end{aligned } \n",
              "  \\ end{equation } \n",
              " \n",
              "  \\ textit{case 3.4 : } xxmaj now , if the content is not even stored in the xxup mbs cache storage , it has to be downloaded from the cloud . \n",
              "  xxmaj this case is termed as a cache miss via both sbss and mbss . \n",
              "  xxmaj in this case , the xxup mbs initiates its xxup fd mode and downloads the content from the cloud . \n",
              "  xxmaj therefore , the cache miss probability is calculated from ( \\ xxunk } ) as \n",
              "  \\ begin{equation } \n",
              "  % \\ small \n",
              "  \\ xxunk } \n",
              "  \\ begin{aligned } \n",
              " \t  \\ xxunk _ { \\ xxunk \\ ! & % = 1 - \\ mathrm{p}_{l}^ { \\ mathbb{i}_s } \\ \\ \n",
              " \t  = \\ xxmaj bigg [ \\ left(1 - \\ eta_{f_k}^{u_0 } \\ right ) \\ prod_{u_i \\ in \\ xxmaj phi_{u } \\ backslash u_0 } \\ left(1 - \\ eta_{f_k}^{u_i } \\ right ) \\ left(1 - \\ eta_{f_k}^{b_0 } \\ right ) \\ \\ \n",
              " \t  & \\ qquad \\ qquad \\ prod_{b_j \\ in \\ xxmaj phi_{b } \\ backslash b_0 } \\ left(1 - \\ eta_{f_k}^{b_j } \\ right ) \\ xxmaj bigg ] \\ left(1 - \\ eta_{f_k}^{m_0 } \\ right ) . \n",
              "  \\ end{aligned } \n",
              "  \\ end{equation } \n",
              " \n",
              " \n",
              "  \\ subsubsection{case 4 - xxup mbs cache hit } \n",
              "  xxmaj recall that \\ textit{case 4 } is only considered when the tagged user is not under the coverage region of any of the sbss . \n",
              "  xxmaj firstly , we consider \\ textit{case 4.1 } , i.e. the requested content is available in the xxup mbs cache ( i.e. $ \\ xxunk $ and $ \\ xxunk $ ) . \n",
              "  xxmaj in this sub - case , the cache hit probability is expressed as \n",
              "  \\ begin{equation } \n",
              "  % \\ small \n",
              "  \\ xxunk } \n",
              " \t  \\ mathrm{p}_{m _ { \\ mathbb{i}_m}}^u = \\ left(1- \\ eta_{f_k}^{u_0 } \\ right ) \\ prod_{u_i \\ in \\ xxmaj phi_{u } \\ backslash u_i } \\ left(1 - \\ eta_{f_k}^{u_i } \\ right ) \\ eta_{f_k}^{m_0 } . \n",
              "  \\ end{equation } \n",
              "  xxmaj furthermore , the total local cache hit probability in this case is given as \n",
              "  \\ begin{equation } \n",
              "  % \\ small \n",
              "  \\ xxunk } \n",
              "  \\ begin{aligned } \n",
              " \t  \\ mathrm{p}_{l}^ { \\ mathbb{i}_m } % & = \\ xxunk } + \\ xxunk + \\ mathrm{p}_{m _ { \\ mathbb{i}_m}}^u \\ \\ \n",
              " \t & = 1 - \\ left(1 - \\ eta_{f_k}^{u_0 } \\ right ) \\ prod_{u_i \\ in \\ xxmaj phi_{u } \\ backslash u_0 } \\ left(1 - \\ eta_{f_k}^{u_i } \\ right ) \\ left ( 1 - \\ eta_{f_k}^{m_0 } \\ right ) . \n",
              "  \\ end{aligned } \n",
              "  \\ end{equation } \n",
              "  xxmaj note that the cache miss probability of \\ textit{case 4.2 } is derived as \n",
              "  \\ begin{equation } \n",
              "  % \\ small \n",
              "  \\ xxunk } \n",
              " \t  \\ xxunk _ { \\ mathbb{i}_m}}^u = \\ left(1 - \\ eta_{f_k}^{u_0 } \\ right ) \\ prod_{u_i \\ in \\ xxmaj phi_{u } \\ backslash u_0 } \\ left(1 - \\ eta_{f_k}^{u_i } \\ right ) \\ left ( 1 - \\ eta_{f_k}^{m_0 } \\ right ) . \n",
              "  \\ end{equation } \n",
              " \n",
              "  \\ subsection{cache xxmaj hit xxmaj ratio } \n",
              "  xxmaj we define xxup chr as the fraction of the requests that are served locally without reaching the cloud . \n",
              "  xxmaj let us denote the $ \\ alpha$ portion of the users by the set of $ \\ xxunk \n",
              "  xxmaj in a heterogeneous caching placement , the fraction of requests of $ u_0 $ that are served from the local nodes is as follows : \n",
              "  \\ begin{equation } \n",
              "  \\ small \n",
              "  \\ xxunk } \n",
              "  \\ begin{aligned } \n",
              "  \\ ! \\ ! \\ ! \\ ! \\ ! \\ ! \\ ! \\ xxunk } \\ ! \\ ! & = \\ ! \\ ! \\ sum_{k=1}^{f } \\ xxunk } \\ ! \\ xxmaj bigg [ \\ ! \\ ! \\ eta_{f_k}^{u_0 } + \\ xxunk \\ mathrm{p}_{s , xxunk } + \\ underbrace { \\ xxmaj big ( \\ xxunk } \\ mathrm{p}_{s , xxunk } + \\ xxunk \\ mathrm{p}_{s , xxunk } + \\ mathrm{p}_{m _ { \\ xxunk \\ mathrm{p}_{s , xxunk } \\ xxmaj big ) } _ { \\ xxunk hit in xxmaj case 3 } } \\ mathbb{i}_s \\ xxmaj bigg ] \\ \\ \n",
              "  & \\ qquad \t + \\ underbrace { \\ xxmaj big ( \\ mathrm{p}_{m _ { \\ mathbb{i}_m}}^u \\ mathrm{p}_{s , f , \\ mathbb{i}_m = xxunk } \\ xxmaj big ) } _ { \\ xxunk hit in xxmaj case 4 } } \\ mathbb{i}_m , \n",
              "  \\ end{aligned } \n",
              "  \\ end{equation } \n",
              "  where the first term represents the self cache hit , the second term represents the successfully achieved cache hit from xxup d2d neighbors . \n",
              "  xxmaj moreover , $ \\ mathrm{p}_{s , xxunk represents the successful transmission probability for the respective ` * ' cases . \n",
              "  xxmaj note that the transmission success probability between two nodes does not depend on the content index . \n",
              "  xxmaj therefore , we mention the success probability as $ \\ xxunk , xxunk instead of $ \\ xxunk , xxunk \n",
              "  % xxmaj now , we derive these transmission success probabilities using appropriate channel models . \n",
              "  % xxmaj however , owing to the space constraint , the detailed derivations of these probabilities are presented in our online technical report \\ xxunk } . \n",
              " \n",
              " \n",
              " \n",
              " \n",
              "  \\ xxunk of xxmaj successful xxmaj transmission } \n",
              " \n",
              "  xxmaj now , we calculate the transmission success probabilities among different nodes . \n",
              "  xxmaj when a tagged user requests a content , interference comes from other active xxup d2d users , active sbss and the xxup mbs . \n",
              "  xxmaj the wireless channel between two nodes follows a xxmaj xxunk fading distribution with $ \\ xxunk \n",
              "  xxmaj let us denote the channel between node $ i$ and node $ j$ by $ xxunk \n",
              "  xxmaj let us also denote the threshold xxup xxunk for successful communication by $ \\ phi$ xxunk \n",
              "  xxmaj the transmission power of the user , the sbs and the xxup mbs are denoted by $ p_u$ , $ p_b$ and $ xxunk , respectively . \n",
              "  xxmaj moreover , the path loss exponent is denoted by $ \\ beta$. \n",
              "  xxmaj owing to the space constraint , the detail derivations of these probabilities are omitted . \n",
              "  xxmaj however , interested readers can find them in our online technical report \\ xxunk } . \n",
              "  xxmaj also , note that we do not consider the case of obtaining the content from the cloud , when we calculate $ \\ xxunk \n",
              "  xxmaj this is due to the fact that we are interested in calculating the percentage of served request from the local nodes only . \n",
              " \n",
              " \n",
              "  \\ xxunk } \\ vspace{-0.2 in } \n",
              "  % \\ small \n",
              "  \\ begin{equation } \n",
              "  \\ xxunk } \n",
              "  \\ begin{aligned } \n",
              "  \\ xxmaj sigma & = \\ frac{1}{| \\ xxunk } \\ sum _ { u_0 \\ in \\ xxunk } \\ sum_{k=1}^{f } \\ xxunk } \\ xxmaj bigg \\ { \\ eta_{f_k}^{u_0 } + \\ left(1- \\ eta_{f_k}^{u_0 } \\ right ) \\ left[1 - \\ prod_{u_i \\ in \\ xxmaj phi_{u } \\ backslash u_0 } \\ left(1 - \\ eta_{f_k}^{u_i } \\ right ) \\ right ] \\ mathrm{p}_{s , xxunk } + \\ xxmaj bigg ( \\ left(1- \\ eta_{f_k}^{u_0 } \\ right ) \\ prod_{u_i \\ in \\ xxmaj phi_{u } \\ backslash u_0 } \\ ! \\ ! \\ ! \\ ! \\ ! \\ ! \\ left(1 - \\ eta_{f_k}^{u_i } \\ right ) \\ eta_{f_k}^{b_0 } \\ mathrm{p}_{s , xxunk } + \\ \\ \n",
              "  & \\ qquad \\ left(1- \\ eta_{f_k}^{u_0 } \\ right ) \\ ! \\ ! \\ ! \\ ! \\ prod_{u_i \\ in \\ xxmaj phi_{u } \\ backslash u_0 } \\ ! \\ ! \\ ! \\ ! \\ left(1 - \\ eta_{f_k}^{u_i } \\ right ) \\ ! \\ ! \\ left(1 - \\ eta_{f_k}^{b_0 } \\ right ) \\ ! \\ ! \\ left(1 - \\ ! \\ ! \\ ! \\ prod_{b_j \\ in \\ xxmaj phi_{b } \\ backslash b_0 } \\ ! \\ ! \\ ! \\ ! \\ left ( 1 - \\ eta_{f_k}^{b_j } \\ right ) \\ ! \\ ! \\ ! \\ right ) \\ mathrm{p}_{s , xxunk } + \\ left(1- \\ eta_{f_k}^{u_0 } \\ right ) \\ prod_{u_i \\ in \\ xxmaj phi_{u } \\ backslash u_0 } \\ left(1 - \\ eta_{f_k}^{u_i } \\ right ) \\ left(1 - \\ eta_{f_k}^{b_0 } \\ right ) \\ \\ \n",
              "  & \\ qquad \\ prod_{b_j \\ in \\ xxmaj phi_{b } \\ backslash xxunk } \\ left ( 1 - \\ eta_{f_k}^{b_j } \\ right ) \\ eta_{f_k}^{m_0 } \\ mathrm{p}_{s , xxunk } \\ xxmaj bigg ) \\ mathbb{i}_s + \\ xxmaj bigg ( \\ left(1- \\ eta_{f_k}^{u_0 } \\ right ) \\ prod_{u_i \\ in \\ xxmaj phi_{u } \\ backslash u_i } \\ left(1 - \\ eta_{f_k}^{u_i } \\ right ) \\ eta_{f_k}^{m_0 } \\ mathrm{p}_{s , f , \\ mathbb{i}_m = xxunk } \\ xxmaj bigg ) \\ mathbb{i}_m \\ xxmaj bigg \\ } . \n",
              "  \\ end{aligned } \n",
              "  \\ end{equation } \n",
              "  \\ xxunk } \n",
              " \n",
              " \n",
              " \n",
              "  \\ xxunk xxmaj hit xxmaj ratio xxmaj maximization using xxmaj particle xxmaj swarm xxmaj optimization } \n",
              "  \\ xxunk } \n",
              "  xxmaj we present the objective function , followed by the proposed m - xxup pso algorithm in this section . \n",
              " \n",
              "  \\ xxunk xxmaj maximization xxmaj objective xxmaj function } \n",
              "  xxmaj to this end , we calculate the average cache hit ratio for the requesting nodes , which is denoted by $ \\ xxmaj sigma$. \n",
              "  xxmaj the detailed derivation of the $ \\ xxmaj sigma$ is shown in ( \\ xxunk } ) . \n",
              "  xxmaj our objective is to maximize $ \\ xxmaj sigma$ given that the storage constraints are not violated . \n",
              "  xxmaj thus , the objective function in the heterogeneous caching model case is expressed as \n",
              "  \\ begin{subequations } \n",
              " \t  \\ begin{align } \n",
              " \t  \\ xxunk : } \\ quad \t & \\ underset { \\ eta_{f_k}^{u_i } , \\ eta_{f_k}^{b_j } , \\ eta_{f_k}^{m_l } } { \\ text{maximize } } \\ quad \\ xxmaj sigma \\ \\ \n",
              " \t & \\ quad \\ text{s . t. } ~ \\ xxunk } \\ sum_{k=1}^{f } \\ eta_{f_k}^{u_i } \\ leq \\ xxunk , \\ quad \\ xxunk u_i \\ in \\ { \\ mathcal{u } \\ } , f_k \\ in \\ { \\ mathcal{f } \\ } \\ \\ \n",
              " \t & \\ xxunk } \\ qquad \t  \\ sum_{k=1}^{f } \\ eta_{f_k}^{b_j } \\ leq \\ mathcal{c}_b , \\ quad \\ xxunk b_j \\ in \\ { \\ mathcal{b } \\ } , f_k \\ in \\ { \\ mathcal{f } \\ } \\ \\ \n",
              " \t & \\ xxunk } \\ qquad \t  \\ sum_{k=1}^{f } \\ eta_{f_k}^{m_l } \\ leq \\ mathcal{c}_m , \\ quad \\ forall ~ xxunk \\ in \\ { \\ mathcal{m } \\ } , f_k \\ in \\ { \\ mathcal{f } \\ } \\ \\ \n",
              " \t & \\ xxunk } \\ qquad \t 0 \\ leq \\ eta_{f_k}^{u_i } \\ leq 1,~ 0 \\ leq \\ eta_{f_k}^{b_j } \\ leq 1,~ 0 \\ leq \\ eta_{f_k}^{m_l } \\ leq 1 , \t \n",
              " \t  \\ end{align } \n",
              " \t  \\ xxunk } \n",
              "  \\ end{subequations } \n",
              "  where the constraints in ( \\ xxunk \\ xxunk } ) ensure the physical storage size limitations of the user , the sbs and the xxup mbs , respectively , while the constraints in ( \\ xxunk } ) are due to the probability range in $ [ 0,1]$. \n",
              "  xxmaj the goal is to find optimal caching placements that give us the optimal solutions . \n",
              "  % xxmaj however , the optimization problem $ \\ xxunk is highly challenging to solve . \n",
              "  xxmaj in general , problem $ \\ xxunk is non - convex \\ cite{8667875 } by nature and may not be solved efficiently in a polynomial time due to the nonlinear and combinatorial content placement variables . \n",
              "  % xxmaj the option of exhaustive search is also out of consideration due to its exponential complexity . \n",
              "  % xxmaj instead , we apply an xxup ai - based framework to obtain sub - optimal yet efficient solutions . \n",
              "  xxmaj in the following , a modified particle swarm optimization ( m - xxup pso ) framework is proposed to obtain the best set of parameters . \n",
              " \n",
              " \n",
              " \n",
              "  \\ xxunk - xxmaj particle xxmaj swarm xxmaj optimization xxmaj algorithm } \n",
              "  xxup pso is a swarm intelligence approach that guarantees to converge \\ xxunk } . \n",
              "  xxmaj in this meta - heuristic algorithm , all possible sets of the candidate solutions are named as the particles , which are denoted by $ i$. \n",
              "  xxmaj each particle has a position denoted by $ x_i$. \n",
              "  xxmaj furthermore , it maintains a personal best position of each particle , denoted by $ xxunk , and the global best positions of the entire swarm , denoted by $ xxunk \n",
              "  xxmaj the algorithm evolves with an exploration and exploitation manner by adding a velocity term $ xxunk at each particle 's previous position aiming to converge at the global optima . \n",
              "  xxmaj the following two simple equations , thus , govern the xxup pso algorithm . % \\ vspace{-0.1 in } \n",
              "  \\ begin{align } \n",
              "  xxunk } & = xxunk + \\ psi_1 \\ epsilon_1 \\ xxunk } - x_i \\ right ) + \\ psi_2 \\ epsilon_2 \\ xxunk } - x_i \\ right ) , \\ xxunk } \\ \\ \n",
              "  xxunk } & = xxunk + xxunk } , \\ xxunk } \n",
              "  \\ end{align } \n",
              "  where $ a$ , $ \\ psi_1 $ , and $ \\ psi_2 $ are the parameters that need to be selected properly . \n",
              "  xxmaj moreover , $ \\ epsilon_1 $ and $ \\ epsilon_2 $ are two $ \\ xxunk random variables . \n",
              "  xxmaj note that $ \\ psi_1 $ and $ \\ psi_2 $ are positive acceleration coefficients , which are also known as the cognitive and social learning factors \\ cite{8667875 } respectively . \n",
              "  xxmaj while this is a general framework for the xxup pso algorithm , it may not be used directly in the constraint optimization \\ xxunk } . \n",
              "  xxmaj in our objective function , each particle must have a position matrix , each dimension of which must not violate the restrictions . \n",
              "  xxmaj therefore , in the following , we modify the xxup pso algorithm to solve the optimization problem efficiently . \n",
              " \n",
              "  xxmaj let $ xxup p$ be the number of particles . \n",
              "  xxmaj let $ \\ pmb { \\ xxunk } \\ in \\ xxunk \\ times 1}$ denote the caching probabilities of user $ u_i$ for all the contents $ f_k \\ in \\ { \\ mathcal{f } \\ } $ . \n",
              "  % xxmaj then , this parameter has a size of $ f \\ times 1$. \n",
              "  xxmaj similarly , for all the sbss and mbss , let $ \\ pmb { \\ xxunk and $ \\ pmb { \\ xxunk denote their caching placement probabilities for all the contents . \n",
              "  xxmaj then , all of these parameters can be stacked into a matrix with dimension of $ ( | \\ mathcal{u}| + | \\ mathcal{b}| + | \\ mathcal{m}| ) \\ times | \\ xxunk , which is the exact shape of each particle . \n",
              "  xxmaj let the current position of each of these particles be denoted by $ \\ xxunk \n",
              "  % xxmaj note that in this case , each particle 's position $ \\ xxunk has a shape of $ ( | \\ mathcal{u}| + | \\ mathcal{b}| + | \\ mathcal{m}| ) \\ times | \\ xxunk \n",
              "  xxmaj let $ \\ xxunk } \\ in \\ xxunk \\ mathcal{u}| + | \\ mathcal{b}| + | \\ mathcal{m}| ) \\ times | \\ mathcal{f}|}$ denote the velocity . xxmaj furthermore , the personal best position of particle $ i$ is $ \\ mathbf{p}_i^ { \\ mathrm{best}}$ , while the global best for the entire swarm is $ \\ mathbf{g}^ { \\ xxunk \n",
              "  xxmaj therefore , each particle updates its velocity with social and individual cognition parameters . \n",
              "  xxmaj we use the following equation to govern these updates . \n",
              "  \\ begin{equation } \n",
              "  \\ small \n",
              "  \\ begin{aligned } \n",
              "  \\ xxunk } \n",
              "  \\ ! \\ ! \\ xxunk } \\ ! \\ ! & = \\ ! a \\ xxunk + \\ psi_1 \\ left [ \\ pmb { \\ xxunk \\ ! \\ odot \\ ! \\ ! \\ left ( \\ mathbf{p}_{i}^ { \\ mathrm{best } } \\ ! \\ ! - \\ ! \\ xxunk } \\ right ) \\ right ] \\ ! + \\ ! \\ psi_2 \\ left [ \\ pmb { \\ xxunk \\ ! \\ odot \\ ! \\ ! \\ left ( \\ mathbf{g}^ { \\ mathrm{best } } \\ ! \\ ! \\ ! - \\ xxunk \\ ! \\ right ) \\ ! \\ right ] \\ ! \\ ! , \n",
              "  \\ end{aligned } \n",
              "  \\ end{equation } \n",
              "  where $ a$ , $ \\ psi_1 $ and $ \\ psi_2 $ are the parameters as described in ( \\ xxunk } ) . \n",
              "  xxmaj moreover , $ \\ pmb { \\ xxunk $ and $ \\ pmb { \\ xxunk $ are two matrices with sizes of $ \\ xxunk \\ mathcal{u}| + | \\ mathcal{b}| + | \\ mathcal{m}| ) \\ times | \\ mathcal{f}|}$ respectively , where their elements are drawn from $ \\ xxunk random distribution . \n",
              "  xxmaj finally , $ \\ odot$ represents xxmaj xxunk product . \n",
              " \n",
              " \n",
              "  xxmaj the position of each particle is then updated by the velocity similar to ( \\ xxunk } ) . \n",
              "  xxmaj however , as there are constraints ( \\ xxunk ( \\ xxunk } ) , we need to modify this equation accordingly . \n",
              "  xxmaj let $ \\ xxunk denote an intermediate updated position of particle $ i$ as shown in the following expression . \n",
              "  \\ begin{equation } \n",
              "  % \\ small \n",
              "  \\ xxunk } \n",
              "  \\ xxunk } = \\ xxunk + \\ xxunk . \n",
              "  \\ end{equation } \n",
              "  % xxmaj we consider this intermediate position to keep each particle 's position in the feasible search space . \n",
              "  xxmaj besides , necessary normalization and scaling need to be performed . \n",
              "  xxmaj note that this intermediate particle position leads to a normalized particle position . \n",
              "  xxmaj this parameter is then used as the current particle position $ \\ xxunk \n",
              "  xxmaj moreover , the ultimate goal for each particle is to converge to an optimal position $ \\ xxunk ( i.e. , the global best $ \\ mathbf{g}^ { \\ mathrm{best}}$ ) . \n",
              "  xxmaj we summarize all the steps in xxmaj alg.~ \\ xxunk } . \n",
              "  xxmaj note that the proposed algorithm can be implemented to solve any similar hard combinatorial problems . \n",
              " \n",
              "  \\ begin{algorithm } \n",
              "  \\ small \n",
              "  \\ xxunk xxmaj maximization using m - xxup pso } \n",
              " \t  \\ begin{algorithmic } [ 1 ] \n",
              " \t\t  \\ xxmaj for { each particle , $ i = 1,2 , \\ dots , xxup p$ } \n",
              " \t\t  \\ xxmaj state { $ \\ mathbf{x}_i = [ ~]$ , $ \\ mathbf{v}_i = [ ~]$ } \n",
              " \t\t  \\ xxmaj for { each dimension $ j = 1,2 , \\ dots , xxup d$ } \\ xxunk \\ mathcal{u}| + | \\ mathcal{b}| + | \\ xxunk } \n",
              " \t\t  \\ xxmaj state initialize the particles positions , $ \\ mathbf{x}_{ji } $ with uniform random vector of size $ \\ mathbb{r}^{| \\ mathcal{f}|}$ by making sure $ \\ sum_{k = xxup xxunk } { xxunk ] = 1 $ and $ 0 \\ leq { xxunk ] \\ leq \\ frac{1 } { \\ xxunk , $ \\ forall ~k \\ in \\ mathcal{f}$ ; then set $ \\ mathbf{x}_i [ j , : ] \\ leftarrow \\ xxunk \\ xxmaj xxunk \\ xxunk is the cache storage of the node in $ j^{th}$ dimension } \\ xxunk } \n",
              " \t\t  \\ xxmaj state initialize particles velocity , $ \\ mathbf{v}_{ji}$ with uniform random vector of size $ \\ mathbb{r}^{| \\ mathcal{f}|}$ by making sure $ \\ sum_{k = xxup xxunk } { xxunk ] = 1 $ and $ 0 \\ leq { xxunk ] \\ leq \\ frac{1 } { \\ xxunk , $ \\ forall ~k \\ in \\ mathcal{f}$ ; then set $ \\ mathbf{v}_i [ j , : ] \\ leftarrow \\ mathbf{v}_{ji}$ \\ xxunk } \n",
              " \t\t  \\ endfor \n",
              " \t\t  \\ xxmaj state set particle best position , $ \\ xxunk as the initial position \n",
              " \t\t  \\ xxmaj if { $ \\ xxmaj sigma \\ left ( \\ mathbf{p}_{i}^ { \\ mathrm{best } } \\ right ) > \\ mathrm { \\ xxmaj sigma } \\ left ( \\ mathbf{g}^ { \\ mathrm{best } } \\ right)$ } \\ xxunk } \n",
              " \t\t  \\ xxmaj state $ \\ mathbf{g}^ { \\ mathrm{best } } \\ leftarrow \\ mathbf{p}_i^ { \\ mathrm{best}}$ \n",
              " \t\t  \\ endif \n",
              " \t\t  \\ endfor \n",
              " \t\t  \\ xxmaj while { termination criteria has not met } \n",
              " \t\t  \\ xxmaj for { each particle , $ i$ } \n",
              " \t\t  \\ xxmaj for { each dimension , $ j = 1,2 , \\ dots , xxup d$ } \n",
              " \t\t  \\ xxmaj state draw uniform random vectors , $ \\ pmb { \\ epsilon}_1 $ and $ \\ pmb { \\ epsilon}_1 $ of size $ \\ mathbb{r}^{| \\ mathcal{f}|}$ \n",
              " \t\t  \\ xxmaj state set $ \\ mathbf{v}_{ji } \\ leftarrow a \\ mathbf{v}_{ji } + \\ psi_1 \\ left [ \\ pmb { \\ epsilon}_1 \\ odot \\ left ( \\ xxunk { \\ mathrm{best } } - \\ mathbf{x}_{ji } \\ right ) \\ right ] + \\ psi_2 \\ left [ \\ pmb { \\ xxunk \\ odot \\ left ( \\ xxunk { \\ mathrm{best } } - \\ mathbf{x}_{ji } \\ right ) \\ right ] $ % \\ xxmaj xxunk \\ mathbf{v}_{ji}$ represents a single row of particle $ i$ 's $ j^{th}$ dimension } \n",
              " \t\t  \\ xxmaj state set $ \\ mathbf{v}_i [ j , : ] \\ leftarrow \\ mathbf{v}_{ji } $ \n",
              " \t\t  \\ endfor \n",
              " \t\t  \\ xxmaj state update particles intermediate position , $ \\ xxunk % using equation ( \\ xxunk } ) \n",
              " \t\t  \\ xxmaj state $ \\ mathbf{x}_{i}^ { \\ mathrm{scl } } = [ ~]$ , $ \\ mathbf{p}_{i}^ { \\ mathrm{scl \\ _ best } } = [ ~]$ , $ \\ mathbf{g}^ { \\ mathrm{scl \\ _ best } } = [ ~]$ \n",
              " \t\t  \\ xxmaj for{each dimension $ j = 1,2 , \\ dots , xxup d$ } \n",
              " \t\t  \\ xxmaj state $ \\ xxunk \\ _ xxunk } \\ leftarrow \\ xxunk } ( \\ xxunk \\ xxunk } \n",
              " \t\t  \\ xxmaj for { i in $ len ( \\ xxunk \\ _ xxunk } \n",
              " \t\t  \\ xxmaj state $ \\ mathbf{x}_{i_{int}}[j , \\ xxunk ) ] \\ leftarrow \\ frac { \\ sum_{k=1}^{f } \\ mathbf{x}_{i_{int}}[j , : ] } { \\ xxunk } $ \\ xxunk } \n",
              " \t\t  \\ endfor \n",
              " \t\t  \\ xxmaj state $ \\ xxunk , : ] \\ leftarrow \\ frac { \\ mathbf{x}_{i_{int}}[j , : ] } { \\ sum_{k=1}^{f } \\ mathbf{x}_{i_{int}}[j , : ] } $ ; $ \\ mathbf{x}_{i}^ { \\ xxunk , : ] \\ leftarrow \\ mathcal{c}^{j } \\ xxunk , : ] $ \\ xxunk particle position } \n",
              " \t\t  \\ xxmaj state $ \\ mathbf{p}_{i}^ { \\ mathrm{scl \\ _ best } } [ j , : ] \\ leftarrow \\ mathcal{c}^{j } \\ mathbf{p}_{i}^ { \\ xxunk , : ] $ \\ xxunk } \n",
              " \t\t  \\ xxmaj state $ \\ xxunk { \\ mathrm{scl \\ _ best } } [ j , : ] \\ leftarrow \\ mathcal{c}^{j } \\ xxunk { \\ xxunk , : ] $ \\ xxunk } \n",
              " \t\t  \\ endfor \n",
              " \t\t  \\ xxmaj if{$ \\ xxmaj sigma \\ left ( \\ mathbf{x}_{i}^ { \\ mathrm{scl } } \\ right ) > \\ mathrm { \\ xxmaj sigma } \\ left ( \\ mathbf{p}_{i}^ { \\ mathrm{scl \\ _ best } } \\ right)$ } \\ xxunk } \n",
              " \t\t  \\ xxmaj state $ \\ mathbf{p}_i^ { \\ mathrm{best } } \\ leftarrow \\ xxunk \n",
              " \t\t  \\ xxmaj state do necessary scaling following step \\ xxunk } \n",
              " \t\t  \\ xxmaj if{$ \\ xxmaj sigma \\ left ( \\ mathbf{p}_{i}^ { \\ mathrm{scl \\ _ best } } \\ right ) > \\ mathrm { \\ xxmaj sigma } \\ left ( \\ mathbf{g}^ { \\ mathrm{scl \\ _ best } } \\ right)$ } \\ xxunk } \n",
              " \t\t  \\ xxmaj state $ \\ mathbf{g}^ { \\ mathrm{best } } \\ leftarrow \\ mathbf{p}_i^ { \\ mathrm{best}}$ \n",
              " \t\t  \\ endif \n",
              " \t\t  \\ endif \n",
              " \t\t  \\ endfor \n",
              " \t\t  \\ endwhile \n",
              " \t\t  \\ xxmaj state \\ textbf{return } $ \\ mathbf{g}^ { \\ mathrm{best}}$ and do necessary scaling following step \\ xxunk } and \\ textbf{return } $ \\ mathbf{g}^ { \\ mathrm{scl \\ _ xxunk \n",
              " \t  \\ end{algorithmic } \\ xxunk } \n",
              "  \\ end{algorithm } \n",
              " \n",
              " \n",
              "  % \\ xxunk observations on the algorithm ] \n",
              "  % xxmaj we model the algorithm such a way that we deal with the normalized particle position and velocity . \n",
              "  % xxmaj the constraints guide us to restrict the particle position in a probability range , while the summation can not exceed the cache storage capacity of the respective node . \n",
              "  % xxmaj therefore , we consider to limit the initial values in the range of $ [ xxunk / \\ xxunk \n",
              "  % xxmaj by doing so , when we perform the necessary scaling , the obtained number does not violate the probability range . \n",
              "  % xxmaj then , we correspondingly initialize the particle position and the velocity in steps \\ xxunk } and \\ xxunk } following this notion . \n",
              "  % xxmaj furthermore , the caching probabilities of the nodes in dimension $ j$ are limited to $ \\ xxunk , in steps \\ xxunk } and \\ xxunk } , hence , we choose the random number of contents , $ \\ xxunk ( \\ xxunk ) } $ , to be stored with higher probability values . \n",
              "  % \\ end{rem } \n",
              " \n",
              "  \\ section{results and xxmaj discussions } \n",
              "  % \\ xxunk } \n",
              "  \\ label{result } \n",
              " \n",
              "  xxmaj the simulation parameters are listed as follows : $ \\ xxunk = 10^{-4}$ ( per $ m^2 $ ) , $ \\ lambda_b = 10^{-5}$ ( per $ m^2 $ ) , $ \\ lambda_m = xxunk ( per $ m^2 $ ) , $ xxmaj xxunk = 15 m$ , $ xxmaj r_b = 150 m$ and $ xxmaj xxunk = 500 m$ , $ | \\ mathcal{f}| = [ 10 , xxunk , $ \\ alpha \\ in [ 0.2 , 0.5]$ , $ \\ xxunk } = 0.1 $ , $ \\ xxunk $ , $ a = 0.9 $ , $ \\ psi_1 = \\ xxunk $ , $ xxunk = 23 $ dbm , $ xxunk $ dbm , $ p_m = 43 $ dbm , $ \\ phi = xxunk db , $ \\ beta = 4 $ , $ \\ xxunk $ and $ \\ sigma^2 = xxunk $ dbm / xxmaj hz . \n",
              "  xxmaj monte xxmaj carlo simulation is used for performance evaluation . \n",
              "  % xxmaj in the following , we use the proposed m - xxup pso algorithm to attain the optimal caching placement solution . \n",
              "  % xxmaj after that , we study its performances for our hard - combinatorial maximization problem . \n",
              " \n",
              " \n",
              "  % \\ subsection{cache xxmaj placement } \n",
              "  xxmaj to show the effectiveness of the proposed algorithm , we firstly validate that the obtained results do not violate any of the constraints . \n",
              "  xxmaj the global best $ \\ mathbf{g}^ { \\ mathrm{scl \\ _ xxunk obtained from xxmaj alg.~ \\ xxunk } is therefore xxunk as follows . \n",
              "  xxmaj note that it must not violate any of the caching storage constraints of the edge nodes . \n",
              "  xxmaj besides , each of the caching probabilities must be in the range of $ [ 0,1]$. \n",
              "  xxmaj furthermore , each node must store different copies of the content . \n",
              "  xxmaj all these constraints are considered in the proposed algorithm . \n",
              "  xxmaj therefore , it is expected that the obtained results shall meet these requirements . \n",
              "  xxmaj the caching probabilities of $ xxunk and $ xxunk for xxup d2d users , sbss and mbss are illustrated in xxmaj fig.~ \\ xxunk } . \n",
              "  xxmaj it is readily observed that each node stores different copies . \n",
              "  xxmaj moreover , caching probabilities and storage constraints are also satisfied . \n",
              "  xxmaj now , we study the performance of our proposed m - xxup pso algorithm and make a fair comparison with the following benchmark caching schemes in this sub - section . \n",
              " \n",
              " \n",
              "  % \\ begin{figure } \\ vspace{-0.1 in } \n",
              "  % \t  \\ centering \n",
              "  % \\ includegraphics[width= 0.45 \\ textwidth ] { xxmaj figures / xxunk } \n",
              "  % % xxmaj if you do n't want the xxunk in the bar plot , please use the following line instead of the above one \n",
              "  % % \\ includegraphics[width= 0.45 \\ textwidth]{figures / xxunk } \n",
              "  % \\ vspace{-0.18 in } \n",
              "  % \t  \\ xxunk caching probabilities at the local nodes when $ \\ mathcal{c}_d = 2 $ , $ \\ mathcal{c}_b = 4 $ and $ \\ mathcal{c}_m = 8 $ } \n",
              "  % \t  \\ xxunk } \n",
              "  % \\ end{figure } \n",
              " \n",
              "  % \\ begin{figure } \\ vspace{-0.1 in } \n",
              "  % \t  \\ centering \n",
              "  % \\ includegraphics[width= 0.45 \\ textwidth ] { xxmaj figures / xxunk } \n",
              "  % % xxmaj if you do n't want the xxmaj error xxmaj bar in the bar plot , please use the following line instead of the above one \n",
              "  % % \\ includegraphics[width= 0.45 \\ textwidth]{figures / xxunk } \n",
              "  % \\ vspace{-0.18 in } \n",
              "  % \t  \\ xxunk using the proposed m - xxup pso algorithms for $ 100 $ iteration , $ | \\ mathcal{f}| = 30 $ , $ \\ mathcal{c}_d = 2 $ , $ \\ mathcal{c}_b = 4 $ and $ \\ mathcal{c}_m = 8 $ } \n",
              "  % \t  \\ xxunk } \n",
              "  % \\ end{figure } \n",
              " \n",
              " \n",
              "  % \\ begin{figure } \n",
              "  % \\ centering \n",
              "  % \\ includegraphics[width= 0.45 \\ textwidth ] { xxmaj figures / xxunk } \n",
              "  % \\ vspace{-0.18 in } \n",
              "  % \t  \\ xxunk of catalog size : xxup chr with $ \\ mathcal{c}_d = 2 $ , $ \\ mathcal{c}_b = 4 $ and $ \\ mathcal{c}_m = 8 $ } \n",
              "  % \t  \\ xxunk } \n",
              "  % \\ end{figure } \n",
              " \n",
              "  \\ begin{figure * } \\ vspace{-0.2 in } \n",
              "  \\ centering \n",
              "  \\ xxunk caching probabilities at the local \n",
              "  ewline nodes when $ \\ mathcal{c}_d = 2 $ , $ \\ mathcal{c}_b = 4 $ and $ \\ mathcal{c}_m = 8 $ ] { \\ xxunk } \\ includegraphics[width= 0.33 \\ textwidth ] { xxmaj figures / xxunk } } \n",
              " \t  \\ subfloat[chr comparison when $ | \\ mathcal{f}| = 30 $ , $ \\ mathcal{c}_d = 2 $ , \n",
              "  ewline $ \\ mathcal{c}_b = 4 $ and $ \\ mathcal{c}_m = 8 $ ] { \\ xxunk } \\ includegraphics[width= 0.33 \\ textwidth ] { xxmaj figures / xxunk } } \n",
              " \t  \\ xxunk of catalog size : xxup chr with $ \\ mathcal{c}_d = 2 $ , \n",
              "  ewline $ \\ mathcal{c}_b = 4 $ and $ \\ mathcal{c}_m = 8 $ ] { \\ xxunk } \n",
              " \t  \\ includegraphics[width= 0.33 \\ textwidth ] { xxmaj figures / xxunk } } \n",
              " \t  \\ caption{performance observation of the proposed m - xxup pso algorithm } \n",
              " \t  \\ xxunk } \n",
              "  \\ end{figure * } \n",
              " \n",
              "  \\ begin{figure * } \\ vspace{-0.2 in } \n",
              " \t  \\ centering \n",
              " \t  \\ subfloat[chr for different user cache storage sizes ] { \\ xxunk } \\ includegraphics[width= 0.33 \\ textwidth ] { xxmaj figures / xxunk } } \n",
              " \t  \\ subfloat[chr for different sbs cache storage sizes ] { \\ xxunk } \\ includegraphics[width= 0.33 \\ textwidth ] { xxmaj figures / xxunk } } \n",
              " \t  \\ subfloat[chr for different xxup mbs cache storage sizes ] { \\ xxunk } \\ includegraphics[width= 0.33 \\ textwidth ] { xxmaj figures / xxunk } } \n",
              " \t  \\ xxunk of cache size on xxup chr } \n",
              " \t  \\ xxunk } \n",
              "  \\ end{figure * } % \\ vspace{-0.1 in } \n",
              " \n",
              " \n",
              "  \\ textbf { \\ textit{random xxmaj caching xxmaj scheme } } : \n",
              "  xxmaj in the random caching scheme , contents are stored randomly while satisfying the constraints . \n",
              " \n",
              "  \\ textbf { \\ xxunk xxmaj caching xxmaj scheme } } : \n",
              "  xxmaj in the equal caching scheme , each content is placed with the same probability . \n",
              " \n",
              "  xxmaj the proposed algorithm runs $ 100 $ iterations and it effectively converges . \n",
              "  xxmaj fig.~ \\ xxunk } demonstrates the xxup chr comparison of the proposed algorithm with the random caching scheme and equal caching scheme . \n",
              "  xxmaj it can be seen that the xxup xxunk achieves $ \\ approx 60 \\ % $ higher performance gain over these benchmark caching schemes . \n",
              "  xxmaj in the following , we use our algorithm to evaluate the system performance in terms of different parameter settings . \n",
              " \n",
              " \n",
              "  \\ subsubsection{impact of the xxmaj catalog xxmaj size } \n",
              " \n",
              "  % xxmaj recall that if the requested content is delivered from one of the cache - enabled edge nodes , a cache hit occurs . \n",
              "  xxmaj considering the catalog size = $ [ 10 , xxunk , we aim to store as many to - be - requested contents as possible into the local edge nodes . \n",
              "  % xxmaj furthermore , the intensities are set as $ \\ xxunk = 10^{-4}$ , $ \\ lambda_b = 10^{-5}$ and $ \\ lambda_m = xxunk \n",
              "  xxmaj the total number of iterations is chosen as $ 100 \\ times [ 1 , 10 , 20 , 40 , xxunk for the catalog size in $ [ 10 , 20 , 30 , 40 , xxunk , respectively . \n",
              "  xxmaj if the catalog size increases , the number of possible combinations also increases . \n",
              "  xxmaj therefore , whenever the content catalog increases , we slightly increase the total number of iterations . \n",
              "  xxmaj also , if the total number of contents increases and there are only a limited number of cache - enabled nodes , the chance of storing the contents locally decreases , meaning that more content requests need to be served from the cloud . \n",
              "  xxmaj therefore , the $ \\ xxmaj sigma$ should decrease if the content catalog increases . \n",
              "  xxmaj moreover , if the percentage of the requester nodes increases , the performance should degrade as we consider the heterogeneous preference of the users . \n",
              "  xxmaj fig.~ \\ xxunk } also demonstrates that if we increase the catalog size , $ | \\ xxunk or the number of requests ( $ \\ alpha$ ) , then $ \\ xxmaj sigma$ decreases . \n",
              " \n",
              " \n",
              "  \\ subsubsection{impact of the xxmaj storage xxmaj size } \n",
              "  % xxmaj we now investigate the impact of the cache sizes of the edge nodes on the system performance . \n",
              "  xxmaj recall that if the cache size increases , more contents can be stored at the cache - enabled nodes . \n",
              "  xxmaj therefore , increasing the cache size of the users means that users store more contents in their local storage . \n",
              "  xxmaj as these storage sizes increase , the proposed m - xxup pso algorithm determines the optimal caching placements . \n",
              "  xxmaj the simulation results , presented in xxmaj fig.~ \\ xxunk } , validate that as the storage size increases , more contents are locally stored leading to an improvement of xxup chr . \n",
              "  xxmaj note that increasing xxup mbs cache size provides a lower xxup chr gain than increasing the cache size of the xxup d2d users ( or , the sbss ) . \n",
              "  xxmaj this is because the total number of mbss is typically much lower than that of the available xxup d2d ( or , sbs ) nodes . \n",
              " \n",
              "  \\ xxunk } \n",
              "  \\ section{conclusion } \n",
              "  \\ xxunk } \n",
              "  xxmaj caching solution helps to achieve better system performances . \n",
              "  xxmaj however , the hard combinatorial decision - making problem of placing the contents at the local nodes is challenging . \n",
              "  xxmaj the e grand problem is effectively solved with good accuracy by using the artificial intelligence based technique . \n",
              "  xxmaj considering heterogeneous content preferences in a real - world network platform , the proposed algorithm converges fast and achieves a much better performance than the existing benchmark caching schemes . \n",
              " \n",
              " \n",
              "  % \\ section*{acknowledgment } \n",
              "  % xxmaj the authors sincerely thank xxmaj xxunk xxmaj shah for the critical and helpful % discussions during this work . \n",
              " \n",
              "  \\ bibliography{reference } \n",
              "  \\ bibliographystyle{ieeetran } \n",
              " \n",
              "  \\ end{document } \n",
              " \n",
              " ,xxbos \\ documentclass[10pt , twocolumn , letterpaper]{article } \n",
              " \n",
              "  \\ usepackage{cvpr } \n",
              "  \\ usepackage{times } \n",
              "  \\ usepackage{epsfig } \n",
              "  \\ usepackage{graphicx } \n",
              "  \\ usepackage{amsmath } \n",
              "  \\ usepackage{amssymb } \n",
              "  \\ usepackage{bm } \n",
              "  \\ usepackage{rotating } \n",
              "  \\ usepackage{mathtools } \n",
              "  \\ xxunk } \n",
              " \n",
              "  ewcommand { \\ r } { \\ mathbb{r } } \n",
              "  % xxmaj include other packages here , before hyperref . \n",
              " \n",
              "  % xxmaj if you comment hyperref and then uncomment it , you should delete \n",
              "  % egpaper.aux before re - running latex . ( xxmaj or just hit ' q ' on the first latex \n",
              "  % run , let it finish , and you should be clear ) . \n",
              "  \\ usepackage[pagebackref = true , breaklinks = true , letterpaper = true , colorlinks , bookmarks = false]{hyperref } \n",
              " \n",
              "  \\ cvprfinalcopy % * * * xxmaj uncomment this line for the final submission \n",
              " \n",
              "  \\ def \\ xxunk } % * * * xxmaj enter the xxup cvpr xxmaj paper xxup id here \n",
              "  \\ def \\ httilde { \\ mbox { \\ tt \\ raisebox{-.5ex } { \\ symbol{126 xxrep 4 } \n",
              " \n",
              "  % xxmaj pages are numbered in submission mode , and unnumbered in camera - ready \n",
              "  \\ ifcvprfinal \\ pagestyle{empty } \\ fi \n",
              "  \\ begin{document } \n",
              " \n",
              "  xxrep 9 % xxup title \n",
              "  \\ xxunk and xxmaj accurate xxmaj fine - grained xxmaj recognition via xxmaj region xxmaj grouping } \n",
              " \n",
              "  \\ xxunk xxmaj xxunk $ \\ quad \\ quad xxmaj yin xxmaj xxunk \\ \\ \n",
              "  $ ^1$department of xxmaj computer xxmaj sciences , $ ^2$department of xxmaj xxunk and xxmaj medical xxmaj informatics \\ \\ \n",
              "  xxmaj university of xxmaj xxunk -- xxmaj xxunk \\ \\ \n",
              "  { \\ tt \\ small \\ { xxunk , xxunk \\ } xxunk } \n",
              "  } % \n",
              " \n",
              "  \\ maketitle \n",
              "  \\ thispagestyle{empty } \n",
              " \n",
              "  xxrep 9 % xxup abstract \n",
              "  \\ begin{abstract } \n",
              "  \\ input{src / abstract.tex } \n",
              "  \\ end{abstract } \n",
              " \n",
              "  % xxmaj introduction \n",
              "  \\ input{src / intro.tex } \n",
              " \n",
              "  % xxmaj related xxmaj work \n",
              "  \\ input{src / related_work.tex } \n",
              " \n",
              "  % xxmaj method \n",
              "  \\ input{src / method.tex } \n",
              " \n",
              "  % xxmaj experiments and xxmaj results \n",
              "  \\ input{src / xxunk } \n",
              " \n",
              "  % xxmaj conclusion \n",
              "  \\ input{src / conclusion.tex } \n",
              " \n",
              " \n",
              "  \\ bibliographystyle{ieee_fullname } \n",
              "  \\ xxunk } \n",
              " \n",
              " \n",
              "  \\ end{document } \n",
              " ,xxbos \\ def \\ year{2020 } \\ relax \n",
              "  \\ documentclass[letterpaper]{article } \n",
              "  \\ usepackage{aaai20 } \n",
              "  \\ usepackage{times } \n",
              "  \\ usepackage{helvet } \n",
              "  \\ usepackage{courier } \n",
              "  % \\ usepackage[hyphens]{url } \n",
              "  % \\ usepackage{parskip } \n",
              " \n",
              "  \\ xxunk } \n",
              " \n",
              " \n",
              "  ewcommand { \\ xxunk \\ xxunk , xxup g)$ } \n",
              " \n",
              "  ewcommand { \n",
              "  xxunk \\ eta$ \\ xxunk } } \n",
              " \n",
              " \n",
              "  ewcommand { \\ xxunk ] { \\ todo [ # 1,color = xxunk \\ xxunk : # 2 } } \n",
              " \n",
              "  ewcommand { \\ xxunk ] { \\ todo [ # 1,color = xxunk \\ xxunk : # 2 } } \n",
              " \n",
              "  ewcommand { \\ xxunk ] { \\ todo [ # 1,color = xxunk \\ xxunk : # 2 } } \n",
              " \n",
              " \n",
              "  ewcommand { \\ idest } { { \\ it i.e. } } \n",
              " \n",
              "  ewcommand { \\ exemp } { { \\ it e.g. } } \n",
              " \n",
              "  ewcommand { \\ etc } { { \\ it etc . } } \n",
              " \n",
              "  ewcommand { \\ etal } { { \\ it et al . } } \n",
              " \n",
              "  \\ xxunk } \n",
              " \n",
              "  \\ usepackage{graphicx } \n",
              "  \\ frenchspacing \n",
              "  \\ setlength { \\ pdfpagewidth}{8.5 in } \n",
              "  \\ setlength { \\ pdfpageheight}{11 in } \n",
              " \n",
              "  \\ pdfinfo { \n",
              "  / xxmaj title ( xxmaj the xxmaj more the xxmaj xxunk ? xxmaj evaluating the xxmaj effect of xxmaj landmark xxmaj extraction xxmaj algorithms on xxmaj landmark - xxmaj based xxmaj goal xxmaj recognition ) \n",
              "  / xxmaj author ( xxmaj kin xxmaj max xxmaj xxunk xxmaj xxunk , xxmaj xxunk xxmaj fraga xxmaj pereira , and xxmaj felipe xxmaj meneguzzi ) \n",
              "  } \n",
              " \n",
              "  \\ setcounter{secnumdepth}{2 } \n",
              " \n",
              "  \\ setlength \\ titlebox{2.5 in } \n",
              " \n",
              "  \\ title{the xxmaj more the xxmaj xxunk ? ! xxmaj evaluating the xxmaj effect of xxmaj landmark xxmaj extraction xxmaj algorithms on xxmaj landmark - xxmaj based xxmaj goal xxmaj recognition } \n",
              " \n",
              "  \\ author { \n",
              "  xxmaj kin xxmaj max xxmaj xxunk xxmaj xxunk , xxmaj xxunk xxmaj fraga xxmaj pereira , and xxmaj felipe xxmaj meneguzzi \\ \\ \n",
              "  xxmaj xxunk xxmaj catholic xxmaj university of xxmaj rio xxmaj grande do xxmaj xxunk ( xxup xxunk ) , xxmaj brazil \\ \\ \n",
              "  % xxmaj graduate xxmaj program in xxmaj computer xxmaj science , xxmaj school of xxmaj technology \\ \\ \n",
              "  \\ xxunk } , \\ xxunk } \\ \\ \n",
              "  \\ xxunk } \n",
              "  } \n",
              " \n",
              "  \\ begin{document } \n",
              " \n",
              "  \\ maketitle \n",
              " \n",
              "  % xxrep 76 - \n",
              "  \\ begin{abstract } \n",
              " \t \n",
              "  xxmaj recent approaches to goal and plan recognition using classical planning domains have achieved state of the art results in terms of both recognition time and accuracy by using heuristics based on planning landmarks . \n",
              "  xxmaj to achieve such fast recognition time these approaches use efficient , but incomplete , algorithms to extract only a subset of landmarks for planning domains and problems , at the cost of some accuracy . \n",
              "  xxmaj in this paper , we investigate the impact and effect of using various landmark extraction algorithms capable of extracting a larger proportion of the landmarks for each given planning problem , up to exhaustive landmark extraction . \n",
              "  xxmaj we perform an extensive empirical evaluation of various landmark - based heuristics when using different percentages of the full set of landmarks . \n",
              "  xxmaj results show that having more landmarks does not necessarily mean achieving higher accuracy and lower spread , as the additional extracted landmarks may not necessarily increase be helpful towards the goal recognition task . \n",
              "  \\ end{abstract } \n",
              "  % xxrep 76 - \n",
              " \n",
              "  % xxrep 76 - \n",
              "  \\ section{introduction } \n",
              " \n",
              "  xxmaj anticipating and recognizing correctly the intended goal that an observed agent aims to achieve based on its interactions in an environment is an important task for several real - world applications~ \\ xxunk } , such as intent recognition for xxunk - xxunk \\ xxunk } , exploratory domain models~ \\ xxunk } , offline and online goal recognition in latent space~ \\ xxunk , xxunk } , and others . \n",
              "  xxmaj most approaches to goal and plan recognition rely on either plan xxunk \\ xxunk } or planning domain theory~ \\ xxunk } . \n",
              "  xxmaj recent work on goal recognition as planning has avoided running a full - fledged planner for recognizing goals , and recent approaches in the literature have successfully exploited the use of well - known automated planning techniques , such as planning graphs~ \\ xxunk } and xxunk \\ xxunk } . \n",
              "  xxmaj thus , as a result of exploiting planning techniques , such approaches have shown that it is possible to recognize goals and plans not only accurately , but also very quickly . \n",
              " \n",
              "  xxmaj in this paper , we investigate the effect of using various landmark extraction algorithms over the landmark - based heuristic to goal recognition proposed by xxmaj pereira , xxmaj oren , and xxmaj meneguzzi~ \\ shortcite{ramonnirmeneguzzi_aaai2017 } . \n",
              "  xxmaj for extracting landmarks , we use five landmark extraction algorithms~ \\ xxunk , xxunk , rhw , hm } from the planning literature . \n",
              "  xxmaj to do so , we use an exhaustive extraction algorithm ( i.e. , an extraction approach that exhaustively checks if all facts are landmark by using a relaxed planning graph ) , and use other extraction algorithms that extract only a subset of xxunk \\ xxunk , xxunk , rhw , hm } . \n",
              "  xxmaj thus , the main contribution of this paper is investigating the real impact of using more or fewer landmarks in the landmark - based goal recognition heuristics . \n",
              " \n",
              "  xxmaj we conduct extensive experiments to empirically evaluate the impact and effect of using a variety different landmark extraction algorithms over landmark - based recognition heuristics using well - known recognition datasets~ \\ xxunk } with missing and full observations , and noisy , missing , and full observations . \n",
              "  xxmaj results show that using more landmarks does not necessarily lead to improved precision and accuracy of the landmark - based heuristics , as the quality of the extracted landmarks is generally more important than the quantity . \n",
              " \n",
              "  xxmaj the remainder of this paper is organized as follows . \n",
              "  xxmaj section~ \\ ref{section : background } provides essential background on planning , goal recognition , and landmarks . \n",
              "  xxmaj we review the landmark - based heuristic approaches we use along with various landmark extraction algorithms in xxmaj section~ \\ ref{section : xxunk } . \n",
              "  xxmaj in xxmaj section~ \\ ref{section : xxunk } , we proceed to evaluate empirically the recognition heuristics we review . \n",
              "  xxmaj finally , in xxmaj section~ \\ ref{section : conclusions } , we conclude this paper by discussing the real impact of using more or fewer landmarks in the heuristics , and provide future directions of how such heuristics could be improved by taking advantage of more landmarks . \n",
              " \n",
              "  % xxrep 76 - \n",
              "  \\ section{background } \\ label{section : background } \n",
              " \n",
              "  % xxrep 72 # \n",
              "  \\ subsection{planning } \n",
              " \n",
              "  xxmaj planning is the problem of finding a sequence of actions ( \\ idest , a plan ) that achieves a goal from an initial state~ \\ xxunk } . \n",
              "  a \\ textit{state } is a finite set of facts that represent logical values according to some interpretation . \n",
              "  \\ xxunk } can be either positive , or negated ground predicates . \n",
              "  a predicate is denoted by an n - ary predicate symbol $ p$ applied to a sequence of zero or more terms ( $ \\ tau_1 $ , $ \\ xxunk $ , ... , $ \\ xxunk ) . \n",
              "  xxmaj an \\ xxunk } is represented by a triple $ a$ $ = $ $ \\ langle$ \\ xxunk ) , \\ xxunk ) , \\ xxunk \\ rangle$ where \\ xxunk ) represents the description or signature of $ a$ ; \\ xxunk ) describes the preconditions of $ a$ --- a set of facts or predicates that must exist in the current state for $ a$ to be executed ; $ \\ xxunk \\ xxunk \\ cup \\ xxunk represents the effects of $ a$ , with \\ xxunk an \\ xxunk - list } of positive facts or predicates , and \\ xxunk a \\ xxunk - list } of negative facts or predicates . \n",
              "  xxmaj when we instantiate an operator over its free variables , we call the resulting ground operator an \\ emph{action } . \n",
              "  a \\ textit{planning instance } is represented by a triple $ \\ xxmaj pi = \\ langle \\ xxmaj xi , \\ mathcal{i } , g \\ rangle$ , in which $ \\ xxmaj xi = \\ langle \\ xxmaj sigma , \\ mathcal{a } \\ rangle$ is a \\ textit{planning domain definition } ; $ \\ xxmaj sigma$ consists of a finite set of facts and $ \\ mathcal{a}$ a finite set of actions ; $ \\ mathcal{i}$ $ \\ subseteq$ $ \\ xxmaj sigma$ is the initial state ; and $ xxup g$ $ \\ subseteq$ $ \\ xxmaj sigma$ is the goal state . \n",
              "  a \\ xxunk } is a sequence of actions $ \\ pi = \\ langle a_1 , a_2 , ... , a_n \\ rangle$ that modifies the initial state $ \\ mathcal{i}$ into one in which the goal state $ xxup g$ holds by the successive execution of actions in a plan $ \\ pi$. xxmaj while actions have an associated cost , as in classical planning , in this paper we assume that this cost is 1 for all actions . a plan $ \\ pi$ is considered optimal if its cost , and thus length , is minimal . \n",
              " \n",
              "  % xxrep 72 # \n",
              "  \\ subsection{goal xxmaj recognition } \n",
              " \n",
              "  xxmaj goal recognition is the task of xxunk the intended goal of autonomous agents or humans by observing their interactions in a particular environment~ \\ cite[chapter xxunk } . \n",
              "  xxmaj such observed interactions are defined as available evidence that can be used to recognize goals . xxmaj we formally define the problem of goal recognition over planning domain theory by adopting the formalism proposed by xxmaj ram { \\ ' { \\ xxunk and xxmaj xxunk \\ xxunk } , as follows in xxmaj definition~ \\ ref{def : xxunk } . \n",
              " \n",
              "  \\ begin{definition } [ \\ textbf{goal xxmaj recognition xxmaj problem } ] \\ label{def : xxunk } \n",
              "  a goal recognition problem is a tuple $ xxup xxunk $ = $ $ \\ langle \\ xxmaj xi , \\ mathcal{i } , \\ mathcal{g } , o \\ rangle$ , in which $ \\ xxmaj xi = \\ langle \\ xxmaj sigma , \\ mathcal{a } \\ rangle$ is a planning domain definition ; $ \\ mathcal{i}$ is the initial state ; $ \\ mathcal{g}$ is the set of possible goals , which include the correct intended goal $ xxup xxunk ( \\ idest , $ xxup xxunk $ \\ in$ $ \\ mathcal{g}$ ) ; and $ xxup o$ $ = $ $ \\ xxunk $ , $ o_2 $ , ... , $ xxunk \\ rangle$ is an observation sequence of executed actions , with each observation $ o_i \\ in \\ mathcal{a}$. \n",
              "  \\ end{definition } \n",
              " \n",
              "  xxmaj the ideal solution for a goal recognition problem is finding the correct intended goal $ xxup g^ { * } \\ in \\ mathcal{g}$ that the observation sequence $ xxup o$ of a plan execution achieves . \n",
              "  xxmaj an observation sequence can be full or partial --- in a full observation sequence we observe all actions of an agent 's plan ; in a partial observation sequence , only a sub - sequence of actions are observed . a noisy observation sequence contains one or more actions ( or a set of facts ) that might not be part of a plan that achieves a particular goal , \\ exemp , when a sensor fails and generates abnormal or spurious readings . \n",
              " \n",
              "  % xxrep 72 # \n",
              "  \\ xxunk } \n",
              " \n",
              "  xxmaj in the planning literature , landmarks are defined as necessary fact ( or actions ) that must be true ( or executed ) at some point along all valid plans that achieve a particular goal from an initial state . xxmaj landmarks are often partially ordered based on the sequence in which they must be achieved . \n",
              "  xxmaj hoffman \\ etal~ \\ shortcite{hoffmann2004_orderedlandmarks } define fact landmarks as follows : \n",
              " \n",
              "  \\ begin{definition } [ \\ xxunk xxmaj landmark } ] \\ label{def : xxunk } \n",
              "  xxmaj given a planning instance $ \\ xxmaj pi = \\ langle \\ xxmaj xi , \\ mathcal{i } , g \\ rangle$ , a formula $ xxup l$ is a fact landmark in $ \\ xxmaj pi$ iff $ xxup l$ is true at some point along all valid plans that achieve $ xxup g$ from $ \\ mathcal{i}$. \n",
              "  a landmark is a type of formula ( \\ exemp , a conjunctive or disjunctive formula ) over a set of facts that must be satisfied at some point along all valid plan executions . \n",
              "  \\ end{definition } \n",
              " \n",
              "  xxmaj hoffman \\ etal~ \\ shortcite{hoffmann2004_orderedlandmarks } proves that the process of generating all landmarks and deciding their ordering is xxup pspace - complete , which is exactly the same complexity as deciding plan xxunk \\ xxunk } . \n",
              "  xxmaj thus , to operate efficiently , most landmark extraction algorithms extract only a subset of landmarks for a given planning instance . \n",
              " \n",
              "  % xxrep 72 # \n",
              "  \\ xxunk xxmaj extraction xxmaj algorithms } \n",
              " \n",
              "  % xxmaj we use various landmark extraction algorithms to investigate whether more or fewer landmarks impact in the recognition accuracy of landmark - based heuristics for goal recognition , and now , we present in detail the landmark extraction algorithms we use in this paper . \n",
              "  xxmaj in this paper , we use the following landmark extraction algorithms to investigate how the number of landmarks impacts on the recognition accuracy of landmark - based heuristics for goal recognition . \n",
              " \n",
              " \n",
              "  oindent \\ textit{exhaust } : xxmaj the first algorithm is an exhaustive extraction approach , its name says for itself , and we denote this algorithm as \\ textit{exhaust } . xxmaj this algorithm exhaustively extracts landmarks for a given planning instance . xxmaj namely , this algorithm uses a xxmaj relaxed xxmaj planning xxmaj graph ( xxup rpg ) and exhaustively checks every fact in the xxup rpg for if it is a landmark or not . xxmaj this is done by removing the fact from the xxup rpg and checking if the goal is still reachable without the given fact , and if not , such fact is considered as a landmark . xxmaj the number of landmarks extracted by this algorithm is used as a baseline in our experiments , as it can extract all landmarks for a planning instance . \n",
              " \n",
              " \n",
              "  oindent $ h^m$ : \\ xxunk \\ xxunk } developed a landmark extraction algorithm that performs a transformation of the original problem $ \\ xxmaj pi$ , originating a new problem $ \\ xxmaj xxunk , in which each fact is a set of facts of size $ m$ , originated from the original problem 's facts . xxmaj the actions are obtained by adding facts that are not required or caused by any action but might be true during plan development , to the action 's preconditions and effects . xxmaj the result is a problem without delete effects that yet has information on the delete effects of the original problem , hence allowing the extraction of landmarks that take delete effects into count . xxmaj this extraction algorithm is denoted as $ xxunk \n",
              " \n",
              " \n",
              "  oindent \\ textit{rhw } : xxmaj in~ \\ xxunk } , \\ xxunk \\ xxunk } develop a landmark extraction algorithm that starts the process by selecting an initial fact landmark , and from this initial landmark , it creates disjunctive sets from the preconditions of the actions that are first xxunk of the initial landmark . xxmaj each disjunctive set is then recorded as a landmark , and ordered before the initial landmark . xxmaj this extraction process is then repeated for all recorded landmarks . xxmaj we denote this algorithm as \\ textit{rhw } . \n",
              " \n",
              " \n",
              "  oindent \\ textit{zhu \\ & xxmaj givan } : xxmaj zhu and xxmaj xxunk \\ xxunk } developed a landmark extraction algorithm that works differently than the ones mentioned above . xxmaj this algorithm works by propagating labels across the planning graph , where each label is a fact or an action . a fact or action at a level $ i$ must be labeled with any fact or action that must occur in any $ xxunk plan that reaches it . xxmaj it starts by labeling each action in the first action level with itself . xxmaj every subsequent action level is then labeled with the union of the labels on its precondition fact nodes , while every subsequent fact node is labeled with the intersection of the labels on the action nodes that reach it . xxmaj at the last level , every label on a goal node is considered a landmark . xxmaj this algorithm is denoted as \\ textit{zhu \\ & xxmaj givan } . \n",
              " \n",
              " \n",
              " \n",
              "  oindent \\ textit{hoffmann et al . } : xxmaj the extraction algorithm originally used by \\ xxunk } is the landmark extraction algorithm of xxmaj hoffman \\ etal~ \\ shortcite{hoffmann2004_orderedlandmarks } . \n",
              "  xxmaj initially , this algorithm builds an xxup rpg ( ignoring all delete effects of all actions ) from the initial state to the goal state , and starts selecting all facts in goal state as candidate landmarks . \n",
              "  xxmaj afterward , it selects the preconditions for all actions that achieve each candidate landmark , checking if those are landmarks by removing them from the graph and checking the reachability of the goal . \n",
              "  xxmaj after , it records as landmarks all preconditions that passed this check and then repeats the process for every fact level on the graph back to the initial state . \n",
              "  xxmaj similar to the \\ textit{exhaust } method , this algorithm evaluates whether a candidate landmark is indeed a landmark by testing the solvability of the problem by removing all actions that achieve such candidate landmark , and if the problem is unsolvable , then this candidate landmark is indeed a landmark . \n",
              "  xxmaj we denote this algorithm as \\ textit{hoffmann et al . } \n",
              " \n",
              "  % xxrep 76 - \n",
              "  \\ xxunk - xxmaj based xxmaj goal xxmaj recognition } \\ label{section : xxunk } \n",
              " \n",
              "  xxmaj we now describe the goal recognition heuristics that rely on planning landmarks that we use to evaluate the effect of using different landmark extraction algorithms . xxmaj such heuristics have proved to be accurate and very quick for recognizing goals over a variety of domain models~ \\ xxunk } . \n",
              " \n",
              "  xxmaj the first landmark - based heuristic proposed by xxmaj pereira , xxmaj oren , and xxmaj meneguzzi~ \\ shortcite{ramonnirmeneguzzi_aaai2017 } is called \\ emph{goal completion heuristic } , and denoted as $ \\ xxunk \n",
              "  xxmaj basically , this heuristic computes a score for a goal $ xxup g$ by calculating the ratio between the number achieved landmarks for $ xxup g$ and the total number of extracted landmarks for $ xxup g$. \n",
              "  xxmaj this score represents the percentage of completion of goal based on the ratio of achieved landmarks and the total number of landmarks . \n",
              " \n",
              "  xxmaj as an extension of $ \\ xxunk , the second heuristic developed by xxmaj pereira , xxmaj oren , and xxmaj meneguzzi~ \\ shortcite{ramonnirmeneguzzi_aaai2017 } exploits the concept of \\ emph{landmark uniqueness xxunk \\ xxunk } , which is a value that represents how unique a landmark is among the set of landmarks for all possible goals . \n",
              "  xxmaj this heuristic is called \\ emph{landmark uniqueness heuristic } , and denoted as $ \\ xxunk \n",
              "  xxmaj thus , by using this uniqueness value , $ \\ xxunk estimates which possible goal is most likely the intended one by summing the uniqueness values of the landmarks achieved in the observations . \n",
              " \n",
              "  % % xxrep 72 # \n",
              "  % \\ subsection{goal xxmaj completion xxmaj heuristic } \n",
              "  % \n",
              "  % % xxrep 72 # \n",
              "  % \\ xxunk xxmaj heuristic } \n",
              " \n",
              "  % xxrep 76 - \n",
              "  \\ section{experiments and xxmaj evaluation } \\ label{section : xxunk } \n",
              " \n",
              "  xxmaj in this section , we present the experiments and evaluations we carried out from using various extraction algorithms over the landmark - based goal recognition heuristics . \n",
              " \n",
              "  % xxrep 72 # \n",
              "  \\ subsection{domains and xxmaj setup } \n",
              " \n",
              "  xxmaj for evaluating each one of the landmark extraction algorithms using both recognition heuristics , we executed several tests using datasets created by xxmaj pereira and xxmaj meneguzzi \\ xxunk } , containing several non - trivial recognition problems . \n",
              "  xxmaj these datasets contain goal recognition problems from 15 classical planning domains and include problems with noisy observations . \n",
              "  xxmaj the domains we used are : xxmaj blocks xxmaj world , xxmaj campus , xxmaj depots , xxmaj xxunk xxmaj worker xxmaj robots , xxmaj xxunk , xxmaj easy xxup xxunk xxmaj grid , xxmaj ferry , xxmaj intrusion xxmaj detection , xxmaj logistics , xxmaj xxunk , xxmaj rovers , xxmaj satellite , xxmaj sokoban and xxmaj zeno xxmaj travel . \n",
              "  xxmaj the xxmaj kitchen domain has been removed from our evaluation , as it is an adaptation of an xxup xxunk planning domain and it caused some issues when using some of the landmark extractors . \n",
              " \n",
              "  xxmaj each domain in these datasets includes recognition problems with partial and full observations . \n",
              "  xxmaj partial observations vary the level ( percentage ) of observability between 10 \\ % , 30 \\ % , 50 \\ % and 70 \\ % of actions observed for missing observations , and 100 \\ % for full observations . \n",
              "  xxmaj for problems with noisy observations , the level ( percentage ) of observability varies between 25 \\ % , 50 \\ % and 75 \\ % of observed actions for missing observations , and consequently 100 \\ % for full observations . \n",
              " \n",
              "  % xxmaj xxunk \n",
              " \n",
              "  % xxmaj with this experimentation setup , we aim to have a complete vision on how each of the heuristics behave when allied to each of the algorithms , with various recognition thresholds . \n",
              " \n",
              "  % xxrep 72 # \n",
              "  \\ subsection{evaluation xxmaj metrics } \n",
              " \n",
              "  xxmaj to evaluate the recognition heuristics , we use three metrics : recognition time ( xxmaj time ) , accuracy ( xxmaj acc \\ % ) and xxmaj spread in $ \\ mathcal{g}$ ( s in $ \\ mathcal{g}$ ) . \n",
              "  xxmaj the recognition time metric is simply the time in seconds that the algorithm took to return the set of recognized goals , including the time for extracting the landmarks . \n",
              "  xxmaj accuracy is a percentage that represents the average number of problems in which the correct goal was among the recognized goals list . \n",
              "  xxmaj finally , xxmaj spread in $ \\ mathcal{g}$ is the average number of returned goals , when multiple goal hypotheses were tied in the recognition algorithm . \n",
              "  xxmaj to have a concise precision metric of the approach , we combine accuracy and xxmaj spread in $ \\ mathcal{g}$ to obtain a third metric . \n",
              "  xxmaj this metric can be considered as a precision metric and is obtained by calculating the ratio between accuracy and xxmaj spread in $ \\ mathcal{g}$. \n",
              " \n",
              "  xxmaj since our goal is to find out if there is a relation between the number of extracted landmarks and the effectiveness of a landmark - based goal recognition technique , we also use a metric to evaluate the extraction capability of each landmark extraction algorithm . \n",
              "  xxmaj we do this by calculating the ratio between the number of landmarks extracted by each algorithm and the number of landmarks extracted by the \\ textit{exhaust } algorithm , since it can extract all landmarks in the planning instance . xxmaj the result is the percentage of extracted landmarks . \n",
              " \n",
              "  % xxrep 72 # \n",
              "  \\ subsection{results : xxmaj missing and xxmaj full xxmaj observations } \n",
              " \n",
              "  xxmaj we now present the results for datasets with missing and full observations . \n",
              "  xxmaj table \\ ref{tab : results } shows the results comparing the use of the five different extraction algorithms along with the landmark - based heuristics . \n",
              "  xxmaj we can see the average number of landmarks extracted , represented by $ \\ mathcal{l}$ , average recognition time in seconds , average accuracy ( xxmaj acc \\ % ) and average xxmaj spread in $ \\ mathcal{g}$ ( s in $ \\ mathcal{g}$ ) for each combination of extraction algorithm and threshold used for heuristics $ xxunk and $ xxunk \n",
              "  xxmaj columns represent different levels of observability . \n",
              " \n",
              "  \\ begin{table*}[ht ! ] \n",
              "  \\ centering \n",
              "  \\ xxunk } \\ selectfont \n",
              "  \\ setlength \\ tabcolsep{3pt } \n",
              "  \\ begin{tabular } { xxrep 5 r @ { \\ hspace*{8mm}}rrr@ { \\ hspace*{8mm}}rrr@ { \\ hspace*{8mm}}rrr@ { \\ xxunk } \n",
              "  \\ toprule \t \n",
              "  \\ hline \n",
              " \n",
              "  & \n",
              "  & \\ multicolumn{3}{c } { \\ bf 10 \\ % } \n",
              "  & \\ multicolumn{3}{c } { \\ bf 30 \\ % } \n",
              "  & \\ multicolumn{3}{c } { \\ bf 50 \\ % } \n",
              "  & \\ multicolumn{3}{c } { \\ bf 70 \\ % } \n",
              "  & \\ multicolumn{3}{c } { \\ bf 100 \\ % } \\ \\ \\ hline \n",
              " \n",
              "  \\ xxunk } \n",
              "  & $ | \\ xxunk \n",
              "  & \\ multicolumn{1}{r } { \\ bf xxmaj time } & \\ multicolumn{1}{r } { \\ bf xxmaj acc \\ % } & \\ multicolumn{1}{l } { \\ bf s in $ \\ mathcal{g}$ } \n",
              "  & \\ multicolumn{1}{r } { \\ bf xxmaj time } & \\ multicolumn{1}{r } { \\ bf xxmaj acc \\ % } & \\ multicolumn{1}{l } { \\ bf s in $ \\ mathcal{g}$ } \n",
              "  & \\ multicolumn{1}{r } { \\ bf xxmaj time } & \\ multicolumn{1}{r } { \\ bf xxmaj acc \\ % } & \\ multicolumn{1}{l } { \\ bf s in $ \\ mathcal{g}$ } \n",
              "  & \\ multicolumn{1}{r } { \\ bf xxmaj time } & \\ multicolumn{1}{r } { \\ bf xxmaj acc \\ % } & \\ multicolumn{1}{l } { \\ bf s in $ \\ mathcal{g}$ } \n",
              "  & \\ multicolumn{1}{r } { \\ bf xxmaj time } & \\ multicolumn{1}{r } { \\ bf xxmaj acc \\ % } & \\ multicolumn{1}{r } { \\ bf s in $ \\ mathcal{g}$ } \\ \\ \\ hline \n",
              "  $ \\ mathit{h_{gc}}$ ( xxmaj exhaust $ \\ theta = 0 $ ) \n",
              "  & 36.9 & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 84.2 \\ % & xxunk \n",
              "  & xxunk & 89.9 \\ % & xxunk \n",
              "  & xxunk & 96.4 \\ % & xxunk \n",
              "  & xxunk & 99.6 \\ % & 1.025 \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{gc}}$ ( xxmaj exhaust $ \\ theta = 10 $ ) \n",
              "  & 36.9 & xxunk & 88.7 \\ % & xxunk \n",
              "  & xxunk & 96.9 \\ % & xxunk \n",
              "  & xxunk & 98.9 \\ % & xxunk \n",
              "  & xxunk & 99.6 \\ % & xxunk \n",
              "  & xxunk & 100.0 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{gc}}$ ( $ h^m$ $ \\ theta = 0 $ ) \n",
              "  & 20.6 & xxunk & 66.7 \\ % & xxunk \n",
              "  & xxunk & 83.2 \\ % & xxunk \n",
              "  & xxunk & 89.7 \\ % & xxunk \n",
              "  & xxunk & 96.5 \\ % & 1.054 \n",
              "  & xxunk & 99.7 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{gc}}$ ( $ h^m$ $ \\ theta = 10 $ ) \n",
              "  & 20.6 & xxunk & 83.6 \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 97.1 \\ % & xxunk \n",
              "  & xxunk & 99.2 \\ % & xxunk \n",
              "  & xxunk & 100.0 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{gc}}$ ( xxup rhw $ \\ theta = 0 $ ) \n",
              "  & 23.5 & xxunk & 64.8 \\ % & xxunk \n",
              "  & xxunk & 81.6 \\ % & xxunk \n",
              "  & xxunk & 89.1 \\ % & xxunk \n",
              "  & xxunk & 96.3 \\ % & 1.062 \n",
              "  & xxunk & 99.5 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{gc}}$ ( xxup rhw $ \\ theta = 10 $ ) \n",
              "  & 23.5 & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 91.2 \\ % & xxunk \n",
              "  & xxunk & 96.3 \\ % & xxunk \n",
              "  & xxunk & 98.6 \\ % & xxunk \n",
              "  & xxunk & 100.0 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{gc}}$ ( xxmaj zhu \\ & xxmaj givan $ \\ theta = 0 $ ) \n",
              "  & 19.9 & xxunk & 66.4 \\ % & xxunk \n",
              "  & xxunk & 83.1 \\ % & xxunk \n",
              "  & xxunk & 89.7 \\ % & xxunk \n",
              "  & xxunk & 96.4 \\ % & xxunk \n",
              "  & xxunk & 99.7 \\ % & 1.054 \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{gc}}$ ( xxmaj zhu \\ & xxmaj givan $ \\ theta = 10 $ ) \n",
              "  & 19.9 & xxunk & 81.9 \\ % & xxunk \n",
              "  & xxunk & 92.6 \\ % & xxunk \n",
              "  & xxunk & 96.5 \\ % & xxunk \n",
              "  & xxunk & 98.6 \\ % & xxunk \n",
              "  & xxunk & 100.0 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{gc}}$ ( xxmaj hoffmann $ \\ theta = 0 $ ) \n",
              "  & 18.8 & xxunk & 61.3 \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 86.1 \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 99.5 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{gc}}$ ( xxmaj hoffmann $ \\ theta = 10 $ ) \n",
              "  & 18.8 & xxunk & 77.8 \\ % & xxunk \n",
              "  & xxunk & 87.4 \\ % & xxunk \n",
              "  & xxunk & 92.5 \\ % & xxunk \n",
              "  & xxunk & 96.5 \\ % & xxunk \n",
              "  & xxunk & 100.0 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  \\ hline \n",
              "  $ \\ mathit{h_{uniq}}$ ( xxmaj exhaust $ \\ theta = 0 $ ) \n",
              "  & 36.9 & xxunk & 56.7 \\ % & xxunk \n",
              "  & xxunk & 76.8 \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 93.4 \\ % & xxunk \n",
              "  & xxunk & 99.2 \\ % & 1.025 \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{uniq}}$ ( xxmaj exhaust $ \\ theta = 10 $ ) \n",
              "  & 36.9 & xxunk & 71.3 \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 97.2 \\ % & xxunk \n",
              "  & xxunk & 100.0 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{uniq}}$ ( $ h^m$ $ \\ theta = 0 $ ) \n",
              "  & 20.6 & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 94.2 \\ % & xxunk \n",
              "  & xxunk & 99.7 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{uniq}}$ ( $ h^m$ $ \\ theta = 10 $ ) \n",
              "  & 20.6 & xxunk & 69.7 \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 90.9 \\ % & xxunk \n",
              "  & xxunk & 97.1 \\ % & xxunk \n",
              "  & xxunk & 100.0 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{uniq}}$ ( xxup rhw $ \\ theta = 0 $ ) \n",
              "  & 23.5 & xxunk & 56.4 \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 85.1 \\ % & xxunk \n",
              "  & xxunk & 93.8 \\ % & xxunk \n",
              "  & xxunk & 99.5 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{uniq}}$ ( xxup rhw $ \\ theta = 10 $ ) \n",
              "  & 23.5 & xxunk & 69.3 \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 90.4 \\ % & xxunk \n",
              "  & xxunk & 96.7 \\ % & xxunk \n",
              "  & xxunk & 100.0 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{uniq}}$ ( xxmaj zhu \\ & xxmaj givan $ \\ theta = 0 $ ) \n",
              "  & 19.9 & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 75.7 \\ % & xxunk \n",
              "  & xxunk & 85.0 \\ % & xxunk \n",
              "  & xxunk & 93.9 \\ % & xxunk \n",
              "  & xxunk & 99.7 \\ % & 1.054 \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{uniq}}$ ( xxmaj zhu \\ & xxmaj givan $ \\ theta = 10 $ ) \n",
              "  & 19.9 & xxunk & 69.3 \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 90.7 \\ % & xxunk \n",
              "  & xxunk & 96.8 \\ % & xxunk \n",
              "  & xxunk & 100.0 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{uniq}}$ ( xxmaj hoffmann $ \\ theta = 0 $ ) \n",
              "  & 18.8 & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 70.8 \\ % & xxunk \n",
              "  & xxunk & 80.2 \\ % & xxunk \n",
              "  & xxunk & 90.8 \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{uniq}}$ ( xxmaj hoffmann $ \\ theta = 10 $ ) \n",
              "  & 18.8 & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 79.9 \\ % & xxunk \n",
              "  & xxunk & 86.9 \\ % & xxunk \n",
              "  & xxunk & 93.9 \\ % & xxunk \n",
              "  & xxunk & 99.2 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  \\ hline \n",
              "  \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  \\ caption{experiments and evaluations with missing and full observations . } \n",
              "  \\ label{tab : results } \t \n",
              "  \\ end{table * } \n",
              " \n",
              "  xxmaj we can see that even with 100 \\ % of actions being observed , the heuristic recognition algorithms do not yield 100 \\ % accuracy . \n",
              "  xxmaj there are some cases , for instance , in xxmaj xxunk and xxmaj logistics for $ \\ mathit{h_{gc}}$ , in which the real goal had more total landmarks than a wrong candidate goal , but only a few extra achieved landmarks than the wrong one . \n",
              "  xxmaj as a result , the heuristic chooses the wrong goal instead the correct one , especially with lower threshold values . \n",
              " \n",
              "  xxmaj we can also see that the extraction $ h^m$ algorithm has the highest recognition time in comparison to all algorithms . \n",
              "  \\ textit{hoffmann et al . } has the second highest recognition time , while other algorithms come in third with similar recognition time . \n",
              " \n",
              "  xxmaj figure~ \\ ref{fig : percentage } shows the average percentage of extracted landmarks by each extraction algorithm we used in our experiments for xxmaj table~ \\ ref{tab : results } . \n",
              "  xxmaj note that , after \\ textit{exhaust } , \\ textit{rhw } was the extraction algorithm that managed to extract the highest number of landmarks , on average , followed by $ h^m$ , \\ textit{zhu \\ & xxmaj givan } , and finally \\ xxunk et al . } . \n",
              " \n",
              "  \\ begin{figure}[h ! ] \n",
              "  \\ centering \n",
              "  \\ includegraphics[width=0.45 \\ xxunk } \n",
              "  \\ caption{percentage of extracted landmarks by algorithm with missing and full observations . } \n",
              "  \\ label{fig : percentage } \n",
              "  \\ end{figure } \n",
              " \n",
              "  xxmaj figures \\ ref{fig : accuracy_gc } and \\ ref{fig : accuracy_uniq } show the average xxmaj accuracy / xxmaj spread in $ \\ mathcal{g}$ ratio with a threshold $ \\ theta$ value of 10 for each combination of heuristic , extraction algorithm , and the level of observability . \n",
              "  xxmaj although \\ textit{exhaust } and \\ textit{rhw } managed to extract the highest number of landmarks , $ h^m$ was the algorithm that led both heuristics to the highest xxmaj accuracy / xxmaj spread in $ \\ mathcal{g}$ ratio , leaving even \\ textit{exhaust } behind . \n",
              " \n",
              "  \\ begin{figure}[h ! ] \n",
              "  \\ centering \n",
              "  \\ includegraphics[width=0.45 \\ xxunk } \n",
              "  \\ caption{accuracy / xxmaj spread in $ \\ mathcal{g}$ ratio for $ \\ mathit{h_{gc}}$ with missing and full observations . } \n",
              "  \\ label{fig : accuracy_gc } \n",
              "  \\ end{figure } \n",
              " \n",
              "  \\ begin{figure}[h ! ] \n",
              "  \\ centering \n",
              "  \\ includegraphics[width=0.45 \\ xxunk } \n",
              "  \\ caption{accuracy / xxmaj spread in $ \\ mathcal{g}$ ratio for $ \\ mathit{h_{uniq}}$ with missing and full observations . } \n",
              "  \\ label{fig : accuracy_uniq } \n",
              "  \\ end{figure } \n",
              " \n",
              "  xxmaj based on the results of xxmaj figures~ \\ ref{fig : accuracy_gc } and~ \\ ref{fig : accuracy_uniq } , we can see that that the amount of extracted landmarks is not the only factor that affects the effectiveness for recognition using landmarks . \n",
              "  xxmaj we note that the quality of the extracted landmarks and how well they inform the heuristics cause real impact in the recognition process . \n",
              "  xxmaj we believe this is the reason $ \\ mathit{h_{uniq}}$ yields a higher xxmaj accuracy / xxmaj spread ratio in the datasets with missing and full observations when compared to $ \\ xxunk \n",
              "  xxmaj the $ \\ mathit{h_{uniq}}$ heuristic considers the degree of information provided by a landmark ( \\ idest , \\ emph{landmark uniqueness values } ) , instead of just estimating using the amount of landmarks , as $ \\ mathit{h_{gc}}$ does . \n",
              "  xxmaj the $ \\ mathit{h_{uniq}}$ heuristic can filter relatively uninformative landmarks , assigning a greater \\ emph{landmark uniqueness value } for those that are found in fewer goals , hence better informing the heuristic . \n",
              " \n",
              "  xxmaj figures~ \\ ref{fig : xxunk } and \\ ref{fig : xxunk } , show how the recognition time varies with the growth of observation length for $ \\ mathit{h_{gc}}$ and $ \\ mathit{h_{uniq}}$ , respectively . \n",
              "  xxmaj we can see that all algorithms provide a close to constant recognition time , except for $ h^m$ , in which we see the recognition time grows as the observation grows in length . xxmaj note that some curves are overlaid by others , causing them to not appear . \n",
              " \n",
              "  xxmaj note that the sequence of observations does not have a direct impact on the landmark extraction algorithms since they are not provided to the algorithms . \n",
              "  xxmaj however , longer observations generally translate to more complex problems , resulting in the increasing recognition time . \n",
              " \n",
              "  \\ begin{figure}[h ! ] \n",
              "  \\ centering \n",
              "  \\ includegraphics[width=0.45 \\ xxunk } \n",
              "  \\ caption{recognition time for $ \\ mathit{h_{gc}}$ with missing and full observations . } \n",
              "  \\ label{fig : xxunk } \n",
              "  \\ end{figure } \n",
              " \n",
              "  \\ begin{figure}[h ! ] \n",
              "  \\ centering \n",
              "  \\ includegraphics[width=0.45 \\ xxunk } \n",
              "  \\ caption{recognition time for $ \\ mathit{h_{uniq}}$ with missing and full observations . } \n",
              "  \\ label{fig : xxunk } \n",
              "  \\ end{figure } \n",
              " \n",
              "  % xxmaj although $ h^m$ shows the best performance in accuracy and % spread , it has the longest running time from all % algorithms . xxmaj the second longest running time we see is in % xxmaj xxunk et al . solution . xxmaj all other algorithms have % similar execution times , being faster than both xxmaj hoffmann et % al . and $ xxunk \n",
              " \n",
              "  % xxrep 72 # \n",
              "  \\ subsection{results : xxmaj noisy , xxmaj missing , and xxmaj full xxmaj observations } \n",
              " \n",
              "  xxmaj in this section , we present and analyze the results obtained by experimenting the different recognition approaches in problems under noisy observations . xxmaj we refer to noisy observations as a set of observed actions in which some of the actions are spurious actions . xxmaj as mentioned before , for the datasets with noisy observations , we have 4 levels of observability , as follows : 25 \\ % , 50 \\ % , 75 \\ % , and 100 \\ % . \n",
              " \n",
              "  xxmaj we can see the results for both recognition heuristics in xxmaj table~ \\ ref{tab : results_noisy } . \n",
              "  xxmaj this table has the same format as the one presented in the previous section , for missing and full observations , the only difference is the number of columns , as now we have four observability levels instead of five . \n",
              " \n",
              "  \\ begin{table*}[ht ! ] \n",
              "  \\ centering \n",
              "  \\ xxunk } \\ selectfont \n",
              "  \\ setlength \\ tabcolsep{3pt } \n",
              "  \\ begin{tabular } { xxrep 5 r @ { \\ hspace*{8mm}}rrr@ { \\ hspace*{8mm}}rrr@ { \\ hspace*{8mm}}rrr@ { \\ xxunk } \n",
              "  \\ toprule \t \n",
              "  \\ hline \n",
              " \n",
              "  & \n",
              "  & \\ multicolumn{3}{c } { \\ bf 25 \\ % } \n",
              "  & \\ multicolumn{3}{c } { \\ bf 50 \\ % } \n",
              "  & \\ multicolumn{3}{c } { \\ bf 75 \\ % } \n",
              "  & \\ multicolumn{3}{c } { \\ bf 100 \\ % } \\ \\ \\ hline \n",
              " \n",
              "  \\ xxunk } \n",
              "  & $ | \\ xxunk \n",
              "  & \\ multicolumn{1}{r } { \\ bf xxmaj time } & \\ multicolumn{1}{r } { \\ bf xxmaj acc \\ % } & \\ multicolumn{1}{l } { \\ bf s in $ \\ mathcal{g}$ } \n",
              "  & \\ multicolumn{1}{r } { \\ bf xxmaj time } & \\ multicolumn{1}{r } { \\ bf xxmaj acc \\ % } & \\ multicolumn{1}{l } { \\ bf s in $ \\ mathcal{g}$ } \n",
              "  & \\ multicolumn{1}{r } { \\ bf xxmaj time } & \\ multicolumn{1}{r } { \\ bf xxmaj acc \\ % } & \\ multicolumn{1}{l } { \\ bf s in $ \\ mathcal{g}$ } \n",
              "  & \\ multicolumn{1}{r } { \\ bf xxmaj time } & \\ multicolumn{1}{r } { \\ bf xxmaj acc \\ % } & \\ multicolumn{1}{l } { \\ bf s in $ \\ mathcal{g}$ } \\ \\ \\ hline \n",
              "  $ \\ mathit{h_{gc}}$ ( xxmaj exhaust $ \\ theta = 0 $ ) \n",
              "  & 29.8 & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 87.3 \\ % & xxunk \n",
              "  & xxunk & 95.7 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{gc}}$ ( xxmaj exhaust $ \\ theta = 10 $ ) \n",
              "  & 29.8 & xxunk & 72.2 \\ % & xxunk \n",
              "  & xxunk & 90.7 \\ % & xxunk \n",
              "  & xxunk & 96.8 \\ % & xxunk \n",
              "  & xxunk & 99.7 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{gc}}$ ( $ h^m$ $ \\ theta = 0 $ ) \n",
              "  & 17.5 & xxunk & 49.5 \\ % & xxunk \n",
              "  & xxunk & 73.4 \\ % & xxunk \n",
              "  & xxunk & 86.9 \\ % & xxunk \n",
              "  & xxunk & 95.7 \\ % & 1.125 \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{gc}}$ ( $ h^m$ $ \\ theta = 10 $ ) \n",
              "  & 17.5 & xxunk & 65.7 \\ % & xxunk \n",
              "  & xxunk & 85.6 \\ % & xxunk \n",
              "  & xxunk & 95.3 \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{gc}}$ ( xxup rhw $ \\ theta = 0 $ ) \n",
              "  & 19.7 & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 86.8 \\ % & xxunk \n",
              "  & xxunk & 95.1 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{gc}}$ ( xxup rhw $ \\ theta = 10 $ ) \n",
              "  & 19.7 & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{gc}}$ ( xxmaj zhu \\ & xxmaj givan $ \\ theta = 0 $ ) \n",
              "  & 16.8 & xxunk & 48.3 \\ % & xxunk \n",
              "  & xxunk & 73.4 \\ % & xxunk \n",
              "  & xxunk & 86.9 \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{gc}}$ ( xxmaj zhu \\ & xxmaj givan $ \\ theta = 10 $ ) \n",
              "  & 16.8 & xxunk & 65.7 \\ % & xxunk \n",
              "  & xxunk & 84.8 \\ % & xxunk \n",
              "  & xxunk & 94.3 \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{gc}}$ ( xxmaj hoffmann $ \\ theta = 0 $ ) \n",
              "  & 16.3 & xxunk & 44.9 \\ % & xxunk \n",
              "  & xxunk & 68.8 \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{gc}}$ ( xxmaj hoffmann $ \\ theta = 10 $ ) \n",
              "  & 16.3 & xxunk & 61.2 \\ % & xxunk \n",
              "  & xxunk & 81.2 \\ % & xxunk \n",
              "  & xxunk & 90.1 \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  \\ \\ \n",
              "  \\ hline \n",
              "  $ \\ mathit{h_{uniq}}$ ( xxmaj exhaust $ \\ theta = 0 $ ) \n",
              "  & 29.8 & xxunk & 38.5 \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 82.1 \\ % & xxunk \n",
              "  & xxunk & 93.8 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{uniq}}$ ( xxmaj exhaust $ \\ theta = 10 $ ) \n",
              "  & 29.8 & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 75.6 \\ % & xxunk \n",
              "  & xxunk & 88.7 \\ % & xxunk \n",
              "  & xxunk & 96.7 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{uniq}}$ ( $ h^m$ $ \\ theta = 0 $ ) \n",
              "  & 17.5 & xxunk & 39.1 \\ % & xxunk \n",
              "  & xxunk & 62.7 \\ % & 1.062 \n",
              "  & xxunk & 82.3 \\ % & 1.054 \n",
              "  & xxunk & 94.2 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{uniq}}$ ( $ h^m$ $ \\ theta = 10 $ ) \n",
              "  & 17.5 & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 74.1 \\ % & xxunk \n",
              "  & xxunk & 88.7 \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{uniq}}$ ( xxup rhw $ \\ theta = 0 $ ) \n",
              "  & 19.7 & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 62.8 \\ % & xxunk \n",
              "  & xxunk & 81.3 \\ % & xxunk \n",
              "  & xxunk & 94.2 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{uniq}}$ ( xxup rhw $ \\ theta = 10 $ ) \n",
              "  & 19.7 & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 75.1 \\ % & xxunk \n",
              "  & xxunk & 87.5 \\ % & xxunk \n",
              "  & xxunk & 96.5 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{uniq}}$ ( xxmaj zhu \\ & xxmaj givan $ \\ theta = 0 $ ) \n",
              "  & 16.8 & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 62.7 \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & 1.062 \n",
              "  & xxunk & 94.2 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{uniq}}$ ( xxmaj zhu \\ & xxmaj givan $ \\ theta = 10 $ ) \n",
              "  & 16.8 & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 96.7 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{uniq}}$ ( xxmaj hoffmann $ \\ theta = 0 $ ) \n",
              "  & 16.3 & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 59.7 \\ % & xxunk \n",
              "  & xxunk & 77.0 \\ % & xxunk \n",
              "  & xxunk & 88.3 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{uniq}}$ ( xxmaj hoffmann $ \\ theta = 10 $ ) \n",
              "  & 16.3 & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 70.7 \\ % & xxunk \n",
              "  & xxunk & 83.2 \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  \\ \\ \n",
              "  \\ hline \n",
              "  \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  \\ caption{experiments and evaluations with missing , noisy and full observations . } \n",
              "  \\ label{tab : results_noisy } \t \n",
              "  \\ end{table * } \n",
              " \n",
              "  xxmaj we notice a drop in the accuracy metric by comparing the results in xxmaj tables~ \\ ref{tab : results } and \\ ref{tab : results_noisy } and argue that it is an expected behavior , as the noise within the observations tends to mislead the recognition heuristics into recognizing the wrong goals as correct . \n",
              "  xxmaj also , as expected , the recognition time is unaffected with relation to noiseless observations , with $ h^m$ having the longest recognition times , followed by \\ textit{hoffmann et al . } and the other algorithms . \n",
              "  xxmaj we can see that in noisy experiments , there is less difference between \\ textit{hoffmann et al . } and $ h^m$ recognition times . \n",
              " \n",
              "  xxmaj figure~ \\ ref{fig : xxunk } shows the average percentage of landmarks extracted by each algorithm for the datasets with noisy observations . \n",
              "  xxmaj this metric has to be xxunk for noisy observations , as the goal recognition problems with noisy observations \\ emph{are different } from the ones without noise . \n",
              "  xxmaj we can see all algorithms , except for \\ textit{exhaust } , managed to achieve a higher percentage of achieved landmarks in comparison to noiseless experiments , as the number of landmarks extracted by \\ textit{exhaust } dropped . \n",
              "  xxmaj yet , the algorithm ranking for the percentage of landmarks extracted remains similar to the noiseless experiments . \n",
              " \n",
              "  \\ begin{figure}[h ! ] \n",
              "  \\ centering \n",
              "  \\ includegraphics[width=0.45 \\ xxunk } \n",
              "  \\ caption{percentage of extracted landmarks by algorithm with missing , noisy and full observations . } \n",
              "  \\ label{fig : xxunk } \n",
              "  \\ end{figure } \n",
              " \n",
              "  xxmaj figures~ \\ ref{fig : xxunk } and \\ ref{fig : xxunk } show the xxmaj accuracy / xxmaj spread in $ \\ xxunk ratio for each algorithm and observability degree for a threshold value of 10 , for $ \\ mathit{h_{gc}}$ and $ \\ mathit{h_{uniq}}$ respectively . \n",
              " \n",
              "  \\ begin{figure}[h ! ] \n",
              "  \\ centering \n",
              "  \\ includegraphics[width=0.45 \\ xxunk } \n",
              "  \\ caption{accuracy / xxmaj spread in $ \\ mathcal{g}$ ratio for $ \\ mathit{h_{gc}}$ with missing , noisy and full observations . } \n",
              "  \\ label{fig : xxunk } \n",
              "  \\ end{figure } \n",
              " \n",
              "  \\ begin{figure}[h ! ] \n",
              "  \\ centering \n",
              "  \\ includegraphics[width=0.45 \\ xxunk } \n",
              "  \\ caption{accuracy / xxmaj spread in $ \\ mathcal{g}$ ratio for $ \\ mathit{h_{uniq}}$ with missing , noisy and full observations . } \n",
              "  \\ label{fig : xxunk } \n",
              "  \\ end{figure } \n",
              " \n",
              "  xxmaj as for the results using the $ \\ mathit{h_{gc}}$ heuristic , we can see a different scenario when comparing to noiseless experiments . \n",
              "  xxmaj with noisy observations , the extraction algorithm that had the best overall performance in xxmaj accuracy / xxmaj spread in $ \\ mathcal{g}$ was \\ textit{rhw } , which also extracted the most landmarks after \\ textit{exhaust } . \n",
              "  \\ textit{rhw } dominated the score for 25 \\ % and 50 \\ % observability levels , only being beaten by $ h^m$ in 75 \\ % and \\ textit{zhu \\ & xxmaj givan } in 100 \\ % . \n",
              " \n",
              "  xxmaj with respect to the results of the $ \\ mathit{h_{uniq}}$ heuristic results , we see the same behavior in noiseless experiments . \n",
              "  xxmaj algorithms that extract a larger number of landmarks yielded better results in comparison to $ \\ mathit{h_{gc}}$ , as we can see from \\ textit{exhaust } results in 25 \\ % and 50 \\ % observability levels , only being beaten by $ h^m$ in 75 \\ % and 100 \\ % . \n",
              " \n",
              "  xxmaj from these results , we can see how the presence of noise in observations really affects the recognition with different landmark extraction algorithms . \n",
              "  xxmaj when we work with noisy observations , the number of landmarks extracted seems have a stronger impact . \n",
              "  xxmaj this can be explained by the fact that having irrelevant actions within the observations makes so that having more landmarks may help the heuristic while comparing them against the relevant observations , as noisy actions are unlikely to coincide within the landmarks for the correct goal . \n",
              "  % xxmaj the recognition time is similar to noiseless experiments though . \n",
              " \n",
              "  xxmaj finally , in xxmaj figures~ \\ ref{fig : xxunk } and~ \\ ref{fig : xxunk } , we can see the recognition time variation as observation length grows for $ \\ mathit{h_{gc}}$ and $ \\ mathit{h_{uniq}}$ , respectively . \n",
              "  a similar time marks can be seen without noisy observations , with $ h^m$ 's running time growing with observation length , while the other algorithms remain almost constant , with minor differences . xxmaj we also see the same curve overlay effect that causes some curves to not appear . \n",
              " \n",
              "  \\ begin{figure}[h ] \n",
              "  \\ centering \n",
              "  \\ includegraphics[width=0.45 \\ xxunk } \n",
              "  \\ caption{recognition time for $ \\ mathit{h_{gc}}$ with missing , noisy and full observations . } \n",
              "  \\ label{fig : xxunk } \n",
              "  \\ end{figure } \n",
              " \n",
              "  \\ begin{figure}[h ] \n",
              "  \\ centering \n",
              "  \\ includegraphics[width=0.45 \\ xxunk } \n",
              "  \\ caption{recognition time for $ \\ mathit{h_{uniq}}$ with missing , noisy and full observations . } \n",
              "  \\ label{fig : xxunk } \n",
              "  \\ end{figure } \n",
              " \n",
              "  % xxrep 76 - \n",
              "  \\ section{conclusions } \\ label{section : conclusions } \n",
              " \n",
              "  xxmaj we have presented an extensive empirical evaluation of how different landmark extraction algorithms affect the performance of landmark - based goal recognition approaches . \n",
              "  xxmaj after analyzing the results in the experiments , we conclude that the number of extracted landmarks does not tell us all about the quality or utility of a landmark when using it in landmark - based goal recognition . \n",
              "  xxmaj we can see from the results that having more landmarks is not necessarily more important than having informative landmarks . \n",
              " \n",
              "  xxmaj as future work , we intend to perform a more qualitative analysis of the landmark extraction algorithms , analyzing not only the amount of extracted landmarks , but also the information level of the landmarks themselves . \n",
              "  xxmaj this ought to provide even more answers on what kind of extraction algorithm is best suited for landmark - based goal recognition , and consequently enabling us to fine - tune solutions to maximize the effectiveness of the goal recognition process . \n",
              "  xxmaj finally , we aim to conduct a similar extensive empirical evaluation by using some of the landmark extraction algorithms over the landmark - based approaches under incomplete domain information~ \\ xxunk } . \n",
              " \n",
              "  % xxrep 76 - \n",
              "  \\ bibliographystyle{aaai } \n",
              "  \\ xxunk } \n",
              " \n",
              "  \\ end{document } \n",
              " \n",
              "y: CategoryList\n",
              "not_peer_reviewed,not_peer_reviewed,not_peer_reviewed,not_peer_reviewed,not_peer_reviewed\n",
              "Path: /content/gdrive/My Drive/fastai-v3/SCIgan/clean;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(38368, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(38368, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f979dfc2d08>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/content/gdrive/My Drive/fastai-v3/SCIgan/clean'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (316 items)\n",
              "x: TextList\n",
              "xxbos \\ documentclass[10pt , twocolumn , letterpaper]{article } \n",
              " \n",
              "  \\ usepackage{cvpr } \n",
              "  \\ usepackage{times } \n",
              "  \\ usepackage{epsfig } \n",
              "  \\ usepackage{graphicx } \n",
              "  \\ usepackage{amsmath } \n",
              "  \\ usepackage{amssymb } \n",
              "  \\ usepackage{multirow } \n",
              "  \\ usepackage{float } \n",
              "  % \\ usepackage{subfigure } \n",
              "  \\ usepackage{color } \n",
              "  \\ usepackage{array } \n",
              "  \\ usepackage{mathrsfs } \n",
              "  \\ usepackage{tabularx } \n",
              "  \\ usepackage{bm } \n",
              "  % \\ xxunk } \n",
              " \n",
              "  \\ xxunk = true , bookmarks = false]{hyperref } \n",
              " \n",
              "  \\ cvprfinalcopy % * * * xxmaj uncomment this line for the final submission \n",
              " \n",
              " \n",
              "  \\ def \\ httilde { \\ mbox { \\ tt \\ raisebox{-.5ex } { \\ symbol{126 xxrep 4 } \n",
              " \n",
              "  \\ setcounter{page}{1 } \n",
              "  \\ begin{document } \n",
              " \t \n",
              " \t % \t  \\ title { xxmaj deep xxmaj sequential xxmaj visual xxmaj understanding through xxmaj semi - xxmaj coupled xxmaj structure } \n",
              " \t  \\ xxunk xxmaj sequential xxmaj understanding through the xxmaj awareness of xxmaj spatial and xxmaj temporal xxmaj concepts } \n",
              " \t  \\ xxunk xxmaj xxunk , xxmaj xxunk xxmaj zha , xxmaj xxunk xxmaj cao , xxmaj xxunk xxmaj tang , xxmaj xxunk xxmaj yu , xxmaj xxunk xxmaj lu * \\ \\ \n",
              " \t\t xxmaj shanghai xxmaj jiao xxmaj tong xxmaj university \\ \\ \n",
              " \t\t { \\ tt \\ small \\ { xxunk , xxmaj kevin \\ _ zha , xxunk \\ _ xxunk , xxunk , xxunk , xxunk \\ } xxunk } } \n",
              " \t \n",
              " \t \n",
              " \t  \\ maketitle \n",
              " \t  \\ renewcommand { \\ thefootnote } { \\ fnsymbol{footnote } } \n",
              " \t \n",
              " \t  \\ begin{abstract } \n",
              " \t\t xxmaj understanding sequential information is a fundamental \n",
              " \t\t task for artificial intelligence . xxmaj current neural \n",
              " \t\t networks attempt to learn spatial and temporal information as a whole , limited their abilities to represent large scale spatial representations over long - range sequences . xxmaj here , we introduce a new modeling strategy called xxmaj semi - xxmaj coupled xxmaj structure ( xxup scs ) , which \t consists of deep neural networks that decouple the complex \n",
              " \t\t spatial and temporal concepts learning . xxmaj semi - xxmaj coupled xxmaj structure can learn to implicitly separate input information into independent parts and process \n",
              " \t\t these parts respectively . xxmaj experiments demonstrate that a xxmaj semi - xxmaj coupled xxmaj structure can successfully annotate the outline of an object in images sequentially and perform video action recognition . xxmaj for sequence - to - sequence problems , a xxmaj semi - xxmaj coupled xxmaj structure can predict future meteorological radar echo images based on observed images . xxmaj taken together , our results demonstrate that a xxmaj semi - xxmaj coupled xxmaj structure has the capacity to improve the performance of xxup lstm - like models on large scale sequential tasks . \n",
              " \t  \\ end{abstract } \n",
              " \t \n",
              " \t xxmaj complex sequential tasks involve extremely high - dimensional spatial signal over long timescales . xxmaj neural networks have made breakthroughs in sequential learning~ \\ xxunk , xxunk } , visual understanding~ \\ cite{krizhevsky2012imagenet , xxunk , xxunk } , and robotic tasks~ \\ cite{levine2016end , schulman2015trust } . \n",
              " \t xxmaj conventional neural networks treat spatial and temporal information as a whole , processing these parts together . xxmaj this limits their ability to solve complex sequential tasks involving high - dimensional spatial and temporal components~ \\ cite{feichtenhofer2018slowfast , xxunk } . a natural idea to address this limitation is to learn the two different concepts relatively independently . \n",
              " \t \n",
              " \t xxmaj here , we introduce a structure that decouples spatial and temporal information , implicitly learning respective spatial and temporal concepts through a deep comprehensive model . xxmaj we find that such concept decomposition significantly simplifies the learning and understanding process of complex sequences . \n",
              " \t xxmaj due to the differentiable property of this structure , which we call xxmaj semi xxmaj coupled xxmaj structure ( xxup scs ) , we can train it end to end with gradient descent , allowing it to effectively learn to decouple and integrate information in a goal - directed manner . \n",
              " \t \n",
              " \t  \\ begin{figure * } \n",
              " \t\t  \\ begin{center } \n",
              " \t\t\t  \\ includegraphics[width= \\ xxunk } \n",
              " \t\t  \\ end{center } \n",
              " \t\t  \\ caption { \\ textbf{the whole pipeline of our xxmaj semi - xxmaj coupled xxmaj structure } . \\ textbf{a } , xxmaj with input $ \\ mathbf{x}$ , $ \\ mathcal{g}$ decouples the spatial - temporal information by $ h_t$ which focuses on temporal features , $ h_s$ that mainly extracts spatial features , and $ \\ mathcal{f}$ integrates them to form the complete temporal - spatial semi - coupled system . \\ textbf{b } , xxmaj to keep the semi - coupled xxunk in a deep structure , we design the xxmaj spatial - xxmaj temporal xxmaj switch xxmaj gradient xxmaj descent ( xxup stsgd ) method ( see xxmaj sec.~ \\ ref{sec : xxup stsgd } ) that stops the gradient back propagating through the dashed lines in a certain probability $ p$ to decouple the training processes of $ h_s$ and $ h_t$. $ \\ mathcal{t}^1 $ and $ \\ mathcal{t}^2 $ are utilized to make $ h_s ( { \\ xxunk and $ h_t ( \\ cdot)$ further focus on their own roles and monitor the training schedule of $ h_s$ to adjust $ q$ in xxmaj advanced xxup stsgd ( xxup astsgd ) . \\ textbf{c } , xxmaj except the main training loss ( $ xxmaj xxunk ) of xxmaj semi - xxmaj coupled xxmaj structure based on main goal $ g$ , there are another two losses $ xxmaj xxunk , $ xxmaj xxunk based on sub - goals $ r_s$ , $ r_t$ for $ \\ mathcal{t}^1 $ , and $ \\ mathcal{t}^2 $ to guide $ h_s$ and $ h_t$ to focus on spatial and temporal features respectively . } \n",
              " \t\t  \\ label{fig : pipeline } \n",
              " \t  \\ end{figure * } \n",
              " \t \n",
              " \t  \\ xxunk of xxmaj spatial and xxmaj temporal xxmaj concept } \\ label{sec : aware } \n",
              " \t xxmaj in the brain , there are two different pathways that feed temporal information and contextual representations respectively into the xxunk \\ xxunk } . xxmaj this implies that spatial and temporal concepts are learnt by different cognitive mechanisms and , moreover , that they should be synchronized in order to effectively process sequential information . xxmaj taking inspiration from this mechanism in the brain , the deep neural model that is implicitly aware of the two concepts can be formulated as : \n",
              " \t  \\ begin{align } \n",
              " \t  \\ xxunk ( \\ xxunk \\ psi_s ) , h_t ( \\ xxunk \\ psi_t ) ] \\ label{eq : split } \n",
              " \t  \\ end{align } \n",
              " \t where $ \\ mathbf{x}$ is the input , and $ \\ xxunk and $ \\ xxunk are the parameters to optimize . $ h_s$ aims at extracting spatial information , while $ h_t$ is designed to handle temporal learning . xxmaj these two kinds of information are fed into $ \\ mathcal{f}$ which is designed to output the final processing results , just like the hippocampus . \n",
              " \t \n",
              " \t  \\ begin{figure * } \n",
              " \t\t  \\ begin{center } \n",
              " \t\t\t  \\ includegraphics[width= \\ xxunk } \n",
              " \t\t  \\ end{center } \n",
              " \t\t  \\ caption { \\ xxunk experiments for semi - coupling xxmaj structure } . \\ textbf{a } , xxmaj the toy examples designed to demonstrate the xxup scs scheme can successfully decouple the temporal - spatial features . xxmaj the contents of input sequences are moving geometries . xxmaj we let the model to distinguish the shapes ( left two sequences ) and the moving directions ( right two sequences ) . \\ textbf{b } , xxmaj the feature maps from $ h_s$ , $ h_t$ and $ \\ mathcal{f}$ in the top layer of the model on the tasks described in \\ textbf{a } . xxmaj when distinguish the geometry 's shape ( left three columns ) , we can see that $ h_s$ and $ \\ mathcal{f}$ only contain spatial information , and temporal features in $ h_t$ do not xxunk into $ h_s$ in high layers due to the filter function of $ \\ mathcal{f}$ in low layers . xxmaj while for the task to distinguish the moving directions , we can see that the temporal information is integrated into $ \\ mathcal{f}$ and the spatial features in $ h_s$ are weakened . \\ textbf{c } , xxmaj feature maps of $ h_s$ and $ h_t$ on auto driving tasks . xxmaj the highlighting parts in the feature maps of $ h_t$ describe more information about the scene changing , while the highlighting parts in $ h_s$ focus on the outline of the objects and roads . } \n",
              " \t\t  \\ label{fig : toyexample } \n",
              " \t  \\ end{figure * } \n",
              " \t \n",
              " \t \n",
              " \t xxmaj we further advance our model by considering the fact that spatial and temporal information are deeply coupled with each other , when processed by a brain~ \\ xxunk } . xxmaj therefore , the model can naturally be extended as a deep nested structure to model such mutual - coupling . xxmaj we define the $ i^{th}$ coupling unit as : \n",
              " \t  \\ begin{align } \n",
              " \t  \\ xxunk ( \\ mathbf{x}_i ) = \\ xxunk ( \\ xxunk \\ xxunk ) , h_t ( \\ xxunk \\ xxunk ) ] \\ label{eq : g } \n",
              " \t  \\ end{align } \n",
              " \t thus , the deep spatial - temporal xxmaj semi - xxmaj coupled xxmaj structure can be expressed as : \n",
              " \t  \\ begin{align } \n",
              " \t  \\ mathcal{t } [ \\ mathbf{x } ; \\ xxmaj psi_s , \\ xxmaj psi_t ] = \\ mathcal{g}_1 \\ circ \\ mathcal{g}_2 \\ circ ... \\ circ \\ xxunk ( \\ mathbf{x } ) \\ label{eq : xxmaj gs } \n",
              " \t  \\ end{align } \n",
              " \t where $ n$ is the depth of the deep nested model , and $ \\ xxmaj psi_s = \\ { \\ xxunk , ... , \\ xxunk \\ } $ and $ \\ xxmaj psi_t = \\ { \\ xxunk , ... , \\ xxunk \\ } $ are the parameter sets . \n",
              " \t \n",
              " \t xxmaj in this structure , spatial and temporal information are intertwined deeply and collaboratively , meanwhile , $ h_s ( \\ cdot)$ and $ h_t ( \\ cdot)$ are responsible for spatial and temporal concept processing respectively . xxmaj to this end , we propose two design paradigms ( see xxmaj fig.~ \\ ref{fig : pipeline } ) . \n",
              " \t \n",
              " \t \n",
              " \t  \\ begin{itemize } \n",
              " \t\t  \\ item \\ xxunk xxmaj xxunk $ h_s ( \\ cdot)$ and $ h_t ( \\ cdot)$ work as their roles by their different structural designs . xxmaj at a certain time stamp of the sequence , the structure of $ h_t ( \\ cdot)$ should have access to the temporal information of other stamps in the sequence like the xxmaj recurrent xxmaj neural xxmaj network ( xxup rnn ) . xxmaj while for $ h_s ( \\ cdot)$ , it has no direct connection to the samples of other time stamps , so it can focus on the spatial information , which normally can be a xxup cnn structure . \n",
              " \t\t \n",
              " \t\t  \\ item \\ textbf{task xxmaj xxunk xxmaj because of the deep nested structure , $ h_s ( \\ cdot)$ and $ h_t ( \\ cdot)$ will disturb each other . xxmaj to make $ h_s ( \\ cdot)$ and $ h_t ( \\ cdot)$ further focus on their roles , besides the main goal : $ g= \\ mathcal{t } [ \\ mathbf{x } ; \\ xxmaj psi_s , \\ xxmaj psi_t]$ , we assign two extra sub - goals : $ r_s = \\ mathcal{t}^1 [ \\ mathbf{x } ; \\ xxmaj psi_s , \\ xxmaj psi_t]$ and $ r_t = \\ mathcal{t}^2 [ \\ mathbf{x } ; \\ xxmaj psi_s , \\ xxmaj psi_t]$ , where $ \\ mathcal{t}^1 $ and $ \\ mathcal{t}^2 $ share the same model components and parameters with $ \\ mathcal{t}$. xxmaj we also call $ r_s$ and $ r_t$ as the spatial and temporal indicating goals which can reflect the qualities of spatial and temporal features . xxmaj the key design is to make both two indicating goals only impact on their own parameters : $ \\ xxmaj xxunk or $ \\ xxmaj xxunk xxmaj that is , in $ \\ mathcal{t}^1 $ , $ { \\ partial r_s } / { \\ partial \\ xxmaj psi_t } = 0 $ and in $ \\ mathcal{t}^2 $ , $ { \\ partial r_t } / { \\ partial \\ xxmaj psi_s } = 0$. xxmaj the specific definition of the sub - goals depends on different tasks . xxmaj taking action recognition as an example , $ r_s$ can be human poses in a single frame that is unrelated to temporal information but useful for action understanding , and $ r_t$ can be the estimates of optical flow . \n",
              " \t  \\ end{itemize } \n",
              " \t xxmaj this new modeling strategy is called xxmaj semi - xxmaj coupled xxmaj structure ( xxup scs ) . xxmaj it is a general framework that is easy to be revised to fit various applications . xxmaj if the temporal indicating label of a specific application is difficult to provide , we find that only $ r_s$ is enough to encourage $ h_s ( \\ cdot)$ to focus on spatial learning , and $ h_t ( \\ cdot)$ can naturally take the responsibility of the remain ( temporal ) information . \n",
              " \t \n",
              " \t  \\ paragraph{discussion } xxmaj the proposed xxup scs makes each component be responsible for a specific sub - concept ( spatial or temporal ) . xxmaj this strategy widely exists in the brain using several different xxunk regions to complete a single complex task~ \\ xxunk , xxunk } . xxmaj during this process , our method learns to separate temporal and spatial information , even though we do not define them separately . xxmaj there are previous works that also try to separate the temporal and spatial information , but they adopt the hand - craft spatial and temporal definitions , like xxmaj two - xxmaj stream model~ \\ cite{simonyan2014two } which uses optical flow~ \\ xxunk } to define temporal information and slowfast xxmaj networks~ \\ cite{feichtenhofer2018slowfast } that uses xxunk spatial and temporal sampling density to distinguish and define them . xxmaj fig.~ \\ ref{fig : toyexample } illustrates that xxup scs can successfully decouple the temporal and spatial information in visual sequences . xxmaj in a toy experiment , the visual sequences show different geometries moving in different directions ( see xxmaj fig.~ \\ ref{fig : toyexample } \\ textbf{a } for details ) and we note that our method outperforms xxup lstm~ \\ cite{hochreiter1997long } on recognizing ` ` xxmaj which direction is the geometry going ? \" when it encounters a specific geometry it never saw and ` ` what is the geometry ? \" when the motion is xxunk . xxmaj fig.~ \\ ref{fig : toyexample } \\ textbf{b } shows the feature maps of $ h_t ( \\ mathbf{x})$ and $ h_s ( \\ mathbf{x})$ , and we can primarily recognize that $ h_t ( \\ mathbf{x})$ represents temporal - related features and $ h_s ( \\ mathbf{x})$ is for the spatial one from the viewpoint of human vision . xxmaj interestingly , our model can quantitatively indicate how important the temporal information is toward the final goal by comparing the indicating goals $ r_s$ and $ r_t$ , thanks to the awareness of the temporal and spatial concepts . xxmaj we believe this quantitative indicator will largely benefit the sequential analysis . \n",
              " \t \n",
              " \t  \\ section{performance xxmaj profiling on xxmaj academic and xxmaj reality xxmaj datasets } \n",
              " \t  \\ xxunk action recognition experiments } \n",
              " \t xxmaj to investigate the capacity of the xxmaj semi - xxmaj coupled xxmaj structure , we conduct the first experiment on video action recognition task . xxmaj we choose xxup xxunk \\ xxunk } , xxup xxunk \\ xxunk } and xxmaj xxunk \\ cite{carreira2017quo } datasets which consist of short videos describing human actions collected from website . xxmaj correct classification is xxunk from the comprehensive abilities of extracting temporal and spatial information : for example , distinguishing ` ` triple jump \" and ` ` long jump \" requires a structure to precisely understand temporal information , while to tell ` ` xxunk floor \" and ` ` xxunk floor \" apart requires great spatial information processing ability . xxmaj we find that our xxup scs can successfully learn the temporal information over long - range sequences on limited resources and compared to the conventional sequential models , such as xxup lstm stacked on xxup xxunk \\ cite{donahue2015long } and xxunk \\ cite{xingjian2015convolutional } , our xxup scs achieves remarkable improvements ( see xxmaj tab.~ \\ ref{tab : actionresult } for details ) . xxmaj unlike the previous architectures , our xxup scs can be trained end - to - end without the support of a backbone network ( such as xxup xxunk \\ xxunk } , resnet~ \\ cite{he2016deep } , and xxmaj xxunk \\ xxunk } . xxmaj due to the temporal and spatial semi - coupling , the network can reduce the interference from the temporal unit to the spatial one so that we can still get high - quality spatial features . \n",
              " \t \n",
              " \t  \\ xxunk outline sequentially annotation experiments } \n",
              " \t xxmaj although the video action recognition task takes a sequence as input , each sequence only need to be assigned one action label . xxmaj therefore , modeling it as a pattern recognition problem instead of a sequence learning is also a way to go . xxmaj for example , xxup 3d convolution model~ \\ cite{ji20133d , carreira2017quo } is widely used recently . xxmaj based on this consideration , we need a typical sequential task to further validate the xxup scs 's performance . xxmaj we , therefore , turn to the outline annotation task . \n",
              " \t \n",
              " \t xxmaj unlike video action recognition , outline annotation task calls for a point sequence to represent the outline of the target . xxmaj each input consists of an image with a start point to declare which object is the annotation target and an end point to indicate which direction to annotate . xxmaj the annotation models are trained to give out the outline 's key points of the target object one by one from the provided start point to the end point . a new key point is generated based on the already calculated key points ( xxmaj fig.~ \\ ref{fig : experiments } a ) . xxmaj the generated key points form the predicted outline and we adopt the iou between the predicted and ground - truth outline as the evaluation metric . \n",
              " \t xxmaj because it is not easy to give out the complete sequential key points in one step only with the start and end point , it is not suitable to model this task as a pattern recognition task like the video action recognition task . \n",
              " \t \n",
              " \t xxmaj we adopt cityscapes dataset~ \\ xxunk } as our data source and the target objects are all from the outdoor scene . xxmaj the relatively complex backgrounds require great ability to extract spatial features . xxmaj different from the action recognition task , the temporal information lies in the sequential key point positions which act as the attentions to assist the selection of the subsequent points . xxmaj as a benchmark we compare our xxup scs based model , a modified xxmaj polygon - xxup rnn model~ \\ cite{castrejon2017annotating } , with the original xxup lstm based xxmaj polygon - xxup rnn model . xxmaj in this case , our deep xxup scs model reaches an average of 70.4 in terms of iou , 15 \\ % relative improvements over the baseline . xxmaj fig.~ \\ ref{fig : experiments } c illustrates the training processes of xxunk with different depths and training strategies . \n",
              " \t \n",
              " \t  \\ xxunk - driving experiments } \n",
              " \t xxmaj next , we want to evaluate the performance of xxup scs on some cutting - edge applications . xxmaj still , we start from a pattern recognition like problem : the simplified auto - driving problem . xxmaj we treat the problem as a visual sequence processing task so that we only focus on the driving direction and ignore the route planning , strong driving safety and other things in the real driving environments . \n",
              " \t \n",
              " \t a driving agent , given the sequence of driver 's perspective images , needs to decide the driving direction for the last image . xxmaj it is worth noting that the agent does not know the historical direction to avoid it making ` ` lazy decision \" : simply repeating the recent direction . xxmaj as the previous experiments , this task also requires great ability to process spatial information to figure out the road direction and xxunk condition , and ability to capture temporal information to make coherent decisions . \n",
              " \t \n",
              " \t xxmaj we evaluate the xxup scs on the xxmaj xxunk dataset~ \\ xxunk } and the livi dataset~ \\ xxunk } . xxmaj the image sequences are the driving videos in real traffic including varied scenes such as highways and mountain roads , and the behaviours of the driver are recorded as the direction label . xxmaj by experiments , we find that features from $ h_s$ record more features of the current road and $ h_t$ records more about scene changes during driving ( xxmaj fig.~ \\ ref{fig : toyexample } c ) . xxmaj this indicates that they divide the works successfully and just as the design purpose , they focus on temporal and spatial features respectively so xxup scs can remarkably xxunk the learning pressure to different components . xxmaj again , the xxup scs performs substantially better than conventional xxup lstm models ( see xxmaj tab.~ \\ ref{tab : drivingresult } ) . \n",
              " \t \n",
              " \t  \\ xxunk forecasting experiments } \n",
              " \t xxmaj we further apply our xxup scs model to precipitation forecasting task in order to test its performance on sequence generation problem . xxmaj unlike the previous experiments , where the model receives the input sequence and gives out the output sequence synchronously , we apply a form of ` ` sequence to sequence \" learning~ \\ cite{sutskever2014sequence } in which the input sequence is encoded into a representation and then the model gives out the output sequence based on this representation . \n",
              " \t \n",
              " \t xxmaj our dataset , which we term as xxup reec-2018 , contains a set of meteorological xxmaj radar xxmaj echo images for xxmaj eastern xxmaj china in 2018 . xxmaj the metric of the radar echo is composite xxunk ( xxup cr ) which can be utilized to predict the precipitation intensity . a model , given a sequence of the radar echo images sorted in time , needs to predict a sequence of the future radar echo images from the previous evolution of xxup cr ( see xxmaj fig.~ \\ ref{fig : experiments } b ) . \n",
              " \t \n",
              " \t xxmaj through experiments , we find that our xxup scs model can successfully generate the results with original evolution trends , such as diffusion and translation . xxmaj compared with the convlstm , a conventional sequence model for visual , again , our xxup scs gains huge performance improvements . \n",
              " \t \n",
              " \t  \\ section{discussion } \n",
              " \t xxmaj in summary , we have built a xxmaj semi - xxmaj coupled xxmaj structure that can learn to divide the work of extracting features automatically . a major reason for utilizing such a structure is to alleviate the interference between learning temporal and spatial features . xxmaj many techniques like xxup stsgd and xxup ltsc ( see xxmaj methods and xxmaj fig.~ \\ ref{fig : xxup stsgd } ) are proposed to make the xxup scs easier to train . xxmaj the performances of our structure are provided by the experiments , and the theme connecting these experiments is the need to synthesize high dimensional temporal and spatial features embedded in data sequences . xxmaj all the experiments demonstrate that xxup scs is able to process visual sequential data regardless of whether the task is sensory processing or sequence learning . xxmaj moreover , we have seen that the temporal and spatial features are handled separately by different sub - structures due to the temporal - spatial semi - coupling mechanism ( see xxmaj fig.~ \\ ref{fig : toyexample } and xxmaj fig.~ \\ ref{fig : ablation_study } ) . \n",
              " \t \n",
              " \t  \\ section{related xxmaj work } \n",
              " \t\t  \\ xxunk models } \n",
              " \t\t xxmaj sequential tasks on high dimensional signal require a model to extract spatial representations as well as temporal features . a series of prior works has shed light on these tough problems : xxmaj constrained by the computational resource , xxunk methods~ \\ xxunk , xxunk , xxunk , xxunk } do not explicitly extract temporal feature , instead , acquire global features by combining spatial information , where pooling is a common method . xxmaj to extract temporal information , some researchers adopt low - level features , like optical flow~ \\ cite{simonyan2014two , carreira2017quo } , trajectories~ \\ xxunk , xxunk } , and pose xxunk \\ xxunk } to deal with temporal information . xxmaj these low - level features are easy to extract but they are xxunk to some extent , therefore , the performance is limited . xxmaj then with more computational resource , xxmaj recurrent xxmaj neural xxmaj networks ( xxup xxunk \\ cite{donahue2015long , xxunk , xxunk } are widely used , where hidden states take charge of ` ` remembering \" the history and extract the temporal features . xxmaj recently , xxup 3d convolutional networks~ \\ cite{ji20133d , carreira2017quo , xxunk , xxunk , xxunk } appear , where the temporal information is treated as the same with the spatial ones . xxmaj the large xxup 3d kernel makes this method consume a large amount of computational resource . \n",
              " \t\t  \\ xxunk to split temporal and spatial information } \n",
              " \t\t a simple method to split temporal - spatial information is to utilize relatively pure spatial information without temporal one to extract spatial features and pure temporal input for temporal ones . xxmaj for example , two - stream models~ \\ cite{simonyan2014two , carreira2017quo , xxunk } adopt one static image as spatial input and optical flows as temporal input . xxmaj one problem of this method is that the processes of extracting spatial and temporal features are completely independent , making it impossible to extract hierarchical spatial - temporal features . xxmaj another method is to adjust the density of these two types of information . xxmaj in slowfast network~ \\ cite{feichtenhofer2018slowfast } , the input of spatial stream has higher spatial resolution and lower temporal sampling rate , while the input of temporal stream is the opposite . \n",
              " \t \n",
              " \t \n",
              " \t  \\ xxunk \\ label{sec : xxmaj method } \n",
              " \t xxmaj in this section , we will introduce the detailed structure of xxup scs , the training method with spatial - temporal switch gradient descent , the strategy to deal with the high - dimension spatial signal and super long sequences , and the designs of the experiments . \n",
              " \t \n",
              " \t  \\ subsection{network for xxup scs } \n",
              " \t xxmaj at every time - stamp $ t$ , the network $ \\ mathcal{t}$ , consisting of $ n$ semi - coupled layers , receives an input matrix $ \\ xxunk from the dataset or environment and outputs an vector $ \\ mathbf{y}_t$ ( the main goal $ g$ ) to approximate the target ( ground truth ) vector $ \\ xxunk \n",
              " \t \n",
              " \t xxmaj as mentioned above , each semi - coupled layer satisfies the structure of $ \\ xxunk = \\ xxunk ( \\ mathbf{u}^{l-1}_t ) , h_t ( \\ xxunk , where $ \\ xxunk is the output of the $ xxunk layer at $ xxunk step and $ \\ xxunk is the input . xxmaj by defining $ \\ xxunk \\ xxunk , we get : \n",
              " \t  \\ begin{align } \n",
              " \t & \\ xxunk h_s ( \\ mathbf{u}^{l-1}_t ; \\ xxunk ) = { \\ rm xxmaj conv } ( \\ mathbf{u}^{l-1}_t ; \\ xxunk ) \\ label{eq : hs } \\ \\ \n",
              " \t & \\ xxunk h_t ( \\ mathbf{u}^{l-1}_t ; \\ xxunk ) = { \\ rm xxmaj conv } ( [ \\ mathbf{u}^{l-1}_t , \\ sigma ( \\ xxunk } ) ] ; \\ xxunk ) \\ label{eq : ht } \n",
              " \t  \\ end{align } \n",
              " \t where $ l$ is the layer index , $ \\ xxunk / ( xxunk is the logistic sigmoid function , $ \\ rm xxmaj conv$ is the convolutional neural layer , $ \\ xxunk and $ \\ xxunk are spatial state and temporal cell state matrix , respectively , of layer $ l$ at time $ t$. $ \\ xxunk \\ xxunk is true for all $ l$. xxmaj we adopt $ \\ rm xxmaj conv$ here for it is an excellent spatial feature extractor and of course , we can replace $ \\ rm xxmaj conv$ by other operators like fully connection , according to different tasks . xxmaj note that xxmaj eq.~ \\ ref{eq : hs } describes the structure of $ h_s$ and xxmaj eq.~ \\ ref{eq : ht } describes $ h_t$ which is a simple naive xxup rnn structure . xxmaj it is feasible to replace $ h_t$ with xxup lstm architecture~ \\ cite{xingjian2015convolutional } , but the computing complexity is too high to apply on visual tasks , so we do not practice this in this paper . \n",
              " \t \n",
              " \t xxmaj the synthesizer $ \\ mathcal{f}$ adopts a parameter - free structure : \n",
              " \t  \\ begin{align } \n",
              " \t & \\ xxunk { \\ rm xxmaj relu } ( \\ xxunk ) \\ circ { \\ rm xxmaj sigmoid } ( \\ xxunk ) \\ label{eq : xxmaj xxunk } \n",
              " \t  \\ end{align } \n",
              " \t \n",
              " \t where $ \\ circ$ denotes element - wise multiplication , $ { \\ rm xxmaj xxunk is the rectified linear unit and $ { \\ rm xxmaj xxunk 1 / ( 1 + e ^ { - x } ) $ is the sigmoid function . xxmaj in this way , the results of $ h_t$ are normalized to $ ( 0,1)$ , so $ h_t$ is treated as a control gate of $ h_s$ in the viewpoint of $ \\ mathcal{f}$. \n",
              " \t \n",
              " \t xxmaj as the network is recurrent , its outputs are a function of the complete sequence $ ( \\ mathbf{x}_1 , ... , \\ xxunk xxmaj we can further encapsulate the operation of the network as \n",
              " \t  \\ begin{align } \n",
              " \t & ( \\ mathbf{u}^n_1 , ... , \\ xxunk \\ mathcal{t } ( [ \\ mathbf{x}_1 , ... , \\ xxunk ] ; \\ xxmaj psi_s , \\ xxmaj psi_t ) \n",
              " \t  \\ end{align } \n",
              " \t where $ \\ bm { \\ xxmaj psi}$ is the set of trainable network weights and $ \\ xxunk is the output of the $ xxunk layer at time stamp $ t$. xxmaj finally , the output vector $ \\ mathbf{y}_t$ is defined by the assembly of $ ( \\ mathbf{u}^n_1 , ... , \\ xxunk : \n",
              " \t  \\ begin{align } \\ label{eq : xxunk } \n",
              " \t & \\ xxunk [ \\ mathbf{u}^n_1 , ... , \\ xxunk ] \n",
              " \t  \\ end{align } \n",
              " \t \n",
              " \t xxmaj for $ \\ mathcal{t}^1 $ and $ \\ mathcal{t}^2 $ , the sub - goal networks , we adopt the same $ h_s ( \\ cdot)$ and $ h_t ( \\ cdot)$ with $ \\ mathcal{t}$ , while the synthesizer $ \\ mathcal{f}$ is different . xxmaj in $ \\ mathcal{t}^1 $ , $ \\ mathcal{f}$ and sub - goal $ r_s$ ( or $ \\ mathbf{y}_t^ { \\ xxunk ) are defined as : \t \n",
              " \t  \\ begin{align } \n",
              " \t  \\ hat { \\ xxunk { \\ rm xxmaj relu } ( \\ xxunk ) \\ \\ \n",
              " \t  \\ mathbf{y}_t^ { \\ xxunk [ \\ hat { \\ xxunk , ... , \\ hat { \\ xxunk ] \n",
              " \t  \\ end{align } \n",
              " \t xxmaj while in $ \\ mathcal{t}^2 $ , $ \\ mathcal{f}$ and sub - goal $ r_t$ ( or $ \\ mathbf{y}_t^ { \\ xxunk ) are defined as : \t \n",
              " \t  \\ begin{align } \n",
              " \t  \\ hat { \\ xxunk { \\ rm xxmaj relu } ( \\ xxunk ) \\ \\ \n",
              " \t  \\ mathbf{y}_t^ { \\ xxunk [ \\ hat { \\ xxunk , ... , \\ hat { \\ xxunk ] \n",
              " \t  \\ end{align } \n",
              " \t  \\ subsection{deep xxmaj nested xxmaj semi - coupled xxmaj structure xxmaj xxunk \\ label{sec : xxup stsgd } \n",
              " \t \n",
              " \t xxmaj as discussed in section \\ ref{sec : aware } , on one hand , $ \\ mathcal{g}$ computes spatial and temporal information by separate modules . xxmaj on the other hand , we adopt deep nested structure of stacked $ \\ mathcal{g}$ , inspired from the spatial and temporal coupling in human brains . xxmaj but this structure leads to a difficult training process , because the deep nested structure actually merges the spatial and temporal information early in the shallow layers , which xxunk the pressure of spatial and temporal decomposition in the later layers as well as reduces the hierarchy of the decoupled features . xxmaj moreover , as the depth of layers and the length of sequences increase , both the number and the length of the back - propagation chains will grow significantly , which makes the training process much more challenging as well ( see xxmaj fig.~ \\ ref{fig : xxup stsgd } ) . \n",
              " \t \n",
              " \t \n",
              " \t  \\ begin{figure } \n",
              " \t\t  \\ begin{center } \n",
              " \t\t\t % \\ fbox { \\ xxunk in } \\ xxunk \\ xxunk } } \n",
              " \t\t\t  \\ includegraphics[width= \\ xxunk } \n",
              " \t\t  \\ end{center } \n",
              " \t\t  \\ caption { \\ xxunk numbers of back - propagation chains } . xxmaj the horizontal axis is the length of the back - propagation chain and the vertical axis is the exception number of the chains . xxmaj note that with the growing of the model depth and sequence length , the number and length of the chains grow significantly . xxmaj our xxup stsgd with large $ p$ can efficiently reduce the number of long sequences . } \n",
              " \t\t  \\ label{fig : xxup stsgd } \n",
              " \t  \\ end{figure } \n",
              " \n",
              " \t xxmaj to address this challenge , the xxmaj spatial - xxmaj temporal xxmaj switch xxmaj gradient xxmaj descent ( xxup stsgd ) is proposed to conduct a higher level of semi - coupling , in which the optimizer updates parameters based on either spatial or temporal information with a certain probability at each training step . \n",
              " \t xxmaj as the training goes on , we reduce the degree of this separation and finally the network can learn all the information . xxmaj this training strategy is also a practice of the semi - coupled mechanism : decoupling first then synthesizing . \n",
              " \t \n",
              " \t \n",
              " \t  \\ xxunk - xxmaj temporal xxmaj switch xxmaj gradient xxmaj descent } \n",
              " \t \n",
              " \t xxup stsgd is also a gradient based optimization method and the gradients are propagated by the xxup bp algorithm~ \\ xxunk } . xxmaj it works like a switch that turns off gradients on spatial and temporal modules with a certain probability . xxmaj this scheme largely reduces the interference between $ h_s ( \\ cdot)$ and $ h_t ( \\ cdot)$ induced by the deep nested structure . \n",
              " \t \n",
              " \t xxmaj given the definition xxmaj eq.~ \\ ref{eq : g } . xxmaj its forward propagation is : \n",
              " \t  \\ begin{align } \n",
              " \t & \\ xxunk = \\ xxunk \\ circ \\ ldots \\ circ \\ mathcal{g}_1 \n",
              " \t  \\ end{align } \n",
              " \t where $ \\ xxunk = \\ xxunk ( \\ cdot ) , h_s ( \\ cdot ) ; \\ xxunk is the $ i^{th}$ layer of the network and $ \\ bm { \\ xxunk is the set of the trainable parameters in the $ i^{th}$ layer . xxmaj the loss between $ \\ mathbf{y}_t$ and ground truth $ \\ xxunk is defined as : \n",
              " \t  \\ begin{align } \n",
              " \t e = \\ xxunk } = \\ xxunk ( \\ xxunk , \\ xxunk ) } \n",
              " \t  \\ end{align } \n",
              " \t where $ xxup l$ is the loss function . \n",
              " \t \n",
              " \t xxmaj then during back - propagation , according to the xxup xxunk xxunk , the gradient of $ \\ bm { \\ xxunk can be presented as : \n",
              " \t  \\ begin{equation } \n",
              " \t  \\ begin{aligned } \n",
              " \t  \\ frac { \\ partial e } { \\ partial \\ bm { \\ psi}_i } = & \\ sum_{t=1}^t \\ frac { \\ partial e } { \\ partial \\ mathcal{g}^t_{i+1 } } \\ frac { \\ partial \\ mathcal{g}^t_{i+1 } } { \\ partial \\ bm { \\ psi_i } } \n",
              " \t  \\ end{aligned } \n",
              " \t  \\ end{equation } \n",
              " \t and in conventional stochastic gradient descent methods , this exact gradient is adopted to update the parameters and continue back propagating . xxmaj in our xxup stsgd , we need to decouple the gradients based on the information carried by these two modules . xxmaj to this end , we rewrite the gradient as : \n",
              " \t  \\ begin{equation } \n",
              " \t  \\ begin{aligned } \n",
              " \t  \\ frac { \\ partial e } { \\ partial \\ bm { \\ psi}_i } & = \\ sum_{t=1}^t \\ frac { \\ partial e } { \\ partial \\ mathcal{g}^t_{i+1 } } ( \\ frac { \\ partial \\ mathcal{g}^t_{i+1 } } { \\ partial \\ mathbf{c}^{i+1}_{t } } \\ frac { \\ partial \\ mathbf{c}^{i+1}_{t } } { \\ partial \\ bm { \\ psi}_i } + \\ frac { \\ partial \\ mathcal{g}^t_{i+1 } } { \\ partial \\ mathbf{s}^{i+1}_{t } } \\ frac { \\ partial \\ mathbf{s}^{i+1}_{t } } { \\ partial \\ bm { \\ psi}_i } ) \n",
              " \t  \\ end{aligned } \n",
              " \t  \\ end{equation } \n",
              " \t \n",
              " \t xxmaj in the equation , the first term in the bracket is the gradient from $ h_t ( \\ cdot)$ and the second term is from $ h_s ( \\ cdot)$. xxmaj as the structures of $ h_t ( \\ cdot)$ and $ h_s ( \\ cdot)$ are designed for temporal and spatial information respectively , the gradients from them carry different concepts . \n",
              " \t \n",
              " \t xxmaj to decouple the gradients , we use a switch to prevent a certain part ( spatial or temporal ) from propagating its gradient in back - propagation , which can be defined as : \n",
              " \t  \\ begin{equation } \n",
              " \t  \\ begin{aligned } \n",
              " \t  \\ hat { \\ frac { \\ partial e } { \\ partial \\ bm { \\ psi}_i } } = \\ sum_{t=1}^t ( & \\ xxunk ) \\ frac { \\ partial e } { \\ partial \\ mathcal{g}^t_{i+1 } } \\ frac { \\ partial \\ mathcal{g}^t_{i+1 } } { \\ partial \\ mathbf{c}^{i+1}_{t } } \\ frac { \\ partial \\ mathbf{c}^{i+1}_{t } } { \\ partial \\ bm { \\ psi}_i } \\ \\ \n",
              " \t + & \n",
              " \t  \\ xxunk ) \\ frac { \\ partial e } { \\ partial \\ mathcal{g}^t_{i+1 } } \\ frac { \\ partial \\ mathcal{g}^t_{i+1 } } { \\ partial \\ mathbf{s}^{i+1}_{t } } \\ frac { \\ partial \\ mathbf{s}^{i+1}_{t } } { \\ partial \\ bm { \\ psi}_i } ) \\ label{eq : split } \n",
              " \t  \\ end{aligned } \n",
              " \t  \\ end{equation } \n",
              " \t where $ \\ gamma$ is a probability function defined as : \n",
              " \t  \\ begin{equation } \n",
              " \t  \\ xxunk ) = \\ left \\ { \n",
              " \t  \\ begin{aligned } \n",
              " \t 0 , & { \\ rm ~ with ~ the ~ probability ~ xxunk \\ \\ \n",
              " \t 1 , & { \\ rm ~ with ~ the ~ probability ~ xxunk ) \n",
              " \t  \\ end{aligned } \n",
              " \t  \\ right . \n",
              " \t  \\ end{equation } \n",
              " \t \n",
              " \t  \\ paragraph{discussion } xxmaj this scheme partly decouples the spatial and temporal learning process by initializing $ p_s$ and $ p_t$ to a relative high value ( $ p_s = xxunk $ ) and as the training goes on , $ p$ decreases to 0 to synthesize the spatial and temporal training processes . xxmaj from a macro perspective , it cuts off some paths in the back propagation with a certain probability , which reduces the number of back - propagation chains significantly , to make the training process more tractable ( see xxmaj fig.~ \\ ref{fig : xxup stsgd } ) . xxmaj according to the xxmaj assumption 4.3 in~ \\ xxunk } , if we set $ p_s = p_t$ , we get $ e ( \\ hat { \\ frac { \\ partial e } { \\ partial \\ bm { \\ xxunk { \\ frac { \\ partial e } { \\ partial \\ bm { \\ xxunk and this will lead to the similar convergence properties with the conventional stochastic gradient descent method . \n",
              " \t \n",
              " \t  \\ xxunk xxup stsgd } \n",
              " \t xxmaj note that , in xxup stsgd , the same value of $ p$ for $ h_s ( \\ cdot)$ and $ h_t ( \\ cdot)$ is the restriction for convergence and is a sufficient condition . xxmaj but , we hope the network can learn more spatial information at the beginning , since temporal information can not be captured given a very unreliable spatial representation . \n",
              " \t xxmaj after getting a relatively mature spatial representation , we hope the xxup stsgd can shift its learning focus between spatial and temporal features . xxmaj to this end , we modify the xxmaj eq.~ \\ ref{eq : split } with a dynamic ratio $ q \\ in [ 0,1]$ to : \n",
              " \t  \\ begin{equation } \n",
              " \t  \\ begin{aligned } \n",
              " \t  \\ hat { \\ frac { \\ partial e } { \\ partial \\ bm { \\ psi}_i } } = \\ sum_{t=1}^t ( & \\ xxunk ) \\ frac { \\ partial e } { \\ partial \\ mathcal{g}^t_{i+1 } } \\ frac { \\ partial \\ mathcal{g}^t_{i+1 } } { \\ partial \\ mathbf{c}^{i+1}_{t } } \\ frac { \\ partial \\ mathbf{c}^{i+1}_{t } } { \\ partial \\ bm { \\ psi}_i } \\ \\ \n",
              " \t + & \n",
              " \t  \\ xxunk ) \\ frac { \\ partial e } { \\ partial \\ mathcal{g}^t_{i+1 } } \\ frac { \\ partial \\ mathcal{g}^t_{i+1 } } { \\ partial \\ mathbf{s}^{i+1}_{t } } \\ frac { \\ partial \\ mathbf{s}^{i+1}_{t } } { \\ partial \\ bm { \\ psi}_i } ) \\ label{eq : xxunk } \n",
              " \t  \\ end{aligned } \n",
              " \t  \\ end{equation } \n",
              " \t \n",
              " \t \n",
              " \t xxmaj although there is no theory to guarantee the convergence of the xxmaj advanced xxup stsgd ( xxup astsgd ) , the experiment results show it works well . xxmaj moreover , to automatically control the process of decreasing $ q$ , we train a small network with 3 fully connection layers which takes $ r_s$ , $ r_t$ , and $ g$ as input to optimize $ q$. xxmaj to simplify the problem , we provide an empirical formula as another option : \n",
              " \t  \\ begin{align } \n",
              " \t q = q_0 + ( xxunk ) \\ frac { \\ max(0 , xxmaj xxunk { \\ rm xxunk } ) } { { \\ rm xxunk } - { \\ rm xxunk } } * ( \\ alpha ( \\ xxunk } xxunk ) \n",
              " \t  \\ end{align } \n",
              " \t where $ xxmaj l_s$ and $ xxmaj xxunk are the loss values of $ r_s$ and $ g$. $ q_0 $ is usually set as 0.5 . xxmaj in this equation , we monitor the decreasing process of $ xxmaj l_s$ to update $ q$. $ \\ rm xxunk is a hyper - parameter that acts as a threshold for $ xxmaj l_s$ , considering that $ xxmaj l_s$ is difficult to decrease to 0 and we want $ q$ get the minimum value when $ xxmaj l_s$ decreasing to $ \\ rm xxunk $ \\ rm xxunk is the initial training loss value of $ g$ , for example , the initial loss of an $ xxunk classification problem , the initial cross entropy loss , is $ xxunk $ \\ alpha$ is a hyper - parameter and the multiplier $ ( \\ xxunk / xxmaj xxunk is designed to balance the integral and spatial information . xxmaj if the task is more depended on the spatial information , we can set $ \\ alpha$ smaller , in this way the function will have a relative big value to better learn the spatial features . \n",
              " \t \n",
              " \t  \\ xxunk long sequences with xxup ltsc } \\ label{sec : xxup ltsc } \n",
              " \t xxmaj making use of the different properties between time and space , $ \\ mathcal{t } [ \\ mathbf{x } ; \\ xxmaj psi_s , \\ xxmaj psi_t]$ decouples the temporal and spatial information . xxmaj as the length of the sequence grows , the enormous increase in information which leads to huge computing requirements also brings up the demand of information decoupling . xxmaj briefly , \\ xxunk range temporal semi - coupling } ( xxup ltsc ) decouples the original long sequence $ \\ mathbf{d}$ into short sequences $ \\ { \\ xxunk = 1, ... ,n \\ } $ along the temporal dimension with a partitioning principle : \n",
              " \t  \\ begin{align } \n",
              " \t & \\ xxunk ... ,n } \\ { \\ tilde { \\ xxunk } \\ } = \\ tilde { \\ mathbf{d } } \\ \\ \n",
              " \t & \\ tilde { \\ xxunk } \\ cap \\ tilde { \\ xxunk \n",
              "  eq \\ varnothing \\ label{eq : overlap } \n",
              " \t  \\ end{align } \n",
              " \t where $ \\ tilde { \\ xxunk and $ \\ tilde { \\ xxunk are the set of $ \\ xxunk contained in sequence $ \\ mathbf{d}_i$ and $ \\ mathbf{d}$ , and $ { \\ xxunk is sorted by index of its first element . xxmaj eq.~ \\ ref{eq : overlap } requires overlaps between the adjacent sub - sequences which are the hinge to transmit the information , for it makes sure that there is no such a point in $ \\ mathbf{d}$ that information can not feed forward and backward across it . xxmaj for example , when splitting $ \\ mathbf{d } = ( \\ mathbf{x}_1 , \\ mathbf{x}_2 , \\ mathbf{x}_3 , \\ mathbf{x}_4)$ into $ \\ xxunk ( \\ mathbf{x}_1 , \\ xxunk and $ \\ xxunk ( \\ mathbf{x}_3 , \\ mathbf{x}_4)$ in which there is no overlap , information will never transfer between $ \\ mathbf{x}_2 $ and $ \\ mathbf{x}_3 $ , but if splitting $ \\ mathbf{d}$ into $ \\ xxunk = ( \\ mathbf{x}_1 , \\ mathbf{x}_2 , \\ xxunk and $ \\ xxunk ( \\ mathbf{x}_2 , \\ mathbf{x}_3 , \\ mathbf{x}_4)$ , there is no such issue . \n",
              " \t \n",
              " \t xxmaj as a hyper - parameter , a high overlap $ \\ eta$ will lead to high computing complexity and a low $ \\ eta$ means worse ability to transmit information . xxmaj in this paper , we chose 25 \\ % for $ \\ eta$. \n",
              " \t \n",
              " \t xxup ltsc can be adopted in any sequence task , while in this paper , xxup ltsc is nested with xxup scs network . \n",
              " \t xxup ltsc further utilizes the overlaps among $ \\ mathbf{d}_i$ to enhance the flow of information and we adopt an error function to shorten the distance between output of the adjacent $ \\ mathbf{d}_i$ : \n",
              " \t  \\ begin{align } \n",
              " \t & xxmaj xxunk \\ xxunk ... ,n } { \\ xxunk ( { \\ xxunk } ) , xxunk ( { \\ xxunk ) ) } \n",
              " \t  \\ end{align } \n",
              " \t where $ \\ xxunk , b)$ is defined as the overlap xxup mse function which calculates the xxup mse value of the overlap parts of $ a$ and $ b$. xxmaj this arrangement makes the output of $ xxunk with adjacent input $ \\ mathbf{d}_i$ be close in the overlap part . \n",
              " \t \n",
              " \t xxmaj note that there are other straightforward methods to decouple the long - range temporal information like xxup xxunk algorithm~ \\ xxunk } or simply sampling from the original $ \\ xxunk \\ cite{carreira2017quo , xxunk , xxunk , xxunk } , but these do not make sure that the semantic information can transmit through the whole sequence or just discard some percentage of information . \n",
              " \t \n",
              " \t a simple example demonstrates the smooth flow of semantic information in xxup ltsc . xxmaj the input visual sequence consists of an image of star and several of xxunk , and the star can appear at any temporal position . xxmaj our model needs to learn how far the current xxunk image is from the appeared star . xxmaj with xxup ltsc , the model can correctly output the results even if the star image appears 50 frames ago when the decoupled sequence lengths are smaller than 10 . xxmaj this can serve as a preliminary verification on xxup ltsc . \n",
              " \t \n",
              " \t  \\ begin{figure * } \n",
              " \t\t  \\ begin{center } \n",
              " \t\t\t  \\ includegraphics[width= \\ xxunk } \n",
              " \t\t  \\ end{center } \n",
              " \t\t  \\ caption { \\ xxunk study on action recognition task } . \\ textbf{a } , xxmaj feature maps of $ h_s$ and $ h_t$. xxmaj with sub - tasks , the splitting of spatial and temporal information is more obvious than without sub - tasks : 1 ) xxmaj with sub - tasks , $ h_s$ contains xxunk spatial information , while without sub - tasks , there is a little temporal information in $ xxunk 2 ) xxmaj without sub - tasks , $ h_t$ also extracts texture information , while sub - tasks makes it focus on the motion changes . xxmaj this reveals that sub - tasks can make $ h_s$ and $ h_t$ focus on their own jobs . \\ textbf{b } , $ q$ values during the training process . xxmaj at the beginning of training , $ q$ is about $ 1 $ , which leads xxup scs to focus on spatial information first . xxmaj as the training goes on , the value of $ q$ gradually approaches $ 0.5 $ to merge temporal and spatial information and the model treats them equally . } \n",
              " \t\t  \\ label{fig : ablation_study } \n",
              " \t  \\ end{figure * } \n",
              " \t \n",
              " \t  \\ begin{figure * } \n",
              " \t\t  \\ begin{center } \n",
              " \t\t\t  \\ includegraphics[width= \\ xxunk } \n",
              " \t\t  \\ end{center } \n",
              " \t\t  \\ caption { \\ xxunk annotation and precipitation forecasting experiments } . \\ textbf{a } , xxmaj to annotate the xxunk , we first crop out the objects , then give the start point ( the red one ) , finally the model needs to give out the outline points starting from it one by one to form a complete outline . \\ textbf{b } , xxmaj some example images annotated by our xxup scs structure . \\ textbf{c } , xxmaj from the training process of the model on outline annotation , we can see that our xxup scs model can benefit from the increasing model depth while xxup lstm model is difficult to train when stacked deep , which is because extracting the hierarchical spatial and temporal features together is difficult and our xxmaj semi - xxmaj coupled xxmaj structure can solve this problem . xxmaj moreover , a larger initial $ q$ can better decouple the training process of $ h_s$ and $ h_t$ , thus leads to a better performance . \\ textbf{d } , xxmaj the precipitation forecasting model consists of an encoder and a decoder . xxmaj the encoder integrates the observed radar echo images into an intermediate representation . xxmaj the decoder takes the representation and the last radar echo image as input , updates the intermediate representation and outputs the future image one by one . } \n",
              " \t\t  \\ label{fig : experiments } \n",
              " \t  \\ end{figure * } \n",
              " \t \n",
              " \t  \\ subsection{comparison with xxmaj deep xxup rnn and spatial - temporal attention model } \n",
              " \t \n",
              " \t xxmaj the xxmaj deep xxup rnn framework~ \\ cite{pang2018deep } is the predecessor to the xxup scs described in this work , yet they have significant differences . \n",
              " \t xxmaj firstly , in the xxmaj deep xxup rnn framework , the splitting of two flows is designed to make the deep recurrent structure easier to train by adding spatial shortcuts over temporal flows . xxmaj while in xxup scs , the semi - coupling mechanism aims at endowing the model with the awareness of spatial and temporal concepts . xxmaj moreover , $ h_s ( \\ cdot)$ and $ h_t ( \\ cdot)$ have the equal status to explicitly learn the two concepts . \n",
              " \t xxmaj secondly , the xxmaj deep xxup rnn framework has no mechanism to ensure the two flows focusing on the two kinds of information . xxmaj this is not an issue for the xxup scs which adopts two extra independent sub - goals and two stand - alone modules tailored for spatial and temporal features . xxmaj thirdly , in the training process , xxmaj deep xxup rnn has no way to control the training degree of the two flows , thus , no way of re - focusing on the spatial or temporal information . xxmaj this problem is addressed in xxup scs by the xxup stsgd mechanism . \n",
              " \t \n",
              " \t \n",
              " \t xxmaj the xxmaj spatial - xxmaj temporal xxmaj attention model ( xxup xxunk \\ xxunk } also introduces spatial and temporal concepts . xxmaj there are several differences between xxup stam and xxup scs . xxmaj firstly , xxup scs aims at extracting the temporal and spatial features ( concepts ) separately from the input , while xxup stam is designed to output the spatial and temporal attention from input features which integrate spatial and temporal information . xxmaj these attentions defined on skeleton key - points rely on human skeleton assumption very much and are not general features . xxmaj secondly , xxup stam is designed for small - scale data format ( skeleton coordinates , xxup xxunk only ) , thus , it is not suitable for the large scale problems which are the targets of xxup scs . xxmaj thirdly , xxup stam does not have awareness of general spatial and temporal concepts . xxmaj the heads of spatial and temporal attention modules are designed for the specific tasks : spatial one for skeleton keypoints and temporal one for video frames , thus , the spatial and temporal concepts are actually human - defined , not learnt by the model itself . \n",
              " \n",
              " \t \n",
              " \t  \\ subsection{action recognition task descriptions } \n",
              " \t xxmaj the experiments of action recognition are conducted on xxup ucf-101 , xxup hmdb-51 and xxmaj xxunk datasets , which comprise sets of 101 , 51 , 400 action categories respectively . xxmaj for each dataset , we follow the official training and testing splits . xxmaj for each video , the frames are rescaled with their shorter side into xxunk and a 224 $ \\ times$ 224 crop is randomly sampled from the rescaled frames or their horizontal flips . xxmaj colour augmentation is used , where all the random augmentation parameters are shared among the frames of each video . \n",
              " \t \n",
              " \t xxmaj for this task , we adopt two kinds of xxmaj semi - xxmaj coupled xxmaj structures : backbone - supported one and stand - alone structure without backbone . xxmaj for the backbone - supported structure , there is a xxup cnn backbone pre - trained on xxunk \\ cite{krizhevsky2012imagenet } ( we choose xxup vgg and xxunk as examples ) before the 15-layer xxup scs network . xxmaj while for the stand - alone version , the model only consists of a xxunk xxup scs network . xxmaj shortcuts between layers like resnet~ \\ cite{he2016deep } are adopted in xxup scs networks to simplify the training process . xxmaj the detailed structures are summarized in xxmaj tab.~ \\ ref{tab : xxunk } . \n",
              " \t \n",
              " \t  \\ begin{table } [ ] \n",
              " \t\t  \\ footnotesize \n",
              " \t\t  \\ caption{detailed stand - alone xxup scs structures for action recognition task . xxmaj there are residual lines between every layer blocks . \n",
              " \t\t } \n",
              " \t\t  \\ renewcommand { \\ xxunk } \n",
              " \t\t  \\ begin{center } \n",
              " \t\t\t  \\ begin{tabular}{c|c } \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t layer blocks & output size \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t % \\ hline \n",
              " \t\t\t\t $ 7 \\ xxunk , 64 , { \\ rm xxunk $ & 112 \\ \\ [ 1.5ex ] \n",
              " \t\t\t\t % \\ hline \n",
              " \t\t\t\t $ \\ left [ \\ begin{aligned } \n",
              " \t\t\t\t 3 \\ times3 , 64 \\ \\ \n",
              " \t\t\t\t 3 \\ times3 , 64 \n",
              " \t\t\t\t  \\ end{aligned } \n",
              " \t\t\t\t  \\ right ] \\ times 2 $ & 56 \\ \\ [ 4ex ] \n",
              " \t\t\t\t % \\ hline \n",
              " \t\t\t\t $ \\ left [ \\ begin{aligned } \n",
              " \t\t\t\t 3 \\ times3 , 128 \\ \\ \n",
              " \t\t\t\t 3 \\ times3 , 128 \n",
              " \t\t\t\t  \\ end{aligned } \n",
              " \t\t\t\t  \\ right ] \\ times 2 $ & 28 \\ \\ [ 4ex ] \n",
              " \t\t\t\t % \\ hline \n",
              " \t\t\t\t $ \\ left [ \\ begin{aligned } \n",
              " \t\t\t\t 3 \\ times3 , 256 \\ \\ \n",
              " \t\t\t\t 3 \\ times3 , 256 \n",
              " \t\t\t\t  \\ end{aligned } \n",
              " \t\t\t\t  \\ right ] \\ times 2 $ & 14 \\ \\ [ 4ex ] \n",
              " \t\t\t\t % \\ hline \n",
              " \t\t\t\t $ \\ left [ \\ begin{aligned } \n",
              " \t\t\t\t 3 \\ times3 , 512 \\ \\ \n",
              " \t\t\t\t 3 \\ times3 , 512 \n",
              " \t\t\t\t  \\ end{aligned } \n",
              " \t\t\t\t  \\ right ] \\ times 2 $ & 7 \\ \\ \n",
              " \t\t\t  \\ end{tabular } \n",
              " \t\t  \\ end{center } \n",
              " \t\t  \\ label{tab : xxunk } \n",
              " \t\t  \\ vspace{-0.2 in } \n",
              " \t  \\ end{table } \n",
              " \n",
              " \t xxmaj the main goal $ g$ of the network is to minimize the cross - entropy of the softmax outputs with respect to the action categories ; the final output is the average of the outputs of every time - stamp frame . xxmaj the spatial goal $ r_s$ is the same as the main goal and the temporal goal $ r_t$ is to estimate the optical flow between the current and last input frames . xxmaj for each step , the network processes a new video frame and the probability distribution over action categories is predicted based on the current processed frames . \n",
              " \t \n",
              " \t xxmaj adopting xxup ltsc enables our network to process much longer sequences than previous works on action recognition in which sampling methods are used to shorten the video length . xxmaj this places greater stress on the long - range memory capacity of the model but preserves more temporal information in the original video . xxmaj in addition , due to the deep structure of xxup scs network , we adopt xxup astsgd . \n",
              " \t \n",
              " \t xxmaj tab.~ \\ ref{tab : actionresult } lists the complete results and hyper - parameters of the experiments on action recognition for xxup scs , xxup lstm and pure xxup cnn model . xxmaj we can see that our xxup scs has much better performances than xxup lstm , convlstm , and xxup cbm~ \\ cite{pang2018deep } models . xxmaj compared with xxup xxunk , the new xxup scs decouples spatial and temporal information and adjusts its focus ( on spatial or temporal information ) strategically during the learning process . xxmaj detailed analysis is shown in ` ` xxmaj ablation xxmaj study \" . \n",
              " \t  \\ begin{table } [ ] \n",
              " \t\t  \\ footnotesize \n",
              " \t\t  \\ caption{action recognition accuracy on xxmaj kinetics , and end - to - end fine - tuning on xxup ucf-101 and xxup hmdb-51 . xxmaj note that our xxup scs model applies 17 layers . ` ` xxup bb \" denotes backbone . % ` ` * \" means the average value over three splits . \n",
              " \t\t } \n",
              " \t\t  \\ renewcommand { \\ arraystretch}{1.2 } \n",
              " \t\t  \\ begin{center } \n",
              " \t\t\t  \\ begin{tabular}{c|c|c|c } \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t xxmaj architecture & xxmaj kinetics & xxup ucf-101 & xxup hmdb-51 \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ multicolumn{2}{c| } { } & \\ xxunk - trained on xxmaj kinetics } \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t xxup lstm with xxup bb ( xxup xxunk \\ cite{donahue2015long } & 53.9 & 86.8 & 49.7 \\ \\ \n",
              " \t\t\t\t % xxup xxunk \\ cite{ji20133d } & 56.1 & 79.9 & xxunk \\ \\ \n",
              " \t\t\t\t % xxmaj two - xxmaj xxunk \\ cite{simonyan2014two } & 62.8 & 93.8 & 64.3 \\ \\ \n",
              " \t\t\t\t xxup 3d - xxmaj xxunk \\ xxunk } & xxunk & 91.5 & xxunk \\ \\ \n",
              " \t\t\t\t % xxup rgb xxup xxunk \\ cite{carreira2017quo } & xxunk & 95.1 * & xxunk * \\ \\ \n",
              " \t\t\t\t xxmaj stand - alone xxup cbm~ \\ cite{pang2018deep } & xxunk & xxunk & 61.7 \\ \\ \n",
              " \t\t\t\t xxmaj stand - alone xxup scs & 61.7 & 92.6 & 65.0 \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ multicolumn{2}{c| } { } & \\ xxunk pre - trained on xxmaj kinetics } \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t 15-layer convlstm & - & 68.9 & 34.2 \\ \\ \n",
              " \t\t\t\t xxup bb ( xxup vgg ) supported xxup cbm~ \\ cite{pang2018deep } & - & xxunk & 40.2 \\ \\ \n",
              " \t\t\t\t xxup bb ( xxup vgg ) supported xxup scs & - & 82.1 & 42.5 \\ \\ \n",
              " \t\t\t\t xxup bb ( xxmaj inception ) supported xxup scs & - & 87.9 & 52.1 \\ \\ xxunk \\ hline \n",
              " \t\t\t  \\ end{tabular } \n",
              " \t\t  \\ end{center } \n",
              " \t\t  \\ label{tab : actionresult } \n",
              " \t\t  \\ vspace{-0.2 in } \n",
              " \t  \\ end{table } \n",
              " \t \n",
              " \t  \\ xxunk xxmaj study } \n",
              " \t xxmaj since our xxup scs is a universal backbone , we conduct the ablation study on this low - level feature - driven task to show the function of each component . xxmaj the results are shown in xxmaj tab.~ \\ ref{tab : xxunk } . xxmaj we first test the design of the spatial - temporal sub - task paradigm . xxmaj from the view of the performances , it leads to 1.2 \\ % accuracy boost and from xxmaj fig.~ \\ ref{fig : ablation_study } \\ textbf{a } , we can see that this paradigm makes $ h_s$ and $ h_t$ more focus on their own functions : $ h_s$ for spatial features and $ h_t$ for temporal ones . xxmaj then we remove the xxup astsgd from the training process , leading to 1.4 \\ % accuracy drop . xxmaj in xxmaj fig.~ \\ ref{fig : ablation_study } \\ textbf{b } , we show the change tendency of $ q$ , which demonstrates that the model learns spatial information first then merges temporal features into it just as we expect . xxmaj the sub - tasks and xxup astsgd are the main improvements on xxup cbm~ \\ cite{pang2018deep } , which make $ h_s$ and $ h_t$ focus on their jobs , the training process controllable , and the model perform better . xxmaj without xxup ltsc , the model can only access a short clip due to the limit of computational resource and the accuracy drops 2 \\ % . \n",
              " \t \n",
              " \t \n",
              " \t  \\ begin{table } [ ] \n",
              " \t\t  \\ footnotesize \n",
              " \t\t  \\ caption{ablation study results ( accuracy ) on action recognition task with xxmaj kinetics and xxup ucf-101 dataset . ` ` w / o \" denotes ` ` without \" . } \n",
              " \t\t  \\ renewcommand { \\ arraystretch}{1.2 } \n",
              " \t\t  \\ begin{center } \n",
              " \t\t\t  \\ begin{tabular}{c|c|c } \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t xxmaj architecture & xxmaj kinetics & xxup hmdb-51 \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t xxmaj whole xxmaj stand - alone xxup scs & 61.7 & 65.0 \\ \\ \n",
              " \t\t\t\t xxmaj stand - alone xxup scs w / o two sub - tasks & 60.5 & xxunk \\ \\ \n",
              " \t\t\t\t xxmaj stand - alone xxup scs w / o sub - task $ xxup xxunk $ only & 61.3 & 64.2 \\ \\ \n",
              " \t\t\t\t xxmaj stand - alone xxup scs w / o xxup astsgd & 60.8 & 63.2 \\ \\ \n",
              " \t\t\t\t xxmaj stand - alone xxup scs w / o xxup ltsc & 59.7 & 62.9 \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t  \\ end{tabular } \n",
              " \t\t  \\ end{center } \n",
              " \t\t  \\ label{tab : xxunk } \n",
              " \t\t  \\ vspace{-0.2 in } \n",
              " \t  \\ end{table } \n",
              " \t \n",
              " \t  \\ xxunk annotation task descriptions } \n",
              " \t xxmaj we adopt cityscapes dataset~ \\ xxunk } to conduct the outline annotation task experiments . cityscapes dataset consists of the street view images and their segmentation labels . xxmaj we crop out the xxunk of the images and only preserve 8 kinds of the xxunk : xxmaj bicycle , xxmaj bus , xxmaj person , xxmaj train , xxmaj truck , xxmaj xxunk , xxmaj car and xxmaj xxunk . xxmaj after cropping , there are xxunk training images and 10k test images . xxmaj the preserved images are resized to 224 $ \\ times$ 224 . \n",
              " \t \n",
              " \t xxmaj similar with xxmaj polygon - xxup rnn~ \\ cite{castrejon2017annotating , xxunk } , a xxup vgg model is adopted first to extract the spatial features of the original images . xxmaj then a deep xxup scs network with 15 layers takes the image features and the outline point positions of time - stamp $ t-1 $ as input for each time - stamp $ t$ and generates the outline point positions sequentially . xxmaj in short , we replace the xxup rnn part in the \n",
              " \t original xxmaj polygon - xxup rnn model with our deep xxup scs network and adjust the optimizing method with our xxup ltsc and xxup stsgd schemes . \n",
              " \t \n",
              " \t xxmaj this task is also treated as a classification task . xxmaj each position of the image is a class and the loss function is the cross - entropy of the softmax outputs with respect to the image positions ( 28 $ \\ times$ 28 $ + $ 1 , 784 positions in total and a xxunk ) . xxmaj the spatial goal $ r_s$ and temporal goal $ r_t$ are the same as the main goal : predicting the positions of the outline 's key points . xxmaj though we do not adopt different targets for $ \\ mathcal{t}^1 $ and $ \\ mathcal{t}^2 $ , the independent optimization processes and xxunk structures allow them to focus on different information . xxmaj the outline position sequence makes up a polygon area and we adopt the iou between the predicted and ground - truth polygon area as the evaluation metric . \n",
              " \t \n",
              " \t xxmaj for each foreground , the model predicts 60 outline points at most . xxmaj with a 15-layer xxup scs network , this sequence length requires huge computing resources , so we adopt the xxup ltsc mechanism to split the sequence into 6 short clips and utilize xxup astsgd to decouple the temporal and spatial training process of the deep structure . \n",
              " \t \n",
              " \t xxmaj detailed results and hyper - parameters of the experiments on outline annotation for xxup scs - xxmaj polygon - xxup rnn , xxmaj polygon - xxup rnn and xxmaj polygon - xxup rnn++ are shown in xxmaj tab.~ \\ ref{tab : xxunk } . xxmaj compared with traditional xxup lstm or xxup gru module , our model can be stacked deeply and achieve better performances with less parameters . xxmaj our xxup scs does not achieve the state - of - the - art performance because xxmaj polygon - xxup rnn++ adopts many advanced tricks to improve the performance ( including reinforcement learning , graph neural network , and attention module ) . xxmaj these tricks are not the focus of this paper . xxmaj compared with xxup cbm~ \\ cite{pang2018deep } , the new xxup scs with sub - tasks and xxup astsgd achieves better performances . \n",
              " \t  \\ begin{table } [ ] \n",
              " \t\t \n",
              " \t\t  \\ caption{performance ( iou in \\ % ) on xxmaj cityscapes validation set ( used as test set in~ \\ cite{castrejon2017annotating } ) . xxmaj note that ` ` xxmaj polyg - xxup lstm \" denotes the original xxmaj polygon - xxup rnn structure with convlstm cell , ` ` xxmaj poly - xxup gru \" for xxmaj polygon - xxup rnn with xxup gru cell , and ` ` xxmaj polyg - xxup scs \" for xxmaj polygon - xxup rnn with our xxmaj semi - xxmaj coupled xxmaj structure . } \n",
              " \t\t  \\ renewcommand { \\ arraystretch}{1.2 } \n",
              " \t\t  \\ begin{center } \n",
              " \t\t\t  \\ footnotesize \n",
              " \t\t\t  \\ begin{tabular}{c|c|c|c } \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ xxunk } & iou \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ xxunk xxmaj polygon - xxup rnn~ \\ cite{castrejon2017annotating } } & xxunk \\ \\ \n",
              " \t\t\t\t  \\ multicolumn{3}{c|}{residual xxmaj polygon - xxup rnn~ \\ cite{acuna2018efficient } } & xxunk \\ \\ \n",
              " \t\t\t\t  \\ multicolumn{3}{c|}{residual xxmaj polygon - xxup rnn + attention + xxup rl~ \\ cite{acuna2018efficient } } & 67.2 \\ \\ \n",
              " \t\t\t\t  \\ multicolumn{3}{c|}{residual xxmaj polygon - xxup rnn + attention + xxup rl + xxup xxunk \\ cite{acuna2018efficient } } & 70.2 \\ \\ \n",
              " \t\t\t\t  \\ xxunk - xxup xxunk \\ cite{acuna2018efficient } } & \\ xxunk } \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t & \\ # layers & \\ # params of xxup rnn & \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t xxmaj polyg - xxup lstm & 2 & 0.47 m & xxunk \\ \\ \n",
              " \t\t\t\t xxmaj polyg - xxup lstm & 5 & 2.94 m & 63.0 \\ \\ \n",
              " \t\t\t\t xxmaj polyg - xxup lstm & 10 & 7.07 m & xxunk \\ \\ \n",
              " \t\t\t\t xxmaj polyg - xxup lstm & 15 & 15.71 m & 46.7 \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t xxmaj polyg - xxup gru & 5 & 2.20 m & 63.8 \\ \\ \n",
              " \t\t\t\t xxmaj polyg - xxup gru & 15 & 11.78 m & xxunk \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t xxmaj polyg - xxup cbm~ \\ cite{pang2018deep } & 5 & 1.13 m & 63.1 \\ \\ \n",
              " \t\t\t\t xxmaj polyg - xxup cbm~ \\ cite{pang2018deep } & 15 & 5.85 m & 70.4 \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t xxmaj polyg - xxup scs & 2 & 0.20 m & 62.9 \\ \\ \n",
              " \t\t\t\t xxmaj polyg - xxup scs & 5 & 1.13 m & xxunk \\ \\ \n",
              " \t\t\t\t xxmaj polyg - xxup scs & 10 & 2.68 m & 68.0 \\ \\ \n",
              " \t\t\t\t xxmaj polyg - xxup scs & 15 & 5.85 m & \\ xxunk } \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t  \\ end{tabular } \n",
              " \t\t  \\ end{center } \n",
              " \t\t  \\ label{tab : xxunk } \n",
              " \t\t  \\ vspace{-0.2 in } \n",
              " \t  \\ end{table } \n",
              " \t \n",
              " \t  \\ xxunk - driving task description } \n",
              " \t \n",
              " \t xxmaj auto driving is a complex task . xxmaj completely solving it requires to conduct scene sensing , route planning , security assurance and so on . xxmaj here we simplify the task into a sequential vision task : given a short video from driver 's perspective and outputting the driving direction in the form of steering wheel angles . xxmaj the experiments are conducted on xxunk \\ xxunk } and livi - xxmaj set~ \\ xxunk } datasets . xxmaj these sets record the real driving behaviours of human drivers and there are various road conditions including town streets , highways and mountain roads . xxmaj to make the model better focus on the road , we crop out the sky and other irrelevant information from the original images . xxmaj and the final input images are resized to 192 $ \\ times$ 64 . \n",
              " \t \n",
              " \t xxmaj we compare our xxup scs network with conventional xxup lstm model and xxup cnn model . xxmaj the xxup scs structure is the same as the stand - alone model used in action recognition and the xxup lstm model adopts a xxup cnn backbone ( xxup vgg ) like xxunk \\ cite{donahue2015long } . xxmaj these two models both take a short driving video as the input and extract the temporal - spatial features . xxmaj while for xxup cnn model , we adopt the resnet~ \\ cite{he2016deep } structure , and it only takes the current driving image as input and utilizes spatial features to commit predicting . \n",
              " \t \n",
              " \t xxmaj this is a regression problem and the main goal $ g$ of the network is set to minimize the xxup mse of the predicted steering angles with the ground truth . xxmaj the same with the action recognition task , the spatial goal $ r_s$ is the same as the main goal and the temporal goal $ r_t$ is to estimate the optical flow . xxmaj we adopt sigmoid function to normalize the angles because the angles before normalization are more likely distributed around 0 and this non - linear function can , to some extent , make the distribution more uniform . xxmaj accuracy is used as the metric which is defined as : \n",
              " \t  \\ begin{align } \n",
              " \t xxmaj xxunk \\ frac { \\ xxunk \\ lfloor { \\ min ( \\ frac { \\ xxunk { \\ rm xxunk { \\ rm xxunk + \\ epsilon } , 1 ) } \\ xxunk } \n",
              " \t  \\ end{align } \n",
              " \t where $ xxup i$ is the number of the samples , $ \\ lambda$ is a threshold , and $ \\ epsilon$ is a small value to prevent the denominator from being zero . $ { \\ rm xxunk and $ { \\ rm xxunk are the predicted angle value and label angle value of sample $ i$. xxmaj in short , if the difference between predicted angle and label angle is less than the threshold , we treat it as an accurate prediction . \n",
              " \t \n",
              " \t xxmaj to predict the current driving direction , the models need to review a short history driving video ( except the xxup cnn model ) . xxmaj we adopt our xxup ltsc scheme when reviewing relative long history and we adopt xxup stsgd for the deep xxup scs networks . xxmaj we find that , adopting xxup ltsc to access more temporal information makes the model achieve better performances without increasing memory resources . xxmaj and xxup stsgd relatively improves the performances by 9 \\ % on average . xxmaj the detailed comparison results are shown in xxmaj tab.~ \\ ref{tab : drivingresult } . \n",
              " \t \n",
              " \t  \\ begin{table } [ ] \n",
              " \t\t \n",
              " \t\t  \\ xxunk - driving performance of xxup scs and baselines ( xxup cnn , xxup xxunk ) on the xxunk and livi - xxmaj set validation set . xxmaj note that ` ` $ \\ lambda$ \" denotes the angle threshold , ` ` p \" denotes the initial probability to stop the back - propagation in xxup stsgd and ` ` length \" denotes the number of observed frames . } \n",
              " \t\t  \\ renewcommand { \\ arraystretch}{1.2 } \n",
              " \t\t  \\ begin{center } \n",
              " \t\t\t  \\ footnotesize \n",
              " \t\t\t  \\ begin{tabular } { xxwrep 2 c| c } \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ xxunk model } \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ multicolumn{2}{c| } { } & \\ xxunk } & \\ xxunk } \\ \\ \n",
              " \t\t\t\t  \\ cline{3 - 8 } \n",
              " \t\t\t\t  \\ multicolumn{2}{c| } { } & $ \\ lambda$=6 & $ \\ lambda$=3 & xxup mse & $ \\ lambda$=6 & $ \\ lambda$=3 & xxup mse \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ xxunk } & p=0.0 & 31.8 & 16.9 & xxunk & xxunk & 15.9 & 0.049 \\ \\ \n",
              " \t\t\t\t & p=0.3 & 34.1 & 17.4 & xxunk & 30.5 & 16.1 & 0.048 \\ \\ \n",
              " \t\t\t\t & p=0.5 & \\ xxunk } & \\ xxunk } & \\ xxunk } & \\ xxunk } & \\ xxunk } & \\ xxunk } \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ xxunk } & p=0.0 & xxunk & 24.5 & 0.060 & 42.5 & 22.9 & 0.05 \\ \\ \n",
              " \t\t\t\t & p=0.3 & xxunk & \\ xxunk } & 0.043 & 46.9 & xxunk & 0.044 \\ \\ \n",
              " \t\t\t\t & p=0.5 & \\ xxunk } & 25.0 & \\ xxunk } & \\ xxunk } & \\ xxunk } & \\ xxunk } \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ xxunk } \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ multicolumn{2}{c| } { } & \\ xxunk } & \\ xxunk } \\ \\ \n",
              " \t\t\t\t  \\ cline{3 - 8 } \n",
              " \t\t\t\t  \\ multicolumn{2}{c| } { } & $ \\ lambda$=6 & $ \\ lambda$=3 & xxup mse & $ \\ lambda$=6 & $ \\ lambda$=3 & xxup mse \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ xxunk } & 29.2 & 15.9 & 0.052 & 27.3 & 14.5 & 0.057 \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ xxunk } & 43.1 & 23.8 & 0.056 & xxunk & xxunk & 0.058 \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ xxunk } \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ multicolumn{2}{c| } { } & \\ xxunk } & \\ multicolumn{3}{c } { } \\ \\ \n",
              " \t\t\t\t  \\ cline{3 - 5 } \n",
              " \t\t\t\t  \\ multicolumn{2}{c| } { } & $ \\ lambda$=6 & $ \\ lambda$=3 & xxup mse & \\ multicolumn{3}{c } { } \\ \\ \n",
              " \t\t\t\t  \\ cline{1 - 5 } \n",
              " \t\t\t\t  \\ xxunk } & 24.5 & 13.0 & 0.057 & \\ multicolumn{3}{c } { } \\ \\ \n",
              " \t\t\t\t  \\ xxunk } & xxunk & 25.3 & 0.056 & \\ multicolumn{3}{c } { } \\ \\ \n",
              " \t\t\t\t  \\ hline xxunk \\ end{tabular } \n",
              " \t\t  \\ end{center } \n",
              " \t\t  \\ label{tab : drivingresult } \n",
              " \t\t  \\ vspace{-0.2 in } \n",
              " \t  \\ end{table } \n",
              " \t \n",
              " \t xxmaj we adopt this experiment to show that our xxup scs can quantitatively indicate how important the temporal information is toward the final goal . xxmaj in this analysis , we set $ r_s$ and $ r_t$ to the same with the main goal . xxmaj by calculating the accuracy of $ \\ mathcal{t}^1 $ and $ \\ mathcal{t}^2 $ , we can determine the importance of temporal and spatial information in different road conditions . xxmaj the results shown in xxmaj tab.~ \\ ref{tab : xxunk } are consistent with our intuition : xxmaj on straight roads , $ \\ mathcal{t}^1 $ and $ \\ mathcal{t}^2 $ have similar performances , which reveals that the temporal information is not so important on this condition . xxmaj while on crossroads , $ \\ mathcal{t}^2 $ performs much better than $ \\ mathcal{t}^1 $ , which shows that we need more temporal information to give out steering angles . xxmaj on these four conditions , the performance gaps of $ \\ mathcal{t}^2 $ and $ \\ mathcal{t}^1 $ can be ordered as : straight roads \\ textless xxunk roads \\ textless t - xxunk \\ textless crossroads . xxmaj this is reasonable and proves that $ \\ mathcal{t}^2 $ and $ \\ mathcal{t}^1 $ focus on temporal and spatial information separately . xxmaj moreover , it preliminarily shows that how can we utilize this method to reveal the importance of temporal information on a specific sample . \n",
              " \t \n",
              " \t  \\ begin{table } [ ] \n",
              " \t\t \n",
              " \t\t  \\ caption{accuracy of $ \\ mathcal{t}^1 $ and $ \\ mathcal{t}^2 $ on livi . xxmaj comparing their performances , we can get the importance of temporal information on different road conditions . } \n",
              " \t\t  \\ renewcommand { \\ arraystretch}{1.2 } \n",
              " \t\t  \\ begin{center } \n",
              " \t\t\t  \\ footnotesize \n",
              " \t\t\t  \\ begin{tabular } { xxwrep 2 c| c } \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ multicolumn{2}{c| } { } & \\ multicolumn{2}{c|}{$ \\ mathcal{t}^1 $ } & \\ multicolumn{2}{c|}{$ \\ mathcal{t}^2 $ } & \\ multicolumn{2}{c}{$ \\ mathcal{t}^2 - \\ mathcal{t}^1 $ } \\ \\ \n",
              " \t\t\t\t  \\ cline{3 - 8 } \n",
              " \t\t\t\t  \\ multicolumn{2}{c| } { } & $ \\ lambda$=6 & $ \\ lambda$=3 & $ \\ lambda$=6 & $ \\ lambda$=3 & $ \\ lambda$=6 & $ \\ lambda$=3 \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ multirow{4 } { * } { \\ xxunk } } & xxmaj crossroads & 18.3 & 10.2 & 29.1 & 16.3 & 10.8 & 6.1 \\ \\ \n",
              " \t\t\t\t & t - junction & xxunk & 12.6 & xxunk & 17.0 & 8.8 & 4.4 \\ \\ \n",
              " \t\t\t\t & xxmaj curve road & xxunk & 17.1 & 37.6 & 20.1 & 4.7 & 3.0 \\ \\ \n",
              " \t\t\t\t & xxmaj straight road & 39.1 & xxunk & 41.7 & 21.4 & 2.6 & 0.4 \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t  \\ end{tabular } \n",
              " \t\t  \\ end{center } \n",
              " \t\t  \\ label{tab : xxunk } \n",
              " \t  \\ end{table } \n",
              " \t \n",
              " \t  \\ xxunk forecasting experiments } \n",
              " \t  \\ begin{table } [ ] \n",
              " \t\t \n",
              " \t\t  \\ caption{performance on the xxup reec-2018 validation set . xxmaj note that ` ` p \" denotes the initial probability to stop the back - propagation in xxup stsgd . } \n",
              " \t\t  \\ renewcommand { \\ arraystretch}{1.2 } \n",
              " \t\t  \\ begin{center } \n",
              " \t\t\t  \\ footnotesize \n",
              " \t\t\t  \\ begin{tabular } { xxwrep 2 c| c } \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ xxunk } & xxup mse & xxup xxunk & xxup far & xxup xxunk & xxup cor \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ xxunk \\ cite{xingjian2015convolutional } } & xxunk & xxunk & xxunk & xxunk & xxunk \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ xxunk } & p=0.0 & xxunk & xxunk & xxunk & \\ xxunk } & xxunk \\ \\ \n",
              " \t\t\t\t & p=0.3 & xxunk & xxunk & xxunk & xxunk & \\ xxunk } \\ \\ \n",
              " \t\t\t\t & p=0.5 & \\ xxunk } & \\ xxunk } & \\ xxunk } & xxunk & \\ xxunk } \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t  \\ end{tabular } \n",
              " \t\t  \\ end{center } \n",
              " \t\t  \\ label{tab : precipitationresult } \n",
              " \t\t  \\ vspace{-0.2 in } \n",
              " \t  \\ end{table } \n",
              " \t \n",
              " \t xxmaj the composite reflectance ( xxup cr ) image received by the weather radar can reflect the precipitation situation in the specific area . xxmaj by predicting the morphological changes of xxup cr in the future we can forecast the precipitation . xxmaj in this task , the models take a short period of the xxup cr images as the input and generate the future xxup cr images . xxmaj the experiments are conducted on our xxup reec-2018 dataset which contains a set of xxup cr images of xxmaj eastern xxmaj china in 2018 and the xxup cr image is recorded every 6 minutes . xxmaj for better prediction , we select the top 100 rainy days from the dataset and crop a 224 $ \\ times$ 244 pixel region as our input images . xxmaj for preprocessing , we normalize the intensity value $ xxup z$ of each pixel to $ xxup z'$ by setting $ xxup xxunk \\ xxunk \\ min ( \\ { xxmaj z_i \\ } ) } { \\ max ( \\ { xxmaj z_i \\ } ) - \\ min ( \\ { xxmaj z_i \\ } ) } $ , where $ \\ { xxmaj z_i \\ } $ is the set of intensity values of all the pixels in the input image . \n",
              " \t \n",
              " \t xxmaj in this task , we compare our xxup scs network with the convlstm network . xxmaj both of them consist of an encoder and a decoder which have the same structure . xxmaj for our model , the encoder and the decoder are 15-layer xxup scs networks while there are multi - stacked xxunk in the convlstm version . xxmaj encoders take one frame in the xxup cr sequence as input for every time - stamp and then generate the intermediate representation of the observed sequence . xxmaj decoders take the intermediate representation as well as the last xxup cr image as input and generate the xxup cr image prediction and new intermediate representation as shown in xxmaj fig.~ \\ ref{fig : experiments } d. \n",
              " \t \n",
              " \t  \\ begin{table * } [ ] \n",
              " \t\t  \\ caption{hyper - parameter settings for action recognition , outline annotation , auto driving and precipitation forecasting experiments . } \n",
              " \t\t  \\ renewcommand { \\ arraystretch}{1.2 } \n",
              " \t\t  \\ begin{center } \n",
              " \t\t\t  \\ footnotesize \n",
              " \t\t\t  \\ begin{tabular } { xxwrep 2 c| c } \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t  \\ multirow{2 } { * } { } & \\ xxunk xxmaj recognition } & \\ xxunk xxmaj annotation } & \\ xxunk xxmaj driving } & \\ xxunk xxmaj forecasting } \\ \\ \n",
              " \t\t\t\t  \\ cline{2 - 9 } \n",
              " \t\t\t\t & xxup bb supported & xxmaj stand - alone & xxup lstm & xxup scs & xxup xxunk & xxup scs & convlstm & xxup scs \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t\t xxmaj batch size & 16 & 40 & 8 & 4 & 128 & 128 & 8 & 4 \\ \\ \n",
              " \t\t\t\t xxmaj learning rate & 1e-4 & 1e-4 & 1e-4 & 2e-4 & 2e-4 & 1e-4 & 1e-4 & 1e-4 \\ \\ \n",
              " \t\t\t\t xxmaj backbone & \\ { xxup vgg , xxmaj inception \\ } & - & xxup vgg & xxup vgg & xxunk \\ cite{he2016deep } & - & - & - \\ \\ \n",
              " \t\t\t\t xxmaj num . layers & xxup bb layers + 15 & 17 & \\ { 2,5 10 , 15 \\ } & \\ { 2,5 10 , 15 \\ } & 18 + 1 & 15 & 15 & 15 \\ \\ \n",
              " \t\t\t\t xxmaj training method & xxup stsgd & xxup stsgd & - & xxup stsgd & xxup xxunk & - & xxup astsgd \\ \\ \n",
              " \t\t\t\t xxup ltsc setting & $ 10 \\ times 7 $ & $ 5 \\ xxunk $ & - & $ 10 \\ times 4 $ & - & - & - & - \\ \\ \n",
              " \t\t\t\t xxmaj feature dimension & 512 & 512 & 256 & 256 & 512 & 512 & 64 & 128 \\ \\ \n",
              " \t\t\t\t $ \\ lambda$ & - & - & - & - & \\ { 3 , 6 \\ } & \\ { xxunk \\ } & - & - \\ \\ \n",
              " \t\t\t\t  \\ hline \n",
              " \t\t\t  \\ end{tabular } \n",
              " \t\t  \\ end{center } \n",
              " \t\t  \\ label{tab : hyperparameter } \n",
              " \t\t  \\ vspace{-0.2 in } \n",
              " \t  \\ end{table * } \n",
              " \t \n",
              " \t xxmaj this is a regression problem and every pixel of xxup cr image represents the reflectance intensity of a specific geographic position . xxmaj the networks are trained under the xxup mse loss function ( the main goal $ g$ is the xxup mse loss ) . xxmaj the spatial goal $ r_s$ is the same as the main goal . xxmaj the temporal goal $ r_t$ is to estimate the optical flow and pixel - wise difference between frames since every pixel has its own independent meaning : the reflectance intensity of that location . xxmaj the optical flow guides $ \\ mathcal{t}^2 $ to learn the variation of wind direction while the pixel - wise difference is designed for the local precipitation changes . xxmaj we evaluate the models using several metrics following~ \\ cite{xingjian2015convolutional } , namely , mean squared error ( xxup mse ) , critical success index ( xxup xxunk ) , false alarm rate ( xxup far ) , probability of detection ( xxup xxunk ) and correlation . xxmaj since every pixel has stand - alone meaning , we evaluate the performance at pixel level . xxmaj we convert the prediction and the label to a 0 / 1 matrix using a threshold of 0.5 and define ` ` hit \" ( prediction = xxunk ) , ` ` miss \" ( xxunk , xxunk ) , ` ` falsealarm \" ( xxunk , label = 0 ) . xxmaj then the metrics are defined as : \n",
              " \t  \\ begin{align } \n",
              " \t & { \\ rm xxup xxunk \\ frac { \\ # { \\ rm hit } } { { \\ rm \\ # hit } + { \\ rm \\ # miss } + { \\ rm \\ # falsealarm } } \\ \\ \n",
              " \t & { \\ rm xxup xxunk \\ frac { { \\ rm \\ # falsealarm } } { { \\ rm \\ # xxunk { \\ rm \\ # falsealarm } } \\ \\ \n",
              " \t & { \\ rm xxup xxunk \\ frac { { \\ rm \\ # hit } } { { \\ rm \\ # xxunk { \\ rm \\ # miss } } \\ \\ \n",
              " \t & { \\ rm xxunk \\ frac { \\ sum_{i , j } { { \\ rm xxup cr \\ _ xxmaj p}_{i , j } \\ times { \\ rm xxup cr \\ _ xxmaj xxunk , j } } } { \\ sqrt { ( \\ sum_{i , j } { { \\ rm xxup cr \\ _ xxmaj p}_{i , j}^2 } ) ( \\ sum_{i , j } { { \\ rm xxup cr \\ _ xxmaj xxunk , xxunk \\ epsilon } } \n",
              " \t  \\ end{align } \n",
              " \t where $ { \\ rm xxup cr \\ _ xxup p}$ is the predicted xxup cr image and $ { \\ rm xxup cr \\ _ xxmaj p}_{i , j}$ is the 0 / 1 value of position ( i , j ) in the xxup cr image . $ { \\ rm xxup cr \\ _ xxup l}$ is the ground - truth xxup cr image , i.e. the label . \n",
              " \t \n",
              " \t xxmaj the models take 5 xxup cr images as input and predict 5 future images . xxmaj this is not a long sequence , so we do not adopt the xxup ltsc scheme . xxup stsgd is utilized in the deep xxup scs network . xxmaj with a higher initial $ p$ , the model achieves better performance ( see details in xxmaj tab.~ \\ ref{tab : precipitationresult } ) , which indicates the important role of xxup stsgd for xxup scs . xxmaj the detailed comparison results are shown in xxmaj tab.~ \\ ref{tab : precipitationresult } . \n",
              " \t \n",
              " \t \n",
              " \t \n",
              " \t  \\ subsection{optimization } \n",
              " \t xxmaj the hyper - parameters are selected from grid searches and are listed in xxmaj tab.~ \\ ref{tab : hyperparameter } . xxmaj for all the experiments , the xxup cnn layer is initialized with the ` ` xxmaj xavier initialization \" method followed by xxmaj batch xxmaj normalization layer~ \\ xxunk } . xxmaj all networks are trained using xxmaj adam optimizer~ \\ cite{kingma2014adam } and the xxunk are pre - trained on imagenet . xxmaj for the huge memory consumption of the long sequential vision tasks , the batch size of each training step is relative small and we accumulate the parameters ' gradients of several training steps , then update the parameters together , which can speed up the training process to some extent . xxmaj in the process of back - propagation - through - time ( xxup xxunk \\ xxunk } , the gradients of xxup rnn parameters was clipped to the range [ -5 , 5 ] . xxunk \\ section{data availability } \n",
              " \t xxmaj the data that support the plots within this paper are available from the corresponding author upon reasonable request . \n",
              " \t \n",
              " \t  \\ xxunk availability } \n",
              " \t a public version of the experiment codes will be made available with this paper , linked to from our website \\ href{http : / / xxunk : / / xxunk } and \\ href{https : / / github.com / xxunk / xxmaj semi - xxmaj coupled - xxmaj structure - for - visual - xxunk - xxunk website } . \n",
              " \t \n",
              " \t  \\ xxunk } \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup d. , xxmaj ling , xxup h. , xxmaj xxunk , a \\ & xxmaj xxunk , xxup s. \n",
              " \t\t xxmaj efficient xxmaj interactive xxmaj annotation of xxmaj segmentation xxmaj datasets xxmaj with xxmaj polygon - xxup rnn++ . \n",
              " \t\t xxmaj in \\ textit{ieee xxmaj conf . xxmaj comp . xxmaj vision and xxmaj pattern xxmaj recog . } xxunk - xxunk ( 2018 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup l. , xxmaj xxunk , xxup xxunk , \\ & xxmaj xxunk , xxup j. \n",
              " \t\t xxmaj optimization methods for large - scale machine learning . \n",
              " \t\t  \\ xxunk xxmaj review } \\ xxunk } , 223 - xxunk ( 2018 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup j. \\ & xxmaj zisserman , xxup a. \n",
              " \t\t xxmaj quo xxunk , action recognition ? a new model and the kinetics dataset . \n",
              " \t\t xxmaj in \\ textit{ieee xxmaj conf . xxmaj comp . xxmaj vision and xxmaj pattern xxmaj recog . } xxunk - xxunk ( 2017 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup l. , xxmaj xxunk , xxup k. , xxmaj xxunk , xxup r. \\ & xxmaj xxunk , xxup s. \n",
              " \t\t xxmaj annotating xxmaj object xxmaj instances with a xxmaj polygon - xxup rnn . \n",
              " \t\t xxmaj in \\ textit{ieee xxmaj conf . xxmaj comp . xxmaj vision and xxmaj pattern xxmaj recog . } 2 ( 2017 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj chen , xxup y. et al . \n",
              " \t\t xxmaj lidar - video driving dataset : xxmaj learning driving policies effectively . \n",
              " \t\t xxmaj in \\ textit{ieee xxmaj conf . xxmaj comp . xxmaj vision and xxmaj pattern xxmaj recog . } xxunk - xxunk ( 2018 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup m. et al . \n",
              " \t\t xxmaj the cityscapes dataset for semantic urban scene understanding . \n",
              " \t\t xxmaj in \\ textit{ieee xxmaj conf . xxmaj comp . xxmaj vision and xxmaj pattern xxmaj recog . } xxunk - xxunk ( 2016 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup i. et al . \n",
              " \t\t a novel brain partition highlights the modular skeleton shared by structure and function . \n",
              " \t\t  \\ xxunk reports } \\ textbf{5 } , xxunk ( 2015 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup j. et al . \n",
              " \t\t xxmaj long - term recurrent convolutional networks for visual recognition and description . \n",
              " \t\t xxmaj in \\ textit{ieee xxmaj conf . xxmaj comp . xxmaj vision and xxmaj pattern xxmaj recog . } xxunk - xxunk ( 2015 ) . \n",
              " \t\t \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup c. , xxmaj fan , xxup h. , xxmaj malik , xxup j. \\ & xxmaj he , xxup k. \n",
              " \t\t slowfast networks for video recognition . \n",
              " \t\t xxmaj in \\ textit{ieee xxmaj int . xxmaj conf . xxmaj comp . xxmaj vision } xxunk - xxunk ( 2019 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxunk , xxup a. \\ & xxmaj zisserman , xxup a. \n",
              " \t\t xxmaj convolutional two - stream network fusion for video action recognition . \n",
              " \t\t xxmaj in \\ textit{ieee xxmaj conf . xxmaj comp . xxmaj vision and xxmaj pattern xxmaj recog . } xxunk - xxunk ( 2016 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup r. , xxmaj xxunk , xxup j. , xxmaj xxunk , xxup c. \\ & xxmaj zisserman , xxup a. \n",
              " \t\t xxmaj video action transformer network . \n",
              " \t\t xxmaj in \\ textit{ieee xxmaj conf . xxmaj comp . xxmaj vision and xxmaj pattern xxmaj recog . } 244 - xxunk ( 2019 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj graves , xxup a. \n",
              " \t\t xxmaj generating sequences with recurrent neural networks . \n",
              " \t\t xxmaj preprint at https : / / arxiv.org / abs / xxunk ( 2013 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj gu , xxup c. et al . \n",
              " \t\t xxup ava : a video dataset of spatio - temporally localized atomic visual actions . \n",
              " \t\t xxmaj in \\ textit{ieee xxmaj conf . xxmaj comp . xxmaj vision and xxmaj pattern xxmaj recog . } xxunk - xxunk ( 2018 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj he , xxup k. , xxmaj xxunk , xxup g. , xxmaj xxunk { \\ ' xxunk , xxup p. \\ & xxmaj xxunk , xxup r. \n",
              " \t\t xxmaj mask r - cnn . \n",
              " \t\t xxmaj in \\ textit{ieee xxmaj int . xxmaj conf . xxmaj comp . xxmaj vision } xxunk - xxunk ( 2017 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj he , xxup k. , xxmaj zhang , xxup x. , xxmaj ren , xxup s. \\ & xxmaj sun , xxup j. \n",
              " \t\t xxmaj deep residual learning for image recognition . \n",
              " \t\t xxmaj in \\ textit{ieee xxmaj conf . xxmaj comp . xxmaj vision and xxmaj pattern xxmaj recog . } xxunk - xxunk ( 2016 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup s. \\ & xxmaj schmidhuber , xxup j. \n",
              " \t\t xxmaj long short - term memory . \n",
              " \t\t  \\ xxunk xxmaj computation } \\ xxunk } , xxunk - xxunk ( 1997 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup r. , xxmaj chen , xxup c. \\ & xxmaj shah , xxup m. \n",
              " \t\t xxmaj tube convolutional neural network ( t - xxup cnn ) for action detection in videos . \n",
              " \t\t xxmaj in \\ textit{ieee xxmaj int . xxmaj conf . xxmaj comp . xxmaj vision } xxunk - xxunk ( 2017 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup s. \\ & xxmaj xxunk , xxup c. \n",
              " \t\t xxmaj batch normalization : xxmaj accelerating deep network training by reducing internal covariate shift . \n",
              " \t\t xxmaj in \\ textit{int . xxmaj conf . xxmaj machine xxmaj learning } xxunk - xxunk ( 2015 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj ji , xxup s. , xxmaj xu , xxup w. , xxmaj yang , xxup m. \\ & xxmaj yu , xxup k. \n",
              " \t\t xxup 3d convolutional neural networks for human action recognition . \n",
              " \t\t  \\ textit{ieee xxmaj trans . xxmaj pattern xxmaj analysis and xxmaj machine xxmaj intel . } \\ xxunk } , 221 - xxunk ( 2013 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj karpathy , xxup a. et al . \n",
              " \t\t xxmaj large - scale video classification with convolutional neural networks . \n",
              " \t\t xxmaj in \\ textit{ieee xxmaj conf . xxmaj comp . xxmaj vision and xxmaj pattern xxmaj recog . } xxunk - xxunk ( 2014 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj kim , xxup j. , xxmaj el - xxmaj xxunk , xxup m. \\ & xxmaj lee , xxup j. \n",
              " \t\t xxmaj residual xxup lstm : xxmaj design of a deep recurrent architecture for distant speech recognition . \n",
              " \t\t xxmaj in \\ xxunk . xxmaj int . xxmaj speech xxmaj xxunk . xxmaj xxunk . } xxunk - xxunk ( 2017 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj kingma , xxup d. \\ & xxmaj ba , xxup j. \n",
              " \t\t xxmaj adam : a method for stochastic optimization . \n",
              " \t\t xxmaj in \\ textit{int . xxmaj conf . xxmaj learning xxmaj representations } ( 2015 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup t. et al . \n",
              " \t\t xxmaj xxunk cortical xxunk cells encode specific contexts and drive context - specific fear memory . \n",
              " \t\t  \\ xxunk } \\ xxunk } , xxunk - xxunk ( 2015 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup a. , xxmaj sutskever , xxup i. \\ & xxmaj hinton , xxup g. \n",
              " \t\t xxmaj imagenet classification with deep convolutional neural networks . \n",
              " \t\t xxmaj in \\ textit{ann . xxmaj conf . xxmaj neural xxmaj inform . xxmaj proc . xxmaj sys . } xxunk - xxunk ( 2012 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup h. , xxmaj xxunk , xxup h. , xxmaj xxunk , xxup e. , xxmaj poggio , xxup t. \\ & xxmaj xxunk , xxup t. \n",
              " \t\t xxup xxunk : a large video database for human motion recognition . \n",
              " \t\t xxmaj in \\ textit{ieee xxmaj int . xxmaj conf . xxmaj comp . xxmaj vision } xxunk - xxunk ( 2011 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj levine , xxup s. , xxmaj finn , xxup c. , xxmaj darrell , xxup t. \\ & xxmaj abbeel , xxup p. \n",
              " \t\t xxmaj end - to - end training of deep visuomotor policies . \n",
              " \t\t  \\ xxunk xxmaj machine xxmaj learning xxmaj research } \\ xxunk } , 1334 - xxunk ( 2016 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj lucas , xxup xxunk \n",
              " \t\t  \\ xxunk image matching by the method of differences } ( 1986 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup s. , xxmaj xxunk , xxup l. \\ & xxmaj malik , xxup j. \n",
              " \t\t xxmaj action recognition from a distributed representation of pose and appearance . \n",
              " \t\t xxmaj in \\ textit{ieee xxmaj conf . xxmaj comp . xxmaj vision and xxmaj pattern xxmaj recog . } xxunk - xxunk ( 2011 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup m. , xxmaj xxunk , xxup g. \\ & xxmaj xxunk , xxup c. \n",
              " \t\t xxmaj spatial -- temporal interactions in the human brain . \n",
              " \t\t  \\ xxunk xxmaj brain xxmaj research } \\ xxunk } , xxunk - xxunk ( 2009 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup b. , xxmaj zha , xxup k. , xxmaj cao , xxup h. , xxmaj shi , xxup c. \\ & xxmaj lu , xxup c. \n",
              " \t\t xxmaj deep xxup rnn xxmaj framework for xxmaj visual xxmaj sequential xxmaj applications . \n",
              " \t\t xxmaj in \\ textit{ieee xxmaj conf . xxmaj comp . xxmaj vision and xxmaj pattern xxmaj recog . } 423 - xxunk ( 2019 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup xxunk et al . \n",
              " \t\t xxmaj learning representations by back - propagating errors . \n",
              " \t\t  \\ textit{cognitive modeling } \\ textbf{5 } 1 ( 1988 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup e. \\ & xxmaj xxunk , xxup g. \n",
              " \t\t xxmaj learning a driving simulator . \n",
              " \t\t xxmaj preprint at https : / / arxiv.org / abs / xxunk ( 2016 ) . \n",
              " \t\t \n",
              " \t\t  \\ bibitem{schulman2015trust } \n",
              " \t\t xxmaj schulman , xxup j. , xxmaj levine , xxup s. , xxmaj abbeel , xxup p. , xxmaj jordan , xxup m. \\ & xxmaj moritz , xxup p. \n",
              " \t\t xxmaj trust xxmaj region xxmaj policy xxmaj optimization . \n",
              " \t\t xxmaj in \\ textit{int . xxmaj conf . xxmaj machine xxmaj learning } 1889 - -1897 ( 2015 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj simonyan , xxup k. \\ & xxmaj zisserman , xxup a. \n",
              " \t\t xxmaj two - stream convolutional networks for action recognition in videos . \n",
              " \t\t xxmaj in \\ textit{ann . xxmaj conf . xxmaj neural xxmaj inform . xxmaj proc . xxmaj sys . } 568 - xxunk ( 2014 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj simonyan , xxup k. , xxmaj zisserman , xxup a. \n",
              " \t\t xxmaj very deep convolutional networks for large - scale image recognition . \n",
              " \t\t xxmaj in \\ textit{int . xxmaj conf . xxmaj learning xxmaj representations } ( 2015 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj song , xxup s. , xxmaj lan , xxup c. , xxmaj xxunk , xxup j. , xxmaj zeng , xxup w. \\ & xxmaj liu , xxup j. \n",
              " \t\t xxmaj an end - to - end spatio - temporal attention model for human action recognition from skeleton data . \n",
              " \t\t xxmaj in \\ xxunk xxmaj conf . xxmaj art . xxmaj intel . } xxunk - xxunk ( 2017 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup k. , xxmaj xxunk , xxup xxunk \\ & xxmaj shah , xxup m. \n",
              " \t\t xxup xxunk : a dataset of 101 human actions classes from videos in the wild . \n",
              " \t\t xxmaj preprint at https : / / arxiv.org / abs / xxunk ( 2012 ) . \n",
              " \t\t \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup n. , xxmaj xxunk , xxup e. \\ & xxmaj xxunk , xxup r. \n",
              " \t\t xxmaj unsupervised learning of video representations using lstms . \n",
              " \t\t xxmaj in \\ textit{int . xxmaj conf . machine learning } 843 - xxunk ( 2015 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj sutskever , xxup i. , xxmaj vinyals , xxup o. \\ & xxmaj le , xxup xxunk \n",
              " \t\t xxmaj sequence to sequence learning with neural networks . \n",
              " \t\t xxmaj in \\ textit{ann . xxmaj conf . xxmaj neural xxmaj inform . xxmaj proc . xxmaj sys . } xxunk - xxunk ( 2014 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup c. et al . \n",
              " \t\t xxmaj going deeper with convolutions . \n",
              " \t\t xxmaj in \\ textit{ieee xxmaj conf . xxmaj comp . xxmaj vision and xxmaj pattern xxmaj recog . } 1 - -9 ( 2015 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj wang , xxup h. , xxmaj xxunk , xxup a. , xxmaj schmid , xxup c. \\ & xxmaj liu xxup c. \n",
              " \t\t xxmaj action recognition by dense trajectories . \n",
              " \t\t xxmaj in \\ textit{ieee xxmaj conf . xxmaj comp . xxmaj vision and xxmaj pattern xxmaj recog . } xxunk - xxunk ( 2011 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj wang , xxup h. , xxmaj xxunk , xxup a. , xxmaj schmid , xxup c. \\ & xxmaj liu , xxup c. \n",
              " \t\t xxmaj dense trajectories and motion boundary descriptors for action recognition . \n",
              " \t\t  \\ textit{int . xxup j. xxmaj comp . xxmaj vision } \\ textbf{103 } , 60 - xxunk ( 2013 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj wang , xxup l. , xxmaj xxunk , xxup y. , xxmaj tang , xxup x. \\ & xxmaj van xxup xxunk \n",
              " \t\t xxmaj xxunk estimation using hybrid fully convolutional networks . \n",
              " \t\t  \\ textit{ieee xxmaj conf . xxmaj comp . xxmaj vision and xxmaj pattern xxmaj recog . } xxunk - xxunk ( 2016 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup p. , xxmaj xxunk , xxup z. \\ & xxmaj schmid , xxup c. \n",
              " \t\t xxmaj learning to track for spatio - temporal action localization . \n",
              " \t\t xxmaj in \\ textit{ieee xxmaj int . xxmaj conf . xxmaj comp . xxmaj vision } xxunk - xxunk ( 2015 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup xxunk et al . \n",
              " \t\t xxmaj backpropagation through time : what it does and how to do it . \n",
              " \t\t  \\ textit{proceedings of the xxup ieee } \\ xxunk } , xxunk - xxunk ( 1990 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj williams , xxup xxunk \\ & xxmaj peng , xxup j. \n",
              " \t\t xxmaj an efficient gradient - based algorithm for on - line training of recurrent network trajectories . \n",
              " \t\t  \\ xxunk xxmaj computation } \\ textbf{2 } , 490 - xxunk ( 1990 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj xxunk , xxup d. \n",
              " \t\t a xxunk of two halves . \n",
              " \t\t  \\ xxunk } \\ xxunk } , 260 - xxunk ( 2012 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj wu , xxup c. et al . \n",
              " \t\t xxmaj long - term feature banks for detailed video understanding . \n",
              " \t\t xxmaj in \\ textit{ieee xxmaj conf . xxmaj comp . xxmaj vision and xxmaj pattern xxmaj recog . } 284 - xxunk ( 2019 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj wu , xxup z. , xxmaj wang , xxup x. , xxmaj jiang , xxup y. , xxmaj ye , xxup h. \\ & xxmaj xxunk , xxup x. \n",
              " \t\t xxmaj modeling spatial - temporal clues in a hybrid deep learning framework for video classification . \n",
              " \t\t xxmaj in \\ xxunk xxmaj int . xxmaj conf . xxmaj multimedia } xxunk - xxunk ( 2015 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj shi , xxup x. et al . \n",
              " \t\t xxmaj convolutional xxup lstm network : a machine learning approach for precipitation xxunk . \n",
              " \t\t xxmaj in \\ textit{ann . xxmaj conf . xxmaj neural xxmaj inform . xxmaj proc . xxmaj sys . } xxunk - xxunk ( 2015 ) . \n",
              " \t\t \n",
              " \t\t  \\ xxunk } \n",
              " \t\t xxmaj yue - xxmaj xxunk xxup xxunk et al . \n",
              " \t\t xxmaj beyond short snippets : xxmaj deep networks for video classification . \n",
              " \t\t xxmaj in \\ textit{ieee xxmaj conf . xxmaj comp . xxmaj vision and xxmaj pattern xxmaj recog . } xxunk - xxunk ( 2015 ) . xxunk \\ end{thebibliography } xxunk \\ xxunk contributions } \n",
              " \t xxup b.p. and xxup c.l. conceived the idea . xxup b.p. , xxup xxunk and xxup c.l. designed the experiments . xxup b.p. , xxup xxunk , xxup xxunk , xxup xxunk and xxup xxunk carried out programming , adjustment , and data analysis . xxup b.p. and xxup c.l. wrote the manuscript . xxup b.p. , xxup xxunk , xxup xxunk and all other authors contributed to the results analysis and commented on the manuscript . \n",
              " \t \n",
              " \t  \\ xxunk xxmaj interests } \n",
              " \t xxmaj the authors declare no competing interests . \n",
              "  \\ end{document } \n",
              " ,xxbos \\ documentclass{article } \n",
              "  \\ usepackage{fontenc , xxunk , calc , indentfirst , xxunk , graphicx , xxunk , ifthen , lineno , float , amsmath , xxunk , xxunk , booktabs , xcolor , microtype , tikz , amsthm , hyperref , url , geometry , xxunk , caption } \n",
              "  \\ usepackage[square , numbers]{natbib } \n",
              "  \\ usepackage{subcaption , bm } \n",
              "  \\ usepackage{xcolor } \n",
              " \n",
              "  \\ xxunk - xxmaj directed xxmaj planning for xxmaj habituated xxmaj agents by xxmaj active xxmaj inference xxmaj using a xxmaj variational xxmaj recurrent xxmaj neural xxmaj network } \n",
              " \n",
              "  \\ xxunk xxmaj xxunk $ \\ and xxmaj jun xxmaj xxunk } \n",
              " \n",
              "  \\ date { \\ small $ xxunk xxmaj institute of xxmaj science and xxmaj technology , \\ xxunk } \\ \\ \n",
              "  $ xxunk xxmaj institute of xxmaj science and xxmaj technology , \\ xxunk } \\ \\ \n",
              "  $ xxunk author } \n",
              " \n",
              "  \\ begin{document } \n",
              "  \\ maketitle \n",
              "  xxrep 42 % \n",
              "  \\ section*{abstract } \n",
              "  xxmaj it is crucial to ask how agents can achieve goals by generating action plans using only partial models of the world acquired through habituated sensory - motor experiences . xxmaj although many existing robotics studies use a forward model framework , there are generalization issues with high degrees of freedom . xxmaj the current study shows that the predictive coding ( xxup pc ) and active inference ( xxup aif ) frameworks , which employ a generative model , can develop better generalization by learning a prior distribution in a low dimensional latent state space representing probabilistic structures extracted from well habituated sensory - motor trajectories . xxmaj in our proposed model , learning is carried out by inferring optimal latent variables as well as synaptic weights for maximizing the evidence lower bound , while goal - directed planning is accomplished by inferring latent variables for maximizing the estimated lower bound . xxmaj our proposed model was evaluated with both simple and complex robotic tasks in simulation , which demonstrated sufficient generalization in learning with limited training data by setting an intermediate value for a regularization coefficient . xxmaj furthermore , comparative simulation results show that the proposed model outperforms a conventional forward model in goal - directed planning , due to the learned prior xxunk the search of motor plans within the range of habituated trajectories . \n",
              " \n",
              "  \\ xxunk : goal directed planning ; active inference ; predictive coding ; variational xxmaj bayes ; recurrent neural network } \n",
              " \n",
              "  xxrep 42 % \n",
              "  \\ section{introduction } \n",
              "  xxmaj it is generally assumed that agents can never access or acquire complete models of the world which they are interacting with \\ xxunk , xxunk } . xxmaj this is because the amount of experience accumulated by interacting with the world in a finite time is limited , and usually the world itself is also dynamically changing . xxmaj under such conditions , agents with higher cognitive capability , such as humans , seem to be able to generate feasible goal - directed actions by mentally imaging possible behavioral plans using only partially developed models of the world , learning from limited experiences of interaction with the world . \n",
              " \n",
              "  xxmaj how is this possible ? xxmaj in addressing this problem , the current paper proposes a novel model for goal - directed plan generation referred to as goal - directed latent variable inference ( glean ) , based on learning by leveraging two related frameworks , \\ emph{predictive coding } ( xxup pc ) \\ xxunk , xxunk , xxunk , xxunk , xxunk , xxunk , xxunk } and \\ emph{active inference } ( xxup aif ) \\ xxunk , xxunk , xxunk , xxunk , xxunk , xxunk } . xxmaj in particular , we attempt to show that agents can generate adequate goal - directed behaviors based on learning in the habituated range of the world by conducting simulation studies on the proposed model . \n",
              " \n",
              "  xxmaj in brain modeling studies , it has long been considered that the brain uses an internal generative model to predict sensory outcomes of its own actions . xxmaj in this scenario , the fit between the model 's prediction and the actual sensation can be improved in two ways . xxmaj the first is by adapting belief or intention represented by the internal state of the generative model so that the reconstruction error can be minimized \\ xxunk , xxunk , xxunk , xxunk } . xxmaj this corresponds to perception . xxmaj the second approach is by acting on the environment in a manner such that the resultant sensation can better fit with the model 's prediction \\ xxunk , xxunk , xxunk } . xxmaj the former idea has been formulated in terms of xxup pc and the latter by xxup aif . xxmaj however , these two frameworks should be considered in xxunk as perception and action are effectively two sides of the same coin in xxunk cognition . \n",
              " \n",
              "  xxmaj originally , the idea of an internal model for sensory - motor systems was investigated in the study of the forward model ( xxup fm ) \\ xxunk , xxunk , xxunk } ( see xxmaj figure \\ ref{fig : xxunk } ) . xxmaj although both xxup fm and xxup pc can predict the next latent state and associated sensory inputs , different types of conditioning on the prediction were considered . xxmaj in xxup fm , the predicted sensory state is conditioned by the current motor commands and the current latent state , while in xxup pc it is conditioned only by the current latent state . xxmaj in theory , it is possible to infer optimal motor commands for achieving desired states using xxup fm by considering additional cost functions such as xxunk minimization , torque minimization , trajectory distance minimization etc . \\ xxunk } . xxmaj in practice , however , this inference tends to produce erroneous solutions unless the predictive model learns the outcomes for all possible motor combinations , which is intractable when the motor component has a high degree of freedom . \n",
              " \n",
              "  \\ begin{figure}[!htbp ] \n",
              "  \\ centering \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.4 \\ textwidth]{figures / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : pcaif_s } } { \\ includegraphics[width=0.4 \\ textwidth]{figures / xxup pcaif_s } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ vspace{1em } \n",
              "  \\ caption { \\ textbf{(a ) } xxmaj the forward model and \\ textbf{(b ) } the predictive coding and active inference framework where $ xxunk and $ xxunk represent the current latent state and prediction of the next sensory state in terms of the exteroception and proprioception . xxmaj the predicted proprioception can then be converted into a motor control signal as necessary , such as by using an inverse model as depicted in \\ textbf{(b ) } . } \n",
              "  \\ end{figure } \n",
              " \n",
              "  xxmaj however , this may not be the case if the xxup pc and xxup aif frameworks are used in combination as shown in xxmaj figure \\ ref{fig : pcaif_s } . xxmaj in the xxup pc component , an internal model predicts both the latent state and sensory inputs in terms of the exteroception and proprioception in the next timestep by receiving the current latent state . xxmaj it can be considered that the sensory sequences are embedded in the latent state space through iterative predictive learning . xxmaj in the xxup aif component , an inverse model can be used to map the predicted sensory inputs to motor commands which can realize the predicted sensation . xxmaj such an inverse model can be implemented in a straightforward manner by , for example , a xxup pid controller wherein the necessary motor torque to generate expected movements in terms of position and velocity can be computed through error feedback between the predicted proprioception ( for e.g. , joint angles in a robot ) and the outcome . \n",
              " \n",
              "  xxmaj given a desired state to be achieved , the optimal motor command at the next timestep can be obtained by first inferring an optimal latent state in the current timestep which can generate the best fit with the desired state with the minimal error . xxmaj the obtained latent state in the current timestep is mapped to the sensory state of the proprioception and exteroception expected in the next timestep , and the proprioception is finally mapped to a motor command by the inverse model . \n",
              " \n",
              "  xxmaj if we assume that agents act on their environment not through all possible combinations of motor command sequences but only a subset of them in terms of habituated trajectories , the effective dimensionality of the sensory space can be reduced drastically . xxmaj this also results in significant reduction in the required dimensionality of the latent state space which embeds the sensory sequences through learning . \n",
              " \n",
              "  xxmaj consequently , the problem of motor planning for achieving a desired state could become tractable when the inference for an optimal latent state can be limited in its relatively low dimensional space . xxmaj the same , however , can not be applied in the case of xxup fm as the search for an optimal motor plan can not be constrained within the range of habituated motor trajectories , as explained previously . \n",
              " \n",
              "  \\ begin{figure}[!htbp ] \n",
              "  \\ centering \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : predcoding0 } } { \\ xxunk \\ textwidth]{figures / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ vspace{1em } \n",
              "  \\ caption{three different models for learning - based goal - directed motor planning . \\ textbf{(a ) } xxmaj the forward model implemented in an xxup rnn , \\ textbf{(b ) } xxup pc and xxup aif frameworks implemented in an xxup rnn using initial sensitivity by latent random variables at the initial step , either by the stochastic $ \\ xxunk or the deterministic $ \\ bm{d}_t$ , and \\ textbf{(c ) } the proposed glean scheme based on the xxup pc and xxup aif framework implemented in a variational xxup rnn . xxmaj in each case , the horizontal axis indicates progression through time ( left to right ) . xxmaj the black arrows represent computation in the forward pass , while the red arrows represent prediction error being propagated during backpropagation through time ( xxup xxunk ) . \\ label{fig : modelcompare } } \n",
              "  \\ end{figure } \n",
              " \n",
              "  xxmaj the glean scheme proposed in this paper implements the aforementioned considerations using a variational recurrent neural network ( xxup rnn ) model and tests it in learning - based robot motor planning tasks . xxmaj in the following , we briefly review how models of learning - based goal - directed planning have been studied and how such prior studies have been extended to the current work . xxmaj tani \\ xxunk } proposed a goal - directed planning scheme for a robot navigation task based on xxup fm ( see xxmaj figure \\ ref{fig : xxunk } ) . xxmaj in this model , the latent state was represented by the activity of the context units in a xxmaj jordan - type xxup rnn \\ xxunk } . xxmaj during action planning , a sequence of discrete actions $ xxunk ... xxunk such as branching or not branching at each encountered branching point in a maze environment can be inferred by minimizing the error between predicted sensory inputs at distal step $ xxunk and the sensory inputs associated with the given goal $ \\ xxunk \n",
              " \n",
              "  xxmaj xxunk et al . \\ xxunk } developed a model of learning - based planning analogous to the xxup pc and xxup aif frameworks ( see xxmaj figure \\ ref{fig : predcoding0 } ) . xxmaj in this model , the initial sensitivity characteristics of deterministic dynamic systems is used wherein diverse sensory - motor sequences experienced are embedded into a distribution of the initial latent state of an xxup rnn model through iterative learning . xxmaj as such , learning a set of sensory - motor sequences is conducted by means of adapting two different types of variables --- connectivity weights of the xxup rnn which are shared by all sequences , and the initial state which is individually adapted for each sequence . xxmaj after learning with a given initial latent state $ \\ bm{d}_0 $ , the corresponding sequence consisting of the exteroception $ v_{1 ... t}$ and the proprioception $ p_{1 ... t}$ is generated . xxmaj by feeding the predicted proprioception at each timestep $ p_t$ as the target body posture to the inverse model , the corresponding motor command $ m_t$ can be generated . xxmaj in planning mode , the initial state is inferred such that the distal state in a generated sensory - motor sequence can agree with the desired goal state with minimal error . xxmaj the inferred initial state represents an intention or belief to generate a motor program reaching the goal state . \n",
              " \n",
              "  xxmaj similar work by xxmaj choi et al . \\ xxunk } employed a deterministic xxup rnn architecture to accomplish goal - directed motor planning with visual predictions for robotic tasks by searching in this initial state space . xxmaj in this case , while the network was able demonstrate adequate generalization for simple tasks such as touching a point with a robot arm , the success rate was considerably reduced in a more complex grasp and place task . xxmaj recently , xxmaj xxunk et al . \\ cite{jung19 } extended this model by allowing random variables $ \\ xxunk $ with mean and variance to represent the initial states for the purpose of extracting a probabilistic distribution among trained sensory - motor sequences ( see xxmaj figure \\ ref{fig : predcoding0 } ) . xxmaj the experimental results using this model for a task of stacking multiple objects by a robot arm showed that this scheme of using random variables for the initial latent state is beneficial in terms of generalization in both training and motor plan generation . \n",
              " \n",
              "  xxmaj in this current paper , we propose a further development of the aforementioned model using the framework of xxup pc and xxup aif to tackle the issue of learning - based goal - directed motor planning by expanding upon the variational xxmaj bayes approach . xxmaj the main purpose of our proposed glean scheme is to enable the network to learn to extract the transition probability distribution of the latent state at each timestep as a sequence prior \\ xxunk } and to utilize it for generating goal - directed plans with improved generalization . xxmaj for this purpose , we utilize a recently proposed variational xxup rnn known as the predictive - coding inspired variational xxup rnn ( xxup pv - xxup rnn ) \\ cite{ahmadi19 } for implementing the xxup pc and xxup aif frameworks such that the latent state at each timestep is represented by both a deterministic variable $ \\ bm{d}_t$ and a random variable $ \\ xxunk as shown in xxmaj figure \\ ref{fig : xxunk } . xxmaj learning of the model is accomplished by maximizing the evidence lower bound , whereas the estimated lower bound is maximized for goal - directed motor plan generation . xxmaj both lower bounds are computed as xxunk of the accuracy term and the complexity term . a formal description of the model is given in xxmaj section \\ ref{sec : model } . \n",
              " \n",
              "  xxmaj the proposed model also uses ideas considered in development of the so - called xxmaj multiple xxmaj timescale rnns ( xxup mtrnn ) \\ xxunk } , which is built on multiple layers of xxmaj continuous xxmaj time rnns ( xxup xxunk ) \\ xxunk } wherein higher layers have slower timescale dynamics and lower layers have faster dynamics ( note that xxmaj figure \\ ref{fig : modelcompare } shows only a single layer for simplicity ) . xxmaj it has been shown that xxup mtrnn enhances development of functional hierarchy among layers . xxmaj it does so by using the timescale difference by which more abstract representations of action plans are developed in the higher layers while a more detailed representation of sensory - motor patterns develop in the lower layers \\ xxunk } . \n",
              " \n",
              "  xxmaj in xxmaj section \\ ref{sec : experiments } we evaluate glean by conducting two sets of simulated experiments . xxmaj using a minimal task set , the first experiment examines essential characteristics of the proposed model in learning to generate goal - directed plans . xxmaj in particular , we investigate the effects that regulating the strength of the complexity term in the lower bound has upon learning performance as well as goal - directed motor plan generation . xxmaj furthermore , we compare the difference in planning performance between more habituated goal states and less habituated goal states in order to examine the effect of habituation in learning on goal - directed plan generation . \n",
              " \n",
              "  xxmaj the second simulation experiment uses a more realistic robotic task employing a model of a real robot and compares the performance between three models depicted in xxmaj figure \\ ref{fig : modelcompare } : xxup fm , xxup pc + xxup aif with initial state sensitivity , and the proposed glean scheme . xxmaj these experiments will clarify how glean can generate feasible goal - directed plans and the resultant actions . xxmaj it does so by developing regions of habituation in terms of the sequence prior in the latent state space by means of learning from a limited amount of sensory - motor experiences . \n",
              " \n",
              "  xxrep 5 % \n",
              "  \\ section{model } \\ label{sec : model } \n",
              "  xxmaj in this section , we will first present an overview of the xxup pv - xxup rnn model followed by a more detailed explanation of training and planning , including formulation of the evidence lower bound and approximate lower bound used in training and planning respectively . xxmaj we do not attempt to make an exhaustive derivation of xxup pv - xxup rnn in this paper , rather we focus on the salient points and changes compared to the originally proposed model in \\ cite{ahmadi19 } . \n",
              " \n",
              "  \\ subsection{overview of xxup pv - xxup rnn } \n",
              "  xxmaj figure \\ ref{fig : gp } shows a graphical representation of xxup pv - xxup rnn as implemented in this paper . xxmaj note that for generality we denote all the output of the model as $ \\ bm{x}$. xxmaj compared to the original xxup pv - xxup rnn , we have made three key changes to the model . xxmaj the first is at $ t=1 $ , the prior distribution is fixed as a unit xxmaj gaussian ( depicted as $ \\ xxunk ) , which acts as a weighted regularization on initial state sensitivity of the network . xxmaj this is primarily to improve the stability of learning in certain edge conditions . xxmaj note that the deterministic variables are always initialized at zero at $ xxunk xxmaj in practice , the deterministic variables will tend to learn the mean of the training sequence while the stochastic variables will learn the deviations from the mean . \n",
              " \n",
              "  xxmaj secondly , bottom - up connections from lower layers to higher layers have been removed in order to simplify the model . xxmaj prediction error from lower layers is still conveyed to higher layers during back - propagation . xxmaj additionally , connections between $ \\ bm{z}$ and the output $ \\ bm{x}$ have been removed . xxmaj preliminary testing has not shown any degradation of planning performance due to this change . \n",
              " \n",
              "  xxmaj finally , connections between $ \\ bm{d}_t$ and the posterior distribution $ \\ xxunk have been removed . xxmaj thus information from the previous timestep flows between stochastic units only by how close the prior and posterior distributions are , which is regulated by the meta - prior setting . xxmaj while this change could impact learning performance , it makes inference of the adaptation variables $ \\ bm{a}$ simpler . \n",
              " \n",
              "  \\ begin{figure}[!htbp ] \n",
              "  \\ centering \n",
              "  \\ includegraphics[width=0.4 \\ textwidth]{figures / xxunk } \n",
              "  \\ caption{graphical representation of xxup pv - xxup rnn as implemented in this paper } \n",
              "  \\ label{fig : gp } \n",
              "  \\ end{figure } \n",
              " \n",
              "  xxmaj as noted previously , xxup pv - xxup rnn is a variational xxup rnn comprised of deterministic variables $ \\ bm{d}$ and stochastic variables $ \\ bm{z}$. xxmaj the model infers an approximate posterior distribution $ q$ by the prior distribution $ p$ by means of error minimization on the generated output $ \\ bm{x}$. xxmaj the parameterized prior generative model $ p _ \\ theta$ is factorized as shown in xxmaj equation \\ ref{eq : genp } . \n",
              " \n",
              "  \\ begin{equation } \\ label{eq : genp } \n",
              "  p _ \\ theta ( \\ bm{x}_{1 : t } , \\ xxunk : t } , \\ bm{z}_{1 : t } | \\ bm{d}_0 ) = \\ prod_{t=1}^t p _ { \\ theta_x } ( \\ bm{x}_t | \\ bm{d}_t ) p _ { \\ theta_d } ( \\ bm{d}_t | \\ bm{d}_{t-1 } , \\ bm{z}_t ) p _ { \\ theta_z } ( \\ bm{z}_t | \\ bm{d}_{t-1 } ) \n",
              "  \\ end{equation } \n",
              " \n",
              "  xxmaj note that unlike in the original implementation of xxup pv - xxup rnn , $ \\ bm{x}$ is not conditioned directly on $ \\ bm{z}$ , only through $ \\ bm{d}$ , which is a xxmaj dirac delta function as defined in xxmaj equation \\ ref{eq : d } . \n",
              " \n",
              "  \\ begin{equation } \\ label{eq : d } \n",
              "  \\ bm{d}_t = \n",
              "  \\ begin{cases } \n",
              "  0 & \\ text{if } t = 0 \\ \\ \n",
              "  f _ { \\ theta_d } ( \\ bm{d}_{t-1 } , \\ bm{z}_t ) & \\ text{if } t > 0 \n",
              "  \\ end{cases } \n",
              "  \\ end{equation } \n",
              " \n",
              "  $ f _ { \\ xxunk is a neural network --- xxup mtrnn is used in this paper . $ \\ bm{d}$ is then the output of the xxup mtrnn , which is the internal state $ \\ bm{h}$ after activation . xxmaj for a multi - layer xxup mtrnn in this model , $ \\ bm{h}$ is calculated as a sum of the value of the stochastic variable $ \\ bm{z}$ , the previous timestep output of the current level $ l$ and previous timestep output of the next higher level $ l+1 $ as shown in xxmaj equation \\ ref{eq : cell } . \n",
              " \n",
              "  \\ begin{equation } \\ label{eq : cell } \n",
              "  \\ begin{aligned } \n",
              "  \\ xxunk & = \\ text{tanh } ( \\ xxunk ) \\ \\ \n",
              "  \\ xxunk & = \\ left(1 - \\ frac{1 } { \\ xxunk } \\ right ) \\ xxunk } + \\ frac{1 } { \\ xxunk } \\ left ( \\ bm{w}^{l , l}_{d , d } \\ xxunk } + \\ bm{w}^{l , xxunk , d } \\ xxunk + \\ xxunk , d } \\ xxunk } \\ right ) \n",
              "  \\ end{aligned } \n",
              "  \\ end{equation } \n",
              " \n",
              "  $ \\ xxunk represent connectivity weight matrices , in this case between layers and between deterministic and stochastic units . xxmaj note that at the top layer , $ \\ xxunk , d } \\ xxunk is omitted . \n",
              " \n",
              "  xxmaj the prior distribution $ p$ of $ \\ bm{z}$ is a xxmaj gaussian distribution which depends on $ \\ xxunk , except at $ t=1 $ which does not depend on $ \\ bm{d}_0 $ and is fixed as a unit xxmaj gaussian . $ \\ bm { \\ mu}$ and $ \\ bm { \\ sigma}$ for the prior distribution are obtained from $ \\ bm{d}$ as shown in xxmaj equation \\ ref{eq : p } . \n",
              " \n",
              "  \\ begin{equation } \\ label{eq : p } \n",
              "  \\ begin{aligned } \n",
              "  p ( \\ bm{z}_1 ) & = \\ mathcal{n}(0 , i ) \\ \\ \n",
              "  p ( \\ bm{z}_t | \\ bm{d}_{t-1 } ) & = \\ mathcal{n } ( \\ bm { \\ xxunk , ( \\ bm { \\ xxunk ) \\ text { where $ xxunk $ } \\ \\ \n",
              "  \\ bm { \\ xxunk & = \\ text{tanh } ( \\ bm{w}^{l , l}_{d , z , \\ xxunk } \\ bm{d}_{t-1 } ) \\ \\ \n",
              "  \\ bm { \\ xxunk & = \\ exp ( \\ bm{w}^{l , l}_{d , z , \\ sigma^p } \\ bm{d}_{t-1 } ) \n",
              "  \\ end{aligned } \n",
              "  \\ end{equation } \n",
              " \n",
              "  xxmaj based on the reparameterization trick proposed by xxmaj kingma and xxmaj xxunk \\ cite{kingma14 } , the latent value $ \\ bm{z}$ for both prior and posterior distributions is a function of $ \\ mu$ and $ \\ sigma$ and a noise sample $ \\ epsilon \\ sim \\ mathcal{n}(0 , xxup i)$. \n",
              " \n",
              "  \\ begin{equation } \n",
              "  \\ bm{z}_t = \\ bm { \\ xxunk + \\ bm { \\ xxunk \\ times \\ epsilon \n",
              "  \\ end{equation } \n",
              " \n",
              "  xxmaj since computing the true posterior distribution is intractable , the model infers an approximate posterior $ q$ of $ \\ bm{z}$ as described in xxmaj equation \\ ref{eq : q } . xxmaj in xxup pv - xxup rnn , while sensory information $ \\ overline { \\ xxunk is not directly available to the network , an adaptation variable $ \\ bm{a}$ is used , so for each training sequence $ \\ overline { \\ xxunk : xxup t}$ there is a corresponding $ \\ xxunk : xxup t}$. $ \\ bm{a}$ is learned together with the other network parameters during training based on the prediction errors $ \\ xxunk between $ \\ bm{x}$ and $ \\ bm { \\ xxunk \n",
              " \n",
              "  \\ begin{equation } \\ label{eq : q } \n",
              "  \\ begin{aligned } \n",
              "  q ( \\ bm{z}_t | \\ bm{e}_{t : t } ) & = \\ mathcal{n } ( \\ bm { \\ xxunk , ( \\ bm { \\ xxunk ) \\ \\ \n",
              "  \\ bm { \\ xxunk & = \\ text{tanh } ( \\ bm{a}^ \\ mu_t ) \\ \\ \n",
              "  \\ bm { \\ xxunk & = \\ exp ( \\ bm{a}^ \\ sigma_t ) \n",
              "  \\ end{aligned } \n",
              "  \\ end{equation } \n",
              " \n",
              "  % % \n",
              "  \\ subsection{learning with evidence lower bound } \n",
              "  xxmaj following from xxmaj equation \\ ref{eq : genp } , we can express the marginal likelihood ( evidence ) as shown in xxmaj equation \\ ref{eq : xxunk } . xxmaj as the value of $ \\ bm{d}$ is deterministic , if we let $ \\ bm { \\ xxunk be the value of $ \\ xxunk as described by xxmaj equation \\ ref{eq : d } , then $ p _ { \\ theta_d } ( \\ bm{d}_t | \\ bm{d}_{t-1 } , \\ xxunk is equivalent to a xxmaj dirac distribution given by $ \\ delta ( \\ bm{d}_t - \\ bm { \\ xxunk , which allows the integral over $ \\ bm{d}$ to be eliminated . \n",
              "  \\ begin{equation } \\ label{eq : xxunk } \n",
              "  \\ begin{aligned } \n",
              "  p _ \\ theta ( \\ bm{x}_{1 : t } | \\ bm{d}_0 ) & = \\ int \\ int \\ prod_{t=1}^t p _ { \\ theta_x } ( \\ bm{x}_t | \\ bm{d}_t ) p _ { \\ theta_d } ( \\ bm{d}_t | \\ bm{d}_{t-1 } , \\ bm{z}_t ) p _ { \\ theta_z } ( \\ bm{z}_t | \\ bm{d}_{t-1 } ) d \\ xxunk \\ xxunk } \\ \\ \n",
              "  & = \\ int \\ int \\ prod_{t=1}^t p _ { \\ theta_x } ( \\ bm{x}_t | \\ bm { \\ tilde{d}}_t ) \\ delta ( \\ bm{d}_t - \\ bm { \\ tilde{d}}_t ) p _ { \\ theta_z } ( \\ bm{z}_t | \\ bm { \\ tilde{d}}_{t-1 } ) d \\ xxunk \\ xxunk } \\ \\ \n",
              "  & = \\ int \\ prod_{t=1}^t p _ { \\ theta_x } ( \\ bm{x}_t | \\ bm { \\ tilde{d}}_t ) p _ { \\ theta_z } ( \\ bm{z}_t | \\ bm { \\ tilde{d}}_{t-1 } ) d \\ bm{z } \n",
              "  \\ end{aligned } \n",
              "  \\ end{equation } \n",
              " \n",
              "  xxmaj factoring the integral , taking the logarithm and refactoring with the parameterized posterior distribution produces an expectation on the posterior distribution as shown in xxmaj equation \\ ref{eq : xxunk } . \n",
              " \n",
              "  \\ begin{equation } \\ label{eq : xxunk } \n",
              "  \\ begin{aligned } \n",
              "  \\ log p _ \\ theta ( \\ bm{x}_{1 : t } | \\ bm{d}_0 ) & = \\ log \\ prod_{t=1}^t \\ int p _ { \\ theta_x } ( \\ bm{x}_t | \\ bm { \\ tilde{d}}_t ) p _ { \\ theta_z } ( \\ bm{z}_t | \\ bm { \\ tilde{d}}_{t-1 } ) d \\ bm{z}_t \\ \\ \n",
              "  & = \\ sum_{t=1}^t \\ log \\ int p _ { \\ theta_x } ( \\ bm{x}_t | \\ bm { \\ tilde{d}}_t ) p _ { \\ theta_z } ( \\ bm{z}_t | \\ bm { \\ tilde{d}}_{t-1 } ) d \\ bm{z}_t \\ \\ \n",
              "  & = \\ sum_{t=1}^t \\ log \\ int p _ { \\ theta_x } ( \\ bm{x}_t | \\ bm { \\ tilde{d}}_t ) \\ frac{p _ { \\ theta_z } ( \\ bm{z}_t | \\ bm { \\ xxunk _ \\ phi ( \\ bm{z}_t | \\ bm{e}_{t : t } ) } q _ \\ phi ( \\ bm{z}_t | \\ bm{e}_{t : t } ) d \\ bm{z}_t \n",
              "  \\ end{aligned } \n",
              "  \\ end{equation } \n",
              " \n",
              "  xxmaj finally , by applying xxmaj jensen 's inequality $ \\ log xxmaj xxunk ] \\ geq e [ \\ log x]$ , the variational evidence lower bound ( xxup elbo ) $ l ( \\ theta , \\ phi)$ is given in xxmaj equation \\ ref{eq : elbo } . \n",
              " \n",
              "  \\ begin{equation } \\ label{eq : elbo } \n",
              "  l ( \\ theta , \\ phi ) = \\ sum_{t=1}^t \\ int \\ log \\ xxmaj bigg [ p _ { \\ theta_x } ( \\ bm{x}_t | \\ bm { \\ tilde{d}}_t ) \\ frac{p _ { \\ theta_z } ( \\ bm{z}_t | \\ bm { \\ xxunk _ \\ phi ( \\ bm{z}_t | \\ bm{e}_{t : t } ) } \\ xxmaj bigg ] q _ \\ phi ( \\ bm{z}_t | \\ bm{e}_{t : t } ) d \\ bm{z}_t \n",
              "  \\ end{equation } \n",
              " \n",
              "  xxmaj following the concept of free energy minimization \\ xxunk } , xxup elbo is rewritten in terms of expected log likelihood under the posterior distribution ( \\ xxunk } ) and the xxmaj kullback - xxmaj leibler divergence ( xxup kld ) between the posterior and prior distributions ( \\ emph{complexity } ) in xxmaj equation \\ ref{eq : xxunk } . xxmaj the deterministic value in the expected log likelihood is substituted with all previous stochastic variables by xxmaj equation \\ ref{eq : d } in order to allow optimization of the posterior adaptive values against the training data . xxmaj for simplicity , we omit the summation over each layer of the xxup rnn and over each training sample . \n",
              " \n",
              "  \\ begin{equation } \\ label{eq : xxunk } \n",
              "  \\ begin{aligned } \n",
              "  l ( \\ theta , \\ phi ) & = \\ sum_{t=1}^t xxmaj e_{q _ \\ phi ( \\ bm{z}_t | \\ bm{z}_{1 : t-1 } , \\ bm{e}_{t : t } ) } \\ big [ p _ { \\ theta_x } ( \\ bm{x}_t | \\ bm { \\ tilde{d}}_t ) \\ big ] - xxup d_{kl } \\ big [ q _ \\ phi ( \\ bm{z}_t | \\ bm{e}_{t : t } ) || p _ { \\ theta_z } ( \\ bm{z}_t | \\ bm { \\ tilde{d}}_{t-1 } ) \\ big ] \\ \\ \n",
              "  & = \\ underbrace { \\ sum_{t=1}^t xxmaj e_{q _ \\ phi ( \\ bm{z}_t | \\ bm{z}_{1 : t-1 } , \\ bm{e}_{t : t } ) } \\ big [ p _ { \\ theta_x } ( \\ bm{x}_t | \\ bm{z}_{1 : t } ) \\ big ] } _ \\ xxunk } - \\ xxunk } \\ big [ q _ \\ phi ( \\ bm{z}_t | \\ bm{e}_{t : t } ) || p _ { \\ theta_z } ( \\ bm{z}_t | \\ bm{z}_{1 : t-1 } ) \\ big ] } _ \\ xxunk } \n",
              "  \\ end{aligned } \n",
              "  \\ end{equation } \n",
              " \n",
              "  xxmaj intuitively , the accuracy term is calculated by the distance between the predicted output $ \\ bm{x}$ and the sensory state or ground truth $ \\ bm { \\ xxunk xxmaj in practice , this is a standard measure such as mean squared error ( xxup mse ) or xxup kld . \n",
              " \n",
              "  xxmaj in xxup pv - xxup rnn , the meta - prior $ w$ is a hyperparameter which affects the degree of regularization ( or the tendency to overfit ) . xxmaj it is similar to the $ \\ beta$ parameter in xxup vae \\ cite{kingma14 } although the effect is reversed , that is , in models that assume a prior normal distribution , a larger regularization constant implies a stronger pull toward the normal distribution , reducing complexity and reducing the tendency to overfit . xxmaj however , as xxup pv - xxup rnn the prior is conditioned on the output of previous timesteps , a larger meta - prior causes the complexity to rise as the output becomes deterministic , resulting in a tendency to overfit training samples . xxmaj during learning , the meta - prior will affect the approximate posterior distribution and cause it to deviate from the true posterior , while during inference the meta - prior will control how much the prior and approximate posterior will deviate . xxmaj we explore this effect in the following xxmaj section \\ ref{sec : experiments } . \n",
              " \n",
              "  xxmaj in this implementation of xxup pv - xxup rnn , the complexity term at $ t=1 $ is a special case where the prior distribution is a unit xxmaj gaussian $ \\ xxunk , and the initial xxmaj gaussian weight $ w_i$ controls how closely the posterior follows . xxmaj this has two effects --- firstly , the xxup rnn can be made more or less sensitive to the initial state at $ t=1 $ by adjusting the degree of regularization with a unit xxmaj gaussian . xxmaj secondly , as it is independent of the meta - prior , it avoids degenerate cases where learning of a probabilistic training set is unsuccessful due to the meta - prior forcing deterministic behavior . xxmaj from preliminary testing , we found settings of either $ w_i = 0.01 $ or $ w_i = 0.001 $ appropriate depending on the data . xxmaj additionally , in this implementation of xxup pv - xxup rnn , we use different values of $ w$ per layer $ l$. xxmaj for simplicity , summation over timesteps is omitted in xxmaj equation \\ ref{eq : lz } . \n",
              " \n",
              "  \\ begin{equation } \\ label{eq : lz } \n",
              "  \\ sum^l_{l=1 } xxunk \\ cdot xxup d_{kl } \\ big [ q _ \\ phi ( \\ bm{z}_t | \\ bm{e}_{t : t } ) || p _ { \\ theta_z } ( \\ bm{z}_t | \\ bm { \\ tilde{d}}_{t-1 } ) \\ big ] = \n",
              "  \\ begin{cases } \n",
              "  \\ sum^l_{l=1 } w_i \\ sum _ { \\ bm { \\ sigma } , \\ bm { \\ mu } \\ in \\ bm{z } } \\ log \\ frac{1 } { \\ bm { \\ sigma}^{q , l}_t } + \\ xxunk \\ bm { \\ xxunk , l}_t)^2 + ( \\ bm { \\ sigma}^{q , xxunk } - \\ frac{1}{2 } & \\ text{if } t = 1 \\ \\ \n",
              "  \\ sum^l_{l=1 } xxunk \\ sum _ { \\ bm { \\ sigma } , \\ bm { \\ mu } \\ in \\ bm{z } } \\ log \\ frac { \\ bm { \\ sigma}^{p , l}_t } { \\ bm { \\ sigma}^{q , l}_t } + \\ frac { ( \\ bm { \\ sigma}^{p , l}_t - \\ bm { \\ xxunk , l}_t)^2 + ( \\ bm { \\ sigma}^{q , xxunk ( \\ bm { \\ sigma}^{p , l}_t)^2 } - \\ frac{1}{2 } & \\ text{if } t > 1 \n",
              "  \\ end{cases } \n",
              "  \\ end{equation } \n",
              " \n",
              "  xxmaj in practice , all parameters are optimized by gradient descent , using the xxmaj adam optimizer provided by tensorflow . xxmaj we note the conditions used in our experiments in xxmaj section \\ ref{sec : experiments } . \n",
              "  % xxmaj no detail on the update steps are given , since these are handled by automatic differentiation in xxup tf \n",
              " \n",
              "  % % \n",
              "  \\ xxunk generation with glean and the estimated lower bound } \n",
              "  xxmaj plan generation uses a variation of error regression \\ xxunk } in order to infer the latent variables that minimize the error . xxmaj however , recent works that utilize error regression \\ cite{ahmadi19 , xxunk } employ a regression window in which error is minimized in order to improve future prediction ( see xxmaj figure \\ ref{fig : xxunk } ) . glean attempts to minimize the errors at the initial timestep and the goal timestep ( see xxmaj figure \\ ref{fig : gdp } ) by maximizing the \\ xxunk lower bound } , shown in xxmaj equation \\ ref{eq : xxunk } . \n",
              " \n",
              "  \\ begin{figure}[!htbp ] \n",
              "  \\ centering \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.45 \\ textwidth]{figures / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : gdp } } { \\ includegraphics[width=0.45 \\ textwidth]{figures / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ vspace{1em } \n",
              "  \\ xxunk in how error regression is employed in \\ textbf{(a ) } future sequence prediction and \\ textbf{(b ) } goal - directed planning . xxmaj solid black lines represent the forward generative model while the dashed red lines represent back - propagation through time used to update $ xxup a^ \\ emptyset$. } \n",
              "  \\ end{figure } \n",
              " \n",
              "  xxmaj compared to xxup elbo shown in xxmaj equation \\ ref{eq : elbo } , the accuracy term is now calculated as the summation of prediction error in the initial ( $ t=1 $ ) and distal ( $ t = xxup t$ ) steps . xxmaj in this work , we assume that the distal step is at a fixed point in time ; in practice , if the goal is reached early , the agent should remain stationary until the final timestep . xxmaj the complexity term is also modified such that , except for the first timestep , the posterior distribution is conditioned only on the prediction error at the goal . \n",
              " \n",
              "  \\ begin{multline } \\ label{eq : xxunk } \n",
              "  xxmaj xxunk ( \\ theta , \\ phi ) = xxmaj e_{q _ \\ phi ( \\ bm{z}_1 | \\ xxunk , \\ bm{e}_t ) } \\ big [ p _ { \\ theta_x } ( \\ bm{x}_1 | \\ bm{z}_1 ) \\ big ] + xxmaj e_{q _ \\ phi ( \\ bm{z}_t | \\ bm{e}_t ) } \\ big [ p _ { \\ theta_x } ( \\ bm{x}_t | \\ bm{z}_{1 : t } ) \\ big ] \\ \\ \n",
              "  - \\ xxmaj big ( xxup d_{kl } \\ big [ q _ \\ phi ( \\ bm{z}_1 | \\ xxunk ) || p _ { \\ theta_z } ( \\ bm{z}_1 ) \\ big ] + \\ xxunk xxup d_{kl } \\ big [ q _ \\ phi ( \\ bm{z}_t | \\ bm{e}_t ) || p _ { \\ theta_z } ( \\ bm{z}_t | \\ bm{z}_{1 : t-1 } ) \\ big ] \\ xxmaj big ) \n",
              "  \\ end{multline } \n",
              " \n",
              "  xxmaj note that while the trained model is loaded before plan generation , the adaptive variable $ \\ bm{a}$ is reset to zero ( denoted as $ \\ bm{a}^ \\ emptyset$ ) . xxmaj during plan generation , only the adaptive variable $ \\ xxunk \\ xxunk is updated , while all other parameters remain fixed . xxmaj the implementation of plan generation is largely similar to training , although for practical reasons the number of epochs is significantly reduced . xxmaj the learning rate , which we refer to as \\ xxunk adaptation rate } in the context of plan generation , is raised to compensate for this . xxmaj in addition , noise sampling is employed by having multiple $ \\ xxunk \\ xxunk sequences and selecting for plans with the highest lower bound . \n",
              " \n",
              "  \\ section{experiments } \\ label{sec : experiments } \n",
              "  xxmaj in order to test glean , we conducted two experiments with simulated agents . xxmaj the first experiment was carried out with a virtual mobile agent in a xxup 2d space in order to examine the impact of the meta - prior on learning as well as plan generation outputs . xxmaj the second experiment used a simulated 8 xxup dof arm robot carrying out a goal - directed object moving task , and compared glean to two previously mentioned models --- a forward model and a stochastic initial state xxup rnn . \n",
              " \n",
              "  xxmaj due to the computational workload of generating long sequences , particularly when executing error regression for plan generation , all plans were generated in an offline manner . xxmaj this allowed the work to be run in batches on a computer cluster . xxmaj similarly , using a simulator to collect data and test the outcomes allowed greater efficiency and automation compared to using real robots . xxmaj however , in the future , we plan to extend this work to real - time trajectory planning using a physical robot . \n",
              " \n",
              "  xxmaj as mentioned previously , we implemented xxup pv - xxup rnn and glean using tensorflow . xxmaj the xxmaj adam optimizer was used with default parameters , except for learning rate and $ \\ hat { \\ varepsilon}$ which was set to $ 1 / 10 $ of learning rate . xxmaj additionally we used random dropout of the error signal ( i.e. the prediction error $ \\ xxunk can either be $ \\ bm{x}- \\ overline { \\ xxunk or $ 0 $ ) . \n",
              " \n",
              "  xxmaj the source code for glean is publicly available at \\ url{https : / / github.com / xxunk - xxunk / glean } for both xxmaj python 2.7 + tensorflow xxunk ( as tested in this paper ) and xxmaj python xxunk + tensorflow xxunk . xxmaj the tested datasets are also included , together with instructions on how to use the software . \n",
              " \n",
              "  xxmaj for these two simulation experiments , we prepared datasets of possible trajectories wherein a portion of the trajectories were used for training of the model and the remaining held back for testing . xxmaj this provides the ground truth under various conditions including non - goal - directed and goal - directed generation . xxmaj to evaluate the performance of trajectory generation after the training , we provide both plots of trajectories for qualitative evaluation as well as tables of qualitative measures . xxmaj for goal - directed plan generation , we judge the quality of the generated outputs by comparing the trajectory to the ground truth trajectory and calculating an average root mean squared error ( xxup rmse ) value . xxmaj the error at the final timestep is also given separately as goal deviation ( xxup gd ) . xxmaj the average xxup kld between prior and posterior ( $ kld_{pq}$ ) is stated as an indication of how closely the network is following its trained prior distribution . xxmaj note this is equivalent to the complexity term without weighting by the meta - prior . \n",
              " \n",
              "  \\ subsection{experiment 1 : simulated mobile agent in a xxup 2d space } \\ xxunk } \n",
              "  xxmaj to gain a better understanding of the generative capabilities of our model , we first conduct an experiment using a simple simulated agent moving in a xxup 2d space as shown in xxmaj figure \\ ref{fig : xxunk } . xxmaj the agent 's position at a given timestep is given by xxup xy coordinates in the range $ [ 0,1]$. xxmaj the training data consists of hand drawn trajectories resampled to 30 timesteps , starting at $ [ xxunk , moving to a central ` branch point ' at approximately $ ( 0.38 , xxunk , and then proceeding with a 50 / 50 chance to one of two goal areas --- the top left centered around $ ( 0.2 , xxunk and the bottom right centered around $ ( xxunk without colliding with obstacles shown as grey areas in xxmaj figure \\ ref{fig : xxunk } , ideally while maintaining a smooth trajectory . \n",
              " \n",
              "  xxmaj the branch point is reached at approximately $ t=10 $ , with the goal reached between $ xxunk $ and $ xxunk xxmaj as the trajectories are hand drawn with a mouse , there is a varying amount of noise in each trajectory and the goal points are also distributed in a fairly uniform distribution . xxmaj the result is that while the task itself is simple ( going from start to one of goal areas ) , a habituated path of sorts is generated out of the bundle of trajectories drawn . \n",
              " \n",
              "  \\ begin{figure}[!htbp ] \n",
              "  \\ centering \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp1 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp1 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp1 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ vspace{1em } \n",
              "  \\ caption{plots of the trajectories prepared for a mobile agent generating goal - directed behaviors in xxup 2d space . \\ textbf{(a ) } xxup xy plot showing the initial position of the agent , the branch point , and the two goal areas , \\ textbf{(b ) } the plot of the x position over time , and \\ textbf{(c ) } the plot of the y position over time . xxmaj the branch point is visible at around $ xxunk \\ label{fig : xxunk } } \n",
              "  \\ end{figure } \n",
              " \n",
              "  xxmaj as noted previously , we use xxup pv - xxup rnn which itself is built on xxup mtrnn . xxmaj in this experiment , we configure the network to have two layers ( note that layer 1 is the bottom layer ) with parameters as shown in xxmaj table \\ ref{tbl : xxunk } . xxmaj neurons refer to the number of deterministic variables , while z - units refer to the number of stochastic variables . xxmaj these are kept in a xxunk ratio as in \\ cite{ahmadi19 } . $ \\ tau$ is the xxup mtrnn time constant , with shorter time constants used in the lower layers which should be more responsive , and longer time constants in the higher layers . xxmaj the network was trained for 50,000 epochs with a learning rate of 0.001 . \n",
              " \n",
              "  \\ begin{table}[!htbp ] \n",
              "  \\ xxunk - xxup rnn parameters for xxmaj experiment 1 } \\ label{tbl : xxunk } \n",
              "  \\ centering . \n",
              "  \\ begin{tabular}{ccc } \n",
              "  \\ toprule \n",
              "  & \\ xxunk layer } \\ \\ \n",
              " \t  & \\ textbf{1 } \t & \\ textbf{2 } \\ \\ \n",
              "  \\ midrule \n",
              "  xxmaj neurons $ | \\ bm{d}^l|$ \t  & 20 \t\t\t & 10 \\ \\ \n",
              "  z - units \t $ | \\ bm{z}^l|$ \t  & 2 \t\t\t & 1 \\ \\ \n",
              "  $ \\ tau$ & 4 & 8 \\ \\ \n",
              "  \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  \\ end{table } \n",
              " \n",
              "  xxmaj in order to explore how the meta - prior affects the output in terms of trajectory generation after learning , we prepared three networks trained with different meta - prior values that we have labeled ` weak ' , ` intermediate ' and ` strong ' as shown in xxmaj table \\ ref{tbl : exp1w } . \n",
              " \n",
              "  \\ begin{table}[!htbp ] \n",
              "  \\ caption{meta - prior settings for the xxup 2d experiment } \\ label{tbl : exp1w } \n",
              "  \\ centering \n",
              "  \\ begin{tabular}{ccc } \n",
              "  \\ toprule \n",
              "  & \\ xxunk layer } \\ \\ \n",
              "  \\ textbf{meta - prior setting $ w$ } & \\ textbf{1 } \t & \\ textbf{2 } \\ \\ \n",
              "  \\ midrule \n",
              "  xxmaj weak \t\t  & 0 . xxrep 4 0 1 \t\t & 0 . xxrep 5 0 5 \\ \\ \n",
              "  xxmaj intermediate & 0.01 \t\t & 0.005 \\ \\ \n",
              "  xxmaj strong & 0.2 & 0.1 \\ \\ \n",
              "  \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  \\ end{table } \n",
              " \n",
              "  \\ xxunk generation } \n",
              "  xxmaj to evaluate the ability of the network to learn to extract the probabilistic characteristics latent in the training data , we test prior generation of trajectories using the prior distribution as illustrated in xxmaj figure \\ ref{fig : xxunk } . xxmaj since there are no target outputs given and $ \\ bm{z}_1 $ is a unit xxmaj gaussian and $ \\ bm{d}_0 = 0 $ , the network is not influenced to go to a particular goal direction . xxmaj ideally , the distribution of trajectories generated in this manner should match the training data in terms of distribution between left and right goal areas as the prior generation should represent the distribution of habituated trajectories . \n",
              " \n",
              "  \\ begin{figure}[!htbp ] \n",
              "  \\ centering \n",
              "  \\ includegraphics[width=0.5 \\ textwidth]{figures / xxunk } \n",
              "  \\ caption{generation using a stochastic initial state ( unit xxmaj gaussian ) } \n",
              "  \\ label{fig : xxunk } \n",
              "  \\ end{figure } \n",
              " \n",
              "  xxmaj table \\ ref{tbl : xxunk } shows the distributions between left and right goal areas for the three networks trained with different meta - priors in comparison to the training data ( ground truth ) . xxmaj we observed that a weaker meta - prior tended to allow slightly more skew in one direction , however by inspecting the plots in xxmaj figure \\ ref{fig : priorgenw } , it is apparent that there is a large amount of noise in the trajectories generated by the weak meta - prior network ( xxmaj figure \\ ref{fig : xxunk } ) . xxmaj in particular , there are large deviations and the overall shape of the trajectories does not follow the training data accurately . \n",
              " \n",
              "  \\ begin{table}[!htbp ] \n",
              "  \\ caption{distribution of goals reached by networks with different meta - priors , after 60 prior generation sequences \\ label{tbl : xxunk } } \n",
              "  \\ centering \n",
              "  \\ begin{tabular}{ccc } \n",
              "  \\ toprule \n",
              "  \\ textbf{training meta - prior } & \\ textbf{left goal \\ % } & \\ textbf{right goal \\ % } \\ \\ \n",
              "  \\ midrule \n",
              "  xxmaj weak & xxunk & 61.7 \\ \\ \n",
              "  xxmaj intermediate & 46.7 & 53.3 \\ \\ \n",
              "  xxmaj strong & 55.0 & xxunk \\ \\ \n",
              "  \\ emph{ground truth } & \\ xxunk } & \\ xxunk } \\ \\ \n",
              "  \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  \\ end{table } \n",
              " \n",
              "  xxmaj in contrast , with a large meta - prior ( xxmaj figure \\ ref{fig : xxunk } ) , there appears to have been a failure to learn the spread of goals , particularly in the right goal area , resulting in some unexpected trajectories . xxmaj in this test , an intermediate meta - prior was best at learning the probabilistic structure of the training data . \n",
              " \n",
              "  \\ begin{figure}[!htbp ] \n",
              "  \\ centering \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp1 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              " \n",
              "  \\ vspace{1em } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp1 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp1 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp1 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ vspace{1em } \n",
              "  \\ caption{trajectory plots showing \\ textbf{(a ) } the training data ( ground truth ) , \\ textbf{(b ) } prior generation with a weak meta - prior , \\ textbf{(c ) } with an intermediate meta - prior , and \\ textbf{(d ) } with a strong meta - prior . xxmaj each plot contains 60 trajectories . \\ label{fig : priorgenw } } \n",
              "  \\ end{figure } \n",
              " \n",
              "  \\ xxunk regeneration } \n",
              "  xxmaj as described previously , xxup pv - xxup rnn learns the probabilistic structure of trajectories by embedding in either initial state sensitive deterministic dynamics or stochastic dynamics based on the meta - prior value . xxmaj this suggests that trajectories for goal - directed behaviors with multiple goals , including decision branching points , can be generated either in an initial state sensitive manner based on deterministic dynamics or in a noise - driven manner based on stochastic dynamics . \n",
              " \n",
              "  xxmaj for the purpose of examining such properties of the trained networks , we conduct a test for target regeneration of the trained trajectories in a manner similar to that originally used in \\ cite{ahmadi19 } . xxmaj in this test , we attempt to regenerate a particular target sequence from the training dataset by using the information of the latent state in the initial step . xxmaj this information was a result of the training process . \n",
              " \n",
              "  xxmaj more specifically , as illustrated in xxmaj figure \\ ref{fig : xxunk } , the prior generation is computed but with the posterior adaptation variable at $ t=1 $ , $ \\ bm{a}_1 $ , fixed to the value obtained after training on the sequence . xxmaj this results in the setting of the initial latent state values of $ xxup z_1 $ and $ d_1 $ with values for the trained sequence . \n",
              " \n",
              "  \\ begin{figure}[!htbp ] \n",
              "  \\ centering \n",
              "  \\ includegraphics[width=0.5 \\ textwidth]{figures / xxunk } \n",
              "  \\ caption{generation using a given posterior adaptation variable $ \\ bm{a}_1 $ } \n",
              "  \\ label{fig : xxunk } \n",
              "  \\ end{figure } \n",
              " \n",
              "  xxmaj in this test , we load a particular $ \\ bm{a}_1 $ adaptation value for a single training sequence that ends in the left goal ( shown in xxmaj figure \\ ref{fig : xxunk } ) as an initial state , and allow the network to generate the trajectory 60 times from the same initial state with different noise sampling in the z - units . xxmaj if the information in the initial state is sufficient to regenerate the trajectory , and the network is deterministic , the generated trajectory should always match the ground truth . xxmaj we refer to this condition as ` initial state sensitive ' . \n",
              " \n",
              "  \\ begin{table}[!htbp ] \n",
              "  \\ centering \n",
              "  \\ caption{distribution of goals reached by networks with different meta - priors , after 60 target regeneration sequences \\ label{tbl : tgtdist } } \n",
              "  \\ begin{tabular}{ccc } \n",
              "  \\ toprule \n",
              "  \\ textbf{training meta - prior } & \\ textbf{left goal \\ % } & \\ textbf{right goal \\ % } \\ \\ \n",
              "  \\ midrule \n",
              "  xxmaj weak & 56.7 & 43.3 \\ \\ \n",
              "  xxmaj intermediate & xxunk & 30.0 \\ \\ \n",
              "  xxmaj strong & 100.0 & 0.0 \\ \\ \n",
              "  \\ emph{target } & \\ xxunk } & \\ xxunk } \\ \\ \n",
              "  \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  \\ end{table } \n",
              " \n",
              "  xxmaj results obtained after 60 target regeneration runs are summarized in xxmaj table \\ ref{tbl : tgtdist } and xxmaj figure \\ ref{fig : tgtregenw } . xxmaj table \\ ref{tbl : tgtdist } shows that the weaker meta - prior networks tend to ignore the target and retain the prior distribution seen previously . xxmaj as the meta - prior increases , the distribution of goals reached xxunk towards the target . xxmaj from this , we can xxunk that a strong training meta - prior creates a network that is initial state sensitive , while networks with a weaker meta - prior do not show such a tendency . \n",
              " \n",
              "  xxmaj visually inspecting the plots in xxmaj figure \\ ref{fig : tgtregenw } shows that in comparison to the prior generation results in xxmaj figure \\ ref{fig : priorgenw } , while the overall distribution of the output from the weak and intermediate meta - prior networks have not been affected by the initial state $ \\ bm{a}_1 $ the trajectories are not as stable . xxmaj we also note that while a strong meta - prior produces a network with a strong initial state sensitivity , the result is not completely deterministic as there is still a noise component in the posterior distribution . \n",
              " \n",
              "  \\ begin{figure}[!htbp ] \n",
              "  \\ centering \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp1 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              " \n",
              "  \\ vspace{1em } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp1 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp1 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp1 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ vspace{1em } \n",
              "  \\ caption{trajectory plots showing \\ textbf{(a ) } the target ( ground truth ) , \\ textbf{(b ) } target regeneration with a weak meta - prior , \\ textbf{(c ) } target regeneration with an intermediate meta - prior , and \\ textbf{(d ) } target regeneration with a strong meta - prior . xxmaj each plot contains 60 trajectories . \\ label{fig : tgtregenw } } \n",
              "  \\ end{figure } \n",
              " \n",
              "  xxmaj to better illustrate the activity of the networks in regenerating a particular sequence given $ \\ bm{a}_1 $ at each timestep , xxmaj figure \\ ref{fig : lz } shows plots of the xxup kld at both layers while xxmaj figure \\ ref{fig : xxunk } shows plots of the $ x$ coordinates over time . \n",
              " \n",
              "  xxmaj with a strong meta - prior , a large spike in xxup kld at $ t=2 $ followed by a rapid drop to near zero is visible at both layers , due to the posterior taking a particular mean with negligible variance to reconstruct the trajectory in an initial sensitive manner . xxmaj note that at $ t=1 $ , xxup kld is regulated independently by $ w_i$ so all the networks show identical behavior . xxmaj this suggests the branching decision is taken early with a strong meta - prior in order to minimize average xxup kld . \n",
              " \n",
              "  \\ begin{figure}[!htbp ] \n",
              "  \\ centering \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp1 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp1 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp1 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ vspace{1em } \n",
              "  \\ caption{plots of xxup kld during target regeneration given a particular $ \\ bm{a}_1 $ adaptation value . \\ textbf{(a ) } xxmaj shows xxup kld for weak , intermediate and strong meta - prior in the bottom layer , \\ textbf{(b ) } shows xxup kld for weak , intermediate and strong meta - prior in the top layer . \\ textbf{(c ) } xxmaj adjusts the scale of ( b ) so the intermediate meta - prior result can be more clearly seen . xxmaj the peak in xxup kld in the intermediate meta - prior network is visible around $ xxunk xxmaj the shaded areas indicate the standard deviation of xxup kld over 60 generated trajectories . \\ label{fig : lz } } \n",
              "  \\ end{figure } \n",
              " \n",
              "  xxmaj the case with an intermediate meta - prior shows a more moderate peak in xxup kld around $ xxunk $ or $ xxunk $ , just before the branch point at $ t=10 $ , with xxup kld remaining flat toward the end . xxmaj this suggests that uncertainty in the prior increases slowly until the branch point while uncertainty in the posterior is kept smaller in order to minimize the reconstruction error . xxmaj therefore , it is considered that the branch decision is built up by slowly accumulating sampled noise in the z - units until the branch point . \n",
              " \n",
              "  xxmaj in xxmaj figure \\ ref{fig : xxunk } , we can clearly see the branch point at approximately $ xxunk xxmaj the spread of the trajectories is relatively low until the branch , after which is a larger spread of trajectories until the goal points are reached . \n",
              " \n",
              "  \\ begin{figure}[!htbp ] \n",
              "  \\ centering \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp1 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp1 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp1 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ vspace{1em } \n",
              "  \\ caption{plots of the $ x$ coordinate over time , target regeneration given a particular $ \\ bm{a}_1 $ adaptation value with \\ textbf{(a ) } a weak meta - prior , \\ textbf{(b ) } an intermediate meta - prior , and \\ textbf{(c ) } a strong meta - prior . xxmaj the branch point is visible around $ t=10 $ , except in \\ textbf{(c ) } which does not exhibit any branching behavior . \\ label{fig : xxunk } } \n",
              "  \\ end{figure } \n",
              " \n",
              "  xxmaj with a weak meta - prior , xxup kld behaves slightly differently in the two layers . xxmaj in the top layer , the xxup kld of the weak meta - prior network behaves similarly to the intermediate meta - prior network until the branch point , after which the xxup kld does not decline --- rather it continues to rise and the spread of xxup kld values also increases significantly . xxmaj in the bottom layer , xxup kld remains low until around $ xxunk $ , where there is a sudden rise in xxup kld . \n",
              " \n",
              "  xxmaj in this case , we xxunk that uncertainty in the prior continues to build even after the branch point . xxmaj this is visible in xxmaj figure \\ ref{fig : xxunk } with a number of trajectories suddenly switching from one goal to the other after the branch point . xxmaj note that due to weighting of xxup kld by the weak meta - prior , the complexity term remains small , resulting in little pressure to follow learned priors . xxmaj in addition , the high uncertainty toward the end of the sequences is likely the reason why in the following test the weak meta - prior network is able to generate trajectories that end closer to untrained goals than other networks . \n",
              " \n",
              "  \\ subsubsection{plan generation } \\ xxunk } \n",
              "  xxmaj to evaluate glean , we first took the three networks previously trained with different meta - priors and then ran plan generation to evaluate the impact of meta - prior during training on the generated motor plans . xxmaj plan generation was conducted using a test dataset containing 20 untrained sequences , with the initial xxup xy and goal xxup xy coordinates of each test sequence used to generate 20 motor plans . xxmaj the goal coordinates of the test data are taken from the same distribution as in the training data . glean was allowed to run for 500 epochs , with a plan adaptation rate ( equivalent to learning rate in training ) of 0.05 . xxmaj the generated motor plans were then compared against the ground truth sequences . \n",
              " \n",
              "  xxmaj in the following results , we present quantitative results in a table , along with the meta - prior setting for training and planning . xxmaj as plan generation using glean is by necessity a non - deterministic process , plan generation was repeated 10 times for each network , with the result being averaged over the 10 runs . xxmaj average root mean squared error ( xxup rmse ) represents how closely the generated plans match the ground truth trajectories for each goal , while the average goal deviation ( xxup gd ) represents the final distance to the goal . xxmaj for both xxup rmse and xxup gd , the standard deviation over 10 runs is given , and the lowest result is highlighted as the best . xxmaj average $ kld_{pq}$ represents the xxup kl - divergence between the prior and posterior distributions , unweighted by the meta - prior . a low average $ kld_{pq}$ indicates the generated plans follow the learned prior distribution closely , while a high average $ kld_{pq}$ indicates significant deviation from learned patterns . xxmaj qualitative results are shown in trajectory plots that show all 20 generated trajectories and can be visually compared to the training data in xxmaj figure \\ ref{fig : xxunk } . \n",
              " \n",
              "  \\ begin{table}[!htbp ] \n",
              "  \\ centering \n",
              "  \\ xxunk generation results on the 20 trajectory test set with varying meta - prior . xxmaj best result highlighted in bold \\ label{tbl : plan1 } } \n",
              "  \\ begin{tabular } { xxrep 4 c } \n",
              "  \\ toprule \n",
              "  \\ textbf{meta - prior } & \\ textbf{average $ \\ bm{kld_{pq}}$ } & \\ textbf{average xxup rmse$ \\ bm { \\ pm \\ sigma}$ } & \\ textbf{average xxup gd$ \\ bm { \\ pm \\ sigma}$ } \\ \\ \n",
              "  \\ midrule \n",
              "  xxmaj weak & xxunk & $ xxunk \\ pm xxunk $ & $ \\ xxunk \\ times xxunk } \\ pm 2.1 \\ times xxunk \\ \\ \n",
              "  xxmaj intermediate & 3.36 & $ \\ xxunk \\ pm xxunk & $ 7.8 \\ times 10^{-5 } \\ pm 1.9 \\ times 10^{-5}$ \\ \\ \n",
              "  xxmaj strong & 0.17 & $ xxunk \\ pm xxunk $ & $ 6.7 \\ times xxunk } \\ pm 8.8 \\ times 10^{-5}$ \\ \\ \n",
              "  \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  \\ end{table } \n",
              " \n",
              "  xxmaj when conducting plan generation with the three networks trained with different meta - prior values , xxmaj table \\ ref{tbl : plan1 } shows that while the intermediate meta - prior network has the lowest average xxup rmse , the weak meta - prior network has the lowest goal deviation . xxmaj as expected , the average xxup kld increases as the meta - prior weight is reduced , although we note that while the increase in xxup kld between strong and intermediate is inversely proportional to the change in meta - prior , the average xxup kld increase from intermediate to weak does not follow the same relationship . xxmaj in addition , while it appears that the weak meta - prior trades a factor of 2 reduction of average xxup rmse for a factor of 10 improvement in goal deviation , the plots in xxmaj figure \\ ref{fig : plan1 } show that the trajectories generated by the weak meta - prior network are very noisy compared to the output from the other two networks . \n",
              " \n",
              "  \\ begin{figure}[!htbp ] \n",
              "  \\ centering \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp1 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              " \n",
              "  \\ vspace{1em } \n",
              "  \\ centering \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp1 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp1 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp1 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ vspace{1em } \n",
              "  \\ caption{plots showing motor plans of the 20 test sequences . \\ textbf{(a ) } xxmaj shows the ground truth for untrained test data set , with the remaining plots generated with a \\ textbf{(b ) } weak meta - prior , \\ textbf{(c ) } intermediate meta - prior , and \\ textbf{(d ) } strong meta - prior as described in xxmaj table \\ ref{tbl : exp1w } . \\ label{fig : plan1 } } \n",
              "  \\ end{figure } \n",
              " \n",
              "  xxmaj from visual inspection of the trajectory plots compared to the ground truth ( xxmaj figure \\ ref{fig : plan1 } ) , we can additionally see that the intermediate meta - prior network tends to average the trajectories more than the strong meta - prior network that is following the training data more strongly and as a result tends to miss the goal . \n",
              "  xxmaj in summary , plans were generated with highest generalization in the case of an intermediate value for meta - prior , whereas the planned trajectories became significantly more noisy in the case with a weak meta - prior , and in the case with a strong meta - prior the trajectories could not reach the specified goals well . xxmaj in xxmaj section \\ ref{sec : discussion } , we discuss further the implications of the meta - prior setting in plan generation . \n",
              " \n",
              "  \\ subsubsection{plan generation for goals set in xxunk regions } \n",
              "  xxmaj the following test examines whether glean can achieve goals set outside of the trained regions . xxmaj figure \\ ref{fig : xxunk } shows 10 ground truth trajectories reaching goals in an untrained region which is in the middle of the left and right trained goal regions . \n",
              " \n",
              "  \\ begin{figure}[!htbp ] \n",
              "  \\ centering \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp1 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp1 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ vspace{1em } \n",
              "  \\ caption{plots showing motor plans of the 10 test sequences with goals set in an untrained region . \\ textbf{(a ) } xxmaj shows the ground truth test trajectories , and \\ textbf{(b ) } shows the results of plan generation . \\ label{fig : xxunk } } \n",
              "  \\ end{figure } \n",
              " \n",
              "  xxmaj figure \\ ref{fig : xxunk } shows the results of plan generation performed by the network trained with the intermediate meta - prior , where it is apparent that glean is not able to reach the specified goals . xxmaj in particular , it can be observed that the trajectories can not go straight at the branching point . xxmaj instead , they branch left and head towards the left goal region . xxmaj this is likely because the learned prior strongly prefers either turning left or right but not going straight at the branching point . xxmaj this result implies that glean is more likely to generate goal - directed plan trajectories within well habituated areas . \n",
              " \n",
              "  \\ subsection{experiment 2 : simulated robotic object manipulation task } \\ label{sec : xxunk } \n",
              "  xxmaj in order to test the performance of glean in a robotic environment , we prepared a simulated environment in the v - xxup rep simulator with a model of a real 8 xxup dof arm robot ( a xxmaj tokyo xxmaj robotics xxmaj xxunk xxmaj arm ) with a gripper end effector ( see xxmaj figure \\ ref{fig : exp2 } ) . xxmaj in front of the robot is a workspace of approximately 30 cm square , with two cube blocks ( 5 cm / side ) and two circles ( 5 cm diameter ) . xxmaj the robot always starts in a set home position with the gripper between and above the four objects , the blocks placed in front and behind the gripper , and the circles placed left and right of the gripper . xxmaj the positions of the objects are randomized following a xxmaj gaussian distribution , with $ \\ sigma \\ simeq xxunk . xxmaj the task is to generate a motor plan to grasp one of the blocks and place it on a disc , as well as predict the coordinates of the gripper and the two blocks . \n",
              " \n",
              "  \\ begin{figure}[!htbp ] \n",
              "  \\ setlength { \\ fboxsep}{0pt } \n",
              "  \\ centering \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox * { } { \\ fbox { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp2 / xxunk } } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox * { } { \\ fbox { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp2 / xxunk } } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox * { } { \\ fbox { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp2 / xxunk } } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ caption{simulated robot executing the grasp and place task . xxmaj in the workspace in front of the robot , there are two graspable blocks and two goal circles . xxmaj xxunk markers show the predicted positions of the gripper and the two blocks . \\ label{fig : exp2 } } \n",
              "  \\ end{figure } \n",
              " \n",
              "  xxmaj in order to achieve this , the robot is trained with 120 trajectories that involve the robot arm ( 1 ) moving forward or backward to grasp the appropriate object , then ( 2 ) carry the object to the desired goal . xxmaj figure \\ ref{fig : xxunk } shows the trajectories of the gripper in two dimensions , overlaid with an illustration of the gripper and objects . xxmaj the training data is generated by a custom kinematic routine that converts the workspace coordinates to a series of pre - recorded movements taken from our previous work with this robot . xxmaj the recorded trajectories are resampled to 80 timesteps , with padding at the end as necessary . \n",
              " \n",
              "  \\ begin{figure}[!htbp ] \n",
              "  \\ centering \n",
              "  \\ includegraphics[width=0.5 \\ textwidth]{figures / xxmaj exp2 / xxunk } \n",
              "  \\ xxunk of the gripper in two dimensions , with the mean positions of the blocks and goal circles overlaid . xxmaj dashed circles represent the standard deviation of the positions . \\ label{fig : xxunk } } \n",
              "  \\ end{figure } \n",
              " \n",
              "  xxmaj the initial state of the environment is given as the joint angles of the robot as well as the xxup 3d $ ( x , y , z)$ coordinates of the gripper and blocks ( xxunk 17 dimensions ) , while the goal is given as only the coordinates of the gripper and blocks . xxmaj using glean , a motor plan to grasp the appropriate block and take it to the correct goal is generated , along with predictions of the coordinates of the gripper and both blocks at each timestep . xxmaj at the end of the generated sequence , the robot releases the block and the control program records the distance between the centers of the block and goal circle . xxmaj if the block and goal circle overlap , the trial is considered successful . \n",
              " \n",
              "  \\ begin{figure}[!htbp ] \n",
              "  \\ centering \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxup fw } } { \\ includegraphics[width=0.4 \\ textwidth]{figures / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxup si } } { \\ includegraphics[width=0.4 \\ textwidth]{figures / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ vspace{1em } \n",
              "  \\ caption{graphical representations of \\ textbf{(a ) } the forward model ( xxup fm ) and \\ textbf{(b ) } the stochastic initial state ( xxup si ) model as implemented in this paper } \n",
              "  \\ end{figure } \n",
              " \n",
              "  xxmaj in order to compare the performance of glean against other typical trajectory planning approaches , we have implemented a forward model with xxup mtrnn ( see xxmaj figure \\ ref{fig : xxup fw } ) and a stochastic initial state xxup mtrnn ( see xxmaj figure \\ ref{fig : xxup si } ) . xxup fm , as mentioned previously , is commonly used in robotic trajectory planning and is able to predict the next sensory state given the current sensory and motor states . xxmaj for this paper , it is implemented using the same xxup mtrnn as used by glean , but with no stochastic units . xxup si is implemented similarly , although using a xxunk ratio of deterministic and stochastic units at $ t=1 $ and no stochastic units at $ xxunk $ ( as in \\ cite{jung19 } ) . xxmaj table \\ ref{tbl : xxunk } shows an overview of the network parameters for glean , xxup fm , and xxup si . \n",
              " \n",
              "  \\ begin{table}[!htbp ] \n",
              "  \\ caption{network parameters used for the simulated robot experiment for 3 different models --- glean , xxup fm , and xxup si . } \\ label{tbl : xxunk } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ begin{subtable}{0.3 \\ textwidth } \n",
              "  \\ xxunk } \n",
              "  \\ centering \n",
              "  \\ begin{tabular } { xxrep 4 c | } \n",
              "  \\ toprule \n",
              "  & \\ xxunk layer } \\ \\ \n",
              " \t  & \\ textbf{1 } \t & \\ textbf{2 } & \\ textbf{3 } \\ \\ \n",
              "  \\ midrule \n",
              "  xxmaj neurons $ | \\ bm{d}^l|$ \t  & 30 & 20 \t\t  & 10 \\ \\ \n",
              "  z - units \t $ | \\ bm{z}^l|$ & 3 & 2 \t\t  & 1 \\ \\ \n",
              "  $ \\ tau$ & 2 & 4 & 8 \\ \\ \n",
              "  \\ bottomrule \n",
              "  \\ multicolumn{4}{l } { } \\ \\ \n",
              "  \\ end{tabular } \n",
              "  \\ end{subtable } \n",
              "  % \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ begin{subtable}{0.3 \\ textwidth } \n",
              "  \\ xxunk } \n",
              "  \\ centering \n",
              "  \\ begin{tabular } { xxrep 4 c | } \n",
              "  \\ toprule \n",
              "  & \\ xxunk layer } \\ \\ \n",
              " \t  & \\ textbf{1 } \t & \\ textbf{2 } & \\ textbf{3 } \\ \\ \n",
              "  \\ midrule \n",
              "  xxmaj neurons $ | \\ bm{d}^l|$ \t  & 30 & 20 \t\t  & 10 \\ \\ \n",
              "  z - units \t $ | \\ bm{z}^l|$ & 0 & 0 \t\t  & 0 \\ \\ \n",
              "  $ \\ tau$ & 2 & 4 & 8 \\ \\ \n",
              "  \\ bottomrule \n",
              "  \\ multicolumn{4}{l } { } \\ \\ \n",
              "  \\ end{tabular } \n",
              "  \\ end{subtable } \n",
              "  % \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ begin{subtable}{0.3 \\ textwidth } \n",
              "  \\ xxunk } \n",
              "  \\ centering \n",
              "  \\ begin{tabular } { xxrep 4 c } \n",
              "  \\ toprule \n",
              "  & \\ xxunk layer } \\ \\ \n",
              " \t  & \\ textbf{1 } \t & \\ textbf{2 } & \\ textbf{3 } \\ \\ \n",
              "  \\ midrule \n",
              "  xxmaj neurons $ | \\ bm{d}^l|$ \t  & 30 & 20 \t\t  & 10 \\ \\ \n",
              "  z - units \t $ | \\ bm{z}^l|$ & 30 * & 20 * & 10 * \\ \\ \n",
              "  $ \\ tau$ & 2 & 4 & 8 \\ \\ \n",
              "  \\ bottomrule \n",
              "  \\ xxunk z - units only at $ t=1 $ } \\ \\ \n",
              "  \\ end{tabular } \n",
              "  \\ end{subtable } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ end{table } \n",
              " \n",
              "  xxmaj both xxup fm and xxup si are trained in a partially closed loop manner to improve their generative ability , blending the ground truth sensory state $ \\ bm { \\ xxunk and the predicted sensory state $ \\ xxunk as in \\ cite{jung19 } . xxmaj for xxup si , we use global norm gradient clipping with a setting of 50 to ensure the network remains stable . xxmaj note that while the forward model has thus far been depicted as operating on the motor space directly , in this comparison the forward model operates in proprioception space to match the other models . \n",
              " \n",
              "  \\ begin{equation } \n",
              "  \\ bm { \\ xxunk } = 0.9 \\ xxunk } + 0.1 \\ bm { \\ xxunk } \n",
              "  \\ end{equation } \n",
              " \n",
              "  xxmaj for this experiment , we have adjusted the meta - prior settings as shown in xxmaj table \\ ref{tbl : xxunk } . xxmaj the range of meta - prior values has been reduced significantly as this task is much more sensitive to this setting , as shown in the following results . \n",
              " \n",
              "  \\ begin{table}[!htbp ] \n",
              "  \\ caption{meta - prior settings for the simulated robot experiment } \\ label{tbl : xxunk } \n",
              "  \\ centering \n",
              "  \\ begin{tabular } { xxrep 4 c } \n",
              "  \\ toprule \n",
              "  & \\ xxunk layer } \\ \\ \n",
              "  \\ textbf{meta - prior setting $ w$ } & \\ xxunk } \t & \\ xxunk } & \\ xxunk } \\ \\ \n",
              "  \\ midrule \n",
              "  xxmaj weak \t\t  & 0.0004 & 0.0002 \t\t & 0.0001 \\ \\ \n",
              "  xxmaj intermediate & xxunk \t\t & 0.0004 & 0.0002 \\ \\ \n",
              "  xxmaj strong & 0.002 & 0.001 & 0.0005 \\ \\ \n",
              "  \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  \\ end{table } \n",
              " \n",
              "  \\ subsubsection{plan generation } \n",
              "  xxmaj as in plan generation results with the xxup 2d dataset in xxmaj section \\ xxunk } , here we use a test set of 20 untrained trajectories , with the results being averaged over 10 plan generation runs . glean was allowed to run for 1000 epochs , with a plan adaptation rate of 0.1 . xxmaj in xxmaj table \\ ref{tbl : exp2 } , we compare generated trajectories to ground truth trajectories , and here it can be xxunk again that finding an intermediate setting of the meta - prior gives the best result --- not only in terms of being close to the ground truth but in terms of success rate in accomplishing the grasp and place task in the simulator . \n",
              " \n",
              "  xxmaj in xxmaj table \\ ref{tbl : xxunk } , we summarize the results of executing the generated plans using the robot simulator --- comprising of success rate at the task as well as the average distance of the final block position from the goal , the latter only being counted in successful attempts . xxmaj as in our previous work with a similar grasping task , succeeding in this task requires high accuracy at the grasp point in the middle of the trajectory . xxmaj thus , even though the differences in the generated trajectories are relatively small , the outcomes in simulation are significantly altered . \n",
              " \n",
              "  xxmaj note that despite the weak meta - prior offering a theoretically lower goal deviation , the actual measured error at the goal is higher than the intermediate meta - prior network . xxmaj this is due to the average distance from the goal measuring from the block center to the goal center , and if the block was off - center when it was grasped , it would likely be off - center when it is placed on the goal . xxmaj due to the weak meta - prior network being less accurate during the intermediate steps , higher errors at the grasp point is likely . \n",
              " \n",
              "  \\ begin{table}[!htbp ] \n",
              "  \\ centering \n",
              "  \\ xxunk generated plans with networks trained with different meta - priors , compared with ground truth . xxmaj note that in order for the results in the following tables to be comparable to the previous experiment , the output values were rescaled to $ [ 0,1]$. xxmaj only the sensory states are compared between generated and ground truth trajectories . xxmaj best result highlighted in bold \\ label{tbl : exp2 } } \n",
              "  \\ begin{tabular } { xxrep 4 c } \n",
              "  \\ toprule \n",
              "  \\ textbf{meta - prior } & \\ textbf{average $ \\ bm{kld_{pq}}$ } & \\ textbf{average xxup rmse$ \\ pm \\ sigma$ } & \\ textbf{average xxup gd$ \\ pm \\ sigma$ } \\ \\ \n",
              "  \\ midrule \n",
              "  xxmaj weak & 12.48 & $ xxunk \\ pm xxunk $ & $ \\ xxunk \\ times 10^{-5 } \\ pm 7.4 \\ xxunk \\ \\ \n",
              "  xxmaj intermediate & 4.64 & $ \\ xxunk \\ pm xxunk & $ 6.9 \\ times 10^{-5 } \\ pm 8.6 \\ times10^{-6}$ \\ \\ \n",
              "  xxmaj strong & 2.35 & $ xxunk \\ pm xxunk $ & $ 1.3 \\ times xxunk } \\ pm 1.4 \\ times 10 xxunk \\ \\ \n",
              "  \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  \\ end{table } \n",
              " \n",
              "  \\ begin{table}[!htbp ] \n",
              "  \\ centering \n",
              "  \\ caption{simulation results of executing glean generated plans with networks trained with different meta - priors . xxmaj best result highlighted in bold \\ label{tbl : xxunk } } \n",
              "  \\ begin{tabular}{ccc } \n",
              "  \\ toprule \n",
              "  \\ textbf{meta - prior } & \\ textbf{success rate } & \\ textbf{average error at xxunk \\ pm \\ sigma$ } \\ \\ \n",
              "  \\ midrule \n",
              "  xxmaj weak & xxunk \\ % & $ 1.74 \\ pm xxunk \\ \\ \n",
              "  \\ xxunk } & \\ xxunk \\ % } & $ \\ xxunk \\ pm xxunk \\ xxunk } \\ \\ \n",
              "  xxmaj strong & 60.5 \\ % & $ 2.02 \\ pm xxunk \\ \\ \n",
              "  \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  \\ end{table } \n",
              " \n",
              "  xxmaj as an illustrative example , xxmaj figure \\ ref{fig : xxunk } shows generated plans consisting of predicted sensory and motor states given the initial environmental state and the goal sensory image . xxmaj as suggested by the overall results , glean trained with an intermediate meta - prior appears to generate trajectories that most resemble the ground truth trajectory . xxmaj while in some other tasks it is possible that the trajectory between the start and the goal is not critical , in order for the robot to successfully complete the task in this experiment accuracy is required at the point where the robot grasps the block . \n",
              " \n",
              "  \\ begin{figure}[!htbp ] \n",
              "  \\ centering \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox * { \\ label{fig : xxunk } } { \\ includegraphics[width=0.24 \\ textwidth]{figures / xxmaj exp2 / plangen / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox * { \\ label{fig : xxunk } } { \\ includegraphics[width=0.24 \\ textwidth]{figures / xxmaj exp2 / plangen / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox * { \\ label{fig : xxunk } } { \\ includegraphics[width=0.24 \\ textwidth]{figures / xxmaj exp2 / plangen / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox * { \\ label{fig : xxunk } } { \\ includegraphics[width=0.24 \\ textwidth]{figures / xxmaj exp2 / plangen / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk m } } { \\ includegraphics[width=0.24 \\ textwidth]{figures / xxmaj exp2 / plangen / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk m } } { \\ includegraphics[width=0.24 \\ textwidth]{figures / xxmaj exp2 / plangen / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk m } } { \\ includegraphics[width=0.24 \\ textwidth]{figures / xxmaj exp2 / plangen / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ subcaptionbox { \\ label{fig : xxunk } } { \\ includegraphics[width=0.24 \\ textwidth]{figures / xxmaj exp2 / plangen / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ vspace{1em } \n",
              "  \\ caption{plots showing the predicted sensory states ( top row ) and the motor plans ( bottom row ) for a given goal . xxmaj the colored lines within each plot represent a sequence of predictions for one sensory or proprioception dimension . xxmaj the columns of plots correspond to \\ textbf{(a ) } weak meta - prior , \\ textbf{(b ) } intermediate meta - prior , \\ textbf{(c ) } strong meta - prior , and \\ textbf{(d ) } ground truth . xxmaj an arrow indicates the grasp point , where the robot attempts to pick up the block . xxmaj while the exact timestep of the grasp point can vary , if the relationship between the predicted dimensions is not maintained the grasping attempt is more likely to fail . \\ label{fig : xxunk } } \n",
              "  \\ end{figure } \n",
              " \n",
              "  \\ subsection{comparison between glean , xxup fm , and xxup si } \n",
              "  xxmaj finally , we compare the plan generation performance of glean against the stochastic initial state ( xxup si ) model and the forward model ( xxup fm ) . glean in this test is represented by the intermediate meta - prior network from the previous test . xxmaj results from xxup si are averaged over 10 runs , as with glean . xxup fm is deterministic and thus some statistics such as $ kld_{pq}$ and $ \\ sigma$ are omitted . \n",
              " \n",
              "  \\ begin{table}[!htbp ] \n",
              "  \\ centering \n",
              "  \\ xxunk generation results of glean , xxup fm , and xxup si . xxmaj best result highlighted in bold \\ label{tbl : xxunk } } \n",
              "  \\ begin{tabular } { xxrep 4 c } \n",
              "  \\ toprule \n",
              "  \\ textbf{model } & \\ textbf{average $ \\ bm{kld_{pq}}$ } & \\ textbf{average xxup rmse$ \\ pm \\ sigma$ } & \\ textbf{average xxup gd$ \\ pm \\ sigma$ } \\ \\ \n",
              "  \\ midrule \n",
              "  xxmaj forward model & -- & $ xxunk $ & $ 6.8 \\ times 10^{-3}$ \\ \\ \n",
              "  xxmaj stochastic initial state & 3.32 & $ xxunk \\ pm xxunk $ & $ 7.8 \\ times 10^{-5 } \\ pm 3.3 \\ times10^{-6}$ \\ \\ \n",
              "  \\ xxunk } & 4.64 & $ \\ xxunk \\ pm xxunk & $ \\ xxunk \\ times 10^{-5 } \\ pm 8.6 \\ xxunk \\ \\ \n",
              "  \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  \\ end{table } \n",
              " \n",
              "  xxmaj from xxmaj table \\ ref{tbl : xxunk } , which evaluates the three algorithms ' planning performance compared to the ground truth , we can observe that xxup fm is the worst performer , with xxup rmse an order of magnitude and xxup gd two orders of magnitude worse than either glean or xxup si . xxmaj on the other hand , glean and xxup si are relatively close in this theoretical planning performance . xxmaj however , as summarized in xxmaj table \\ ref{tbl : xxunk } , executing the generated plans in the robot simulator demonstrates a significant advantage for glean . xxup fm is unable to generate any plausible motor plans and thus achieved no successful runs . \n",
              " \n",
              "  \\ begin{table}[!htbp ] \n",
              "  \\ centering \n",
              "  \\ caption{simulation results of executing plans generated by glean , xxup fm , and xxup si . xxmaj best result highlighted in bold \\ label{tbl : xxunk } } \n",
              "  \\ begin{tabular}{ccc } \n",
              "  \\ toprule \n",
              "  \\ textbf{model } & \\ textbf{success rate } & \\ textbf{average error at xxunk \\ pm \\ sigma$ } \\ \\ \n",
              "  \\ midrule \n",
              "  xxmaj forward model ( xxup fm ) & 0.0 \\ % & -- \\ \\ \n",
              "  xxmaj stochastic initial state ( xxup si ) & 68.0 \\ % & $ 2.02 \\ pm xxunk \\ \\ \n",
              "  \\ xxunk } & \\ xxunk \\ % } & $ \\ xxunk \\ pm xxunk \\ xxunk } \\ \\ \n",
              " \n",
              "  \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  \\ end{table } \n",
              " \n",
              "  xxmaj given that glean and xxup si were able to generate plans with successful outcomes while xxup fm had no successful plans , it is apparent that the forward model in this condition is not capable of generating goal - directed plans . xxmaj this is visible in xxmaj figure \\ ref{fig : exp2compare } , showing a comparison between generated sensory predictions and ground truth sensory states , where unlike glean and xxup si , xxup fm is unable to find any motor plan in order to generate a plausible sensory prediction . \n",
              "  % \n",
              "  \\ begin{figure}[!htbp ] \n",
              "  \\ setlength { \\ fboxsep}{0pt } \n",
              "  \\ centering \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ xxunk \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp2 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ xxunk \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp2 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ xxunk \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp2 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ vspace{1em } \n",
              "  \\ caption{comparison between the generated sensory predictions ( solid lines ) and the ground truth sensory states ( dashed lines ) for \\ textbf{(a ) } forward model , \\ textbf{(b ) } stochastic initial state , and \\ textbf{(c ) } glean \\ label{fig : exp2compare } } \n",
              "  \\ end{figure } \n",
              "  % \n",
              "  xxmaj naturally , we may ask whether the observed failure of plan generation by xxup fm is due to insufficient sensory prediction capability . xxmaj in order to examine this , one - step look ahead prediction capability in the three models were compared . xxmaj in xxup fm , one - step look ahead prediction was generated at each current timestep by providing the ground truth sensory - motor sequence inputs up to the current timestep . xxmaj the resultant sensory prediction was compared with the ground truth sensory inputs . xxmaj for glean and xxup si , one - step look ahead prediction was generated analogously . xxmaj specifically , with glean , this was done by using error regression for inferring the latent state at each timestep until the current timestep . xxmaj with xxup si , the latent state is inferred at the initial timestep only . \n",
              " \n",
              "  % \n",
              "  \\ begin{table}[!htbp ] \n",
              "  \\ caption{comparison of average errors in sensory predictions generated by glean , xxup fm , and xxup si when provided with the ground truth motor states } \\ label{tbl : exp2compare } \n",
              "  \\ centering \n",
              "  \\ begin{tabular}{cc } \n",
              "  \\ toprule \n",
              "  \\ textbf{model } & \\ textbf{average xxup rmse } \\ \\ \n",
              "  \\ midrule \n",
              "  xxmaj forward model ( xxup fm ) & xxunk \\ \\ \n",
              "  xxmaj stochastic initial state ( xxup si ) & xxunk \\ \\ \n",
              "  glean & xxunk \\ \\ \n",
              "  \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  \\ end{table } \n",
              " \n",
              "  xxmaj table \\ ref{tbl : exp2compare } shows the result of comparison among those three models . xxmaj it can be observed that the prediction capabilities of these three models are relatively similar . xxmaj in particular , by looking at a comparison of one - step ahead prediction for an example trajectory among the models as shown in xxmaj figure \\ ref{fig : xxunk } , we observe that xxup fm is able to generate adequate sensory predictions in a similar manner to xxup si and glean . xxmaj this result suggests that the failure of motor plan generation by xxup fm is not due to lack of sensory prediction capability but due to other reasons . xxmaj we speculate that this is caused by the fact that no prior knowledge or constraints exist for generating motor sequences in xxup fm . xxmaj we discuss this issue in xxmaj section \\ ref{sec : discussion } . \n",
              " \n",
              "  \\ begin{figure}[!htbp ] \n",
              "  \\ setlength { \\ fboxsep}{0pt } \n",
              "  \\ centering \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ xxunk \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp2 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ xxunk \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp2 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ xxunk \\ label{fig : xxunk } } { \\ includegraphics[width=0.3 \\ textwidth]{figures / xxmaj exp2 / xxunk } } \n",
              "  \\ hspace * { \\ fill } \n",
              "  \\ vspace{1em } \n",
              "  \\ caption{comparison of one - step look ahead sensory prediction ( solid lines ) and the ground truth ( dashed lines ) among three different xxunk \\ textbf{(a ) } forward model , \\ textbf{(b ) } stochastic initial state , and \\ textbf{(c ) } glean \\ label{fig : xxunk } } \n",
              "  \\ end{figure } \n",
              " \n",
              "  xxrep 42 % \n",
              "  \\ section{conclusion and xxmaj discussion } \\ label{sec : discussion } \n",
              "  xxmaj the current study proposed glean as a novel goal - directed planning scheme to investigate the problem of how agents can generate effective goal - directed plans based on learning using limited amount and range of sensory - motor experiences . glean was developed using the frameworks of predictive coding ( xxup pc ) and active inference ( xxup aif ) . xxmaj with these frameworks , learning is conducted by inferring optimal latent variables and synaptic weights for maximizing the evidence lower bound . xxmaj in a similar manner , glean accomplishes goal - directed planning by inferring optimal latent variables for maximizing the estimated lower bound . xxmaj actual implementation of glean was achieved by using the predictive coding inspired variational recurrent neural network ( xxup pv - xxup rnn ) previously proposed by our group \\ cite{ahmadi19 } . \n",
              " \n",
              "  xxmaj the model was evaluated using a simple virtual agent in xxup 2d environment and a more complex simulated robotic pick and place task . xxmaj the analysis based on the results from the first experiment revealed that the prior distribution developed initial state sensitive deterministic dynamics by increasing the complexity with a strong meta - prior . xxmaj meanwhile , it developed noisy stochastic dynamics by reducing the complexity with a weaker meta - prior . \n",
              " \n",
              "  xxmaj both experiments showed that glean produces the best performance in goal - directed planning by achieving sufficient generalization in learning when setting the meta - prior to an adequate intermediate value between the two extremes of weak and strong during the learning phase . xxmaj furthermore , it was shown that motor plans can not be generated for those goals set in xxunk regions . xxmaj this is because the learned prior tends to prevent the motor trajectory from going beyond the learned region . \n",
              " \n",
              "  xxmaj the performance of glean in goal - directed planning was compared against the forward model ( xxup fm ) and stochastic initial state model ( xxup si ) using the robotic pick and place task . xxmaj the results showed that glean outperforms the other two models , especially when considering the simulation results . xxmaj moreover , it was shown that xxup fm can not generate corresponding motor plans at all even with sufficient capability for predicting next timestep sensory inputs when provided with the current motor commands . xxmaj this outcome can be accounted for by the fact that in xxup fm the motor plan search is carried out without any learned priors for constraining generation of hypothetical motor sequences , since xxup fm does not facilitate any functions for probabilistically predicting next motor commands . \n",
              " \n",
              "  xxmaj in this circumstance , xxunk trajectories that seemingly reach given goals can be generated by arbitrarily combining motor states in sequences that happen to minimize the distal goal error . xxmaj on the other hand , in the case of glean a generative model is learned as a probabilistic mapping from the latent state in the current timestep to the proprioception in terms of the joint angles as well as the exteroception in terms of sensory state . xxmaj in this case , motor sequence plans can be inferred under the constraints of the learned prior by which goal - directed plans can be generated within the boundary of well - habituated trajectories . \n",
              " \n",
              "  xxmaj the aforementioned idea aligns well with the concept of ` ` niche construction ' ' of agents discussed in \\ xxunk } . xxmaj it is argued that agents should not attempt to learn complete global models of the world , and instead should learn local models of habituated patterns which should be feasible given that the amount of possible experiences in the world is certainly limited . xxmaj the free energy minimization principle \\ xxunk } naturally realizes this as its inherent drive for minimizing surprise places limits on plan generation as well as actions beyond the boundary of habituated space . \n",
              " \n",
              "  xxmaj another similar line of research that we have recently become aware of is model - based reinforcement learning for plan generation \\ xxunk , xxunk } . xxmaj an agent learns either deterministic \\ xxunk } or stochastic \\ xxunk } latent dynamics for predicting the sensation and reward in a similar manner to xxup fm . xxmaj the agent after learning can generate actions not by using an action policy network as is the case in model - free reinforcement learning but by planning in the latent space using an evolutionary search for maximizing the reward accumulation in the future . \n",
              " \n",
              "  xxmaj the aforementioned studies , however , could suffer from the problem of generating faulty action plans because the planning process can not be constrained by a learned action prior for preventing action space search from going beyond the learned region , as the current paper has discussed . xxmaj this problem could be solved if the model - based learning and the model - free learning components could be sufficiently combined as the latter could provide the action prior to be former . \n",
              " \n",
              "  xxmaj the current study has potential to be extended in various directions in future study . xxmaj one significant drawback in the current study is that an optimal value for meta - prior which results in the best generalization in learning and planning can be obtained only though trial and error . xxmaj although our preliminary study showed that generalization is less sensitive to the setting of the meta - prior when an ample amount of training data is used , the meta - prior should still be set within a reasonable range . xxmaj future study should explore possible measures for adapting meta - prior automatically depending the training data . \n",
              " \n",
              "  xxmaj one interesting possibility is that shifts of the meta - prior during planning could affect the quality of motor plan generation analogously to the choking effect \\ xxunk , xxunk } . xxmaj the choking effect is the tendency of xxunk experts to show performance disruption such as drops in the quality and precision of generated sensorimotor behavior . xxmaj xxunk et al . \\ xxunk } proposed that this effect can be accounted for by imprecise precision modulation during active inference for generating motor plans . xxmaj this imprecise precision modulation could take place during the inference of the latent variable , if the meta - prior in our model is set with different values during the plan generation phase compared to the optimal values used during the learning phase . xxmaj future study should explore such mechanisms in detail . \n",
              " \n",
              "  xxmaj another drawback is that the current investigation is limited to an offline plan generation processes . xxmaj extended studies should investigate how the model could deal with the problem of online planning , which requires the model to be responsive to dynamically changing environments in real time . xxmaj for this purpose , the model should be extended such that all three processes of ( 1 ) recognizing the current situation by maximizing the evidence lower bound , ( 2 ) updating current goal - directed plans based on currently recognized situation by maximizing the estimated lower bound , and ( 3 ) acting on the environment by executing the plan , to be carried out in real time , as has been demonstrated by a simulation study on the retrospective and prospective inference scheme ( xxup xxunk ) \\ xxunk } . \n",
              " \n",
              "  xxmaj in such a situation , an interesting problem to be considered is how to dynamically allocate cognitive computational resources required for real time computation of these multiple cognitive processes by adapting to the on - going situation under a resource bounded condition . xxmaj it is also important to investigate how agents can assure the minimum cognitive and behavioral competency for their survival when the optimization involved with these cognitive processes can not be guaranteed under real time constraints . xxmaj these research problems are left for future studies . \n",
              " \n",
              "  xxmaj although the current study employed supervised training schemes for acquiring the generative models , it may also be interesting if self - exploration - based learning can be introduced to the scheme . xxmaj one possible scenario for achieving this would be to incorporate the idea of intrinsic motivation \\ cite{oudeyer07 , xxunk } into the model . xxmaj with intrinsic motivation , agents tend to explore particular goals more frequently for which the success rate of achievement improves more rapidly or other goals \\ xxunk } . xxmaj the exploration can switch to other goals when the exploration of the current goal hits a plateau in its improvement . xxmaj in order to incorporate such a mechanism into glean , glean should be extended to facilitate a mechanism for learning a meta - policy \\ xxunk } to generate its own goals , some more frequently than others , by monitoring the improvement rate for successful achievement of each goal . xxmaj it may be worthwhile to examine what sort of development in generating various goal - directed behaviors , from simple to more complex , can be observed by using this scheme . \n",
              " \n",
              "  xxrep 42 % \n",
              " \n",
              "  \\ section*{acknowledgments } \n",
              "  xxmaj the authors are grateful for the help and support provided by xxmaj dr. xxmaj xxunk xxmaj ahmadi , as well as the xxmaj scientific xxmaj computing section of xxmaj research xxmaj support xxmaj division at xxup xxunk . \n",
              " \n",
              "  xxrep 42 % \n",
              " \n",
              "  \\ bibliographystyle{abbrvnat } \n",
              "  \\ xxunk } \n",
              " \n",
              "  \\ end{document } \n",
              " ,xxbos \\ documentclass{ios - xxmaj book - xxmaj article } \n",
              "  \\ xxunk } \n",
              " \n",
              "  \\ usepackage[utf8]{inputenc } \n",
              "  \\ usepackage{hyperref } \n",
              "  \\ xxunk } \n",
              " \n",
              "  \\ usepackage{mathptmx } \n",
              " \n",
              "  \\ usepackage{graphicx } \n",
              "  \\ usepackage{url } \n",
              "  \\ usepackage{amssymb } \n",
              "  % \\ usepackage{pifont}% http : / / ctan.org / pkg / pifont \n",
              "  % \\ xxunk } % for the verbatim indent \n",
              "  % \\ usepackage{framed } \n",
              "  \\ usepackage[dvipsnames]{xcolor } \n",
              "  \\ usepackage{enumerate } \n",
              "  \\ usepackage{algpseudocode , algorithm } \n",
              "  % \\ usepackage{wrapfig } \n",
              " \n",
              " \n",
              "  \\ usepackage{caption } \n",
              "  \\ usepackage{subcaption } \n",
              "  % \\ usepackage{booktabs } % xxmaj for professional looking tables \n",
              "  \\ usepackage{multirow } \n",
              "  % \\ usepackage{rotating } \n",
              "  % \\ usepackage{multicol } \n",
              "  % \\ usepackage{longtable } \n",
              "  % \\ usepackage{tabularx } \n",
              "  % \\ xxunk } \n",
              "  % \\ usepackage{tablefootnote } \n",
              " \n",
              " \n",
              " \n",
              "  \\ def \\ hb { \\ hbox to 10.7 cm { } } \n",
              " \n",
              "  \\ begin{document } \n",
              " \n",
              "  \\ pagestyle{headings } \n",
              "  \\ def \\ thepage { } \n",
              " \n",
              "  \\ begin{frontmatter } % xxmaj the preamble begins here . \n",
              " \n",
              "  % \\ xxunk } \n",
              "  \\ xxunk is this xxmaj explanation for ? \\ \\ xxmaj human xxmaj intelligence and xxmaj knowledge xxmaj graphs for explainable xxup ai } \n",
              " \n",
              "  \\ xxunk 2020 \\ xxunk 2020 \\ hb } \n",
              "  % \\ subtitle{subtitle } \n",
              " \n",
              "  \\ author { \\ xxunk } \\ xxunk } } \\ xxunk - print version of the xxmaj book xxmaj chapter accepted in : xxmaj ilaria xxmaj xxunk , xxmaj xxunk xxmaj xxunk , xxmaj pascal xxmaj xxunk ( eds . ) , xxmaj knowledge xxmaj graphs for explainable xxup ai -- xxmaj foundations , xxmaj applications and xxmaj challenges . xxmaj studies on the xxmaj semantic xxmaj web , xxmaj volume 47 , xxup ios xxmaj press , xxmaj amsterdam , xxunk \n",
              "  % \\ author[a ] { \\ xxunk } \\ xxunk \n",
              "  % \\ xxunk this if needed . } , \n",
              "  % \\ author[b ] { \\ xxunk } \\ xxunk } } \n",
              "  % and \n",
              "  % \\ author[b ] { \\ xxunk } \\ xxunk } } \n",
              " \n",
              "  \\ xxunk xxmaj xxunk } \n",
              "  \\ xxunk -- xxmaj politecnico di xxmaj milano \\ \\ xxmaj xxunk xxmaj xxunk 226 , xxunk xxmaj milano -- xxmaj italy } \n",
              "  % \\ xxunk -- xxmaj politecnico di xxmaj milano } \n",
              "  % \\ xxunk xxmaj affiliation of xxmaj second xxmaj author and xxmaj third xxmaj author } \n",
              " \n",
              "  \\ begin{abstract } \n",
              "  % \\ xxunk abstract here . } \n",
              "  explainable xxup ai focuses on generating explanations for the output of an xxup ai algorithm to a user , usually a decision - maker . xxmaj such user needs to interpret the xxup ai system in order to decide whether to trust the machine outcome . xxmaj when addressing this challenge , therefore , proper attention should be given to produce explanations that are \\ xxunk } by the target community of users . \n",
              " \n",
              "  xxmaj in this chapter , we claim for the need to better investigate what constitutes a \\ emph{human explanation } , i.e. a justification of the machine behaviour that is interpretable and actionable by the human decision makers . xxmaj in particular , we focus on the contributions that \\ emph{human xxmaj intelligence } can bring to explainable xxup ai , especially in conjunction with the exploitation of xxmaj knowledge xxmaj graphs . \n",
              " \n",
              "  xxmaj indeed , we call for a better interplay between xxmaj knowledge xxmaj representation and xxmaj reasoning , xxmaj social xxmaj sciences , xxmaj human xxmaj computation and xxmaj human - xxmaj machine xxmaj cooperation research -- as already explored in other xxup ai branches -- in order to support the goal of explainable xxup ai with the adoption of a \\ emph{human - in - the - xxmaj loop } approach . \n",
              "  \\ end{abstract } \n",
              " \n",
              "  \\ begin{keyword } \n",
              "  xxmaj explainability \\ sep xxmaj human xxmaj intelligence \\ sep xxmaj human xxmaj computation \\ sep xxmaj human - in - the - xxmaj loop \\ sep xxmaj human - xxmaj machine xxmaj cooperation \\ sep xxmaj knowledge xxmaj graphs \n",
              "  \\ end{keyword } \n",
              "  \\ end{frontmatter } \n",
              " \n",
              "  \\ xxunk 2020 \\ xxunk 2020 \\ hb } \n",
              "  % \\ thispagestyle{empty } \n",
              "  % \\ pagestyle{empty } \n",
              " \n",
              "  xxrep 96 % \n",
              "  \\ section{introduction } \\ label{sec : intro } \n",
              " \n",
              "  % xxmaj modeling ( as in xxup ml ) needs humans ( slide 23 ) \n",
              "  xxmaj the recent xxunk of xxmaj machine xxmaj learning and xxmaj artificial xxmaj intelligence approaches brought a new wave of interest in such methods and technologies . xxmaj autonomous agents and automatic systems are now available and more affordable than before , but , if we relied only on popular news and communication , we would tend to think that they completely got rid of human intervention both in their setup and in their operation . xxmaj any practitioner , however , knows very well that human contributions are indispensable in order to set up , train , optimise and operate such systems . \n",
              " \n",
              "  xxmaj referring to the xxup ai systems that more strongly rely on data and in particular to predictive xxmaj machine xxmaj learning , human knowledge is still required in all phases to answer relevant questions that are not necessarily targeted to the xxup ai experts : \n",
              "  \\ begin{itemize } \n",
              " \t  \\ item \\ xxunk creating a model } : \n",
              " \t\t % \\ begin{itemize } \n",
              " \t\t % \\ item \n",
              " \t\t during training set creation ( ` ` what data can i use to build a model ? ' ' ) \n",
              " \t % \\ end{itemize } \n",
              " \t  \\ item at \\ emph{model building time } : \n",
              " \t % \\ begin{itemize } \n",
              " \t\t % \\ item \n",
              " \t\t during model validation ( ` ` is my model correct ? ' ' , ` ` is my model good enough ? ' ' ) and \n",
              " \t\t % \\ item \n",
              " \t\t during model refinement ( ` ` what additional training data / features would improve my model performance ? ' ' ) \n",
              " \t % \\ end{itemize } \n",
              " \t  \\ item \\ xxunk the model in production } : \n",
              " \t % \\ begin{itemize } \n",
              " \t\t % \\ item \n",
              " \t\t to ensure algorithmic transparency ( ` ` should i trust the way my model gave such a prediction ? ' ' ) and \n",
              " \t\t % \\ item \n",
              " \t\t to provide explainability ( ` ` why did my model give such an outcome / prediction ? ' ' ) \n",
              " \t % \\ end{itemize } \n",
              "  \\ end{itemize } \n",
              " \n",
              " \n",
              "  oindent xxmaj in this chapter , we focus on the role that xxmaj human xxmaj intelligence and ( human - generated ) xxmaj knowledge xxmaj graphs play to answer the above questions . xxmaj we also claim that , with special reference to explainability , humans are only partially considered in explainable xxup ai research , while they should , because the required explanations should be useful for human comprehension . \n",
              " \n",
              "  xxmaj the remainder of the chapter is structured as follows : related work is illustrated in xxmaj section \\ ref{sec : related } , and xxmaj section \\ ref{sec : explanation } clarifies what we mean by explanation and why humans are needed in their generation ; opportunities for ( human ) explainable xxup ai coming from the employment of xxmaj human xxmaj intelligence and xxmaj knowledge xxmaj graphs are outlined in xxmaj section \\ ref{sec : xxunk } , and xxmaj section \\ ref{sec : concl } presents some conclusions and traces some possible future work . % \\ xxunk } \n",
              " \n",
              "  xxrep 96 % \n",
              "  \\ section{related xxmaj work } \\ label{sec : related } \n",
              " \n",
              "  xxmaj in the context of xxmaj artificial xxmaj intelligence and xxmaj machine xxmaj learning , several research trends investigate the role and interplay between humans and machines . \n",
              " \n",
              "  a new emerging process of scientific inquiry is shown in~ \\ xxunk } : different people beyond scientists are now involved in such a process , because xxunk participate both in the creation / collection of information ( via user - generated content ) and in the coding / labelling / validation phases ( e.g. through xxmaj crowdsourcing or xxmaj citizen xxmaj science ) ; the authors call for a new data analytics paradigm with user involvement , and demonstrate experimental results to show the effect of interface design on how users transform information . \n",
              " \n",
              "  xxmaj indeed , the power of the ` ` crowd ' ' is often leveraged to create large - scale training sets for xxmaj machine xxmaj learning , by adopting xxmaj crowdsourcing~ \\ xxunk } , xxmaj human xxmaj computation~ \\ xxunk } and xxmaj citizen xxmaj xxunk \\ xxunk } approaches . \n",
              "  % \n",
              "  xxmaj moreover , knowledge in human cognitive processes may assist the design and implementation of xxmaj machine xxmaj learning , as claimed in~ \\ xxunk } ; however , the current popularity of black - box models hinders an effective human intervention because those approaches negatively impact on trustworthiness , interpretability and the discovery of hidden rules . \n",
              " \n",
              "  xxmaj user trust is indeed an important indicator because it correlates with system accuracy : humans are able to dynamically adjust their reliance based on a system perceived accuracy and they even show acceptance xxunk \\ xxunk } : this implies the need to correctly design an xxup ai system to xxunk the desired level of user trust . \n",
              "  % \n",
              "  xxmaj the validation phase of xxmaj machine xxmaj learning algorithms also benefits from the integration of user - centred evaluation : the authors of~ \\ xxunk } advocate adopting user - centred design ( iterative ) approaches for xxmaj machine xxmaj learning , in model optimisation , selection and validation . \n",
              " \n",
              "  xxmaj different families of methods explicitly aim to improve learned models based on human knowledge . xxmaj active xxmaj learning~ \\ xxunk } is based on the idea that a xxmaj machine xxmaj learning algorithm can achieve greater accuracy with fewer labeled training instances if it is allowed to ` ` choose ' ' the data from which it learns , by asking queries to an ` ` oracle ' ' which usually is a human annotator . xxmaj transfer xxmaj learning~ \\ xxunk } emerged to fulfill the need to build real world applications in which it is expensive or impossible to re - collect the training data required and xxunk the models ; in such cases knowledge transfer is attempted by adapting a model already trained on some domain ( with the help of human annotators ) to a different domain . \n",
              " \n",
              "  xxmaj human - xxmaj machine xxmaj cooperation is at the heart of xxmaj interactive xxmaj machine xxmaj learning~ \\ xxunk } , in which a human operator and a machine collaborate to achieve a task ; while coupling algorithm - centred analysis with human - centred evaluation seems to yield better results than a fully automated or fully manual approach , research is still needed to explore to what extent this mix can provide xxunk \\ xxunk } : participatory design with end - users could help incorporating human expertise in algorithms and models ; visualisation techniques could facilitate user feedback ; creativity , lateral thinking and exploration can also support , if suitable tools and objective and subjective metrics are developed . \n",
              " \n",
              "  xxmaj in general , in order to improve and optimise the interaction between humans and machines , a perspective shift should be adopted , for example by walking away from a purely technical optimisation and embracing a designer xxunk , like the one proposed in~ \\ xxunk } , in which the author xxunk to stop seeing technologies as a collection of tools and xxunk and instead start seeing them as an evolutionary flow around human problems , whose parts ultimately integrate to create a new category of things named xxunk technologies or ` ` xxup ai that works for people ' ' . \n",
              " \n",
              "  % \\ begin{itemize } \n",
              " \t % \\ item \\ xxunk } : process of scientific enquiry ( xxunk ) , claim on new data analytics paradigm for user involvement , results on effect of user interface on results \n",
              " \t % \\ item \\ xxunk } : how knowledge in human cognitive processes may assist he design and implementation of xxmaj machine xxmaj learning ( however with claims against black box ... ) \n",
              " \t % \\ item \\ xxunk } : user trust correlate with system accuracy and users develop acceptance thresholds \n",
              " \t % \\ item \\ xxunk } : integration of user - centred evaluation in ml algorithm design process ( model optimisation , selection and validation ) \n",
              " \t % \\ item \\ xxunk } : coupling algorithm - centred analysis with human - centred evaluation ; implications for research \n",
              " \t % \\ item crowdsourcing / human computation / citizen science as a way to create training sets [ xxunk xxunk ? ] \n",
              " \t % \\ item active learning \\ xxunk } and transfer learning \\ xxunk } as ways to improve modeling based on ( human ) knowledge \n",
              " \t % \\ item \\ xxunk } : stop seeing technologies as a collection of tools and xxunk and instead see it as an evolutionary flow around human problems , whose parts ultimately integrate to become a new category of thing % https : / / xxunk / xxunk = xxunk = xxunk = xxunk = xxunk = xxunk = xxunk # v = xxunk = xxunk = false \n",
              " \t % in xxunk xxunk 58 e xxunk ! ! ! \n",
              "  % \\ end{itemize } \n",
              " \n",
              "  xxrep 96 % \n",
              "  \\ section{what is an explanation for humans } \\ label{sec : explanation } \n",
              " \n",
              "  xxmaj the rationale behind explainable xxup ai research is that xxmaj artificial xxmaj intelligence systems should not only display an intelligent behaviour , but they also should be able to explain such behaviour . xxmaj the naturally raising question is what an explanation is and how to generate it . xxmaj in this section , we attempt at illustrating the characteristics of explanations and we justify the need for ` ` xxmaj human xxmaj intelligence ' ' and ` ` xxmaj human - in - the - xxmaj loop ' ' approaches also in relation to explainable xxup ai . \n",
              " \n",
              "  % xxrep 62 - \n",
              "  \\ subsection{a working definition of explanation } \\ label{sub : def - expl } \n",
              " \n",
              "  xxmaj let us consider the simple example of email categorisation between spam and non - spam . xxmaj here the task is binary classification ( i.e. , the output of a xxmaj machine xxmaj learning classifier is the labeling of each mail as spam or non - spam ) . \n",
              " \n",
              "  xxmaj an explanation consists in a set of hints to understand the relationship between the characteristics of an individual ( e.g. an email ) and the model prediction on that individual ( e.g. this email is spam ) . xxmaj the explanation is used by a human decision - maker , who should decide whether to trust the system ( e.g. accept or reject the prediction of the spam xxunk \\ cite{ribeiro2016whytrust } . \n",
              " \n",
              "  xxmaj user trust can happen at different levels : on the individual prediction , when the user requires an explanation about a specific instance ( e.g. why \\ xxunk } mail is spam ) or on an entire model , when the user needs to decide whether to trust the system altogether . xxmaj in the latter case , an explanation could require selecting a representative sample of individuals ( e.g. a set of spam / non - spam emails ) and explaining each individual in the sample . \n",
              " \n",
              "  xxmaj the main characteristics that an explanation should display ( again according to~ \\ cite{ribeiro2016whytrust } ) are fidelity , model - independence and interpretability . \\ emph{local fidelity } or local faithfulness means that a prediction should be valid in the vicinity of the individual ; global fidelity would of course be desirable , but it could be challenging for complex models . xxmaj the explanation should also be \\ emph{model - agnostic } , in that it should be independent on the specific type of xxup ai model . xxmaj finally , \\ xxunk } is the qualitative understanding of the relationship between the input variables and the response ( e.g. the relation between the words contained in an email and the email categorisation as spam / non - spam ) . \n",
              " \n",
              "  xxmaj interpretability is the key aspect for an explanation to be accepted by a user ; in our example of an email classifier , an interpretable explanation could rely on a list of words ( e.g. the system thinks this email is spam because it contains the following words ) rather that be based on opaque clues ( e.g. word embeddings ) which are not easily understandable by a human . xxmaj the level of interpretability of an explanation of course depends on the audience , because humans use their previous knowledge about the application domain to interpret an explanation and accept / reject a prediction based on their understanding . \n",
              " \n",
              "  % \\ cite{ribeiro2016whytrust } ( slide 25 ) \n",
              "  % \n",
              "  % \\ begin{itemize } \n",
              " \t % \\ item xxmaj explanation = set of hints to understand the relationship between the characteristics of an individual ( e.g. an email ) and the model prediction on that individual ( e.g. this email is spam ) \n",
              " \t % \\ item xxmaj different levels of prediction trust \n",
              " \t % \\ begin{itemize } \n",
              " \t\t % \\ item xxmaj on individual prediction : it requires explanation about the individual ( e.g. why this mail is spam ) \n",
              " \t\t % \\ item xxmaj on entire model : it requires ( 1 ) selecting a representative sample of individuals ( e.g. a set of spam / non - spam emails ) + ( 2 ) explaining each individual in the sample \n",
              " \t % \\ end{itemize } \n",
              " \t % \\ item xxmaj characteristics of explanations \n",
              " \t % \\ begin{itemize } \n",
              " \t\t % \\ item xxmaj local fidelity : valid in the vicinity of the individual ( but non necessarily globally ) \n",
              " \t\t % \\ item xxmaj model agnostic : independent on the specific black box model \n",
              " \t\t % \\ item xxmaj interpretability : quantitative understanding of the explanation ( e.g. words , not word embeddings ) ; this depends on the audience , because humans use their previous knowledge to interpret an explanation \n",
              " \t % \\ end{itemize } \n",
              "  % \\ end{itemize } \n",
              " \n",
              "  % xxrep 59 - \n",
              "  \\ subsection{explanation from a human point of view } \\ label{sub : xxunk - expl } \n",
              " \n",
              "  xxmaj the latest point on interpretability clarifies that proper attention should be given to the different kinds of explanations that could be generated , in particular by distinguishing ` ` machine ' ' explanations from ` ` human ' ' explanations . \n",
              " \n",
              "  xxmaj indeed , most xxup xai research has been focusing on generating \\ emph{machine explanations } , i.e. justifications of what / how the machine ` ` thinks ' ' . xxmaj in other words , machine explanations try to explain the scientific theory behind a model , to allow for phenomena comprehension . xxmaj in case of interpretable models ( like linear regression or decision trees ) , the machine explanation consists in making explicit the mathematical / logical relation between inputs and outputs ( e.g. tree model of decisions ) . xxmaj in case of black - box models , especially for deep learning and other complex approaches , the machine explanation may be based on ` ` compressed ' ' models or other approximation techniques that still use an explicit representation of the relation between inputs and outputs . \n",
              " \n",
              "  xxmaj instead , \\ emph{human explanations } focus on what a human user wants to know in order to interpret a model and make subsequent decisions . xxmaj the user may be xxunk in the internal functioning of an algorithm , as she may even be unable to understand a potentially complex mathematical formulation of the function that transforms the input parameters in the output prediction . xxmaj on the contrary , the user is interested in getting useful clues on why a specific output is given , in order to evaluate if such output is ` ` reliable ' ' from a human understanding point of view . \n",
              " \n",
              "  xxmaj as a consequence , in order to be useful , a human explanation needs to display some specific characteristics~ \\ xxunk } . xxmaj an explanation should be \\ xxunk } : it should not provide all possible reasons , but convey only the ` ` relevant ' ' causes ; indeed , people usually do not expect an explanation to consist of a complete cause of an event , also to let the explanation itself being reduced to a cognitively manageable size ; moreover , an explanation should not contain useless information , like xxunk or beliefs that the user already holds . xxmaj humans xxunk prefer \\ xxunk } explanations , in that they are used to reason according to counter - factual causality ( i.e. people do not ask why an event a happened , but rather why an event a happened instead of some other event b ) , especially in case of an anomaly or an abnormal event . xxmaj another characteristic of human explanations is that they are usually \\ emph{social } , involving the interaction between ( multiple ) explainers and explainees ; also with respect to explainable xxup ai , explanations should be seen as an interactive process , including interaction and dialogue with a mix of human and machine participants . \n",
              " \n",
              "  xxmaj from all the above considerations , it is apparent that explainable xxup ai research should go well beyond automatic methods to generate explanations ; it is of utmost importance to keep the \\ emph{human - in - the - xxmaj loop } . xxmaj there are at least two main reasons to advocate for the active involvement of people in explainable xxup ai~ \\ xxunk } : on the one hand , if explanation formulation is delegated to ` ` computer scientists ' ' , the risk is that such explanations are too close to the model and too far from human understanding , especially that of domain / business users who need to interpret such information ; on the other hand , there is a large body of knowledge about explanations from the social sciences ( philosophy , psychology , cognitive science ) , which could bring tangible benefits to explainable xxup ai research in terms of getting to a ` ` good ' ' explanation from a human point of xxunk \\ xxunk } . \n",
              " \n",
              "  % \\ xxunk , xxunk } ( slide 26 ) \n",
              " \n",
              "  % \\ begin{itemize } \n",
              " \t % \\ item xxmaj two meaning of explanation \n",
              " \t % \\ begin{itemize } \n",
              " \t\t % \\ item ` ` xxmaj machine ' ' explanation = what the machine thinks ( scientific theory , phenomena comprehension ) \n",
              " \t\t % \\ item ` ` xxmaj human ' ' explanation = what the human wants to know to interpret a model \n",
              " \t % \\ end{itemize } \n",
              " \t % \\ item xxmaj characteristics of explanations from the human point of view \n",
              " \t % \\ begin{itemize } \n",
              " \t\t % \\ item xxmaj selective explanations ( not all possible reasons , but only ` ` relevant ' ' causes , not including pre - existing beliefs / assumptions ) \n",
              " \t\t % \\ item xxmaj contrastive explanations ( counterfactual causality , ` ` why p and not q ? ' ' ) \n",
              " \t\t % \\ item xxmaj social explanations ( dialogue / conversation , interaction , iteration ) \n",
              " \t % \\ end{itemize } \n",
              " \t % \\ item xxmaj why human - in - the - loop is needed for xxmaj explainable xxup ai \n",
              " \t % \\ begin{itemize } \n",
              " \t\t % \\ item xxmaj do n't let computer scientists decide how to formulate explanations , because otherwise explanations are too close to the model and too far from human understanding \n",
              " \t\t % \\ item xxmaj there is a large body of knowledge about explanations from social sciences \n",
              " \t % \\ end{itemize } \n",
              "  % \\ end{itemize } \n",
              " \n",
              "  xxrep 96 % \n",
              "  \\ xxunk xxmaj intelligence and xxmaj knowledge xxmaj graphs to support explainable xxup ai } \\ label{sec : xxunk } % why / how can humans and kg help xai \n",
              " \n",
              "  xxmaj the xxmaj semantic xxmaj web has always relied on humans , since most of its tasks are knowledge - intensive and context - specific and , as such , they require user engagement for their solution ( e.g. , conceptual modelling , multi - language resource labelling , content annotation with ontologies , concept / entity similarity recognition ) . xxmaj with the rise of xxmaj knowledge xxmaj graphs and their popularity , new opportunities have emerged to exploit them for xxup ai in general and specifically for explainable xxup ai~ \\ xxunk } . \n",
              " \n",
              "  xxmaj without the claim of being exhaustive , in the following we illustrate a set of approaches that can bring xxmaj human xxmaj intelligence and xxmaj knowledge xxmaj graphs to the benefit of explainable xxup ai , with specific reference to xxmaj machine xxmaj learning . xxmaj we distinguish between two main types of opportunities , those related to the exploitation of ( human - generated ) xxmaj knowledge xxmaj graphs and those that xxunk on the direct involvement of people ; we depict them in xxmaj figure~ \\ ref{fig : approaches } along two axes , representing whether xxmaj human xxmaj intelligence is employed in data / knowledge representation or for explanations . % in relation to data preparation / manipulation and with respect to model explanation . \n",
              " \n",
              "  % \\ textcolor{red}{todo : fare xxunk xxunk xxunk e in xxunk ( 1 ) xxunk a xxunk serve per xxup xai e ( 2 ) xxunk xxunk xxunk xxunk xxunk / xxunk } \n",
              " \n",
              "  \\ begin{figure}[htb ] \n",
              " \t  \\ centering \n",
              " \t\t  \\ includegraphics[width=0.95 \\ textwidth]{img / xxunk } \n",
              " \t  \\ caption{graphical representation of xxmaj human xxmaj intelligence approaches } \n",
              " \t  \\ label{fig : approaches } \n",
              "  \\ end{figure } \n",
              " \n",
              " \n",
              "  % xxunk \n",
              "  \\ xxunk ) xxmaj knowledge xxmaj graphs for xxup xai } \n",
              "  xxmaj the first set of approaches exploits xxmaj knowledge xxmaj graphs to support explanation generation . xxmaj we specifically focus on the role of human - generated information to directly and indirectly support xxup xai . \n",
              " \n",
              "  % xxrep 59 - \n",
              "  \\ subsubsection{dataset metadata } \n",
              "  xxmaj structured data represents an invaluable input for any xxmaj machine xxmaj learning approach . xxmaj consequently , linked data and xxmaj knowledge xxmaj graphs represent as such a rich and xxunk contribution . xxmaj an important role can even be played by simple metadata : descriptive metadata about datasets , in the form of xxup xxunk \\ xxunk - v2 } and related vocabularies , can be exploited to improve data sourcing . xxmaj the information about where some data comes from can also be re - used for explanations : users can better judge the reliability or the meaningfulness of a machine output if they are given also the detail about the original sources . \n",
              " \n",
              "  xxmaj for example , the opportunities to facilitate dataset reuse in the development of chatbots are illustrated by the xxunk - xxup ap xxunk \\ xxunk } , an extension of the xxmaj data xxmaj xxunk ( xxup xxunk ) xxmaj application xxmaj profile . xxunk - xxup ap enables the description of intents ( i.e. , the actions users want to accomplish by interacting with a chatbot ) and entities ( i.e. , individual information units associated to an intent ) supported by a dataset and the method to access it ; as such , it enables and fosters xxunk of datasets ( including xxmaj knowledge xxmaj graphs ) across chatbot systems . xxmaj it could also be exploited further to support the generation of explanations for the chatbot ` ` replies ' ' in terms of recognised intents / entities and used datasets . \n",
              " \n",
              "  % xxrep 59 - \n",
              "  \\ xxunk - specific semantics } \n",
              "  xxmaj different users may have different interests or skills and , as a consequence , they may need different explanations . xxmaj user - generated data often implicitly contains hints on \\ emph{what people care about } ; this can be an opportunity to exploit when providing explanations on systems trained on such data . \n",
              " \n",
              "  xxmaj for example , spatial data analytics of xxunk manual tagging showed to be beneficial for geo - ontology engineering , by surfacing latent semantic differences in concepts by different xxunk \\ xxunk } : the same ` ` concept ' ' of spatial object ( e.g. , a pub ) may have slightly diverging meanings in different places ( e.g. , a place to xxunk in xxup uk , a bar to have a drink in xxmaj italy ) . xxmaj this implicit semantics , when extracted and made explicit , can be exploited also for explanation generation , because it can contribute to convey the right ` ` semantics ' ' to the right community . \n",
              " \n",
              "  % xxrep 59 - \n",
              "  \\ xxunk of user - generated data } \n",
              "  xxmaj providing better data for training in turn leads to better models , as well as to more interpretable explanations . xxmaj when data is user - generated , quality assurance is an important step , for example to aggregate inputs from multiple contributors ( cf . ` ` truth inference ' ' in xxmaj crowdsourcing~ \\ xxunk } ) . xxmaj provenance metadata about human contributions often contain important clues that can be exploited both for quality improvement and for generating explanations . \n",
              " \n",
              "  % xxmaj when data is user - generated , provenance information can be exploited to improve data quality , as \n",
              "  xxmaj for example , in the case of the xxmaj human xxmaj computation - powered volunteered geographic information ( xxup vgi ) illustrated in~ \\ xxunk } , the involvement of a crowd of volunteers , potentially untrained or non - experts , implies that xxup vgi can be of varying quality ; tracing xxup vgi provenance enables the recording of the collection activity : the information about who gathered what , where and when is then employed to compute and judge the xxup vgi quality . xxmaj the same provenance information can be offered to users of systems trained on such user - generated data , to explain where some prediction comes from . \n",
              " \n",
              "  % xxrep 59 - \n",
              "  \\ subsubsection{knowledge graphs as explanation content } \n",
              "  xxmaj structured knowledge and xxmaj knowledge xxmaj graphs can be used as basis for explanations , because they may already contain the rationale behind the relationship between inputs and outputs of a system . xxmaj whenever a predictive system is based on a knowledge base , the relevant part of it that motivates a system output can be directly used as explanation . \n",
              " \n",
              "  % , in terms of resources and properties connecting them , \n",
              "  xxmaj for example , graph traversal information is used to explain the suggestions of a knowledge - based recommender system in~ \\ xxunk } : the logical path connecting a user ( e.g. , xxmaj john loves hard rock music ) and a recommended item ( e.g. , x is a xxmaj web - radio broadcasting rock music ) provides a xxunk account of the reasons behind the recommendation ( e.g. , xxmaj john is recommended to listen to x , because xxmaj john \\ xxunk } hard rock music , hard rock \\ emph{is a kind of } rock music , x \\ xxunk } rock music ) . xxmaj the chain of relevant connected resources / properties ( i.e. , the set of triples composing a path between the user and the recommended item ) already constitutes a human explanation for the recommendation . \n",
              " \n",
              " \n",
              "  % xxunk \n",
              "  \\ subsection{human xxmaj intelligence for xxup xai } \n",
              "  xxmaj the second set of approaches directly focuses on the active involvement of people to the benefit of xxup xai . \n",
              " \n",
              "  % xxrep 59 - \n",
              "  \\ subsubsection{user engagement for data quality } \n",
              "  xxmaj as claimed in xxmaj section \\ ref{sec : explanation } , in order to provide human explanations , we should turn to social sciences , which may help in the involvement and engagement of people also during the phase of explanation generation for xxup ai systems . xxmaj engaging humans is a challenge by itself , therefore explainable xxup ai could reuse the research results in relation to designing and exploiting behaviours , personal motivations and incentive mechanisms . \n",
              " \n",
              "  xxmaj for example , the evaluation and improvement of data quality can be achieved through an analysis of contributions : % the unconscious contributions of users as well as by improving user experience xxmaj it is xxunk that people can display varied levels of attention when performing a task , due to attitude or contextual conditions ; therefore , \n",
              "  user behaviour influences data quality and should be taken into account , to evaluate the reliability of user - generated information , to better design data collection systems and to generate explanations . xxmaj as demonstrated in~ \\ xxunk } , the presence of tangible rewards , leveraging extrinsic motivation , affects quantity and quality of collected data ; moreover , an analysis of accuracy and participation of contributors highlights different engagement profiles , which should be taken into account when aggregating user - generated data and should be xxunk for explainability . \n",
              " \n",
              "  % xxrep 59 - \n",
              "  \\ subsubsection{user interaction and user experience } \n",
              "  xxmaj lessons learned and best practices from user experience design can also inform human - powered explanation generation , because they can help in designing suitable tools and data value chains that involve and engage people to bring benefit to xxup ai in general and explainable xxup ai specifically . \n",
              " \n",
              "  xxmaj indeed , a carefully designed user interaction with digital tools proves to be key in raising attention and improving data quality , as shown in~ \\ xxunk } with respect to survey data collection : an improvement on user experience , making questionnaire compilation more enjoyable , leads also to higher - quality information , because it reduces the satisficing effect and increases response quality . xxmaj therefore , involving users for the generation or validation of explanations , for example by adopting a social and interactive pattern guided by a design thinking approach , can maximise user attention and ease user experience , thus making sure that the result is a \\ xxunk } explanation from a human point of view . \n",
              " \n",
              "  % xxrep 59 - \n",
              "  \\ subsubsection{human and machine confidence } \n",
              "  xxmaj predictive xxmaj machine xxmaj learning modelling aims at building a trustworthy system able to provide prediction on unknown cases ; to evaluate model confidence , different metrics are usually employed to give quantitative estimates of a prediction reliability . xxmaj reporting confidence metrics to support prediction explanation is a means to increase user trust , but again those quantitative hints should be interpretable from a human point of view . \n",
              " \n",
              "  xxmaj human intervention can be also employed to support a model evaluation and , consequently , a model explanation through confidence metrics . xxmaj indeed , it can happen that what is ` ` difficult ' ' to predict for an algorithm ( i.e. predictions with low confidence metrics ) is also difficult for humans to judge ; the case of questionable image classification is illustrated in~ \\ xxunk } , where the correspondence exists between low - confidence machine classifications and user disagreement . xxmaj the correlation between human and machine predictions and their respective confidence / reliability can be exploited to understand the reasons behind a model and can therefore improve both the modelling phase ( by incorporating additional human knowledge in training ) and the generation of explanations ( which can be closer to human understanding ) . \n",
              " \n",
              "  % xxrep 59 - \n",
              "  \\ xxunk as a means to improve user involvement } \n",
              "  xxmaj the most challenging aspect of xxmaj human - xxmaj machine xxmaj cooperation is the effective involvement of people in the various phases of modelling . xxmaj while users are already employed in data collection and model validation , further opportunities lie in a more xxunk interaction between human steps and automatic steps . xxmaj therefore , explanations are not only an objective as such , but they can be an instrument to further involve and motivate human participants in the xxup ai system life - cycle . \n",
              " \n",
              "  xxmaj for example , in order to identify and reduce bias in knowledge representation and modelling , the involved users should not only be exposed to potential biased information , but should also be given an explanation for such an identified bias , to understand the reasons behind a questionable piece of information or prediction . a xxmaj human - in - the - xxmaj loop approach to identify and resolve implicit bias in xxmaj knowledge xxmaj graphs is illustrated in~ \\ xxunk } : users are involved not only to accept / reject an identified bias , but they are also engaged as decision - makers to evaluate if further actions should be taken to solve such bias . \n",
              " \n",
              "  % xxrep 59 - \n",
              "  % \\ subsection { } \n",
              " \n",
              "  % xxrep 59 - \n",
              "  % \\ xxunk related to xxmaj data for xxmaj explanation } \\ label{sub : data } \n",
              "  % \\ begin{itemize } \n",
              " \t % \\ item metadata to improve data sourcing ( reusable for explanations ? ) \\ xxunk } : xxunk i dataset per xxunk il xxunk ? ? \n",
              " \t % \\ item provenance to evaluate and improve data quality \\ xxunk } : xxrep 4 ? \n",
              " \t % \\ item xxunk to understand what people care about \\ xxunk } : crowdsourced data give information in an implicit way ? ? \n",
              " \t % \\ item user behaviour to evaluate and improve data quality \\ xxunk } : xxunk degli xxunk influenza i xxunk \n",
              " \t % \\ item user engagement to improve data quality \\ xxunk } : engagement degli xxunk xxunk i xxunk ? \n",
              "  % \\ end{itemize } \n",
              " \n",
              "  % xxrep 59 - \n",
              "  % \\ xxunk related to xxmaj model xxmaj explanation } \n",
              "  % \\ begin{itemize } \n",
              " \t % \\ item xxunk to evaluate model confidence \\ xxunk } : xxunk che e ' xxunk per xxunk e ' xxunk xxunk per la xxunk ( xxunk ) \n",
              " \t % \\ item kg as explanation \\ xxunk } : path in the kg as en explanation for recommendations \n",
              " \t % \\ item provenance as explanation \\ xxunk } : bias degli input xxunk e xxunk xxunk xxunk / provenance \n",
              "  % \\ end{itemize } \n",
              " \n",
              "  xxrep 96 % \n",
              "  \\ section{conclusions } \\ label{sec : concl } \n",
              " \n",
              "  explainable xxup ai aims at generating explanations to justify the output of an algorithm to a user , usually a decision - maker . xxmaj those explanations need to be interpretable by the intended target users and , therefore , can not be restricted to the ` ` scientific modelling ' ' ( i.e. , the explanation of the scientific / mathematical law or theory behind an artificial model ) , but should be focused on addressing the needs of the decision makers , which exploit such explanations and decide whether to trust an xxup ai system . \n",
              " \n",
              "  xxmaj therefore , a better understanding of \\ emph{human xxmaj intelligence } is needed to make sure that the generated explanations are ` ` good enough ' ' to be used in practice : a certain help can come from social sciences , but even within the xxup ict community , we identify several opportunities . xxmaj on the one hand , xxmaj knowledge xxmaj representation and xxmaj reasoning ( xxup krr ) research has always been addressing the open issue of human knowledge formalisation ; in this context , therefore , explainable xxup ai can leverage all the experience related to the involvement of human annotators and crowdsourced knowledge bases and xxmaj knowledge xxmaj graphs ( e.g. xxunk \\ xxunk } and xxmaj xxunk \\ xxunk } ) : indeed , the same xxmaj human xxmaj intelligence that supports xxup krr tasks can be similarly exploited for explainable xxup ai . \n",
              " \n",
              "  xxmaj on the other hand , xxmaj human xxmaj computer xxmaj interaction ( xxup hci ) research has been focusing on improving and optimizing user experience with digital tools ; in this context , explainable xxup ai can leverage the approaches and methods to support the ` ` interaction ' ' between a human user and a digital explanation , improving interpretability and promote trust . xxup ai system should be designed to allow and facilitate the exchange with the relevant user communities : while people are already heavily involved in data collection , their engagement in other steps of the xxup ai life - cycle is still to be fully explored , especially with respect to explainability . \n",
              " \n",
              "  xxmaj the big challenge is to define flexible and complex human - computer cooperative systems , able to guide in the preparation , building and production of data processing pipelines involving xxmaj artificial xxmaj intelligence technologies . xxmaj human xxmaj intelligence and xxmaj knowledge xxmaj graphs should become first - order citizens of such data value chains , not only to improve the performance of such artificial systems , but also -- and foremost -- to assure that xxup ai outcomes are relevant and usable by human decision makers . \n",
              " \n",
              " \n",
              "  \\ section*{acknowledgments } \n",
              "  xxmaj the presented research was partially supported by the xxup action project ( grant agreement number xxunk ) , co - funded by the xxmaj european xxmaj commission under the xxmaj horizon 2020 xxmaj framework xxmaj programme . xxmaj we would like to thank xxmaj xxunk xxmaj re xxmaj xxunk and xxmaj ilaria xxmaj xxunk for their feedback and revision on this chapter . \\ emph { } \n",
              " \n",
              "  \\ xxunk } \n",
              "  \\ bibliography{biblio } \n",
              " \t \n",
              "  % \\ begin{thebibliography}{99 } \n",
              "  % \n",
              "  % \\ xxunk } \n",
              "  % xxup xxunk xxmaj xxunk , xxmaj xxunk hoc et xxunk et xxunk xxunk xxunk , \n",
              "  % \\ xxunk } \\ xxunk } ( 1993 ) , xxunk - xxunk . \n",
              "  % \n",
              "  % \\ end{thebibliography } \n",
              "  \\ end{document } \n",
              " ,xxbos \\ xxunk } % xxmaj include author names \n",
              "  % \\ xxunk } % xxmaj anonymized submission \n",
              " \n",
              "  % xxmaj the following packages will be automatically loaded : \n",
              "  % jmlr , amsmath , amssymb , natbib , graphicx , url , algorithm2e \n",
              "  % xxunk , xxunk and probably more \n",
              "  % make sure they are installed with your latex distribution \n",
              "  \\ usepackage{amsmath } \n",
              "  \\ def \\ xxmaj inf { \\ xxunk \\ xxunk } } } \n",
              "  \\ usepackage{graphicx } \n",
              "  % \\ usepackage{subfig } \n",
              " \n",
              "  \\ usepackage{caption } \n",
              "  % \\ usepackage{subcaption } \n",
              " \n",
              "  \\ xxunk xxunk xxmaj imaging with xxmaj deep xxmaj learning 2020 } \n",
              "  \\ xxunk { } \n",
              "  \\ xxunk { } \n",
              "  \\ xxunk 2020 -- xxmaj short xxmaj paper } \n",
              "  \\ editors { } \n",
              " \n",
              " \n",
              "  \\ xxunk } % to get dummy images \n",
              "  \\ usepackage{amssymb } \n",
              "  % \\ xxunk xxmaj under xxmaj review } \n",
              "  % \\ xxunk xxmaj review for xxup xxunk 2020 } \n",
              "  \\ xxunk xxmaj space xxmaj variation xxunk xxmaj space xxmaj variational xxmaj inference for xxmaj uncertainty xxmaj estimation in xxmaj computer xxmaj aided xxmaj diagnosis } \n",
              " \n",
              "  % xxmaj use \\ name{author xxmaj name } to specify the name . \n",
              "  % xxmaj if the surname contains spaces , enclose the surname \n",
              "  % in braces , e.g. \\ name{john { xxmaj smith xxmaj jones } } similarly \n",
              "  % if the name has a \" von \" part , e.g \\ xxunk { de xxmaj winter } } . \n",
              "  % xxmaj if the first letter in the xxunk is a diacritic \n",
              "  % enclose the diacritic in braces , e.g. \\ xxmaj name { { \\ ' xxmaj xxunk xxmaj smith } \n",
              " \n",
              "  % xxmaj two authors with the same address \n",
              "  % \\ xxunk { \\ name{author xxmaj name1 } \\ xxmaj xxunk } \\ and \n",
              "  % \\ name{author xxmaj name2 } \\ xxmaj xxunk } \\ \\ \n",
              "  % \\ addr xxmaj address } \n",
              " \n",
              "  % xxmaj three or more authors with the same address : \n",
              "  % \\ xxunk { \\ name{author xxmaj name1 } \\ xxmaj xxunk } \\ \\ \n",
              "  % \\ name{author xxmaj name2 } \\ xxmaj xxunk } \\ \\ \n",
              "  % \\ name{author xxmaj xxunk } \\ xxmaj xxunk } \\ \\ \n",
              "  % \\ addr xxmaj address } \n",
              " \n",
              " \n",
              "  % xxmaj authors with different addresses : \n",
              "  % \\ xxunk { \\ name{author xxmaj name1 } \\ xxmaj xxunk } \\ \\ \n",
              "  % \\ addr xxmaj address 1 \n",
              "  % \\ xxup and \n",
              "  % \\ name{author xxmaj name2 } \\ xxmaj xxunk } \\ \\ \n",
              "  % \\ addr xxmaj address 2 \n",
              "  % } \n",
              " \n",
              "  % \\ xxunk equally } \n",
              " \n",
              "  % xxmaj more complicate cases , e.g. with dual affiliations and joint authorship \n",
              "  \\ xxunk { \\ xxunk xxmaj xxunk { } \n",
              "  ametag { } } \\ xxmaj xxunk } \\ \\ \n",
              "  % \\ addr $ xxunk xxmaj address 1 \\ \\ \n",
              "  % \\ addr $ xxunk xxmaj address 2 \\ xxup and \n",
              "  \\ xxunk xxmaj xxunk \n",
              "  ametag { } } \\ xxmaj xxunk } \\ \\ \n",
              "  \\ xxunk xxmaj sethi \n",
              "  ametag { } } \\ xxmaj xxunk } \\ \\ \n",
              "  \\ addr xxmaj department of xxmaj electrical xxmaj engineering , xxmaj indian xxmaj institute of xxmaj technology , xxmaj xxunk \\ xxup and \n",
              "  } \n",
              " \n",
              "  \\ begin{document } \n",
              " \n",
              "  \\ maketitle \n",
              " \n",
              "  \\ begin{abstract } \n",
              "  xxmaj deep neural networks have xxunk medical image analysis and disease diagnosis . xxmaj despite their impressive performance , it is difficult to generate well - calibrated probabilistic outputs for such networks , which makes them uninterpretable black boxes . xxmaj bayesian neural networks provide a principled approach for modelling uncertainty and increasing patient safety , but they have a large computational overhead and provide limited improvement in calibration . xxmaj in this work , by taking skin lesion classification as an example task , we show that by shifting xxmaj bayesian inference to the functional space we can craft meaningful priors that give better calibrated uncertainty estimates at a much lower computational cost . \n",
              "  % xxmaj despite their impressive performance , they have been criticized for being non - interpretable black box . xxmaj standard approach for uncertainty estimation in neural networks is by approaching problem from a xxmaj bayesian view , by placing a prior on the parameters and approximating the posterior . xxmaj in this work we show that by shifting to the functional space we can craft more meaningful prior 's https : / / www.overleaf.com / project / xxunk in turn give us far better calibrated uncertainty estimates at a significantly lower computational cost . \n",
              "  \\ end{abstract } \n",
              " \n",
              "  \\ begin{keywords } \n",
              "  xxmaj bayesian approximation , uncertainty estimates , calibration , skin xxunk \n",
              "  \\ end{keywords } \n",
              " \n",
              "  \\ section{introduction } \n",
              " \n",
              "  xxmaj in computer - aided diagnosis , xxup ai models must not only be accurate , but they should also indicate when they are likely to be incorrect . xxmaj for instance , control should be passed on to human doctors when the confidence of a neural network for disease diagnosis is low . xxmaj model calibration is the degree to which a model ‚Äôs predicted probabilities reflect the true correctness likelihood . xxmaj calibrated confidence estimates are also important for model interpretability and they provide a valuable extra bit of information to establish trustworthiness with the user . xxmaj this is important for deep neural networks , whose classification decisions are often and difficult to interpret . \n",
              " \n",
              "  xxmaj it is well known that popular neural network frameworks only provide a point estimate of the true underlying distribution . xxmaj furthermore , the typical classification setting of training the softmax output layer using cross - entropy loss typically gives ‚Äú over - confident ‚Äù ( low entropy ) class probability mass distributions , even when there is a classification error . xxmaj this is especially concerning for training on medical datasets that are often relatively smaller and suffer from severe class imbalance \\ xxunk } . xxmaj in other words , the popular deep learning models give poorly calibrated uncertainty estimates for cases that are ambiguous , or difficult , or \\ xxunk - of - distribution } ( xxup ood ) , including those from a new class . \n",
              " \n",
              "  % xxmaj recently deep learning methods have received significant attention for computer aided diagnosis in a variety of medical imaging domains \\ xxunk } . xxmaj they outperform former methods on performance metrics such as accuracy , xxup f1 score , or xxup roc - xxup auc etc . xxmaj however care has to be taken before deploying deep neural networks to support medical diagnosis . xxmaj this is because it is known that neural networks are only a point estimate of the true underlying distribution , and the softmax output layer that is used to get a probability score is typically ‚Äú over - confident ‚Äù for one class . xxmaj this issue causes most deep learning models to be poorly calibrated and give over - confident estimates for ambiguous or unknown cases . \n",
              " \n",
              "  xxmaj bayesian modelling offers a set of tools to reason about uncertainty . xxmaj existing xxmaj bayesian approaches involve approximate inference using either xxmaj markov xxmaj chain xxmaj monte xxmaj carlo \\ xxunk } or variational inference methods , such as dropout \\ xxunk } . xxmaj this idea has attracted attention of the medical community to ensure that difficult cases for computer - aided diagnosis are xxunk flagged for review \\ xxunk } . xxmaj since most xxmaj bayesian neural networks ( bnns ) have their prior defined on the weight space , the regularization caused by these prior is not able to xxunk the network output , nor do these priors explicitly make the model under - confident on the xxup ood samples . xxmaj we show that by performing variational inference on the functional space we can craft a prior that is able to simultaneously xxunk the network as well as ensure the the recognition of xxup ood samples as more uncertain . xxmaj our method is also significantly less computationally expensive as compared to xxmaj bayesian or frequentist approaches . xxmaj although our method shares some similarities with xxmaj xxunk xxmaj deep xxmaj learning ( xxup xxunk ) \\ xxunk } , it has been derived from a variational xxmaj bayesian framework and it can distinguish distributional versus data uncertainties ( shift in distribution versus class confusion , respectively ) , unlike xxup xxunk . \n",
              " \n",
              "  % xxunk show the advantage of our method on the xxup xxunk xxrep 4 0 dataset for skin lesion classification . \n",
              " \n",
              "  % xxmaj in order to craft such a prior we need to shift to the functional space , and we show the advantage of our method on the xxup xxunk xxrep 4 0 dataset for skin lesion classification . xxmaj our method is also significantly less computational expensive as compared to xxmaj dropouts , xxmaj deep xxmaj ensembles etc . as we do not have to rely on the expensive xxmaj monte - xxmaj carlo samples on test time to approximate the output distribution . \n",
              " \n",
              " \n",
              " \n",
              "  % xxmaj deep neural networks ( dnns ) have emerged as powerful image analysis and prediction tools , especially so for medical image analysis and disease diagnosis . xxmaj thus although they provide super - human performance on tasks like skin cancer xxunk from xxunk images \\ xxunk } etc . they still have a fatal weakness which prevents them from being deployed on real world tasks safely . xxmaj that is dnns do not generally generate well - calibrated reliable uncertainty estimates regarding their decisions \\ xxunk } , \\ xxunk } , \\ xxunk } . \n",
              "  % \\ par \n",
              "  % xxmaj in most medical domains where there is abundance of data , reaching impressive scores on performance metrics , such as accuracy , sensitivity , xxunk , xxup f1 score , or xxup roc - xxup auc is no longer an issue , rather the major challenges of the upcoming era , are likely to lie elsewhere . xxmaj for example are current models able to detect shifts in the data distribution ? xxmaj this is important because cancer patients from a different ethnicity or locality may not have the same distribution as each , also natural mutations in the disease may cause shift in the data over long period of time , making it imperative for our model to not only be accurate but also well calibrated , while still having the capability of saying \" i do not know \" in unseen scenarios . \n",
              " \n",
              " \n",
              "  \\ section{proposed xxmaj method } \n",
              " \n",
              "  xxmaj for classification among $ xxup k$ classes , deep neural networks represent a function $ f _ { \\ xxunk \\ rightarrow \\ textbf{p } \\ in [ xxup xxunk , where $ xxup x$ represents the input , and $ \\ xxunk represents a probability mass function such that $ \\ xxunk = 1$. xxmaj the output distribution $ p(y|x , \\ theta ) = \\ xxunk \\ xxunk a prior on $ \\ theta$ implicitly defines a prior measure on the space of $ f(x)$ , denoted as $ xxunk xxmaj priors of convenience on $ \\ theta$ , such as a fully factorized xxmaj gaussian , are often used , and it is difficult to formulate a prior on the weight space that is informative in the sense that it leads to high uncertainty on xxup ood examples . xxmaj we therefore define a uniform prior on the $ xxmaj xxunk unit simplex for the functional space , such that $ xxunk ) = d ( \\ xxunk \\ xxunk , \\ xxunk \\ xxunk ( completely uncertain prior ) . xxmaj while it seems intuitively satisfying to have a model that is not biased towards ` ` over - confident \" outputs ( towards which the usual cross - entropy loss is severely biased ) , we also empirically show that such a uniform prior gives well - calibrated outputs . % xxmaj completely uncertain prior is added \n",
              " \n",
              "  xxmaj given the training data $ d = ( xxup xxunk , xxunk and the test points $ ( xxunk we have : \n",
              "  \\ begin{equation } \n",
              "  xxunk ) = \\ int xxunk \\ textbf{p } ) \\ , p ( \\ xxunk ) \\ , d \\ textbf{p } \n",
              "  \\ end{equation } \n",
              "  xxmaj we assume $ xxunk \\ textbf{p } ) = \\ xxunk \\ xxunk xxmaj we further assume that the neural network estimates a xxmaj dirichlet distribution $ \\ xxunk } ( \\ xxunk \\ alpha)$ with $ \\ alpha>0 $ , as done by \\ xxunk } , because of its analytical tractability . \n",
              "  xxmaj in other words , unlike for a standard neural network where $ \\ textbf{p } = f _ { \\ xxunk is the point estimate output , in our case $ \\ xxunk } ( \\ xxunk \\ alpha ) = q _ { \\ xxunk is the marginal functional distribution . xxmaj this is similar to how a xxmaj gaussian process has a multivariate xxmaj gaussian as its marginal distribution . \n",
              " \n",
              "  xxmaj the true functional posterior $ xxunk is intractable , but it can be approximated by minimizing the functional evidence lower bound ( xxunk ) as done by \\ xxunk } : \n",
              "  % such that the objective is : \n",
              " \n",
              "  \\ begin{equation } \n",
              "  \\ label{eq : xxunk } \n",
              "  \\ xxunk ) = - \\ mathbb{e } _ { xxunk ) } [ \\ log xxunk ) ) ] + \\ xxunk ) ] \n",
              "  \\ end{equation } \n",
              " \n",
              "  xxmaj the second term in xxmaj equation~ \\ ref{eq : xxunk } is the functional xxup kl divergence , which is hard to estimate . xxmaj therefore , we shift to a more familiar metric , the xxup kl divergence between the marginal distributions of function values at finite sets of points $ \\ xxunk : n}$. \\ xxunk } has shown : \n",
              "  \\ begin{equation } \n",
              "  \\ xxunk \\ smash { \\ displaystyle \\ sup _ { \\ xxunk : n } } } \\ mathop { \\ mathbb { \\ text{kl } } } \\ left [ xxunk ( \\ xxunk : xxunk ( \\ xxunk : n } ) \\ right ] = \\ sum_{i=1}^n \\ text{kl } [ \\ xxunk } ( \\ xxunk \\ xxunk \\ xxunk } ( \\ xxunk \\ langle 1 , \\ dots 1 \\ rangle ) ] \n",
              "  \\ end{equation } \n",
              "  a more relaxed way of sampling these ‚Äú measure points \" $ \\ xxunk : n}$ , is to assume $ \\ xxunk : k } \\ sim xxup xxunk ( training distribution ) and $ \\ xxunk : n } \\ sim c$ where $ c$ is a distribution having the same support as the training distribution , which could be xxup ood samples , that can be forced to be more uncertain . xxmaj this approach is similar to \\ xxunk } , \\ xxunk } . \n",
              "  % xxmaj note $ y$ is assumed to be a one - hot vector , such that if the true label is $ j$ then $ y_j = 1 $ and $ y_i = 0 $ for all $ i \n",
              "  eq j$. xxmaj so now we can get the closed form solution of the first term in loss function as - \n",
              " \n",
              "  xxmaj we get a closed form solution for the first part in xxmaj equation~ \\ ref{eq : xxunk } by assuming $ y$ to be a one - hot vector as follows : \n",
              "  \\ begin{equation } \n",
              "  \\ mathcal{l}_1 = \\ int \\ left [ \\ sum_{i=1}^k xxunk \\ log p_i \\ right ] \\ frac{1}{b ( \\ alpha ) } \\ prod_{i=1}^k xxunk { \\ xxunk } d \\ textbf{p } = \\ sum_{i=1}^k y_i \\ left ( \\ xxunk ( \\ xxunk \\ xxunk \\ xxunk ( \\ alpha_i ) \\ right ) \n",
              "  \\ end{equation } \n",
              "  % where $ \\ xxunk ( . ) $ is the xxunk function . xxmaj thus , both parts of xxmaj equation~ \\ ref{eq : xxunk } have analytically closed forms , which helps in smooth training as we do not have to rely on the noisy xxmaj monte xxmaj carlo estimates , unlike previously proposed xxmaj bayesian neural networks . \n",
              " \n",
              "  $ \\ xxunk is the xxunk function . xxmaj to measure calibration of the proposed model we group predictions $ p \\ in [ 0,1]$ into $ xxup m$ bins each of size $ \\ xxunk , and let $ xxmaj xxunk be the set of indices of samples whose prediction confidence falls into the interval $ ( \\ xxunk } , \\ xxunk for $ m \\ in \\ { 1 , \\ dots , m \\ } $ . xxmaj now we define accuracy of $ xxmaj xxunk as xxunk $ \\ xxunk } \\ sum_{i \\ in xxup b_m } 1 _ { \\ { \\ xxunk = y_i \\ } } $ , where $ \\ hat{y}$ is the predicted outcome with confidence $ p$ , and $ y$ is the true label . xxmaj similarly , we define the average confidence as xxunk ) = $ \\ xxunk } \\ sum_{i \\ in xxmaj b_m } p_i$. xxmaj for perfect calibration we expect xxunk ) = xxunk ) . xxmaj in order to quantify how well calibrated our networks are , we use xxmaj expected xxmaj calibration xxmaj error ( xxup ece ) $ = \\ sum_{i=1}^m \\ xxunk \\ xxunk ) - \\ xxunk as the metric . xxmaj note xxup ece = 0 for perfect calibration . \n",
              " \n",
              "  \\ section{results } \n",
              "  % xxmaj we apply our method to the problem of skin lesion xxunk , using the xxup xxunk xxrep 4 0 dataset \\ xxunk xxrep 4 0 } . xxmaj this dataset contains xxunk images of common xxunk skin xxunk , divided over seven classes . xxmaj similar to other medical datasets , this dataset is heavily imbalanced . xxmaj the images are down - scaled to xxunk pixels , and normalized . xxmaj we randomly split the full dataset into a training set ( xxunk images ) , a validation set , and a hold - out test set ( both 501 images ) . xxmaj we use the training and validation set to train a deep neural network architecture and optimize hyperparameters . xxmaj for training we use the resnet18 \\ xxunk } architecture and the trainable parameters are optimized using the xxmaj adam , with an initial learning rate of 0.0001 . \n",
              "  % \\ par \n",
              "  xxmaj we applied our method to the problem of skin lesion classification , using the xxup xxunk xxrep 4 0 dataset \\ xxunk xxrep 4 0 } . resnet 50 architecture optimized by xxmaj adam was used . \n",
              "  % xxmaj we trained a resnet50 architecture using the xxmaj adam optimizer , with an initial learning rate of 0.0001 . \n",
              " \n",
              "  % xxmaj for example , if we have a well calibrated weather prediction model that predicts xxunk event with 80 \\ % probability for 100 days then , any deviation from 80 xxunk days and 20 non - xxunk days will imply a poorly calibrated model . a poorly calibrated model is hard to interpret and is too unreliable to be deployed in the real world . xxmaj this is especially true when a classification model is not trained for its own sake but instead for the purpose of passing on such probabilities to some other decision - making component , which is often the case in medical domain . \n",
              " \n",
              "  xxmaj from xxmaj table 1 we can see that although standard xxmaj bayesian approaches do help xxunk the model , our method has a significantly lower xxup ece . xxmaj that too at a much lower computational cost , approximately xxunk less computationally expensive than xxmaj dropouts ( monte carlo approximation ) and xxunk more memory efficient than xxmaj ensembles ( ensemble size ) . \n",
              "  % , with only a marginal compromise in test accuracy . \n",
              " \n",
              "  % xxmaj because minimizing a cross entropy loss does not ensure calibration , and even tends to over - fit classification accuracy \\ xxunk } , it ‚Äôs imperative to xxunk any model where probabilities are passed on to some other decision making system , which is often the case in practical medical applications . xxmaj regular xxmaj bayesian xxmaj neural xxmaj networks like xxmaj bayes by xxmaj backprop ( xxup xxunk ) \\ xxunk } , xxmaj dropouts \\ xxunk } etc . tend to be better calibrated than the standard xxmaj neural xxmaj networks but are far from satisfactory , since the regular prior used in these cases are not able to prevent under - estimation or over - estimation of class probabilities . \n",
              " \n",
              "  % \\ begin{table}[!htb ] \n",
              "  % \\ caption{comparison of classification accuracy and xxup ece on xxup xxunk xxrep 4 0 dataset for the proposed and the other xxmaj bayesian approaches } \n",
              "  % \\ xxunk } \n",
              "  % \\ centering \n",
              "  % \\ begin{tabular}{|l|l|l| } \n",
              "  % \\ toprule \n",
              "  % \\ hline \n",
              "  % xxmaj method & xxmaj test xxmaj accuracy & xxup ece \\ \\ \n",
              "  % \\ midrule \n",
              "  % \\ hline \n",
              "  % xxmaj standard xxup nn & xxunk \\ % & 7.73 \\ % \\ \\ \n",
              "  % \\ hline \n",
              "  % xxmaj concrete xxmaj dropout & \\ xxunk \\ % } & 6.39 \\ % \\ \\ \n",
              "  % \\ hline \n",
              "  % xxmaj deep xxmaj ensemble & xxunk \\ % & 3.12 \\ % \\ \\ \n",
              "  % \\ hline \n",
              "  % xxmaj bayes - xxmaj by - xxmaj backprop & xxunk \\ % & xxunk \\ % \\ \\ \n",
              "  % \\ hline \n",
              "  % xxmaj functional xxmaj space xxup vi & xxunk \\ % & \\ xxunk } \\ % \\ \\ \n",
              "  % \\ hline \n",
              "  % \\ bottomrule \n",
              "  % \\ end{tabular } \n",
              "  % \\ end{table } \n",
              " \n",
              " \n",
              " \n",
              "  \\ begin{table}[h ! ] \n",
              "  \\ caption{comparison of classification accuracy and xxup ece on xxup xxunk xxrep 4 0 dataset } \n",
              "  \\ xxunk } \n",
              "  \\ centering \n",
              "  \\ begin{tabular}{| xxwrep 2 l| } \n",
              "  % \\ toprule \n",
              "  \\ hline \n",
              "  xxmaj method & xxmaj standard xxup nn & xxmaj dropout & xxmaj deep xxmaj ensemble & xxmaj functional xxmaj space xxup vi \\ \\ \n",
              "  % \\ midrule \n",
              "  \\ hline \n",
              "  xxmaj test xxmaj accuracy & xxunk \\ % & \\ xxunk } \\ % & xxunk \\ % & xxunk \\ % \\ \\ \n",
              "  \\ hline \n",
              "  xxup ece ( m = 15 ) & 7.73 \\ % & 6.39 \\ % & 3.12 \\ % & \\ xxunk } \\ % \\ \\ \n",
              "  % \\ hline \n",
              "  % xxmaj deep xxmaj ensemble & xxunk \\ % & 3.12 \\ % \\ \\ \n",
              "  % \\ hline \n",
              "  % xxmaj bayes - xxmaj by - xxmaj backprop & xxunk \\ % & xxunk \\ % \\ \\ \n",
              "  % \\ hline \n",
              "  % xxmaj functional xxmaj space xxup vi & xxunk \\ % & \\ xxunk } \\ % \\ \\ \n",
              "  \\ hline \n",
              "  % \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  \\ end{table } \n",
              " \n",
              "  \\ par \n",
              "  % \\ textbf{experiment to show benefits of uncertainty yet to think of \n",
              "  % } \n",
              "  % xxmaj refer to the xxmaj appendix for our work on quantifying different types of uncertainty . \n",
              "  % xxmaj in the xxmaj appendix we show how our model can distinguish distributional uncertainty from data uncertainty , allowing it distinguish xxup ood samples much better than the previous xxmaj bayesian approaches , while also detecting samples within the distribution that are overlapping . \n",
              "  xxmaj the entropy $ \\ xxunk , xxup xxunk is a measure of total uncertainty , whereas differential entropy $ \\ xxunk ( \\ xxunk \\ alpha ) ] $ is a measure of the distributional xxunk xxmaj appendix a for more xxunk , both of which have an analytically closed form . \n",
              "  \\ section{conclusions } \n",
              "  % xxmaj our method shares similarity with xxmaj xxunk xxmaj deep xxmaj learning ( xxup xxunk ) \\ xxunk } , but has been derived completely from a xxmaj variational xxmaj bayesian xxmaj framework , also unlike xxup xxunk our model can distinguish xxmaj distributional xxmaj uncertainty from xxmaj data xxmaj uncertainty . \n",
              "  xxmaj we proposed a novel xxmaj bayesian xxup nn framework whose prior explicitly forces xxup ood samples to become xxunk as well as allow us to estimate uncertainty analytically at test time , without needing approximate or expensive algorithms . xxmaj we have also shown that our model gives well - calibrated uncertainty outputs , which can increase patient safety and assist a transfer of xxup ai systems into clinical settings by including trustworthiness as a design factor in machine learning models for medical diagnosis . xxmaj our method is also significantly more computationally efficient making it a more viable option for resource - constrained problems . \n",
              "  % xxmaj we observe that our model 's xxunk uncertainty correlates negatively with the number of training examples it has seen , and that it remains highly uncertain on \\ xxunk - of - distribution } samples . \n",
              " \n",
              " \n",
              "  % xxmaj the practical effectiveness of bnns is limited by our ability to specify meaningful prior distributions and by the intractability of posterior inference . xxmaj choosing a meaningful prior distribution over network weights is xxunk because the weights have a complicated relationship to the function computed by the network . xxmaj here , we propose to perform variational inference directly on the distribution of functions , where a xxup bnn is trained to produce a distribution of functions with small xxup kl divergence to the true posterior over functions . xxmaj to do so we define \n",
              " \n",
              " \n",
              " \n",
              "  % xxmaj this is where the content of your paper goes . xxmaj some random \n",
              "  % notes \\ xxunk footnote are xxunk } : \n",
              "  % \\ begin{itemize } \n",
              "  % \\ item xxmaj you should use \\ latex \\ xxunk : xxmaj xxunk } . \n",
              "  % \\ item xxup jmlr / xxup pmlr uses natbib for references . xxmaj for simplicity , here , \\ verb| \\ xxunk defaults to \n",
              "  % xxunk citations , i.e. \\ verb| \\ citep| . xxmaj you can of course also \n",
              "  % use \\ verb| \\ citet| for textual citations . \n",
              "  % \\ item xxmaj you should follow the guidelines provided by the conference . \n",
              "  % \\ item xxmaj read through the xxup jmlr template documentation for specific \\ latex \n",
              "  % usage questions . \n",
              "  % \\ item xxmaj note that the xxup jmlr template provides many handy functionalities \n",
              "  % such as \\ verb| \\ xxunk to refer to a figure , \n",
              "  % e.g. \\ figureref{fig : example } , \\ verb| \\ xxunk to refer to a table , \n",
              "  % e.g. \\ xxunk : example } and \\ verb| \\ xxunk to refer to an equation , \n",
              "  % e.g. \\ xxunk : example } . \n",
              "  % \\ end{itemize } \n",
              " \n",
              "  % \\ begin{table}[htbp ] \n",
              "  % % xxmaj the first argument is the label . \n",
              "  % % xxmaj the caption goes in the second argument , and the table contents \n",
              "  % % go in the third argument . \n",
              "  % \\ floatconts \n",
              "  % { tab : xxunk \n",
              "  % { \\ caption{an xxmaj example xxmaj xxunk \n",
              "  % { \\ begin{tabular}{ll } \n",
              "  % \\ bfseries xxmaj dataset & \\ bfseries xxmaj result \\ \\ \n",
              "  % xxmaj xxunk & xxunk \\ \\ \n",
              "  % xxmaj xxunk & xxunk \\ \\ \n",
              "  % xxmaj xxunk & xxunk \\ \\ \n",
              "  % xxmaj xxunk & xxunk \n",
              "  % \\ end{tabular } } \n",
              "  % \\ end{table } \n",
              " \n",
              "  % \\ begin{figure}[htbp ] \n",
              "  % % xxmaj caption and label go in the first argument and the figure contents \n",
              "  % % go in the second argument \n",
              "  % \\ floatconts \n",
              "  % { fig : example } \n",
              "  % { \\ caption{example xxmaj image } } \n",
              "  % { \\ includegraphics[width=0.5 \\ xxunk - image } } \n",
              "  % \\ end{figure } \n",
              " \n",
              "  % \\ xxunk } \n",
              "  % \\ xxunk xxmaj net xxmaj activation } \n",
              "  % \\ label{alg : net } \n",
              "  % % older versions of algorithm2e have \\ dontprintsemicolon instead \n",
              "  % % of the following : \n",
              "  % % \\ dontprintsemicolon \n",
              "  % % older versions of algorithm2e have \\ linesnumbered instead of the \n",
              "  % % following : \n",
              "  % % \\ linesnumbered \n",
              "  % \\ xxunk , \\ ldots , x_n , w_1 , \\ ldots , xxunk } \n",
              "  % \\ xxunk , the net activation } \n",
              "  % $ y \\ leftarrow 0 $ \\ ; \n",
              "  % \\ xxmaj for{$i \\ leftarrow 1 $ \\ kwto $ n$ } { \n",
              "  % $ y \\ leftarrow y + xxunk \\ ; \n",
              "  % } \n",
              "  % \\ end{algorithm2e } \n",
              " \n",
              "  % % xxmaj acknowledgments --- xxmaj will not appear in anonymized version \n",
              "  % \\ xxunk thank xxmaj nvidia for its xxunk of gpus . } \n",
              " \n",
              " \n",
              "  \\ xxunk - xxunk } \n",
              " \n",
              " \n",
              "  \\ appendix \n",
              " \n",
              "  ewpage \n",
              "  \\ xxunk xxmaj uncertainty } \n",
              " \n",
              "  xxmaj we use two measures to estimate uncertainty -- differential entropy and output entropy . xxmaj the output entropy is a measure of the total uncertainty , where as the differential entropy is a good measure of distributional uncertainty . xxmaj output entropy is high whenever we encounter overlap between classes or we encounter samples from xxup ood . xxmaj on the other hand , the differential entropy is high only when we encounter xxup ood samples and remains low even in case of data uncertainty \\ xxunk } . \n",
              " \n",
              "  xxmaj output entropy is defined as : \n",
              "  \\ begin{equation } \\ label{eq : example } \n",
              "  \\ xxunk , d ) ] = - \\ sum_{i=1}^k xxunk , d ) \\ xxunk , d ) ) \n",
              "  \\ end{equation } \n",
              "  where \n",
              "  \\ begin{equation } \\ label{eq : example } \n",
              "  xxunk , d ) = \\ int p(y_i| \\ textbf{p } ) \\ xxunk } ( \\ xxunk \\ alpha ) d \\ textbf{p } = \\ frac { \\ alpha_i } { \\ xxunk \\ alpha_j } \n",
              "  \\ end{equation } \n",
              " \n",
              " \n",
              "  xxmaj differential entropy is maximized when all categorical distributions are xxunk . i.e. when posterior $ q _ { \\ xxunk ) ) = d ( \\ xxunk \\ xxunk , \\ xxunk \\ xxunk , and it is defined as : \n",
              "  \\ begin{equation } \\ label{eq : example } \n",
              "  \\ xxunk ( \\ xxunk \\ alpha ) ] = \\ log b ( \\ alpha ) + ( \\ sum_{i=1}^k \\ alpha_i - k ) \\ xxunk ( \\ sum_{i=1}^k \\ alpha_i ) - \\ sum_{i=1}^k ( \\ alpha_i - 1 ) \\ xxunk ( \\ alpha_i ) \n",
              "  \\ end{equation } \n",
              " \n",
              "  % \\ begin{figure } \n",
              "  % \\ begin{subfigure}[b]{0.25 \\ textwidth } \n",
              "  % \\ centering \n",
              "  % \\ xxunk . xxup png } \n",
              "  % \\ caption{high xxmaj data xxmaj uncertainty } \n",
              "  % \\ label{fig : xxunk } \n",
              "  % \\ end{subfigure}% \n",
              "  % \\ begin{subfigure}[b]{0.25 \\ textwidth } \n",
              "  % \\ xxunk . xxup png } \n",
              "  % \\ caption{high xxmaj distributional xxmaj uncertainty } \n",
              "  % \\ label{fig : xxunk } \n",
              "  % \\ end{subfigure}% \n",
              "  % \\ xxunk ( a ) implies high data uncertainty so we will have low differential entropy \\ \\ xxmaj fig ( b ) has high distributional uncertainty so both uncertainty metrics will be high } \n",
              "  % \\ end{figure } \n",
              " \n",
              " \n",
              "  % \\ xxunk \n",
              "  % \\ centering \n",
              "  % \\ xxunk xxmaj data xxmaj uncertainty ] { \\ xxunk . xxup png } } % \n",
              "  % \\ qquad \n",
              "  % \\ xxunk xxmaj distributional xxmaj uncertainty ] { \\ xxunk . xxup png } } % \n",
              "  % \\ xxunk ( a ) implies high data uncertainty so we will have low differential entropy \\ \\ xxmaj fig ( b ) has high distributional uncertainty so both uncertainty metrics will be xxunk \n",
              "  % \\ label{fig : xxunk \n",
              "  % \\ end{figure } \n",
              " \n",
              "  \\ begin{figure}[htbp ] \n",
              "  \\ floatconts \n",
              "  { fig : xxunk } \n",
              "  { \\ caption{(a ) implies high data uncertainty so we will have low differential entropy \\ \\ ( b ) has high distributional uncertainty so both uncertainty metrics will be high } } \n",
              "  { % \n",
              "  \\ xxunk xxmaj data xxmaj uncertainty ] { \\ label{fig : xxunk \n",
              "  \\ xxunk . xxup xxunk \n",
              "  \\ qquad \n",
              "  \\ xxunk xxmaj distributional xxmaj uncertainty ] { \\ label{fig : xxunk \n",
              "  \\ xxunk . xxup png } } \n",
              "  } \n",
              "  \\ end{figure } \n",
              " \n",
              "  xxmaj from xxmaj figure 1 it becomes clear that our method allows us to easily distinguish between xxmaj data and xxmaj distributional xxmaj uncertainty . \n",
              " \n",
              "  ewpage \n",
              "  \\ section{additional xxmaj experiment } \n",
              "  \\ begin{figure}[htbp ] \n",
              "  \\ centering \n",
              "  \\ xxunk } \n",
              "  \\ end{figure } \n",
              "  xxmaj we observe our model is very confident on xxmaj xxunk ( xxup xxunk ) class , which is expected since it make majority of the dataset , this reinforces the importance of well balanced data for learning . xxmaj we can also see our xxup ood samples can be distinctly separated from the in - class samples . xxmaj the xxup ood sample used for training and testing are from different distributions . xxmaj for simplicity we used xxmaj gaussian xxmaj distribution for training xxup ood samples and xxmaj uniform xxmaj distribution for testing xxup ood samples . xxmaj ideally more complex techniques should be used for generating xxup ood samples on the decision boundary \n",
              "  \\ xxunk } . \n",
              "  \\ end{document } \n",
              " ,xxbos \\ xxunk } \n",
              " \n",
              "  % xxrep 8 xxunk xxmaj user 's xxmaj packages xxrep 7 xxunk \n",
              "  \\ usepackage{amsmath } \n",
              "  % \\ usepackage{arydshln } % dashed lines \n",
              "  % \\ usepackage{amsfonts } \n",
              "  \\ usepackage{array } % new column type \n",
              "  \\ usepackage{amssymb } % for using \\ varnothing \n",
              "  \\ usepackage{bm } \n",
              "  \\ xxunk } \n",
              "  \\ usepackage{booktabs } % nice tables \n",
              "  \\ usepackage{calc } \t  % calculations over tikz coordinates \n",
              "  \\ usepackage{caption } \n",
              "  % \\ xxunk } % crossing \n",
              "  \\ usepackage{enumitem } \n",
              "  \\ usepackage{diagbox } \n",
              "  % \\ usepackage{fancyvrb } % xxunk verbatim \n",
              "  \\ usepackage{float } \n",
              "  \\ usepackage{graphicx } % % % for including graphics \n",
              "  \\ xxunk } \n",
              "  \\ usepackage[colorlinks = true , allcolors = xxunk , xxunk } % ( cross ) referencing \n",
              "  % \\ usepackage{latexsym } \n",
              "  \\ usepackage{listings } % for amr \n",
              "  \\ xxunk } % xxup user xxup define xxup macros \n",
              "  \\ usepackage{multicol } % multicolumn structure \n",
              "  \\ usepackage{multirow } % nice tables \n",
              "  \\ usepackage{nicefrac } \n",
              "  \\ usepackage{natbib } % xxunk citation xxunk \n",
              "  \\ usepackage{pifont } % arrow in amr to clausal form translation \n",
              "  % \\ usetikzlibrary{positioning } \n",
              "  \\ usepackage{ragged2e } % xxunk \n",
              "  \\ usepackage{subcaption } \n",
              "  \\ xxunk } \n",
              "  \\ xxunk } \n",
              "  \\ usepackage{textcomp } % xxunk text < and > \n",
              "  \\ usepackage{times } % times font \n",
              "  \\ usepackage{tcolorbox } % for colored boxes \n",
              "  \\ usepackage{colortbl } % coloured columns \n",
              "  % \\ usepackage[dvipsnames]{xcolor } \n",
              "  \\ xxunk } % xxunk notes for communication \n",
              "  % \\ usepackage{times } \n",
              "  \\ usepackage[normalem]{ulem } % underline and xxunk \n",
              "  \\ usepackage{url } % % % for including urls \n",
              "  \\ usepackage{pifont}% for xxunk \n",
              " \n",
              "  % \\ setlength { \\ xxunk mm } % ! ! ! xxup remove xxup before xxup submission \n",
              " \n",
              "  % uncomment below if xxmaj error \" \\ xxunk ended up in ... \" occurs \n",
              "  % \\ xxunk } \n",
              " \n",
              "  % xxrep 10 xxunk xxmaj user 's xxmaj macros xxrep 11 xxunk \n",
              "  % \n",
              "  ewcommand { \\ xxunk ] { } % xxunk it to get rid of notes \n",
              " \n",
              "  ewcommand { \\ xxunk ] { \\ xxunk \\ tiny ] { # 1 } { } } % comment it out to get rid of notes \n",
              "  % \n",
              "  ewcommand { \\ xxunk ] { } % for multiline comments \n",
              " \n",
              "  ewcommand { \\ xxunk ] { \\ textcolor{red } { # 1 } } \n",
              "  % \n",
              "  ewcommand { \\ xxunk ] { # 1 } % uncomment to remove alerts \n",
              "  % \\ xxunk } \n",
              " \n",
              "  ewcommand { \\ xxunk ] { \\ textbf { # 1 } } \n",
              " \n",
              "  ewcommand { \\ xxunk ] { \\ texttt { # 1 } } \n",
              " \n",
              "  ewcommand { \\ xxunk ] { \\ sout { \\ mbox { # 1 } } } \n",
              " \n",
              "  ewcommand { \\ xxunk } { \\ xxunk mm } } \n",
              " \n",
              "  ewcommand { \\ xxunk ] { # 1 \\ xxunk . \\ xxunk # 2 } \n",
              " \n",
              "  ewcommand { \\ xxunk ] { \\ xxunk } { # 1 } } \n",
              " \n",
              "  ewcommand { \n",
              "  xxunk ] { \\ xxunk } { # 1 } } \n",
              " \n",
              "  ewcommand { \n",
              "  xxunk ] { \\ xxunk [ # 1 ] { \\ texttt { # 2 } } } \n",
              " \n",
              "  ewcommand { \\ xxunk ] { \\ ensuremath { \\ langle # 1 \\ rangle } } \n",
              "  \\ xxunk } \n",
              " \n",
              "  ewcommand { \\ xxunk ] { \\ mbox{$ \\ langle$ \n",
              "  tt [ # 1 ] { # 2}$ \\ rangle$ } } \n",
              " \n",
              "  ewcommand { \\ cross } { \\ textcolor{red } { \\ xxunk } } } \n",
              " \n",
              "  ewcommand { \\ cmark } { \\ textcolor{green } { \\ xxunk } } } \n",
              " \n",
              "  ewcommand { \\ xxunk ] { \\ textcolor{red } { \\ textbf { # 1 } } } \n",
              " \n",
              "  ewcommand { \\ xxunk ] { \\ textcolor{red } { \\ ensuremath { \\ bm { # 1 xxrep 4 } \n",
              " \n",
              "  \\ xxunk } \n",
              " \n",
              "  xxunk } \n",
              "  \\ xxunk } \n",
              " \n",
              " \n",
              "  ewcommand { \\ xxunk } { \\ catcode ` \\ _ = 11 } \n",
              " \n",
              "  ewcommand { \\ xxunk } { \\ catcode ` \\ _ = \\ active } \n",
              " \n",
              "  ewcommand { \\ xxunk } { \\ xxunk \\ hbox{$ \\ scriptstyle \\ mathtt { \\ xxunk } } \n",
              " \n",
              "  % xxrep 10 xxunk xxmaj abbreviations xxrep 11 xxunk \n",
              " \n",
              "  ewcommand { \\ xxunk } { \\ xxunk } } \n",
              " \n",
              "  ewcommand { \\ xxunk } { \\ mbox { \\ xxunk } } } \n",
              " \n",
              "  ewcommand { \\ xxunk } { \\ xxunk } } \n",
              " \n",
              "  ewcommand { \\ xxunk } { \\ xxunk } } \n",
              " \n",
              "  ewcommand { \\ xxunk } { \\ xxunk et xxunk } } \n",
              " \n",
              "  ewcommand { \\ xxunk } { \\ xxunk et xxunk } } \n",
              " \n",
              "  ewcommand { \\ xxunk } { \\ xxunk et al . } } \n",
              " \n",
              "  ewcommand { \\ xxunk } { \\ xxunk et al . } } \n",
              " \n",
              "  ewcommand { \\ xxunk } { \\ xxunk } } \n",
              " \n",
              "  ewcommand { \\ tacl } { \\ xxunk } } \n",
              " \n",
              "  ewcommand { \\ xxunk } { \\ xxunk } } \n",
              " \n",
              "  ewcommand { \\ liu } { \\ xxunk } } \n",
              " \n",
              "  ewcommand { \\ xxunk } { \\ xxunk } } \n",
              " \n",
              "  ewcommand { \\ xxunk } { \\ xxunk } } \n",
              " \n",
              "  \\ title{the xxmaj first xxmaj shared xxmaj task on \\ \\ xxmaj discourse xxmaj representation xxmaj structure xxmaj parsing } \n",
              "  \\ date { } \n",
              "  \\ xxunk xxmaj xxunk \\ qquad xxmaj xxunk van xxmaj xxunk \\ qquad xxmaj xxunk xxmaj xxunk \\ qquad xxmaj xxunk xxmaj xxunk \\ \\ \n",
              "  xxup xxunk , xxmaj university of xxmaj groningen \\ \\ \n",
              "  \\ texttt { \\ { xxunk , \\ , r \\ ! xxunk \\ ! xxunk , \\ , xxunk , \\ , xxunk \\ } xxunk } \n",
              "  } \n",
              " \n",
              "  % xxrep 21 xxunk xxup main xxrep 20 xxunk \n",
              "  \\ begin{document } \n",
              "  \\ xxunk \n",
              "  \\ maketitle \n",
              "  \\ thispagestyle{empty } \n",
              "  \\ pagestyle{empty } \n",
              " \n",
              "  \\ begin{abstract } \n",
              "  xxmaj the paper presents the xxup xxunk 2019 shared task on semantic parsing where the goal is to produce xxmaj discourse xxmaj representation xxmaj structures ( xxunk ) for xxmaj english sentences . \n",
              "  xxunk originate from xxmaj discourse xxmaj representation xxmaj theory and represent xxunk meaning representations that capture the semantics of negation , xxunk , quantification , and presupposition triggers . \n",
              "  xxmaj additionally , concepts and event - participants in xxunk are described with wordnet synsets and the thematic roles from xxunk . \n",
              "  xxmaj to measure similarity between two xxunk , they are represented in a clausal form , i.e. as a set of tuples . \n",
              "  xxmaj participant systems were expected to produce xxunk in this clausal form . \n",
              "  xxmaj taking into account the rich lexical information , explicit scope marking , a high number of shared variables among clauses , and highly - constrained format of valid xxunk , all these makes the xxup xxunk parsing a challenging xxup nlp task . \n",
              "  xxmaj the results of the shared task displayed improvements over the existing state - of - the - art parser . \n",
              "  \\ end{abstract } \n",
              " \n",
              "  % xxrep 27 xxunk \n",
              "  \\ section{introduction } \n",
              "  \\ label{sec : intro } \n",
              " \n",
              " \n",
              "  xxmaj semantic parsing has been gaining in popularity in the last few years . \n",
              "  xxmaj there have been a series of shared tasks in semantic parsing organized , where each task requires to generate meaning representations of specific types : \n",
              "  xxmaj broad - xxmaj coverage xxmaj broad - coverage xxmaj semantic xxmaj dependencies \\ xxunk - xxunk , xxunk - xxunk } , \n",
              "  xxmaj abstract xxmaj meaning xxmaj representation \\ xxunk - xxup xxunk , semeval - xxup xxunk } , \n",
              "  or xxmaj universal xxmaj conceptual xxmaj cognitive xxmaj annotation \\ xxunk } . \n",
              " \n",
              "  xxmaj the xxmaj discourse xxmaj representation xxmaj structure ( xxup xxunk ) parsing task extends this development by aiming at producing meaning representations that ( i ) come with more expressive power than existing ones and ( ii ) are easily xxunk into formal logic , thereby opening the door to applications that require automated forms of inference \\ xxunk } . \n",
              "  xxunk are meaning representations employed by xxmaj discourse xxmaj representation xxmaj theory ( xxup xxunk , \\ xxunk : xxunk } ) . \n",
              "  xxmaj they have been successfully applied for wide - coverage semantic representations \\ xxunk : xxunk } , xxmaj natural xxmaj language xxmaj inference \\ xxunk , xxunk } , and xxmaj natural xxmaj language xxmaj generation \\ xxunk } . \n",
              "  xxmaj to the best of our knowledge , there has never been a shared task on xxunk meaning representations . \n",
              " \n",
              "  xxmaj the aim of the task is to compare semantic parsing methods and the performance of systems that take as input an xxmaj english text and provide as output the xxunk meaning representation of that text % ( see \\ autoref{fig : xxunk : afraid } ) . \n",
              "  xxmaj since a xxup xxunk combines logical ( negation , quantification and xxunk ) , pragmatic ( xxunk ) and lexical ( word senses and thematic roles ) components of semantics in a single meaning representation , \n",
              "  the xxup xxunk parsing task shares parts of the following xxup nlp tasks : semantic role labeling , reference resolution , scope detection , named entity tagging , word sense disambiguation , predicate - argument structure prediction , and presupposition projection . \n",
              " \n",
              "  xxmaj there are only a few previous approaches to xxup xxunk parsing . xxmaj traditionally , due to the complexity of the task , it has been the domain of symbolic and statistical approaches \\ xxunk : xxunk , xxunk , xxunk } . xxmaj recently , however , neural sequence - to - sequence systems achieved impressive performance on the task \\ xxunk , xxunk } , without relying on any external linguistic resources . \n",
              " \n",
              "  xxmaj in the first shared task on xxup xxunk parsing , taking into account the information - rich and complex structure of the target meaning representation , we tested participant systems mainly on short , open - domain xxmaj english texts . \n",
              "  xxmaj in this way , we lowered the threshold for participation to encourage higher results in the shared task and mitigate challenges associated to semantic parsing long texts . \n",
              "  xxmaj in total five systems participated in the shared task . \n",
              "  xxmaj the top - ranked systems outperformed the existing state - of - the - art system in xxup xxunk parsing . \n",
              "  xxmaj the shared task was hosted on xxunk \n",
              "  \\ footnote { \\ url{https : / / xxunk / competitions / xxunk } } . \n",
              " \n",
              " \n",
              " \n",
              "  % xxrep 7 xxunk 2 xxup xxunk xxrep 7 xxunk \n",
              "  \\ begin{figure } \n",
              "  \\ centering \n",
              "  % xxrep 5 xxunk xxup xxunk xxrep 5 xxunk \n",
              "  \\ xxunk \\ textwidth } \n",
              "  \\ centering \n",
              "  \\ xxunk } { \n",
              "  \\ begin{tabbing } \n",
              "  12 \\ = xxunk \\ = \\ kill \n",
              "  { \\ sc system input } : \\ \\ [ 0pt ] \n",
              "  \\ > \\ > xxmaj tom is n't afraid of anything . \n",
              "  \\ \\ [ 1 mm ] \n",
              "  { \\ sc system output } : \\ \\ [ 0pt ] \n",
              "  \\ > \\ > \\ xxunk ] { \\ xxunk \n",
              "  \\ xxunk { \\ , } l } \n",
              "  % \\ toprule \n",
              "  \\ xxunk } xxup ref \\ xxunk } \\ \\ \n",
              "  \\ xxunk } male \" \\ xxunk } \" \\ xxunk } \\ \\ \n",
              "  \\ xxunk } xxmaj name \\ xxunk } \" tom \" \\ \\ \n",
              "  \\ xxunk } xxup ref \\ xxunk } \\ \\ \n",
              "  \\ xxunk } xxup xxunk \\ xxunk } \" now \" \\ \\ \n",
              "  \\ xxunk } time \" \\ xxunk } \" \\ xxunk } \\ \\ \n",
              "  \\ xxunk } xxup not \\ xxunk } \\ \\ \n",
              "  \\ xxunk } xxup ref \\ xxunk } \\ \\ \n",
              "  \\ xxunk } xxmaj time \\ xxunk } \\ xxunk } \\ \\ \n",
              "  \\ xxunk } xxmaj xxunk \\ xxunk } \\ xxunk } \\ \\ \n",
              "  \\ xxunk } afraid \" \\ xxunk } \" \\ xxunk } \\ \\ \n",
              "  \\ xxunk } xxmaj stimulus \\ xxunk } \\ xxunk } \\ \\ \n",
              "  \\ xxunk } xxup ref \\ xxunk } \\ \\ \n",
              "  \\ xxunk } entity \" \\ xxunk } \" \\ xxunk } \\ \\ \n",
              "  % \\ bottomrule \n",
              "  \\ end{tabular } } } \n",
              "  \\ \\ [ 1 mm ] \n",
              "  { \\ sc box format } : \\ \\ [ 3pt ] \n",
              "  \\ xxunk mm } \n",
              "  [ { \\ xxunk $ } { \n",
              "  \\ xxunk \n",
              "  eg$ } \n",
              "  \\ xxunk $ ~ $ x_2 $ } { \n",
              "  xxunk \\ xxunk \\ \\ \n",
              "  \\ xxunk \\ xxunk , xxunk \\ \\ \n",
              "  \\ xxunk \\ xxunk , xxunk \\ \\ \n",
              "  \\ xxunk \\ xxunk , xxunk \\ \\ \n",
              "  xxunk \\ xxunk } \\ \\ \n",
              "  $ \\ xxunk \\ \\ \n",
              "  \\ xxunk = \\ xxunk \n",
              "  } } \n",
              "  [ { \\ xxunk $ } { \n",
              "  $ \\ xxunk \\ \\ \n",
              "  \\ xxunk \\ xxunk , \\ xxunk } } \n",
              "  ] \n",
              "  ] \n",
              "  \\ xxunk } \n",
              "  \\ end{tabbing } \n",
              "  } \\ vspace{-7 mm } \n",
              "  \\ caption{the xxup xxunk parsing task : the ~ system input is a short text ( the xxup pmb document \\ href{http : / / xxunk / explorer / xxunk / xxunk } ) , and the expected output is a xxup xxunk in clausal form . xxmaj its standard visualisation in box - notation , following xxup xxunk , is presented below . } \n",
              "  \\ label{fig : xxunk : afraid } \n",
              "  \\ end{minipage}% \n",
              "  \\ qquad \n",
              "  % xxrep 5 xxunk xxup xxunk xxrep 5 xxunk \n",
              "  \\ xxunk \\ textwidth } \n",
              "  \\ xxunk mm } \n",
              "  \\ xxunk } { \\ xxunk } \n",
              "  \\ mbox { \\ href{http : / / xxunk / explorer / xxunk / xxunk } } : \n",
              "  xxmaj he played the xxunk and she xxunk . \n",
              "  \\ \\ [ -1 mm ] \n",
              "  \\ xxunk ] { \\ texttt { \n",
              "  \\ renewcommand * { \\ arraystretch}{1.1 } \n",
              "  \\ xxunk { \\ xxunk { } } \\ toprule \n",
              "  \\ xxunk } xxup xxunk \\ xxunk } & \n",
              "  \\ xxunk } xxup xxunk \\ xxunk } \\ \\ \n",
              "  \\ xxunk } xxup ref \\ xxunk } & \n",
              "  \\ xxunk } xxup ref \\ xxunk } \\ \\ \n",
              "  \\ xxunk } male \" \\ xxunk } \" \\ xxunk } & \n",
              "  \\ xxunk } female \" \\ xxunk } \" \\ xxunk } \\ \\ \n",
              "  \\ xxunk } xxup ref \\ xxunk } & \n",
              "  \\ xxunk } xxup ref \\ xxunk } \\ \\ \n",
              "  \\ xxunk } play \" \\ xxunk } \" \\ xxunk } & \n",
              "  \\ xxunk } xxunk \" \\ xxunk } \" \\ xxunk } \\ \\ \n",
              "  \\ xxunk } xxmaj agent \\ xxunk } \\ xxunk } & \n",
              "  \\ xxunk } xxmaj agent \\ xxunk } \\ xxunk } \\ \\ \n",
              "  \\ xxunk } xxmaj theme \\ xxunk } \\ xxunk } & \n",
              "  \\ xxunk } xxmaj time \\ xxunk } \\ xxunk } \\ \\ \n",
              "  \\ xxunk } xxup ref \\ xxunk } & \n",
              "  \\ xxunk } xxup ref \\ xxunk } \\ \\ \n",
              "  \\ xxunk } xxunk \" \\ xxunk } \" \\ xxunk } & \n",
              "  \\ xxunk } xxup tpr \\ xxunk } \" now \" \\ \\ \n",
              "  \\ xxunk } xxup ref \\ xxunk } & \n",
              "  \\ xxunk } time \" \\ xxunk } \" \\ xxunk } \\ \\ \n",
              "  \\ xxunk } time \" \\ xxunk } \" \\ xxunk } & \n",
              "  \\ xxunk } xxup continuation \\ xxunk } \\ xxunk } \\ \\ \n",
              "  \\ xxunk } xxup tpr \\ xxunk } \" now \" & \n",
              "  \\ xxunk } xxmaj time \\ xxunk } \\ xxunk } \\ \\ \n",
              "  \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  } } \n",
              "  \\ \\ \n",
              "  xxunk mm } \n",
              "  \\ xxunk } { \n",
              "  \\ xxunk mm } \n",
              "  [ { \\ xxunk } { } { \n",
              "  \\ xxunk $ ~ $ t_1 $ } { \n",
              "  xxunk \\ xxunk \\ \\ \n",
              "  \\ xxunk \\ xxunk , xxunk \\ \\ \n",
              "  \\ xxunk \\ xxunk , xxunk \\ \\ \n",
              "  \\ xxunk \\ xxunk , xxunk \\ \\ \n",
              "  $ \\ xxunk \\ \\ \n",
              "  \\ xxunk \\ prec \\ xxunk } \n",
              "  \\ xxunk $ ~ $ t_2 $ } { \n",
              "  xxunk \\ xxunk \\ \\ \n",
              "  \\ xxunk \\ xxunk , xxunk \\ \\ \n",
              "  \\ xxunk \\ xxunk , xxunk \\ \\ \n",
              "  $ \\ xxunk \\ \\ \n",
              "  \\ xxunk \\ prec \\ xxunk } } \n",
              "  { $ \\ xxunk } } \n",
              "  [ { \\ xxunk $ } { \n",
              "  xxunk \\ xxunk } } \n",
              "  ] \n",
              "  [ { \\ xxunk $ } { \n",
              "  xxunk \\ xxunk } } \n",
              "  ] \n",
              "  [ { \\ xxunk $ } { \n",
              "  xxunk \\ xxunk } } \n",
              "  ] \n",
              "  ] \n",
              "  \\ xxunk } \n",
              "  } \n",
              "  \\ end{tabular } \n",
              "  } \n",
              "  % from dev - set \n",
              "  \\ caption{the segmented box \\ xxunk } consists of a set of labelled boxes , i.e. the discourse segments \\ xxunk } and \\ xxunk } , and a single discourse condition . \n",
              "  xxmaj in the condition , discourse relation holds between two discourse segments and is formatted in uppercase . \n",
              "  xxmaj the definite noun phrase and the pronouns are presupposition ( \\ xxunk } , \\ xxunk } , and \\ xxunk } ) triggers . \n",
              "  } \n",
              "  \\ label{fig : xxunk : xxunk } \n",
              "  \\ end{minipage } \n",
              "  \\ vspace{-0.4 cm } \n",
              "  \\ end{figure } \n",
              " \n",
              "  % xxrep 27 xxunk \n",
              "  \\ section{task xxmaj description } \n",
              "  \\ label{sec : task } \n",
              " \n",
              "  xxmaj the xxup xxunk parsing in a nutshell is presented in \\ autoref{fig : xxunk : afraid } . \n",
              "  xxmaj here , the input , a short xxmaj english sentence , needs to be mapped to the output , a xxunk meaning representation in clausal form . \n",
              "  xxmaj concepts , states and events are represented by the word senses ( male \\ xxunk } , entity \\ xxunk } , afraid \\ xxunk } ) from wordnet 3.0 \\ xxunk } and relations are modeled with thematic roles ( \\ xxunk } , \\ xxunk } , \\ xxunk } ) drawn from an extended version of xxunk \\ xxunk } . \n",
              " \n",
              "  xxmaj each entity needs to introduce a discourse referent , i.e. a variable , in the right scope , form an instance of the right concepts , and be connected to other entities via thematic roles or comparison operators . \n",
              "  xxmaj for example , in \\ autoref{fig : xxunk : afraid } , \\ xxunk } introduces a discourse referent $ x_2 $ in the scope \\ xxunk } with the help of the clause \\ xxunk xxup ref x2 } . \n",
              "  xxmaj the clause \\ xxunk entity \" \\ xxunk } \" x2 } makes $ x_2 $ an instance of entity \\ xxunk } . \n",
              "  xxmaj finally , the clause \\ xxunk xxmaj stimulus s1 x2 } connects $ x_2 $ to the event entity $ s_1 $ of \\ xxunk } via the \\ xxunk } thematic role . \n",
              " \n",
              "  xxmaj the xxunk of negation , implication , modal operators or propositional arguments need to be correctly identified . \n",
              "  xxmaj proper names , pronouns , definite descriptions and xxunk \n",
              "  are treated as xxunk and get their own box if they can not be resolved by the local context . xxmaj tense is locally accommodated . \n",
              "  xxmaj for example , \\ autoref{fig : xxunk : afraid } shows how the negation operator introduces the scope ( \\ xxunk } ) and how the named entity \\ xxunk } gives rise to the presupposition ( \\ xxunk } ) . \n",
              "  \\ autoref{fig : xxunk : xxunk } demonstrates how discourse segments get their own scope ( \\ xxunk } and \\ xxunk } ) and how definite noun phrases and pronouns trigger xxunk ( \\ xxunk } , \\ xxunk } , and \\ xxunk } ) . \n",
              "  xxmaj finally , \\ autoref{fig : xxunk : xxunk } depicts an implication with two xxunk ( \\ xxunk } and \\ xxunk } ) , modeling semantics of a universal quantifier , and nested xxunk ( \\ xxunk } and \\ xxunk } ) due to a xxunk pronoun . \n",
              " \n",
              "  xxmaj given the aforementioned nuances of the fine - grained xxunk meaning representations , the xxup xxunk parsing task represents a challenge for machine learning methods . \n",
              " \n",
              " \n",
              " \n",
              " \n",
              "  % xxrep 27 xxunk \n",
              "  \\ xxunk xxmaj representation xxmaj structure } \\ label{sec : xxunk } \\ label{ssec : boxes } \n",
              " \n",
              "  xxmaj the meaning representations used in this shared task are based on \n",
              "  the xxunk put forward in xxup xxunk \\ xxunk : xxunk } and derived from the xxmaj parallel xxmaj meaning xxmaj bank \\ xxunk } . xxmaj there are some important extensions to the theory , though . \n",
              "  xxmaj first , the xxunk are language - neutral , and all non - logical symbols are disambiguated to wordnet synsets or xxunk roles . xxmaj furthermore , xxunk are explicitly represented following \n",
              "  \\ xxunk } and xxmaj xxunk xxup xxunk \\ xxunk } . xxmaj discourse structure is analysed following by xxmaj segmented xxup xxunk \\ xxunk } . xxmaj as in the original xxup xxunk , xxunk are displayed in box format for reading convenience ( xxunk xxunk are displayed with outgoing arrows of the boxes that triggered them ) . xxunk are recursive structures , and for the purpose of evaluation , they are translated into clauses , flattening down the recursion by reification . \n",
              " \n",
              " \n",
              "  \\ xxunk ! ] \n",
              "  \\ centering \n",
              "  \\ caption{a xxup bnf of xxunk : ( possibly empty ) sets are denoted with curly brackets as \\ { $ \\ langle$ xxunk \\ rangle$ \\ } . \n",
              "  xxmaj the string elements for operators and punctuation are in red . } \n",
              "  \\ label{def : bnf } \n",
              "  \\ xxunk \\ textwidth } \n",
              "  \\ xxunk \n",
              "  \\ setlength { \\ xxunk mm plus 1pt minus 1pt } % increase separation between rules \n",
              "  \\ setlength { \\ xxunk mm } % increase separation between xxup lhs / xxup rhs \n",
              "  \\ footnotesize \n",
              "  \\ xxunk } \n",
              "  < xxup xxunk > : : = \\ { < xxup xxunk > \\ } < labelled xxup box > \n",
              " \n",
              "  < labelled xxup box > : : = < label > < xxup box > \n",
              " \n",
              "  < xxup box > : : = < simple xxup box > | < segmented xxup box > \n",
              " \n",
              "  < simple xxup box > : : = \\ { < discourse referent > \\ } \\ { < condition > \\ } \n",
              " \n",
              "  < condition > : : = < basic condition > | < complex condition > \n",
              " \n",
              "  < term > : : = < discourse referent > | < constant > \n",
              " \n",
              "  < basic condition > : : = < semantic role > \\ xxunk > \\ xxunk { , } < term > \\ xxunk { ) } \\ alt < term > < comparison operator > < term > \n",
              "  \\ alt < concept > \\ xxunk \\ _ sense \\ _ number > \\ xxunk > \\ xxunk { ) } \n",
              " \n",
              "  < complex condition > : : = \\ xxunk { \\ xxunk xxup box > | \\ xxunk { \\ xxmaj xxunk xxup box > | \\ xxunk { \\ xxmaj xxunk xxup box > \\ alt < labelled xxup box > \\ xxunk { \\ xxmaj xxunk xxup box > \n",
              "  \\ alt < discourse referent > \\ xxunk xxup box > \n",
              " \n",
              "  < segmented xxup box > : : = \\ { < labelled xxup box > \\ } \\ { < discourse condition > \\ } \n",
              " \n",
              "  < discourse condition > : : = < discourse relation > \\ xxunk > \\ xxunk { , } < label > \\ xxunk { ) } \n",
              " \n",
              "  \\ xxunk } \n",
              "  \\ xxunk \n",
              "  \\ end{minipage } \n",
              "  \\ xxunk } \n",
              " \n",
              "  % xxrep 12 xxunk \n",
              " \n",
              "  a xxup xxunk always contains a main labelled box along with an optional set of presupposition xxunk ( see xxmaj definition \\ , \\ ref{def : bnf } ) . \n",
              "  xxmaj for example , the main labelled box in \\ autoref{fig : xxunk : afraid } is \\ xxunk } while \\ xxunk } is a presupposition . \n",
              "  a box can be simple ( e.g. , the box labelled with \\ xxunk } in \\ autoref{fig : xxunk : afraid } ) or segmented ( e.g. , the box labelled with \\ xxunk } in \\ autoref{fig : xxunk : xxunk } ) . \n",
              "  a simple box consists of a set of discourse referents and a set of conditions . xxmaj conditions can be basic or complex . \n",
              "  xxmaj basic conditions are concept predicates or relations over discourse referents and constants . \n",
              "  xxmaj xxunk are treated as constants , not as discourse referents \\ xxunk } , for example , { \\ em now } is one of such xxunk ( see \\ autoref{fig : xxunk : afraid } ) . \n",
              "  xxmaj complex conditions are those involving labelled boxes . \n",
              "  xxmaj the examples of complex conditions are $ \n",
              "  eg \\ xxunk in \\ autoref{fig : xxunk : afraid } and $ \\ xxunk } \\ xxmaj rightarrow \\ xxunk in \\ autoref{fig : xxunk : xxunk } . \n",
              "  xxmaj finally , a segmented box contains a set of labelled boxes ( \\ xxunk } and \\ xxunk } in \\ autoref{fig : xxunk : xxunk } ) and discourse conditions . \n",
              "  a discourse condition is a discourse relations over box labels , e.g. , $ \\ xxunk in \\ autoref{fig : xxunk : xxunk } . \n",
              " \n",
              "  % xxrep 12 xxunk \n",
              "  % \n",
              "  % \\ xxunk format } \n",
              "  \\ label{ssec : clauses } \n",
              " \n",
              "  xxmaj the clausal form and the box - notation are two different forms of displaying xxunk meaning representations \\ xxunk } . \n",
              "  xxmaj we consider the clausal form a machine - readable format that is suitable for the evaluation with a continuous score between 0 and 1 ( see xxmaj section \\ , \\ ref{sec : evaluation } ) . \n",
              "  xxmaj on the other hand , the box - notation is a human - readable format and originates from xxmaj discourse xxmaj representation xxmaj theory . \n",
              "  xxmaj conversion from the box - notation to the clausal form and vice versa is transparent : each box gets a label , and discourse referents and conditions in the clausal form are preceded by the label of the box they occur in . \n",
              " \n",
              " \n",
              " \n",
              "  % xxrep 5 xxunk xxup xxunk xxrep 5 xxunk \n",
              "  \\ begin{figure}[t ! ] \n",
              "  \\ centering \n",
              "  \\ begin{tabular}{c } \n",
              "  \\ href{https : / / xxunk / explorer / xxunk / xxunk } : xxmaj he put all his money in the box . \n",
              "  \\ \\ [ -2 mm ] \n",
              "  \\ xxunk ] { \\ xxunk \n",
              "  \\ xxunk { \\ , } l l @ { \\ xxunk mm } } l xxunk { \\ , } } \n",
              "  \\ toprule \n",
              "  \\ xxunk } xxup ref \\ xxunk } & \n",
              "  \\ xxunk { \\ % xxmaj he [ 0 ... 2 ] his [ 11 ... 14 ] } \n",
              "  & \\ xxunk } xxup imp \\ xxunk } \\ xxunk } & \n",
              "  \\ xxunk { \\ % all [ 7 ... 10 ] } \n",
              "  \\ \\ \n",
              "  \\ xxunk } male \" \\ xxunk } \" \\ xxunk } & \n",
              "  \\ xxunk { \\ % xxmaj he [ 0 ... 2 ] his [ 11 ... 14 ] } \n",
              "  & \\ xxunk } xxup ref \\ xxunk } & \n",
              "  \\ xxunk { \\ % all [ 7 ... 10 ] } \n",
              "  \\ \\ \n",
              "  \\ xxunk } xxup ref \\ xxunk } & \n",
              "  \\ xxunk { \\ % put [ 3 ... 6 ] } \n",
              "  & \\ xxunk } xxunk \\ xxunk } \\ xxunk } & \n",
              "  \\ xxunk { \\ % all [ 7 ... 10 ] } \n",
              "  \\ \\ \n",
              "  \\ xxunk } xxup tpr \\ xxunk } \" now \" & \n",
              "  \\ xxunk { \\ % put [ 3 ... 6 ] } \n",
              "  & \\ xxunk } entity \" \\ xxunk } \" \\ xxunk } & \n",
              "  \\ xxunk { \\ % all [ 7 ... 10 ] } \n",
              "  \\ \\ \n",
              "  \\ xxunk } time \" \\ xxunk } \" \\ xxunk } & \n",
              "  \\ xxunk { \\ % put [ 3 ... 6 ] } \n",
              "  & \\ xxunk } xxup ref \\ xxunk } & \n",
              "  \\ xxunk { \\ % his [ 11 ... 14 ] } \n",
              "  \\ \\ \n",
              "  \\ xxunk } xxup ref \\ xxunk } & \n",
              "  \\ xxunk { \\ % put [ 3 ... 6 ] } \n",
              "  & \\ xxunk } xxmaj owner \\ xxunk } \\ xxunk } & \n",
              "  \\ xxunk { \\ % his [ 11 ... 14 ] } \n",
              "  \\ \\ \n",
              "  \\ xxunk } xxmaj agent \\ xxunk } \\ xxunk } & \n",
              "  \\ xxunk { \\ % put [ 3 ... 6 ] } \n",
              "  & \\ xxunk } money \" \\ xxunk } \" \\ xxunk } & \n",
              "  \\ xxunk { \\ % money [ 15 ... 20 ] } \n",
              "  \\ \\ \n",
              "  \\ xxunk } xxmaj theme \\ xxunk } \\ xxunk } & \n",
              "  \\ xxunk { \\ % put [ 3 ... 6 ] } \n",
              "  & \\ xxunk } xxmaj destination \\ xxunk } \\ xxunk } & \n",
              "  \\ xxunk { \\ % in [ 21 ... 23 ] } \n",
              "  \\ \\ \n",
              "  \\ xxunk } xxmaj time \\ xxunk } \\ xxunk } & \n",
              "  \\ xxunk { \\ % put [ 3 ... 6 ] } \n",
              "  & \\ xxunk } xxup ref \\ xxunk } & \n",
              "  \\ xxunk { \\ % the [ 24 ... 27 ] } \n",
              "  \\ \\ \n",
              "  \\ xxunk } put \" \\ xxunk } \" \\ xxunk } & \n",
              "  \\ xxunk { \\ % put [ 3 ... 6 ] } \n",
              "  & \\ xxunk } box \" \\ xxunk } \" \\ xxunk } & \n",
              "  \\ xxunk { \\ % box [ 28 ... 31 ] } \n",
              "  \\ \\ \n",
              "  \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  } } \n",
              "  \\ \\ \n",
              "  xxunk mm } \n",
              "  \\ xxunk mm } \n",
              "  [ { \\ xxunk $ } { \n",
              "  xxunk \\ xxunk \\ \\ \n",
              "  \\ xxunk \\ prec \\ xxunk \\ \\ \n",
              "  xxunk } \n",
              "  \\ xxunk $ } { \n",
              "  xxunk \\ xxunk \\ \\ \n",
              "  \\ xxunk \\ xxunk , xxunk } \n",
              "  \\ xxunk \\ xxmaj rightarrow$ } \n",
              "  \\ xxunk $ } { \n",
              "  xxunk \\ xxunk \\ \\ \n",
              "  \\ xxunk \\ xxunk , xxunk \\ \\ \n",
              "  \\ xxunk \\ xxunk , xxunk \\ \\ \n",
              "  \\ xxunk \\ xxunk , xxunk \\ \\ \n",
              "  \\ xxunk \\ xxunk , xxunk } } } \n",
              "  [ { \\ xxunk $ } { \n",
              "  xxunk \\ xxunk \\ \\ \n",
              "  \\ xxunk \\ xxunk , xxunk } } \n",
              "  [ { \\ xxunk $ } { \n",
              "  xxunk \\ xxunk } } \n",
              "  ] \n",
              "  ] \n",
              "  [ { \\ xxunk $ } { \n",
              "  box$ \\ xxunk } } \n",
              "  ] \n",
              "  ] \n",
              "  \\ xxunk } \n",
              "  \\ end{tabular } \n",
              "  % from xxup pmb - test \n",
              "  \\ caption{the xxup xxunk contains the example of nested xxunk triggered by the xxunk pronoun \\ xxunk } . \n",
              "  xxmaj the main box \\ xxunk } of the xxup xxunk xxunk a set of two xxunk . \n",
              "  xxmaj at the same time , one of the xxunk xxunk , namely $ \\ pair { \\ { \\ xxunk } \\ } , \\ xxunk , itself carries the presupposition \\ xxunk } . \n",
              "  xxmaj note that the xxunk about a male discourse referent , triggered by \\ xxunk } and \\ xxunk } separately , are merged into a single presupposition box \\ xxunk } . xxmaj the clauses are accompanied with aligned tokens . \n",
              "  } \n",
              "  \\ label{fig : xxunk : xxunk } \n",
              "  \\ end{figure } \n",
              " \n",
              " \n",
              "  % xxrep 27 xxunk \n",
              "  \\ section{data } \n",
              "  \\ label{sec : data } \n",
              "  % xxrep 12 xxunk \n",
              "  \\ xxunk xxmaj data } \n",
              "  \\ label{ssec : xxunk } \n",
              " \n",
              "  xxmaj for the shared task we released the training , development , and test data , taken from the xxmaj parallel xxmaj meaning xxmaj bank ( xxup pmb , \\ xxunk } ) . xxmaj the xxup pmb is a parallel corpus annotated with formal meaning xxunk \n",
              "  \\ footnote{a part of the corpus can be viewed online via the xxup pmb explorer : \\ url{http : / / xxunk / explorer } } \n",
              "  xxmaj these representations capture the most probable interpretation of a sentence ; no ambiguities or under - specification techniques are employed . \n",
              "  xxmaj the formal meaning representations are automatically constructed and manually corrected . xxmaj completely correct representations are flagged as \\ xxunk } . \n",
              "  xxmaj representations that are partly manually corrected are marked as \\ xxunk } , while the rest is marked \\ xxunk } . \n",
              " \n",
              " \n",
              "  xxmaj the xxup pmb release number used for the shared task is xxunk % \n",
              "  \\ footnote { \\ url{https : / / xxunk / xxunk } } , of which some statistics are shown in \\ xxunk : stats } . xxmaj note that xxup xxunk tokens and types are underrepresented in the silver and xxunk data compared to the gold data . \n",
              "  xxmaj this is because the gold data contains more manual corrections on the token level than the silver and xxunk data . \n",
              "  xxmaj for the example of multi - word expressions see \n",
              "  \\ autoref{fig : xxunk } . \n",
              "  xxmaj in the shared task , participants were allowed to use the silver and xxunk data , this would especially make sense in the case of data - hungry neural models , though there is no guarantee that those representations resemble the gold standard . \n",
              " \n",
              "  \\ begin{table}[t ] \n",
              "  \\ centering \n",
              "  \\ caption{statistics for the xxup pmb release xxunk and the shared task evaluation set . } \n",
              "  \\ label{tab : stats } \n",
              "  \\ begin{tabular } { l | xxwrep 6 r } \n",
              "  \\ toprule \n",
              "  \\ bf xxmaj data splits & \\ bf xxmaj docs & \\ bf xxmaj tokens & \\ bf xxmaj word types & \\ bf xxup xxunk tokens & \\ bf xxup xxunk types \\ \\ \n",
              "  \\ midrule \n",
              "  xxup pmb xxunk gold train & xxunk & xxunk & xxunk & xxunk & xxunk \\ \\ \n",
              "  xxup pmb xxunk gold dev & xxunk & xxunk & xxunk & 71 & 61 \\ \\ \n",
              "  xxup pmb xxunk gold test & 650 & xxunk & xxunk & 108 & 100 \\ \\ \n",
              "  xxup pmb xxunk silver & xxunk & xxunk & xxunk & xxunk & xxunk \\ \\ \n",
              "  xxup pmb xxunk xxunk & xxunk & xxunk & xxunk & xxunk & 699 \\ \\ \n",
              "  \\ midrule \n",
              "  xxmaj evaluation set & 600 & xxunk & xxunk & 92 & 79 \\ \\ \n",
              "  \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  \\ vspace{-0.4 cm } \n",
              "  \\ end{table } \n",
              " \n",
              " \n",
              " \n",
              "  xxmaj the data provided to the shared task participants consists of pairs of a raw natural language text and its corresponding xxunk meaning representation in clausal xxunk \n",
              "  \\ footnote { \\ url{https : / / github.com / xxunk / xxunk / tree / master / data / xxunk } } \n",
              "  xxmaj whether the meaning representation is of gold , silver or xxunk standard is explicitly indicated . \n",
              "  xxmaj to facilitate automatic learning of xxunk meaning representations , we also provided automatically induced alignments between clauses and tokens , where token positions are provided with character xxunk . \n",
              "  xxmaj the examples of clause - token alignments are give in \\ autoref{fig : xxunk : xxunk } and \\ autoref{fig : xxunk } . \n",
              "  xxmaj the latter represents an exact formatting of the text and clausal form pair provided in the shared task . \n",
              " \n",
              " \n",
              " \n",
              "  % xxrep 7 xxunk xxup begin samples of training data \n",
              "  \\ xxunk ] \n",
              "  \\ centering \n",
              "  % \\ lstset { \n",
              "  % frame = single , \n",
              "  % xxunk , \n",
              "  % xxunk mm , \n",
              "  % xxunk mm \n",
              "  % } \n",
              "  % \\ begin{subfigure } { \\ textwidth } \n",
              "  % \\ xxunk mm , xxunk mm } \n",
              "  \\ begin{tabular}{c } \n",
              "  \\ xxunk { \\ ttfamily \\ small } , xxunk \\ $ ] \n",
              "  xxmaj xxunk xxmaj xxunk was xxunk for collapse of xxmaj xxunk xxmaj bank xxup xxunk . \n",
              " \n",
              "  b1 xxup ref x1 % xxmaj xxunk \\ xxunk [ 0 ... 11 ] \n",
              "  b1 xxmaj name x1 \" xxunk \\ xxunk \" % xxmaj xxunk \\ xxunk [ 0 ... 11 ] \n",
              "  b1 male \" xxunk \" x1 % xxmaj xxunk \\ xxunk [ 0 ... 11 ] \n",
              "  b2 xxup ref t1 % was [ 12 ... 15 ] \n",
              "  b2 xxup tpr t1 \" now \" % was [ 12 ... 15 ] \n",
              "  b2 xxmaj time e1 t1 % was [ 12 ... 15 ] \n",
              "  b2 time \" xxunk \" t1 % was [ 12 ... 15 ] \n",
              "  b2 xxup ref e1 % xxunk [ 16 ... 24 ] \n",
              "  b2 xxmaj patient e1 x1 % xxunk [ 16 ... 24 ] \n",
              "  b2 arrest \" xxunk \" e1 % xxunk [ 16 ... 24 ] \n",
              "  b2 xxmaj theme e1 x2 % for [ 25 ... 28 ] \n",
              "  b2 xxup ref x2 % collapse [ 29 ... 37 ] \n",
              "  b2 collapse \" xxunk \" x2 % collapse [ 29 ... 37 ] \n",
              "  b2 xxmaj patient x2 xxunk % of [ 38 ... 40 ] \n",
              "  xxunk xxup ref xxunk % \n",
              "  xxunk xxmaj name xxunk \" xxunk \\ xxunk \\ xxunk \" % xxmaj xxunk \\ xxunk \\ xxunk [ 41 ... 57 ] \n",
              "  xxunk company \" xxunk \" xxunk % xxmaj xxunk \\ xxunk \\ xxunk [ 41 ... 57 ] \n",
              "  % . [ 57 ... 58 ] \n",
              "  \\ end{lstlisting } \n",
              "  \\ end{tabular } \n",
              "  % \\ xxunk translation and the corresponding clausal form with xxmaj english word senses } \n",
              "  % \\ xxunk : en } \n",
              "  % \\ end{subfigure } \n",
              "  \\ xxunk mm } \n",
              "  \\ caption{a sample of a training document ( \\ href{http : / / xxunk / explorer / xxunk / xxunk } ) . \n",
              "  xxmaj for each document there is a pair of raw text and the corresponding clausal form . \n",
              "  xxmaj clausal forms incorporate automatically induced clause - token alignment . } \n",
              "  \\ label{fig : xxunk } \n",
              "  \\ end{figure } \n",
              " \n",
              "  % xxrep 27 xxunk \n",
              " \n",
              "  \\ subsection{evaluation set } \n",
              "  \\ label{ssec : xxunk } \n",
              " \n",
              "  xxmaj the official evaluation set contains 600 instances that were not released previously . xxmaj they will not be released publicly , but are still available for ( blind ) scoring via the shared task xxunk \n",
              "  \\ footnote { \\ url{https : / / xxunk / competitions / xxunk } } \n",
              "  xxmaj however , during the evaluation phase , we asked the participants to provide xxunk for a set of xxunk short texts . \n",
              "  xxmaj in addition to the raw texts ( 600 ) from the evaluation split , this set contained the train ( xxunk ) , development ( xxunk ) , and test ( 650 ) data from the xxup xxunk release and the sentences ( xxunk ) from the xxup sick dataset \\ xxunk } . \n",
              "  xxmaj the reason for providing the xxunk set of raw texts was three - fold : \n",
              "  ( i ) xxmaj xxunk the raw texts of the evaluation set to make it hard to tune models on them ; \n",
              "  ( ii ) xxmaj obtain the complete information about the performance of the systems on the provided training , development and test sets ; \n",
              "  ( iii ) xxmaj carry out extrinsic evaluation of the participant systems on the natural language inference task . \n",
              " \n",
              " \n",
              "  % xxrep 27 xxunk \n",
              "  \\ section{evaluation xxmaj metrics and xxmaj baselines } \n",
              "  % xxup la : we agreed on to make the section for this \n",
              "  \\ label{sec : evaluation } \n",
              " \n",
              "  xxmaj before comparing a system produced clausal form to the gold one , the produced form is checked on validity --- whether it represents a xxup xxunk . xxmaj if the clausal form is invalid , it is replaced by a single non - matching clause . \n",
              "  xxmaj in the shared task , we include three baseline systems . \n",
              "  xxmaj the evaluation and validation scripts and the baselines are publicly xxunk \n",
              "  \\ footnote { \\ url{http : / / github.com / xxunk / xxunk } } \n",
              " \n",
              " \n",
              "  % xxrep 12 xxunk \n",
              "  \\ xxunk } \n",
              "  \\ label{ssec : xxunk } \n",
              " \n",
              "  xxmaj not all sets of clauses correspond to a well - formed xxup xxunk , e.g. , discourse referents found in the conditions should be explicitly introduced in the boxes , or there should exist labelled boxes for the labels used in the discourse conditions . \n",
              "  xxmaj we employ the validator \\ xxunk } \\ xxunk } to automatically check a set of clauses on well - xxunk . \n",
              "  \\ xxunk } does several checks for validity checking . \n",
              "  xxmaj for example , first it scans each clause separately in a clausal form and identifies the types of variables based on the operators . \n",
              "  xxmaj for each discourse referent variable , it checks the existence of the binding discourse referent . \n",
              "  xxmaj during this procedure , \\ xxunk } also detects positions of the boxes in the xxup xxunk ( i.e. , so - called the subordinate relation ) . \n",
              "  xxmaj based on this information , it is checked that nested boxes do not create loops and there is a unique main box in the xxup xxunk . \n",
              " \n",
              "  xxmaj all the released clausal forms of the xxunk are valid . \n",
              "  xxmaj we provided the participants with \\ xxunk } in order to help them identify the ill - formed clausal forms produced by their systems . \n",
              " \n",
              " \n",
              "  % xxrep 12 xxunk \n",
              "  \\ subsection{evaluation } \n",
              "  \\ label{ssec : xxunk } \n",
              " \n",
              "  xxmaj the evaluation defines to what degree a system output clausal form is similar to the corresponding gold one . \n",
              "  xxmaj to compare the system output and gold representations , we compute the xxmaj f1-score over the clauses , following \\ xxunk : xxunk } . \n",
              "  xxmaj we use the tool \\ xxunk } \\ xxunk } , which is specifically designed to evaluate xxunk . xxmaj it is based on the \\ xxunk } \\ xxunk } tool that is used to evaluate xxup amr parsers . xxmaj it is essentially a hill - climbing algorithm that finds the best variable mapping between the produced xxup xxunk and the gold standard . xxmaj to avoid local optima , we restart the procedure 10 times . xxmaj in order to prevent an xxunk f - score , before searching the maximal matching , \\ xxunk } discards those { \\ tt xxunk which are deemed redundant . \n",
              "  a { \\ tt xxunk \\ mbox{$ \\ langle$ \n",
              "  xxunk xxup ref x}$ \\ rangle$ } is redundant if and only if its discourse referent \n",
              "  xxunk } occurs with a concept predicate in a basic condition of the same box \n",
              "  xxunk } -- in other words , there exists a clause of the form \\ mbox{$ \\ langle$ \n",
              "  xxunk $ xxunk \" $ xxunk \" x}$ \\ rangle$ } . \\ footnote{in \\ autoref{fig : xxunk - match } redundant { \\ tt xxunk are xxunk through . } \n",
              " \n",
              " \n",
              "  % xxrep 5 xxunk match clausal forms xxrep 5 xxunk \n",
              "  \\ xxunk ! ] \n",
              "  \\ centering \n",
              "  \\ begin{tabular}{c c c } \n",
              "  xxmaj sample system output & xxmaj optimal mapping & xxmaj gold representation \\ \\ \n",
              "  \\ xxunk ] { \\ texttt { \n",
              "  \\ xxunk { \\ , } xxunk { \\ , } } \\ toprule \n",
              "  \\ matched { \\ xxunk } xxup imp \\ xxunk } \\ xxunk } } \\ \\ \n",
              "  \\ xxunk { \\ xxunk } xxup ref \\ xxunk } } \\ \\ \n",
              " \n",
              "  xxunk { \\ xxunk } every \" \\ xxunk } \" \\ xxunk } } \\ \\ \n",
              "  \\ xxunk { \\ xxunk } xxup ref \\ xxunk } } \\ \\ \n",
              " \n",
              "  xxunk { \\ xxunk } xxmaj agent \\ xxunk } \\ xxunk } } \\ \\ \n",
              "  \\ matched { \\ xxunk } new \" \\ xxunk } \" \\ xxunk } } \\ \\ \n",
              "  \\ matched { \\ xxunk } xxmaj time \\ xxunk } \\ xxunk } } \\ \\ \n",
              "  \\ xxunk { \\ xxunk } xxup ref \\ xxunk } } \\ \\ \n",
              " \n",
              "  xxunk { \\ xxunk } time \" \\ xxunk } \" \\ xxunk } } \\ \\ \n",
              " \n",
              "  xxunk { \\ xxunk } xxup ref \\ xxunk } } \\ \\ \n",
              "  \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  } } \n",
              "  & \n",
              "  \\ xxunk ] { \\ texttt { \n",
              "  \\ renewcommand \\ arraystretch{1.2 } \n",
              "  \\ xxunk } \n",
              " \n",
              "  xxunk mm } \n",
              "  \\ xxunk } $ \\ xxunk \\ xxunk } \\ \\ \n",
              "  \\ xxunk } $ \\ xxunk \\ xxunk } \\ \\ \n",
              "  \\ xxunk } $ \\ xxunk \\ xxunk } \\ \\ \n",
              "  \\ xxunk } $ \\ xxunk \\ xxunk } \\ \\ \n",
              "  \\ xxunk } $ \\ xxunk \\ xxunk } \\ \\ \n",
              "  \\ xxunk } $ \\ xxunk \\ xxunk } \\ \\ \n",
              "  \\ xxunk } $ \\ xxunk \\ xxunk } \\ \\ \n",
              "  \\ xxunk } $ \\ xxunk \\ textnormal { \\ xxunk / a } } \n",
              "  \\ end{tabular } \n",
              "  } } \n",
              "  & \n",
              "  \\ xxunk ] { \\ texttt { \n",
              "  \\ xxunk { \\ , } xxunk { \\ , } } \\ toprule \n",
              "  \\ matched { \\ xxunk } xxup imp \\ xxunk } \\ xxunk } } \\ \\ \n",
              "  \\ xxunk { \\ xxunk } xxup ref \\ xxunk } } \\ \\ \n",
              " \n",
              "  xxunk { \\ xxunk } entity \" \\ xxunk } \" \\ xxunk } } \\ \\ \n",
              "  \\ xxunk { \\ xxunk } xxup ref \\ xxunk } } \\ \\ \n",
              " \n",
              "  xxunk { \\ xxunk } xxmaj theme \\ xxunk } \\ xxunk } } \\ \\ \n",
              "  \\ matched { \\ xxunk } new \" \\ xxunk } \" \\ xxunk } } \\ \\ \n",
              "  \\ matched { \\ xxunk } xxmaj time \\ xxunk } \\ xxunk } } \\ \\ \n",
              "  \\ xxunk { \\ xxunk } xxup ref \\ xxunk } } \\ \\ \n",
              " \n",
              "  xxunk { \\ xxunk } time \" \\ xxunk } \" \\ xxunk } } \\ \\ \n",
              " \n",
              "  xxunk { \\ xxunk } xxup xxunk \\ xxunk } \" now \" } \\ \\ \n",
              "  \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  } } \n",
              "  \\ end{tabular } \n",
              "  \\ \\ [ 3 mm ] \n",
              " \n",
              "  \\ xxunk mm } \n",
              "  \\ begin{tabular}{@{}cc@ { } } \n",
              "  \\ xxunk } \n",
              "  \\ xxunk mm } \n",
              "  [ { \\ xxunk $ } { \n",
              "  xxunk } \n",
              "  \\ xxunk $ } { \n",
              "  xxunk \\ xxunk } \n",
              "  \\ xxunk \\ xxmaj rightarrow$ } \n",
              "  \\ xxunk $ } { \n",
              "  xxunk \\ xxunk \\ \\ \n",
              "  \\ xxunk \\ xxunk , xxunk \\ \\ \n",
              "  \\ xxunk \\ xxunk , xxunk } } } \n",
              "  [ { \\ xxunk $ } { \n",
              "  $ \\ xxunk } } \n",
              "  ] \n",
              "  ] \n",
              "  \\ xxunk } \n",
              "  & \n",
              "  \\ xxunk } \n",
              "  \\ xxunk mm } \n",
              "  [ { \\ xxunk \\ xxunk \\ \\ \n",
              "  \\ xxunk = \\ xxunk \\ \\ \n",
              " \n",
              "  xxunk } \n",
              "  \\ xxunk $ } { \n",
              "  xxunk \\ xxunk } \n",
              "  \\ xxunk \\ xxmaj rightarrow$ } \n",
              "  \\ xxunk $ } { \n",
              "  xxunk \\ xxunk \\ \\ \n",
              "  \\ xxunk \\ xxunk , xxunk \\ \\ \n",
              "  \\ xxunk \\ xxunk , xxunk } } } \n",
              "  ] \n",
              "  \\ xxunk } \n",
              "  \\ end{tabular } \n",
              "  \\ caption{an optimal mapping of variables which maximizes overlap between the system output and gold clausal forms for the sentence ( xxup pmb document \\ href{http : / / xxunk / explorer / xxunk / xxunk } ) \\ xxunk is new } . \n",
              "  xxmaj the maximal overlap yields an f - score of $ xxunk \n",
              "  xxmaj matching , non - matching and redundant clauses are in green , red , and xxunk through , respectively . \n",
              "  xxmaj the box - notation of xxunk meaning representations is not available during the comparison of clausal forms . } \n",
              "  \\ label{fig : xxunk - match } \n",
              "  \\ vspace{-0.4 cm } \n",
              "  \\ end{figure * } \n",
              " \n",
              " \n",
              "  xxmaj an example of comparing the clausal forms of two xxunk meaning representations is shown in \\ autoref{fig : xxunk - match } . \n",
              "  xxmaj with respect to the optimal mapping , both , the sample system output and gold clauses , include three clauses that could not be matched with each other while four clauses are matched . \n",
              "  xxmaj the optimal mapping gives us a precision and recall of $ \n",
              "  xxunk , resulting in an f - score of $ xxunk xxmaj similarly to xxup amr , we use micro - averaged f - score when evaluating a set of xxunk . \n",
              " \n",
              "  xxmaj an aspect that is different from the xxup amr evaluation system is that we generalize over synonyms . \n",
              "  xxmaj in a preprocessing step of the evaluation , all word senses are converted to its wordnet 3.0 synset xxup id . \n",
              "  xxmaj for example , fox \\ xxunk } and xxunk \\ xxunk } both get normalized to xxunk \\ xxunk } and are thus able to match . \n",
              " \n",
              "  xxmaj to calculate whether two systems differ significantly , we perform approximate randomization \\ xxunk - xxunk } , with $ \\ alpha$ = $ 0.05 $ , \\ xxunk } = $ 1000 $ and $ xxmaj xxunk } ) > xxmaj xxunk as test statistic for each individual xxup xxunk pair . \n",
              " \n",
              "  \\ subsection{baselines } \n",
              " \n",
              "  xxmaj we provide three baseline parsers : \\ xxunk } , \\ xxunk - xxunk } and \\ xxunk } . \\ xxunk } simply outputs a default xxup xxunk , which is a xxup xxunk that is the most similar to the xxunk in our training set . \\ footnote{for xxup pmb release xxunk this is the xxup xxunk for \\ xxunk xxunk for himself . } } \n",
              "  \\ xxunk - xxunk } outputs the xxup xxunk of the most similar sentence in the training set , based on the cosine distance of the average word - embedding vector , calculated using glove \\ xxunk } . \n",
              "  \\ xxunk } is a script that converts the output of an xxup amr parser to a valid xxup xxunk by applying a set of rules , described in \\ xxunk } and \\ xxunk } . \n",
              "  xxmaj we will provide scores on the development , test and evaluation sets by using the xxup amr parser of \\ xxunk } . \n",
              " \n",
              " \n",
              " \n",
              "  % xxrep 27 xxunk \n",
              "  \\ xxunk xxmaj systems } \n",
              " \n",
              "  xxmaj we received a total of five submissions in the shared task out of 32 registered participants . \n",
              "  xxmaj three out of five submitted a system paper . \n",
              "  xxmaj the general characteristics of the participating systems are give in \\ xxunk : systems } . \n",
              "  xxmaj following \\ xxunk } , we explicitly encouraged the participants to include ablation experiments and negative results ( if any ) . \n",
              "  xxmaj note that the authors of the systems \\ xxunk { } and \\ xxunk { } are from the organizers . \n",
              "  xxmaj below , we provide a short description of each system . \n",
              " \n",
              "  \\ xxunk ] \n",
              "  % \\ vspace{-0.4 cm } \n",
              "  \\ centering \n",
              "  \\ caption{overview of the participating systems } \n",
              "  \\ label{tab : systems } \n",
              "  \\ begin{tabular}{ll xxrep 4 c } \n",
              "  \\ toprule \n",
              "  & \\ textbf{model } & \\ textbf{input } & \\ xxunk } & \\ xxunk } & \\ xxunk } \\ \\ \n",
              "  \\ midrule \n",
              "  \\ xxunk & xxmaj transformer & char & \\ cross & \\ cmark & \\ cmark \\ \\ \n",
              "  \\ xxunk & seq2seq & char & \\ cross & \\ cmark & \\ cross \\ \\ \n",
              "  \\ xxunk & seq2seq & char & \\ cross & \\ cmark & \\ cross \\ \\ \n",
              "  \\ xxunk & stack - lstms & word & \\ cmark & \\ cross & \\ cross \\ \\ \n",
              "  \\ xxunk & bi - xxup lstm & word & \\ cmark & \\ cross & \\ cross \\ \\ \n",
              "  \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  \\ vspace{-0.4 cm } \n",
              "  \\ end{table } \n",
              " \n",
              "  % xxrep 10 xxunk \n",
              "  \\ subsection { \\ xxunk } } \n",
              " \n",
              "  \\ xxunk { } , the parser described in \\ xxunk } , uses a character - level neural sequence - to - sequence model to produce xxunk . xxmaj they apply a number of methods to improve performance , such as rewriting the variables to a more general format , introducing a feature for uppercase letters and \\ emph{not } using character - level representation for xxup xxunk roles and operators . xxmaj moreover , they show that performance can be substantially improved by first pre - training on gold and silver data , after which the parser is fine - tuned on only the gold standard data . \n",
              "  \\ vspace{-0.1 cm } \n",
              "  % xxrep 10 xxunk \n",
              "  \\ subsection { \\ xxunk : xxunk } } \n",
              "  xxmaj the system of \\ xxunk { } is the parser described in \\ xxunk } and \\ xxunk : xxunk } , which follows up on their work previously described in \\ xxunk } . xxmaj they improve on this work in two ways : ( i ) by switching their sequence - to - sequence framework from opennmt \\ xxunk } to xxmaj xxunk \\ xxunk } and ( ii ) by providing the encoder with linguistic information ( lemmas , semantic tags \\ xxunk - xxunk } , xxup pos - tags , dependency parses and xxup xxunk xxunk ) that are encoded in a separate encoder . \n",
              "  \\ vspace{-0.1 cm } \n",
              " \n",
              "  % xxrep 10 xxunk \n",
              "  \\ subsection { \\ xxunk : liu } } \n",
              "  \\ xxunk { } also follow the approach of \\ xxunk } in terms of pre- and postprocessing the data , but they improve on it by using the xxmaj transformer model \\ citep{vaswani2017attention } , instead of a sequence - to - sequence xxup rnn . xxmaj also , they show that employing the xxunk standard in addition to the gold and silver standard leads to improved performance . \n",
              "  \\ vspace{-0.1 cm } \n",
              " \n",
              "  % xxrep 10 xxunk \n",
              "  \\ subsection { \\ xxunk : xxunk } } \n",
              "  \\ xxunk { } aim to find a middle - ground between traditional symbolic approaches and the recent neural ( sequence - to - sequence ) models . xxmaj they employ a transition - based parser that relies on explicit word - meaning pairs that are found in the training set . xxmaj parsing decisions are made based on vector representations of parser states , which are encoded using stack - lstms . \n",
              "  \\ vspace{-0.1 cm } \n",
              " \n",
              "  % xxrep 10 xxunk \n",
              "  \\ subsection { \\ xxunk \\ protect \\ footnotemark } \n",
              "  \\ xxunk full list of authors : xxmaj xxunk xxmaj xxunk , xxmaj xxunk xxmaj xxunk , xxmaj adam xxmaj xxunk and xxmaj xxunk xxmaj xxunk ( xxmaj university of xxmaj edinburgh ) . \n",
              "  xxmaj since the authors xxunk from submitting a system paper due to the xxup acl policy for submission , we include a slightly extended summary of their system , xxunk provided by them . } \n",
              "  % \n",
              "  \\ xxunk { } propose a graph decoder that given an input sentence encoded via a bidirectional xxup lstm generates a xxup dag ( xxmaj directed xxmaj acyclic xxmaj graph ) as a sequence of fragments from a graph grammar . \n",
              "  xxmaj these fragments are \\ xxunk } ; predicate names , synset and information on whether the predicate is xxunk or not are predicted in a second step , conditioned on the fragment and the decoding history . \n",
              "  xxmaj two are the main features of the graph parser : 1 ) it is agnostic to the underlying semantic formalism and does not need any preprocessing step to deal with variable binding ; \n",
              "  2 ) fragments are aware of the overall graph structure and the graph is built incrementally via a process of non - terminal rewriting . \n",
              "  ( 1 ) sets this method apart from the graph parser of \\ xxunk } where a grammar is extracting via an elaborate pre - processing step , tailored to a specific formalism , whereas ( 2 ) allows to leverage neural sequential decoding \\ xxunk } . \n",
              "  xxmaj the only preprocessing step required is to convert xxunk in clause format into single - rooted , fully instantiated dags ; \n",
              "  we do so by treating both variables and boxes as nodes and semantic roles , operators and discourse relations as edges between those ( where each binary operator or relation gives rise to two edges ) . \n",
              "  xxmaj similarly , the only postprocessing step lies in converting the graph back to clause format . xxmaj this last step can inject errors in the parse and it is the reason why some of the output graphs can be ill - formed . \n",
              " \n",
              "  % xxrep 27 xxunk \n",
              "  \\ section{results } \n",
              " \n",
              "  \\ begin{table}[t ] \n",
              "  \\ centering \n",
              "  \\ xxunk results of the shared task for the participating systems } \n",
              "  \\ begin{tabular } { l | c c c | c c c } \n",
              "  \\ toprule \n",
              "  % \\ multirow{2 } { * } { \\ xxunk \\ xxunk mm } { \\ xxunk mm xxmaj sets } } \n",
              "  & \\ xxunk xxunk ( f \\ % ) } & \\ xxunk set ( \\ % ) } \\ \\ \n",
              "  % \\ cline{2 - 7 } \n",
              "  & xxmaj train & xxmaj dev & xxmaj test & xxmaj prec . & xxmaj rec . & f \\ \\ \n",
              "  \\ midrule \n",
              "  \\ xxunk } & xxup na & xxunk & 40.1 & \\ xxunk } & \\ xxunk } & 38.8 \\ \\ \n",
              "  \\ xxunk } & xxup na & 40.0 & xxunk & \\ xxunk } & \\ xxunk } & xxunk \\ \\ \n",
              "  \\ xxunk - xxunk } & xxup na & 53.3 & 57.7 & \\ xxunk } & \\ xxunk } & xxunk \\ \\ \n",
              "  \\ midrule \n",
              "  \\ xxunk & 91.1 & 69.9 & 73.3 & \\ xxunk } & \\ xxunk } & xxunk \\ \\ \n",
              "  \\ xxunk & 84.2 & xxunk & xxunk & \\ xxunk } & \\ xxunk } & 70.9 \\ \\ \n",
              "  \\ xxunk { } & 88.5 & 81.2 & xxunk & \\ xxunk } & \\ xxunk } & 79.7 \\ \\ \n",
              "  \\ xxunk { } & 94.9 & 86.5 & 86.8 & \\ xxunk } & \\ xxunk } & xxunk \\ \\ \n",
              "  \\ xxunk & 96.9 & 85.5 & xxunk & \\ xxunk } & \\ xxunk } & 84.8 \\ \\ \n",
              "  \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  \\ label{tab : results } \n",
              "  \\ end{table } \n",
              " \n",
              "  \\ xxunk : results } shows the official results of the shared task . xxmaj the system of \\ xxunk \\ achieved the best performance , though there is no significant difference with the work of \\ xxunk \\ ( $ p = 0.23 $ ) . xxmaj the systems of \\ xxunk \\ and \\ xxunk , though clearly outperforming the baselines , are a bit behind the best three systems . xxmaj however , they can likely improve performance by incorporating silver and xxunk standard data . xxmaj no systems seem to have overfit on the provided dev and test sets . xxmaj the work of \\ xxunk \\ is perhaps overfit on the training set , given their high score on train compared to the test sets . \n",
              " \n",
              "  \\ xxunk : xxunk } shows a more detailed overview of the results . xxmaj all teams produced a substantial amount of perfect xxunk , but only 31 xxunk of them were perfectly produced by each system . \n",
              "  \\ xxunk { } is the only system with a substantial number of ill - formed xxunk . xxmaj this hurts their performance , since they get an f - score of 0.0 in evaluation . xxmaj if we ignore xxunk and score their ill - formed xxunk as if they were valid , their score increases to 72.1 . xxmaj on the other hand , calculating an f - score for \\ xxunk } the ill - formed xxunk ( without xxunk ) gives us an f - score of $ xxunk $ , suggesting that the model would not have scored very well in either way . \n",
              " \n",
              "  xxmaj similar as was observed in \\ xxunk } , word sense disambiguation is problematic for the xxup xxunk parsers . xxmaj when assuming oracle sense numbers , all systems obtain a substantially higher f - score ( increases of $ 1.8 $ to $ 3.6 $ ) . \\ xxunk { } propose a simple method to improve on this sub - problem by taking the most frequent sense in the training set for a concept , though this only increased their f - scores by $ 0.2 $ to $ 0.4 $ on the dev and test sets . xxmaj nouns are the easiest for all models to correctly produce ( possibly due to the frequent \\ xxunk } ) , while adverbs are the hardest , though there are only 12 such clauses in the evaluation set . \n",
              " \n",
              "  \\ begin{table}[t ] \n",
              "  \\ centering \n",
              "  % \\ xxunk } { \n",
              "  \\ xxunk - scores of fine - grained evaluation of the participating systems on the evaluation set . ` ` xxmaj winner out of 5 ' ' counts only those instances for which the parser obtained a higher score than all the rest , while ` ` xxmaj highest out of 5 ' ' allows ties . } \n",
              "  \\ begin{tabular}{l xxrep 5 c } \n",
              "  \\ toprule \n",
              "  & \\ liu { } & \\ xxunk { } & \\ tacl { } & \\ xxunk { } & \\ xxunk { } \\ \\ \\ midrule \n",
              "  \\ textbf{all clauses } & 84.8 & xxunk & 79.7 & 70.9 & xxunk \\ \\ \\ midrule \n",
              "  \\ xxunk xxmaj operators } & 93.9 & 94.2 & xxunk & 75.2 & 76.3 \\ \\ \n",
              "  \\ xxunk roles } & xxunk & xxunk & 78.1 & 72.4 & 66.4 \\ \\ \n",
              "  \\ xxunk synsets } & 83.8 & 82.3 & xxunk & xxunk & xxunk \\ \\ \n",
              "  \\ textbf { \\ quad nouns } & 89.2 & 87.5 & xxunk & xxunk & xxunk \\ \\ \n",
              "  \\ textbf { \\ quad verbs } & 69.5 & 68.9 & xxunk & xxunk & 58.3 \\ \\ \n",
              "  \\ textbf { \\ quad adjectives } & xxunk & xxunk & xxunk & 61.5 & xxunk \\ \\ \n",
              "  \\ textbf { \\ quad adverbs } & xxunk & xxunk & 33.3 & 0.0 & xxunk \\ \\ \\ midrule \n",
              "  \\ xxunk sense numbers } & xxunk & xxunk & xxunk & xxunk & xxunk \\ \\ \n",
              "  \\ xxunk synsets } & xxunk & 90.7 & 87.5 & xxunk & xxunk \\ \\ \n",
              "  \\ xxunk roles } & 88.4 & 88.5 & xxunk & xxunk & xxunk \\ \\ \n",
              "  \\ midrule \n",
              "  \\ textbf { \\ # of perfect xxunk } & 214 & 210 & 160 & 95 & 104 \\ \\ \n",
              "  \\ textbf { \\ # highest out of 5 } & 383 & xxunk & 261 & 171 & xxunk \\ \\ \n",
              "  \\ textbf { \\ # winner out of 5 } & 100 & 77 & 26 & 18 & 18 \\ \\ \n",
              "  \\ textbf { \\ # of ill - formed xxunk } & 1 & 0 & 1 & 37 & 5 \\ \\ \n",
              "  \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  % } \n",
              "  \\ label{tab : xxunk } \n",
              "  \\ end{table } \n",
              " \n",
              " \n",
              " \n",
              "  % xxrep 27 xxunk \n",
              "  \\ section{analysis } \n",
              " \n",
              "  xxmaj longer sentences are probably harder to parse , but which systems behave well on longer sentences ? \n",
              "  \\ autoref{fig : xxunk } shows the performance of the systems plotted over sentence length . xxmaj as expected , all systems show a clear drop in performance for longer sentences . xxmaj the work of \\ xxunk { } is based on the xxmaj transformer model \\ citep{vaswani2017attention } , which claims that performance should not degrade for longer sentences . xxmaj however , for xxup xxunk parsing this does not seem to be the case , as \\ xxunk { } shows a similar decrease in performance as the neural models of \\ xxunk { } and \\ xxunk { } . \n",
              " \n",
              "  \\ begin{figure}[!t ] \n",
              "  \\ centering \n",
              "  \\ includegraphics[width=0.75 \\ xxunk } \n",
              "  \\ caption { \\ label{fig : xxunk of the systems per sentence length ( punctuation are counted as tokens ) . } \n",
              "  \\ end{figure } \n",
              " \n",
              "  xxmaj how similar were the outputs of the participating systems to each other ? \n",
              "  \\ xxunk : comp } shows pairwise comparison of the outputs of the systems on the evaluation set . \n",
              "  xxmaj the only system that has a substantially higher similarity to one of the systems than their official f - score is \\ xxunk { } compared to \\ xxunk { } , which tells us the models make similar mistakes . xxmaj this makes sense given that they are both character - level sequence - to - sequence models trained on the same data . \n",
              "  xxmaj additionally , the output of \\ xxunk { } comes closest to the output of \\ xxunk { } when compared to other systems ' outputs . \n",
              "  xxmaj similarly , \\ xxunk { } is most similar to \\ xxunk { } than to any other systems . \n",
              " \n",
              " \n",
              "  \\ begin{table}[t ] \n",
              "  \\ centering \n",
              "  \\ caption { \\ label{tab : xxunk - scores of all systems compared to each other . } \n",
              "  \\ begin{tabular}{l| xxrep 5 c } \n",
              "  \\ toprule \n",
              "  & ~ ~~ \\ xxunk ~ & \\ xxunk & \\ tacl & ~~ \\ xxunk & \\ xxunk \\ \\ \\ midrule \n",
              "  \\ liu & \\ xxunk { } & 83.4 & xxunk & xxunk & xxunk \\ \\ \n",
              "  \\ xxunk & 83.4 & \\ xxunk { } & xxunk & 70.9 & 68.1 \\ \\ \n",
              "  \\ tacl & xxunk & xxunk & \\ xxunk { } & xxunk & 67.1 \\ \\ \n",
              "  \\ xxunk & xxunk & 70.9 & xxunk & \\ xxunk { } & 61.3 \\ \\ \n",
              "  \\ xxunk & xxunk & 68.1 & 67.1 & 61.3 & \\ xxunk { } \\ \\ \n",
              "  \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  \\ end{table } \n",
              " \n",
              "  xxmaj how complementary were the participating systems to each other ? xxmaj if we had an ensemble system , with an oracle component that selected the best xxup xxunk for each sentence out of the participants submissions , it would obtain an f - score of xxunk . xxmaj when only combining the submissions of \\ xxunk { } and \\ xxunk , it would already result in an f - score of 89.1 . xxmaj this suggests that the neural models in fact do learn different things , though there is still a significant portion that both methods could not learn . \n",
              " \n",
              " \n",
              " \n",
              "  xxmaj finally , are there phenomena that are especially hard for all participating systems ? xxmaj this is not an easy question to answer , and here we show just a first step to such an analysis . \n",
              "  \\ xxunk : worst } shows sentences for which systems , on average , performed badly . xxmaj some of them show non - standard use of xxmaj english , others are phenomena that are relatively rare , such as xxunk , multi - word expressions , and coordination . \n",
              " \n",
              " \n",
              "  \\ begin{table}[htb ] \n",
              "  \\ centering \n",
              "  \\ xxunk for which participating systems , on average , produced the worst xxunk } \n",
              "  \\ label{tab : worst } \n",
              "  \\ xxunk } \n",
              "  \\ toprule \n",
              "  \\ xxunk } & \\ xxunk . f } & \\ xxunk } \\ \\ \n",
              "  \\ midrule \n",
              "  xxmaj thou xxunk . & 21.4 & xxunk xxmaj english \\ \\ \n",
              "  i xxunk ken . & 21.8 & xxmaj xxunk \\ \\ \n",
              "  xxmaj my fault . & 24.2 & noun phrase \\ \\ \n",
              "  a cat has two ears . & xxunk & generic \\ \\ \n",
              "  i look down on xxunk and xxunk . & xxunk & coordination , xxup xxunk \\ \\ \n",
              "  xxmaj get me the number of this young xxunk . & 41.8 & imperative \\ \\ \n",
              "  xxmaj she attends school at night . & xxunk & temporal xxunk \\ \\ \n",
              "  xxmaj the union of xxmaj xxunk and xxmaj england took place in xxunk . & 46.4 & coordination , xxup xxunk \\ \\ \n",
              "  xxmaj something i had n't anticipated happened . & 47.0 & reduced relative clause \\ \\ \n",
              "  xxmaj charles i had his head cut off . & xxunk & ordinal , xxup xxunk \\ \\ \n",
              "  \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  \\ end{table } \n",
              " \n",
              "  % xxrep 27 xxunk \n",
              "  \\ section{conclusion } \n",
              " \n",
              "  xxmaj the first shared task on xxup xxunk parsing was successful . xxmaj it improved the state - of - the - art in xxup xxunk parsing , and the variety in methods used ( models based on recursive neural networks , transformer models , models based on transition - based parsing , graph decoders ) gives inspiration for future research . xxmaj in the future xxup xxunk parsing will be made more challenging by moving to longer sentences and texts ( where we expect simple seq2seq models to have a harder time ) , more complex phenomena ( xxunk , xxunk , multi - word expressions ) , and to languages other than xxmaj english . \n",
              " \n",
              "  \\ section*{acknowledgements } \n",
              " \n",
              "  xxmaj we would like to thank the xxup xxunk organizers , xxmaj xxunk xxmaj xxunk , xxmaj xxunk xxmaj xxunk , xxmaj simon xxmaj xxunk \n",
              "  and xxmaj xxunk xxmaj xxunk , for hosting the shared task in xxmaj xxunk . \n",
              "  xxmaj we also would like to thank all participants for their feedback on the task . \n",
              "  xxmaj this work was funded by the xxup nwo - xxup xxunk grant ` ` xxmaj lost in xxmaj translation -- xxmaj found in xxmaj meaning ' ' ( 288 - 89 - 003 ) . \n",
              " \n",
              " \n",
              "  \\ xxunk } \n",
              "  \\ xxunk } \n",
              " \n",
              " \n",
              "  \\ end{document } \n",
              " \n",
              "y: CategoryList\n",
              "peer_reviewed,peer_reviewed,peer_reviewed,peer_reviewed,peer_reviewed\n",
              "Path: /content/gdrive/My Drive/fastai-v3/SCIgan/clean;\n",
              "\n",
              "Valid: LabelList (79 items)\n",
              "x: TextList\n",
              "xxbos xxrep 8 % xxup icml 2020 xxup example xxup latex xxup submission xxup file xxrep 17 % \n",
              " \n",
              "  \\ documentclass{article } % xxmaj for latex2e \n",
              " \n",
              "  % xxmaj recommended , but optional , packages for figures and better typesetting : \n",
              "  \\ usepackage{microtype } \n",
              "  \\ usepackage{epsfig } \n",
              "  \\ usepackage{graphicx } \n",
              "  \\ usepackage{wrapfig } \n",
              "  % \\ usepackage{subfigure } \n",
              "  \\ usepackage{caption } \n",
              "  \\ usepackage{subcaption } \n",
              " \n",
              "  % table management \n",
              "  \\ usepackage{multirow } \n",
              "  \\ usepackage{rotating } \n",
              "  \\ usepackage{booktabs } \n",
              " \n",
              "  % hyperref makes hyperlinks in the resulting xxup pdf . \n",
              "  % xxmaj if your build breaks ( sometimes temporarily if a hyperlink spans a page ) \n",
              "  % please comment out the following usepackage line and replace \n",
              "  % \\ usepackage{icml2020 } with \\ usepackage[nohyperref]{icml2020 } above . \n",
              "  \\ usepackage{hyperref } \n",
              " \n",
              "  % xxmaj attempt to make hyperref and algorithmic work together better : \n",
              " \n",
              "  ewcommand { \\ thehalgorithm } { \\ arabic{algorithm } } \n",
              " \n",
              " \n",
              "  ewcommand { \\ xxunk ] { \\ multicolumn { # 1 } { # 2 } { \\ rlap { \\ xxunk { # 3 } { # xxunk } } } \n",
              " \n",
              "  % xxmaj use the following line for the initial blind version submitted for review : \n",
              "  % \\ usepackage{icml2020 } \n",
              " \n",
              "  \\ xxunk - xxunk } \n",
              "  \\ usepackage{xspace } \n",
              "  \\ makeatletter \n",
              "  \\ declarerobustcommand \\ onedot { \\ futurelet \\ @let@token \\ @onedot } \n",
              "  \\ def \\ @onedot { \\ ifx \\ @let@token . \\ else . \n",
              "  ull \\ fi \\ xspace } \n",
              "  \\ def \\ eg { \\ emph{e.g } \\ onedot } \\ def \\ xxmaj eg { \\ emph{e.g } \\ onedot } \n",
              "  \\ def \\ ie { \\ emph{i.e } \\ onedot } \\ def \\ xxmaj ie { \\ emph{i.e } \\ onedot } \n",
              "  \\ def \\ xxunk \\ onedot } \\ def \\ xxmaj st { \\ xxunk } \\ onedot } \n",
              "  \\ def \\ cf { \\ emph{c.f } \\ onedot } \\ def \\ xxmaj cf { \\ emph{c.f } \\ onedot } \n",
              "  \\ def \\ etc { \\ xxunk } \\ onedot } \\ def \\ vs { \\ emph{vs } \\ onedot } \n",
              "  \\ def \\ wrt{w.r.t \\ onedot } \\ def \\ xxunk \\ onedot } \n",
              "  \\ def \\ etal { \\ emph{et al } \\ onedot } \n",
              "  \\ makeatother \n",
              " \n",
              " \n",
              "  % xxmaj if accepted , instead use the following line for the camera - ready submission : \n",
              "  \\ usepackage[accepted]{icml2020 } \n",
              " \n",
              "  % xxmaj the \\ icmltitle you define below is probably too long as a header . \n",
              "  % xxmaj therefore , a short form for the running title is supplied here : \n",
              "  \\ xxunk xxmaj emergent xxmaj semantics in xxmaj predictive xxmaj agents via xxmaj question xxmaj answering } \n",
              " \n",
              "  \\ begin{document } \n",
              " \n",
              "  \\ twocolumn [ \n",
              "  \\ xxunk xxmaj emergent xxmaj semantics in xxmaj predictive xxmaj agents via xxmaj question xxmaj answering } \n",
              " \n",
              "  % xxmaj it is xxup okay to include author information , even for blind \n",
              "  % submissions : the style file will automatically remove it for you \n",
              "  % unless you 've provided the [ accepted ] option to the icml2020 \n",
              "  % package . \n",
              " \n",
              "  % xxmaj list of affiliations : xxmaj the first argument should be a ( short ) \n",
              "  % identifier you will use later to specify author affiliations \n",
              "  % xxmaj academic affiliations should list xxmaj department , xxmaj university , xxmaj city , xxmaj region , xxmaj country \n",
              "  % xxmaj industry affiliations should list xxmaj company , xxmaj city , xxmaj region , xxmaj country \n",
              " \n",
              "  % xxmaj you can specify symbols , otherwise they are numbered in order . \n",
              "  % xxmaj ideally , you should not use this facility . xxmaj affiliations will be numbered \n",
              "  % in order of appearance and this is the preferred way . \n",
              "  \\ icmlsetsymbol{equal } { * } \n",
              " \n",
              "  \\ begin{icmlauthorlist } \n",
              "  \\ xxunk xxmaj xxunk } \n",
              "  \\ xxunk xxmaj xxunk } \n",
              "  \\ xxunk xxmaj xxunk } \n",
              "  \\ xxunk xxmaj xxunk } \n",
              "  \\ xxunk xxmaj xxunk } \n",
              "  \\ xxunk xxmaj xxunk } \n",
              "  \\ xxunk xxmaj xxunk } \n",
              "  \\ xxunk xxmaj xxunk } \n",
              "  \\ xxunk xxmaj xxunk } \n",
              "  \\ xxunk xxmaj xxunk } \n",
              "  \\ xxunk xxmaj xxunk } \n",
              "  \\ end{icmlauthorlist } \n",
              " \n",
              "  \\ xxunk xxmaj institute of xxmaj technology } \n",
              "  \\ xxunk } \n",
              " \n",
              "  \\ xxunk } \n",
              " \n",
              " \n",
              "  % xxmaj you may provide any keywords that you \n",
              "  % find helpful for describing your paper ; these are used to populate \n",
              "  % the \" keywords \" metadata in the xxup pdf but will not be shown in the document \n",
              "  \\ xxunk xxmaj learning , xxup icml } \n",
              " \n",
              "  \\ vskip 0.3 in \n",
              "  ] \n",
              " \n",
              " \n",
              "  % this must go after the closing bracket ] following \\ twocolumn [ ... \n",
              " \n",
              "  % xxmaj this command actually creates the footnote in the first column \n",
              "  % listing the affiliations and the copyright notice . \n",
              "  % xxmaj the command takes one argument , which is text to display at the start of the footnote . \n",
              "  % xxmaj the \\ icmlequalcontribution command is standard text for equal contribution . \n",
              "  % xxmaj remove it ( just { } ) if you do not need this facility . \n",
              " \n",
              "  \\ printaffiliationsandnotice { \\ icmlequalcontribution } % otherwise use the standard text . \n",
              " \n",
              "  \\ begin{abstract } \n",
              "  xxmaj recent work has shown how predictive modeling can endow \n",
              "  agents with rich knowledge of their surroundings , improving \n",
              "  their ability to act in complex environments . xxmaj we propose \n",
              "  question - answering as a general paradigm to decode and \n",
              "  understand the representations that such agents develop , applying \n",
              "  our method to two recent approaches to predictive modeling -- \n",
              "  action - conditional xxup xxunk \\ xxunk } and xxunk \\ xxunk } . \n",
              "  xxmaj after training agents with these predictive objectives in a \n",
              "  visually - rich , $ xxup xxunk environment with an xxunk of objects , colors , shapes , \n",
              "  and spatial configurations , we probe their internal state representations \n",
              "  with synthetic ( xxmaj english ) questions , without backpropagating gradients \n",
              "  from the question - answering decoder into the agent . xxmaj the performance of \n",
              "  different agents when probed this way reveals that they learn to \n",
              "  encode factual , and seemingly compositional , information about \n",
              "  objects , properties and spatial relations from their physical environment . \n",
              "  xxmaj our approach is intuitive , \\ ie ~ humans can easily interpret responses of the model \n",
              "  as opposed to inspecting continuous vectors , and \n",
              "  model - agnostic , \\ ie applicable to any modeling approach . \n",
              "  xxmaj by revealing the implicit knowledge of objects , quantities , properties and relations \n",
              "  acquired by agents as they learn , \\ xxunk - conditional agent probing } can \n",
              "  stimulate the design and development of stronger \n",
              "  predictive learning objectives . \n",
              "  \\ end{abstract } \n",
              " \n",
              "  \\ input{sections / intro } \n",
              "  \\ input{sections / related } \n",
              "  \\ input{sections / data } \n",
              "  \\ input{sections / approach } \n",
              "  \\ input{sections / results } \n",
              "  \\ input{sections / discussion } \n",
              " \n",
              "  % xxmaj acknowledgements should only appear in the accepted version . \n",
              "  % \\ section*{acknowledgements } \n",
              "  % \\ textbf{do not } include acknowledgements in the initial version of \n",
              "  % the paper submitted for blind review . \n",
              " \n",
              "  \\ bibliographystyle{icml2020 } \n",
              "  \\ bibliography{main } \n",
              " \n",
              "  \\ clearpage \n",
              " \n",
              "  \\ appendix \n",
              "  \\ input{sections / appendix } \n",
              " \n",
              "  \\ end{document } \n",
              " ,xxbos \\ documentclass{article } \n",
              " \n",
              "  % if you need to pass options to natbib , use , e.g. : \n",
              "  % \\ passoptionstopackage{numbers , compress}{natbib } \n",
              "  % before loading neurips_2020 \n",
              " \n",
              "  % ready for submission \n",
              "  % \\ usepackage{neurips_2020 } \n",
              " \n",
              "  % to compile a preprint version , e.g. , for submission to arxiv , add add the \n",
              "  % [ preprint ] option : \n",
              "  \\ usepackage[preprint]{neurips_2020 } \n",
              " \n",
              "  % to compile a camera - ready version , add the [ final ] option , e.g. : \n",
              "  % \\ usepackage[final]{neurips_2020 } \n",
              " \n",
              "  % to avoid loading the natbib package , add option nonatbib : \n",
              "  % \\ usepackage[nonatbib]{neurips_2020 } \n",
              " \n",
              "  \\ usepackage[utf8]{inputenc } % allow utf-8 input \n",
              "  \\ usepackage[t1]{fontenc } % use 8-bit xxup t1 fonts \n",
              "  \\ usepackage{hyperref } % hyperlinks \n",
              "  \\ usepackage{url } % simple xxup url typesetting \n",
              "  \\ usepackage{booktabs } % professional - quality tables \n",
              "  \\ usepackage{amsfonts } % blackboard math symbols \n",
              "  \\ usepackage{nicefrac } % compact symbols for 1 / 2 , etc . \n",
              "  \\ usepackage{microtype } % microtypography \n",
              "  \\ usepackage{amsmath } \n",
              "  \\ usepackage{amssymb } \n",
              "  \\ usepackage{graphicx } \n",
              "  % \\ graphicspath{{figures / } } \n",
              " \n",
              "  \\ declaremathoperator { \\ xxup ex } { \\ xxunk expected value \n",
              "  \\ declaremathoperator * { \\ argmax}{arg \\ , max } \n",
              "  \\ declaremathoperator * { \\ argmin}{arg \\ , min } \n",
              " \n",
              "  ewcommand { \\ pluseq } { \\ mathrel{+}= } \n",
              " \n",
              "  % \\ xxunk of observation costs with xxmaj active xxmaj measure xxmaj reinforcement xxmaj learning } \n",
              "  \\ title{active xxmaj measure xxmaj reinforcement xxmaj learning for xxmaj observation xxmaj cost xxmaj minimization } \n",
              "  % \\ title{active xxmaj measure xxmaj reinforcement xxmaj learning \\ \\ \n",
              "  % \\ large a framework for minimizing measurement costs in reinforcement learning } \n",
              "  % \\ large a framework for observation costs minimization } \n",
              " \n",
              "  % xxmaj the \\ author macro works with any number of authors . xxmaj there are two commands \n",
              "  % used to separate the names and addresses of multiple authors : \\ xxmaj and and \\ xxup and . \n",
              "  % \n",
              "  % xxmaj using \\ xxmaj and between authors leaves it to latex to determine where to break the \n",
              "  % lines . xxmaj using \\ xxup and forces a line break at that point . xxmaj so , if latex puts 3 of 4 \n",
              "  % authors names on the first line , and the last on the second line , try using \n",
              "  % \\ xxup and instead of \\ xxmaj and before the third author name . \n",
              " \n",
              "  \\ author{% \n",
              "  xxmaj xxunk xxmaj xxunk \\ \\ \n",
              "  xxmaj digital xxmaj technologies \\ \\ \n",
              "  xxmaj national xxmaj research xxmaj council of xxmaj canada \\ \\ \n",
              "  xxmaj ottawa , xxmaj canada \\ \\ \n",
              "  \\ xxunk } \\ \\ \n",
              "  \\ xxmaj and \n",
              "  xxmaj xxunk xxmaj xxunk \\ \\ \n",
              "  xxmaj department of \n",
              "  xxmaj university of xxmaj victoria \\ \\ \n",
              "  xxmaj victoria , xxmaj canada \\ \\ \n",
              "  \\ xxunk } \\ \\ \n",
              "  \\ xxup and \n",
              "  xxmaj mark xxmaj xxunk \\ \\ \n",
              "  xxmaj faculty of xxmaj engineering \\ \\ \n",
              "  xxmaj university of xxmaj waterloo \\ \\ \n",
              "  xxmaj waterloo , xxmaj canada \\ \\ \n",
              "  \\ xxunk } \\ \\ \n",
              "  \\ xxmaj and \n",
              "  xxmaj xxunk xxmaj xxunk \\ \\ \n",
              "  xxmaj security and xxmaj disruptive xxmaj technologies \\ \\ \n",
              "  xxmaj national xxmaj research xxmaj council of xxmaj canada \\ \\ \n",
              "  xxmaj ottawa , xxmaj canada \n",
              "  xxmaj vector xxmaj institute for xxmaj artificial xxmaj intelligence \\ \\ \n",
              "  xxmaj toronto , xxmaj canada \\ \\ \n",
              "  \\ xxunk } \\ \\ \n",
              "  } \n",
              " \n",
              " \n",
              "  % \\ xxunk xxmaj xxunk et al . } \n",
              " \n",
              "  % xxmaj first names are abbreviated in the running head . \n",
              "  % xxmaj if there are more than two authors , ' et al . ' is used . \n",
              "  % \n",
              " \n",
              "  \\ begin{document } \n",
              " \n",
              "  \\ maketitle \n",
              " \n",
              "  \\ begin{abstract } \n",
              " \n",
              "  xxmaj standard reinforcement learning ( xxup rl ) algorithms assume that the observation of the next state comes instantaneously and at no cost . xxmaj in a wide variety of sequential decision making tasks ranging from medical treatment to scientific discovery , however , multiple classes of state observations are possible , each of which has an associated cost . xxmaj we propose the active measure xxup rl framework ( xxmaj amrl ) as an initial solution to this problem where the agent learns to maximize the costed return , which we define as the discounted sum of rewards minus the sum of observation costs . xxmaj our empirical evaluation demonstrates that xxmaj amrl - q agents are able to learn a policy and state estimator in parallel during online training . xxmaj during training the agent naturally shifts from its reliance on costly measurements of the environment to its state estimator in order to increase its reward . xxmaj it does this without harm to the learned policy . xxmaj our results show that the xxmaj amrl - q agent learns at a rate similar to standard q - learning and xxmaj dyna - xxup q. xxmaj critically , by utilizing an active strategy , xxmaj amrl - q achieves a higher costed return . \n",
              "  \\ end{abstract } \n",
              " \n",
              "  \\ section{introduction } \n",
              " \n",
              "  % xxup suggest : xxmaj do we need an intro section here \n",
              " \n",
              "  xxmaj when seeing a patient concerned about a potentially xxunk skin xxunk , a doctor must decide which diagnostic assessments are required . xxmaj some measurements , such as touch and visual inspection , can easily be conducted during the initial xxunk , whilst others require sophisticated equipment , drawn - out lab analyses , and have higher costs associated with them . xxmaj the doctor must actively decide whether the higher cost assessment will provide information necessary in order to accurately and efficiently select the next treatment action . \n",
              " \n",
              "  xxmaj the above scenario describes a xxmaj markov xxmaj decision xxmaj process ( xxup mdp ) with observation classes and costs . xxmaj environments of this nature include the following properties : \n",
              "  \\ begin{itemize } \n",
              "  \\ item xxmaj one or more classes of observations ( measurements ) of the next state are possible ; \n",
              "  \\ item xxmaj the measurements have explicit associated costs ; and , \n",
              "  \\ item xxmaj the value of the measurement depends on time and space . \n",
              "  \\ end{itemize } \n",
              " \n",
              "  xxmaj indeed , a wide variety of sequential decision making tasks , such as materials design , public health planning during a pandemic and operational planning ( business decision making ) involve the choice of actions and classes of observations with associated costs . \n",
              " \n",
              "  xxmaj the xxup mdp formalism and the environments on which reinforcement learning ( xxup rl ) algorithms are developed and tested , however , are not designed to explore such settings \\ cite{brockman2016openai } . xxmaj in the canonical framework , observations of the state of the environment are produced automatically , instantaneously and have no explicit associated costs . xxmaj generally , agents are agnostic to the state observations provided by the environment in the sense that they learn from what they receive . xxmaj to the extent that the agent might try to improve the quality of observations , it is through deep feature representations \\ cite{mnih2015human } , maintaining a belief state for partially observable mdps \\ cite{kaelbling1998planning } , or taking actions to change the state of the environment in order to gain a better understanding of it \\ xxunk } . xxmaj thus prior work has considered observations , yet has not dealt with the selection of observation classes , nor minimizing observation costs . \n",
              " \n",
              "  xxmaj here , we frame mdps with observation classes and costs as an active learning problem . xxmaj active learning is typically applied to supervised machine learning with the aim of reducing the cost of labelling training data \\ xxunk } . xxmaj however , active learning has recently been applied to xxup rl in the context of determining reward from external experts \\ xxunk , xxunk , xxunk } . xxmaj conversely , we postulate that in some domains observations of the state of the environment , like supervised labels , are expensive to obtain . xxmaj in the context of this work , the active component is applied to learning which measurements to make in a given state at a particular time , or deciding not to make a measurement at all - thereby xxunk the additional information and cost associated with it . xxmaj the aim is to discounted sum of rewards minus observation costs , which we denote as the \\ xxunk return } . \n",
              " \n",
              "  xxmaj we propose the xxmaj active xxmaj measure xxmaj reinforcement xxmaj learning ( xxmaj amrl ) framework in which the agent learns a policy and a state estimator in parallel via online experience . xxmaj the agent chooses actions pairs that change the environment and dictate whether the next state is measured directly or estimated . xxmaj as the state estimator is refined over time , the agent smoothly shifts to increasingly rely on it thereby lowering its observations cost . xxmaj this enables the xxmaj amrl agents to achieve a higher costed return . \n",
              " \n",
              "  xxmaj we demonstrate an implementation of xxmaj amrl using q - learning and a statistical state estimator ( xxmaj amrl - q ) . xxmaj we compare xxmaj amrl - q to q - learning and xxmaj dyna - q on four benchmark learning environments , including a new chemistry motivated environment ; specifically , the junior scientist environment . xxmaj the results show that xxmaj amrl - q achieves a higher sum of rewards minus observation cost than q - learning and xxmaj dyna - q , whilst learning at an equivalent rate to q - learning and xxmaj dyna - xxup q. \n",
              " \n",
              "  % xxmaj amrl represents a new paradigm not described by xxup pomdp or model based xxup rl . < --- xxmaj do we need a sentence like this in the xxunk \n",
              " \n",
              "  \\ xxunk } \n",
              " \n",
              "  xxmaj the main contributions of this work are : \n",
              "  \\ begin{itemize } \n",
              "  \\ item xxmaj formalization of mdps with observation classes and costs \n",
              "  \\ item xxmaj definition of the xxmaj active xxmaj measure xxup rl framework ( xxmaj amrl ) \n",
              "  \\ item xxmaj initial implementation of a q - learning approach , the xxmaj amrl - q algorithm \n",
              "  \\ item xxmaj analysis of xxmaj amrl - q on benchmark xxup rl environments \n",
              "  \\ end{itemize } \n",
              " \n",
              "  \\ section{related xxmaj work } \n",
              " \n",
              "  xxmaj previous work on active reinforcement learning has focused on ameliorating the problem of defining a complete reward function over the state - action space \\ xxunk , xxunk , xxunk } . xxmaj in addition to selecting an action at each time step , the agents in these proposals actively decide to request a human expert to provide the reward for the state - action pair . xxmaj to minimize reliance on human experts , there is a cost assigned to requesting a human - specified reward . xxmaj the agent aims to minimize this cost whilst maximizing the discounted sum of rewards . xxmaj similarly , xxmaj amrl maximizes the discounted sum of rewards minus the sum of observations cost . xxmaj however , the xxmaj amrl agent differs in the sense that state observations are the bottleneck in the learning process rather than the rewards . xxmaj moreover , the xxmaj amrl agent may have multiple different measurements of the state of the environment available to it , each of which has a distinct cost . \n",
              " \n",
              "  xxmaj active perception relates to our work in that the agent takes actions to increase the information available \\ xxunk } . xxmaj the key distinction , however , is that in active adaptive perception applied to xxup rl , the agents employ self - modification and self - evaluation to improve its perception \\ xxunk } . xxmaj alternatively , the xxmaj amrl agent aims to judiciously select observation classes in order to have the necessary and sufficient amount of information to choose the next action in order to maximize costed return . \n",
              " \n",
              "  xxmaj recently , the authors in \\ xxunk , xxunk } proposed the extension of the concept of multi - view learning from supervised domains reinforcement learning . xxmaj they formulate this as an agent having multiple views of the state - space available to it . xxmaj this is the case , for example , for agents controlling autonomous vehicles equipped with multiple sensors . xxmaj this previous work , however , does not contain the concept of observation costs , which are fundamental in applications of xxmaj amrl . \n",
              "  xxmaj approximate dynamic programming ( xxup adp ) aims to ameliorate the ` ` curse - of - dimensionality ' ' in dynamic programming \\ xxunk } . xxmaj it is connected to our work in the sense that it introduces a new component , the post - decision state , to the interaction with the environment . xxmaj alternatively , our work , which is not focused on the curse - of - dimensionality , formulates an action pair that determines the process to be applied in the environment and the class observation to be made . \n",
              " \n",
              "  xxmaj the learning of the state transition dynamics of the xxmaj amrl framework is consistent with the techniques employed in model - based xxup rl \\ xxunk , xxunk , xxunk } . xxmaj the goal of model - based xxup rl , however , is to reduce the number of real - world training steps needed to obtain an optimal policy . xxmaj this does not solve our problem of selecting the observation class , nor minimizing associated observations . \n",
              " \n",
              "  % xxup suggest : xxmaj somewhere , we need to say xxup model based xxup rl wants less real world episodes , xxunk of whether some of those xxunk are \" cheap \" in terms of observation costs . xxmaj amrl only wants less observations in the real world . xxmaj that means it is xxup ok to do lots of real world runs , but you ca n't burn through your observation budget on them . xxmaj this is a more realistic setup for lots of problems . xxmaj e.g. talking to a patient is n't that expensive , but ordering and xxup mri , xxunk , etc etc is . xxup xxunk \n",
              " \n",
              "  % but the key point is that we are solving an xxup xxunk with observation costs where the agent can choose to operate in pseudo xxup pomdp mode in the interest of increasing its costed return \n",
              " \n",
              "  % xxup pomdp , the agent is always in a state of uncertainty . xxmaj the agent is keeping a history in order to try and narrow that uncertainty . \n",
              " \n",
              "  xxmaj learning algorithms for pomdps utilize a state estimator to xxunk the agent 's recent experience in order to reduce uncertainty in partially observable environments . xxmaj at each time step , the next action $ a_t$ is selected based on the the agent 's belief state $ b_t$ as determined by its state estimator , rather than the observation emitted from the environment $ o_t$ \\ cite{kaelbling1998planning } . xxmaj alternatively , in xxmaj amrl the agent is learning an optimal policy under a xxup mdp with observation costs . xxmaj the agent chooses between paying the cost to measure the true state of the environment $ s_t$ or estimating it $ \\ xxunk xxmaj thus , in xxmaj amrl the state estimator is a mechanism to increase the costed return , not manage partial observability . \n",
              " \n",
              "  % xxmaj critically , while uncertainty in pomdps is a consequence of the external environment , uncertainty in xxmaj amrl is a function of agent 's choice to xxunk measuring the state of the environment to lower its observation costs . a xxup pomdp agent can only indirectly affect uncertainty by choosing actions that change the environment thereby lowering its uncertainty . xxmaj alternatively , an xxmaj amrl agent can always opt to measure the state of the environment to removing uncertain at a cost . \n",
              " \n",
              " \n",
              "  \\ section{preliminaries } \n",
              " \n",
              "  xxmaj we define active measure reinforcement learning as a tuple : $ ( s , a , p , xxup s^ \\ prime , r , c , \\ gamma)$. xxmaj the components $ ( s , a , p , xxup s^ \\ prime , r , \\ gamma)$ make up a standard xxup mdp where $ xxup s$ is the state - space , $ xxup a$ is the action - space , $ xxmaj xxunk \\ prime | s , a)$ is the state transition probabilities , $ xxmaj r(s , a)$ is the reward function , and $ \\ gamma \\ in [ 0,1]$ is a discount factor . $ xxup p$ and $ xxup r$ are not known by the agent . $ xxmaj xxunk is the cost charged to the agent each time it decides to measure the state of the environment . xxmaj thus , for a state $ s$ , the environment returns the cost as follows : \n",
              "  \\ begin{equation } \n",
              "  xxmaj xxunk \n",
              "  \\ begin{cases } \n",
              "  c>0 , & \\ text{if } m = \\ xxunk the state } \\ \\ \n",
              "  0 , & \\ text{otherwise } . \n",
              "  \\ end{cases } \n",
              "  \\ end{equation } \n",
              " \n",
              "  xxmaj applications may have multiple observation classes $ \\ mathcal{m } = \\ { 0 , 1,2 , ... \\ } $ , such as different sensors that serve different purposes . xxmaj in this case , each measurement class $ m \\ in \\ mathcal{m}$ may have a different associated cost . xxmaj selecting $ m$ constitutes the active learning choice on the part of the agent . xxmaj the values of $ m>0 $ indicate a specific observation class ( such as a specific sensor ) to be used , whereas $ m=0 $ specifies that no measurement of the environment is to made \\ footnote{when $ m=0 $ , the agent uses its state estimator in place of a measurement of the environment . } . \n",
              " \n",
              "  % xxmaj as in \\ xxunk } , at each time step $ t$ the agent selects an action pair . xxmaj in xxmaj amrl , the action pair $ ( a_t , m_t)$ consists of an atomic process $ a_t \\ in xxup a$ ( \\ textit{e.g . } , move left ) and an observation class $ m_t \\ in \\ mathcal{m}$. \n",
              " \n",
              "  % xxmaj the value of $ m_t$ constitutes the active learning choice on the part of the agent . xxmaj choosing $ m_t>0 $ indicates which observation class ( such as a specific sensor ) of the environment should be used , whereas $ m_t=0 $ specifies that no measurement of the environment is to made at time $ t$ \\ footnote{when $ m_t=0 $ , the agent uses its state estimator in place of the measurement of the environment . } . \n",
              "  % xxmaj in the context of active learning , $ m_t>0 $ is analogous to using an oracle . xxmaj the oracle , however , need not be a human , but rather a sensor in the environment . xxmaj for $ m_t>0 $ , the xxmaj amrl agent utilizes its learned state estimator $ \\ xxunk xxmaj the state estimator is learned in parallel with the agent 's policy . \n",
              " \n",
              "  xxmaj as in \\ xxunk } , at each time step $ t$ the agent selects an action pair . xxmaj in xxmaj amrl , the action pair $ ( a_t , m_t)$ consists of an atomic process $ a_t \\ in xxup a$ ( \\ textit{e.g . } , move left ) and an observation class $ m_t \\ in \\ mathcal{m}$. xxmaj thus , if $ m_t>0 $ , the process $ a_t$ is applied to the environment , and the environment returns the reward $ xxunk and the next state observation $ s_{t+1}$ measured via $ m_t$ ( $ r_{t+1 } , s_{t+1 } = xxmaj xxunk , m_t)$ ) . xxmaj here , $ s_{t+1}$ results from the underlying , unknown transition dynamics $ xxmaj p(s_t , a_t)$. xxmaj for $ m_t=0 $ , the process $ a_t$ is applied to the environment , but the environment only returns the reward $ r_{t+1 } = xxmaj xxunk , xxunk xxmaj in this case , the xxmaj amrl agent estimates the next state $ \\ xxunk } \\ sim \\ xxunk , a_t)$ , and selects its next action pair $ ( a_{t+1 } , xxunk based on this estimate , $ \\ xxunk xxmaj this leads to an alternative agent - environment interaction sequence of the form : \n",
              "  \\ begin{equation } \n",
              "  xxunk ) , \\ xxunk ) , \\ xxunk ... , \n",
              "  \\ end{equation } \n",
              "  where the agent starts each episode with a true measurement of the environment 's current state , $ s_0 $ , and proceeds to sequentially select action pairs that determine the process $ a_t$ to be applied and whether to measure the next state $ s_{t+1}$ or estimate $ \\ xxunk instead . \n",
              " \n",
              "  xxmaj importantly , the reward emitted from the environment is always a function of the process $ a_{t}$ and the true state of the environment $ s_t$ xxunk of whether the agent selected $ a_t$ based on $ s_t$ or an estimate $ \\ xxunk xxmaj for simplicity and generalization , at times we drop the hat notation on the state estimates . \n",
              " \n",
              "  xxmaj in this work , we focus on episodic environments with discrete states , $ s = \\ { 1, ... xxup xxunk \\ } $ , and action sets $ a = \\ { 1, ... xxup xxunk \\ } $ , and stationary state - transition dynamics . xxmaj in an xxup mdp with measurement costs , the objective is to select a sequence of action pairs $ ( a_t , m_t)$ that maximize the costed return , which is defined as the discounted sum of rewards minus the sum of measurement costs : \n",
              "  \\ begin{equation } \n",
              "  v(s ) = \\ xxup ex \\ bigg [ \\ sum^ { \\ xxunk } \\ gamma^t \\ xxunk , a_t ) - xxmaj xxunk ) \\ big ) ~|~ s = s_0 \\ bigg ] . \n",
              "  \\ end{equation } \n",
              " \n",
              "  xxmaj in xxmaj amrl , a policy , $ \\ pi$ maps states $ xxup s$ and actions pairs $ xxup ap$ to a probability $ \\ pi : s \\ times xxup ap \\ rightarrow [ 0,1]$ , such that $ \\ pi(s , xxunk is the probability of selecting action pair $ ap \\ in xxup ap$ in state $ s \\ in xxup s$. xxmaj the value function associated with policy $ \\ pi$ is : \n",
              "  \\ begin{equation } \n",
              "  v _ \\ pi(s ) = \\ xxup ex \\ bigg [ \\ sum^ { \\ xxunk } \\ gamma^t \\ xxunk , a_t ) - xxmaj xxunk , a_t ) \\ big ) ~|~ s = s_0 \\ bigg ] , \n",
              "  \\ end{equation } \n",
              "  where the actions are selected according to $ \\ pi$. xxmaj since actions pairs can be though of as a higher - level class of action , the standard xxup rl theorems hold . xxmaj thus , there is at least one policy $ \\ pi^*$ such that $ xxup v^ { \\ pi}(s ) \\ ge xxup v^ { \\ xxunk , where $ \\ pi^*$ is an optimal policy and $ xxup v^*$ is the corresponding value function . \n",
              " \n",
              "  \\ xxunk - q } \\ label{sec : xxmaj xxunk } \n",
              " \n",
              "  xxmaj we propose an initial implementation of the xxmaj amrl framework for a tabular learning environment . xxmaj our proposed solution utilizes q - learning for the value function and a statistical state transition model . xxmaj we focus on tabular problems here for clarity in the demonstration and analysis . xxmaj our future work will implement xxmaj amrl solutions for continuous state and action spaces . \n",
              " \n",
              "  \\ subsection{overview } \n",
              " \n",
              "  xxmaj as previously stated , xxmaj amrl - q framework learns a value function $ xxup q$ , and a state estimator $ \\ xxunk , a_t)$ in parallel . xxmaj learning $ \\ hat{p}$ and $ xxup q$ is essential to the active learning based solution which enables the agent to reduce its the total number of times it requests a true measurement . xxmaj the theory behind this can be demonstrated with the xxmaj markov chain in xxmaj figure \\ ref{fig : markovchain } . \n",
              " \n",
              "  \\ begin{figure * } \n",
              "  \\ centering \n",
              "  \\ xxunk } \n",
              "  \\ caption{this figure illustrates a five state xxmaj markov chain . } \n",
              "  \\ label{fig : markovchain } \n",
              "  \\ end{figure * } \n",
              " \n",
              "  xxmaj this xxmaj markov chain forms a two action ( left , right ) episodic xxup rl problem where the agent starts in stage zero , and receives a reward of one upon entering the absorbing state , state four . xxmaj for temporal difference ( xxup td ) learning methods , such as q - learning , applied to episodic problems such as this , the value of states and actions is refined over episodes of training from the state closest to the absorbing state back to the start state . xxmaj the backup algorithm for q - learning is : \n",
              "  \\ begin{equation } \n",
              "  xxmaj q(s_t , a_t ) \\ leftarrow xxmaj q(s_t , a_t ) + \\ alpha \\ xxunk } ~ \\ gamma \\ max_a xxmaj q(s_{t+1},a ) - xxmaj q(s_t , a_t ) \\ bigg ] , \n",
              "  \\ end{equation } \n",
              "  where $ xxmaj q(s_t , a_t)$ is the value of action $ a$ in state $ s$ at time $ t$ , $ \\ alpha$ is the learning rate and $ \\ gamma$ is the discount factor . xxmaj if we assume a $ xxmaj q$-table initialized to zeros , after one episode of training is complete , only $ xxmaj xxunk \\ xxunk will have a value greater than zero ; after the second episode is complete , states 2 and 3 will have values greater than zero , and so on . xxmaj in general , for an $ xxunk chain of this nature , the agent will require $ n-1 $ episodes of training to start to improve the $ xxmaj q$-values associated with the start state , state 0 . \n",
              " \n",
              "  xxmaj the number of times the agent visits each state per episode indicates how many true measurements of the environment it will make . xxmaj we can estimate this by calculating the fundamental matrix $ xxup n$ of the absorbing xxmaj markov chain $ xxup p$ shown in xxmaj figure \\ ref{fig : markovchain } . xxmaj the fundamental matrix is defined as $ xxup xxunk - xxup xxunk , where $ xxup i$ is the identify matrix and $ xxup q$ is the $ t \\ times t$ matrix representing the transient states in $ xxup p$. xxmaj based on this , the expected number of state visits before absorbing for an agent starting in state 0 and following a random policy is xxunk and 2 , respectively . xxmaj thus , in the first four episodes of training , the q - agent is expected to take 46 measurements of the environment . \n",
              " \n",
              "  xxmaj if we consider the state estimator $ \\ hat{p}$ learned by xxmaj amrl , according to the calculations above , in the first episode of training the agent is expected to have tried both actions in each state 4 , 3 , 2 and 1 times , respectively . xxmaj since for a deterministic $ xxup p$ , the agent must try each state - action pair once to have an accurate $ \\ hat{p}$ , xxmaj amrl can safely switch from actively measuring the next state , to estimating it with $ \\ hat{p}$ after the first episode of training . xxmaj moreover , because the agent tries actions in states closer to the start sooner and more frequently , it can switch to using $ \\ hat{p}$ in these states even before the first episode of training ends . xxmaj in this way , xxmaj amrl is able to improve measurement efficiency well beyond what can be achieved by standard xxup rl methods and model - based xxup rl . \n",
              " \n",
              "  \\ xxunk } \n",
              " \n",
              "  xxmaj the xxmaj amrl - q algorithm maintains $ xxup |a|$ , $ xxup |s| \\ xxunk count - based statistics table for state transitions models $ \\ xxunk xxmaj in this initial presentation , we limit the agent to selecting from one observation class . xxmaj therefore , the agent maintains an $ xxup |s| \\ xxunk \\ xxunk \\ cdot 2)$ dimensional $ xxmaj q$-table , where $ | \\ xxunk \\ times 2 $ is the number of action pairs . xxmaj an environment with 2 action has 4 action pairs , and thus , a four column $ xxmaj q$-table . \n",
              " \n",
              "  xxmaj the q - table is update in the standard way as : \n",
              "  \\ begin{equation } \n",
              "  xxmaj q(s_t , a_t ) \\ leftarrow xxmaj q(s_t , a_t ) + \\ alpha \\ xxunk } ) ~ \\ gamma \\ max_a xxmaj q(s_{t+1},a ) - xxmaj q(s_t , a_t ) \\ bigg ] \n",
              "  \\ end{equation } \n",
              "  xxmaj the agent employs an $ \\ epsilon$-greedy strategy to pick action pairs from the q - table . xxmaj if the action pair at time $ t$ includes $ m_t = 1 $ , then the agent chooses to pay the cost $ c$ of measuring the next state from the environment . xxmaj otherwise , the agent estimates the next state from its model as $ s_{t+1 } \\ sim \\ xxunk xxmaj when the agent chooses to measure the true state , it updates $ \\ xxunk , s_{t+1})$ for the corresponding action $ a = a_t$ \n",
              " \n",
              "  xxmaj much like a human learning a new task , the first few times an agent enters a state it must measure the result of taking an action . xxmaj we produce this behaviour by initializing q - values for action pairs involving state measurements $ m=1 $ with small positive value , and zero for q - values related to measurements $ m=0 $ ( implications of initialization are discussed below ) . \n",
              " \n",
              "  xxmaj over successive visits to a state $ s$ and applications of a process $ a$ and measurement $ m=1 $ , the return for $ s$ will be less than the maximum possible return because the measurement cost $ xxmaj xxunk is subtracted from the reward $ xxmaj r(s , a)$. xxmaj since moving without measuring does not incur an additional measurement cost , in time and as the model improves , moving and relying on the learned model produces an increased reward and the agent shifts to this strategy . \n",
              " \n",
              "  xxmaj the outline of the algorithm is : \n",
              "  \\ begin{itemize } \n",
              "  \\ item xxmaj initialize a biased q - table of size $ xxup |s| \\ times xxup |a| \\ cdot 2 $ \n",
              "  \\ item xxmaj initialize xxup |a| state - transition statistic table of size $ xxup |s| \\ times xxup |s|$ to zeros \n",
              "  \\ item get the first state $ s = s_0 $ from the environment \n",
              "  \\ item repeat until done \n",
              "  \\ begin{itemize } \n",
              "  \\ item xxmaj select action pair $ ( a , m)$ with $ \\ epsilon$ greedy policy from q table for state $ s$ \n",
              "  \\ item xxmaj apply action $ a$ to environment \n",
              "  \\ item xxmaj if measure $ m=1 $ : \n",
              "  \\ begin{itemize } \n",
              "  \\ item xxmaj measure next state $ s^ \\ prime$ in environment \n",
              "  \\ item xxmaj update state transition model for action $ a$ $ \\ xxunk , s^ \\ prime ] \\ pluseq 1 $ \n",
              "  \\ end{itemize } \n",
              "  \\ item xxmaj else : \n",
              "  \\ begin{itemize } \n",
              "  \\ item xxmaj sample next state $ s^ \\ prime \\ sim \\ xxunk \n",
              "  \\ end{itemize } \n",
              "  \\ item xxmaj get reward $ r$ from environment \n",
              "  \\ item xxmaj get cost $ c$ from the environment \n",
              "  \\ item xxmaj update q table for state $ s$ with tuple $ ( s , a , r - c , s^ \\ prime)$ \n",
              "  \\ item xxmaj set $ s \\ leftarrow s^ \\ prime$ \n",
              "  \\ end{itemize } \n",
              "  \\ end{itemize } \n",
              " \n",
              " \n",
              "  \\ section{experimental xxmaj setup } \n",
              " \n",
              "  xxmaj the following experiments are conducted on episodic , discrete state and action problems . xxmaj our analysis involves three standard xxup rl environments ( xxmaj chain , xxmaj frozen xxmaj lake $ 8 \\ times 8 $ and xxmaj taxi ) and one new environment ( xxmaj junior xxmaj scientist ) . xxmaj each of these environments has the feature that the agent must actively decide if and when to measure the state of the environment . xxmaj in the case of the openai xxmaj gym environments ( xxmaj frozen xxmaj lake and xxmaj taxi ) , we have implemented a wrapper class in xxmaj python that adds the xxmaj amrl functionality . \n",
              " \n",
              "  \\ subsection{rl xxmaj environments } \n",
              " \n",
              "  \\ textbf { \\ xxunk environment } } : a chain of 11 states , $ s \\ in \\ { 0, ... xxunk \\ } $ , where the agent starts at $ s_0 $ and the episodes ends when the agent enters $ xxunk xxmaj upon entering goal state $ xxunk , the agent receives a reward of $ xxunk xxmaj the agent receives a reward of $ xxunk $ at each time step . xxmaj the agent is charged a measure cost of $ xxunk $ for measuring the state of the environment . xxmaj measuring the state results in the environment returning the current state in chain . xxmaj the action space is $ xxup a= \\ { \\ text{move left , move right } \\ } $ . xxmaj we evaluate the performance with both deterministic state transitions and stochastic state transitions . xxmaj in the stochastic setup , the environment has a probability $ p$ of the actions being swapped at each time step . \n",
              " \n",
              "  \\ textbf { \\ xxunk xxmaj lake $ 8 \\ times 8 $ environment } } : xxmaj in this environment , the agent learns to navigate from a start location to a goal in a frozen lake grid with holes in the ice . xxmaj each episode ends when the agent reaches the goal or falls through a hole in the ice . xxmaj the agent receives a reward of $ r=1 $ at the goal , $ r=0 $ otherwise . xxmaj the agent pays a cost of $ c=0.01 $ for measuring the state of the environment . xxmaj measuring the state results in the environment returning the current position in the 2-dimensional frozen lake grid . xxmaj the action - space in the environment is $ xxup a= \\ { \\ text{move left , move right , move up , move down } \\ } $ . xxmaj in this implementation , the agent is prevented from moving off the grid . xxmaj we evaluate the agents with both the predefined deterministic and slippery settings in the openai gym . \n",
              " \n",
              "  \\ textbf { \\ xxunk environment } } : xxmaj the agent learns to navigate a city grid world to pick up and drop off passengers at the appropriate location \\ xxunk } . xxmaj the agent receives a reward $ xxunk $ for dropping off at the correct location , $ xxunk $ for illegal pickup or drop - off and $ xxunk $ at each time step . xxmaj the agent is charged a cost of $ c=0.01 $ for measuring the state of the environment . xxmaj measuring the state results in the environment returning the current position in the city grid . xxmaj the action - space includes $ xxup a= \\ { \\ text{move left , move right , move up , move down , pickup , drop - off } \\ } $ . \n",
              " \n",
              "  \\ textbf { \\ xxunk xxmaj scientist environment } } : xxmaj this environment emulates a student learning to manipulate an energy source to produce a desired state change in a target material . xxmaj specifically , the agent starts with a xxunk container of water composed of an initial $ h_0 $ percent ice , $ l_0 $ percent water and $ g_0 $ percent gas ( $ xxunk $ ) . xxmaj the agent learns to sequentially and incrementally adjust a heat source in order to transition the ratio of ice , liquid , gas from $ ( xxunk to a goal ratio $ ( h , l , g)$. xxmaj the episode ends when the agent declares that it has reached the goal and it is correctly in the goal state . xxmaj the action - space includes $ xxup a= \\ { \\ xxunk , increase , done } \\ } $ , where \\ xxunk } and \\ emph{increase } are fixed incremental adjustments in the energy source . xxmaj the agent receives a reward of $ r=1 $ when it reaches the goal and it correctly declares that it is done , and receives a reward of $ xxunk $ at each time step . xxmaj the agent is charged $ c=0.01 $ for measuring the state of the environment . xxmaj measuring the state results in the environment returning the cumulative energy which has been added or removed from the system . \n",
              " \n",
              "  \\ subsection{rl xxmaj algorithms } \n",
              " \n",
              "  xxmaj we compare the relative performance of xxmaj amrl - q to non - active methods : q - learning \\ xxunk } and xxmaj dyna - q \\ xxunk } . xxmaj since neither q - learning nor xxmaj dyna - q are active xxup rl methods , they require a measurement of the environment at each time step . xxmaj as a result , they are charged the measurement cost $ xxup c$ at each time step . xxmaj the relative performance of these methods is assessed in terms of the sum of reward minus observation costs , along with the mean number of steps and measurements per episode . xxmaj to the best of our knowledge , we are proposing the first solution to the xxmaj amrl problems . xxmaj as such , q - learning and xxmaj dyna - q are a reasonable baseline for comparison in this introductory work . \n",
              " \n",
              "  \\ subsection{methodology } \n",
              " \n",
              "  xxmaj for each xxup rl algorithm in our evaluation , we utilize a discount factor of $ \\ xxunk $ and $ \\ epsilon$-greedy exploration $ \\ xxunk xxmaj the $ xxmaj xxunk for both q - learning and xxmaj dyna - q are initialized to zeros . xxmaj the columns of the $ xxmaj q$-table in xxmaj amrl - q associated with estimate ( $ m=0 $ ) are initialized to zeros and those associated with measure ( $ m=1 $ ) were set to a small positive , typically $ 0.1 $ ( we also explore the impact of larger values ) . xxmaj the results presented are mean performance averaged over 20 random trials , enough to be statistically significant . xxmaj we employ 5 planning steps , a reasonable baseline , in xxmaj dyna - q after each real step . \n",
              " \n",
              "  \\ section{results } \n",
              " \n",
              "  xxmaj we initially focus on the performance of each agent in the deterministic environments . xxmaj we highlight the impact of stochasticity in the xxmaj discussion . \n",
              " \n",
              "  \\ xxunk } \n",
              "  \\ begin{figure * } \n",
              "  \\ centering \n",
              "  \\ xxunk } \n",
              "  \\ xxunk } \n",
              "  \\ caption{left : xxmaj mean steps to the goal by episode in the deterministic xxmaj chain environment . xxmaj right : xxmaj mean costed return in the deterministic xxmaj chain environment . } \n",
              "  \\ label{fig : detchainstepsandsum } \n",
              "  \\ end{figure * } \n",
              " \n",
              "  xxmaj the mean performance of each agent is shown in xxmaj figure \\ ref{fig : detchainstepsandsum } . xxmaj the left plot displays the mean number of steps to the goal for q - learning , xxmaj dyna - q , and xxmaj amrl - xxup q. xxmaj all three methods learn a policy that takes a similar number of steps to the goal . xxmaj naturally , xxmaj dyna - q learns faster ( red line versus green and blue ) . xxmaj it worth noting that xxmaj dyna styled planning could easily be incorporated into xxmaj amrl - q as an enhancement , however , this is beyond the scope of this study . \n",
              " \n",
              "  xxmaj whilst q - learning and xxmaj dyna - q require a measurement after each action , xxmaj amrl - q actively decides whether to measure or estimate the next state . xxmaj the purple line in xxmaj figure \\ ref{fig : detchainstepsandsum } show the mean number of measurements per episode made by xxmaj amrl - xxup q. xxmaj in the very early episodes , the number of measurements is similar to xxmaj dyna - q , however , it quickly drops well below the alternatives . \n",
              " \n",
              "  xxmaj the cost savings resulting from fewer measurements for xxmaj amrl - q can be seen in the higher costed return presented in the plot on the right . xxmaj as in the previous analysis , xxmaj amrl - q is initially similar to xxmaj dyna - xxup q. xxmaj this holds while xxmaj amrl - q learns about state transition dynamics . xxmaj because xxmaj amrl - q dynamically shifts its measurement behaviour in each state as it learns about the transition dynamics , over episodes of training it reduces its measurement costs to acquire a higher costed return ( blue line ) . \n",
              " \n",
              "  \\ begin{figure * } \n",
              "  \\ centering \n",
              "  \\ xxunk } \n",
              "  \\ xxunk } \n",
              "  \\ xxunk } \n",
              "  \\ caption{bar plots comparing the state visit and measurement distribution for q - learning and xxmaj amrl - q on the xxmaj chain environment after 1 , 20 and 40 ( left , centre , right ) episodes of training . } \n",
              "  \\ label{fig : xxunk } \n",
              "  \\ end{figure * } \n",
              " \n",
              "  xxmaj figure \\ ref{fig : xxunk } summarizes the total number of visits and measurements made in each state after 1 , 20 and 40 episodes of training for q - learning \\ footnote{the state visits and measurements are equivalent for q - learning . } and xxmaj amrl - xxup q. xxmaj the plot on the left shows that initially xxmaj amrl - q ( blue bar ) visits most states slightly more frequently than q - learning ( red bar ) . xxmaj importantly , however , the purple bars show that it measures each state less frequently than q - learning . xxmaj thus , the measurement costs are lower from the outset . xxmaj after 20 and 40 episodes of training ( centre and right plots ) , the state visit frequency of xxmaj amrl - q is consistent with q - learning . xxmaj in these later episodes of training , however , xxmaj amrl - q requires significantly fewer state measurements than q - learning . xxmaj this highlights the advantage that the xxmaj amrl framework has in its ability to shift from measuring the state of the environment to estimating it as more experience ( episodes of training ) is gathered . xxmaj this behaviour is shown in greater detail in xxmaj figure \\ ref{fig : detchainmeasureanalysis } . \n",
              " \n",
              "  \\ begin{figure * } \n",
              "  \\ centering \n",
              "  \\ xxunk } \n",
              "  \\ caption{two - dimensional histograms comparing of the number of state visits and measurements made by q - learning versus xxmaj amrl - q on the xxmaj chain environment . } \n",
              "  \\ label{fig : detchainmeasureanalysis } \n",
              "  \\ end{figure * } \n",
              " \n",
              "  xxmaj figure \\ ref{fig : detchainmeasureanalysis } contains four 2-dimensional histograms . xxmaj these depict the number of visits to each state ( plots 1 and 2 ) and the number of measurements in each state ( plots 3 and 4 ) \\ xxunk - learning measures the state on each visit , therefore , plots 1 and 3 are the same . } as a function of episodes of training . xxmaj the $ x$-axis specifies the state in the chain and the $ y$-axis indicates the number of episodes of training completed . xxmaj the darker black cells indicate more visits / measurements , whilst white indicates a moderate number and red depicts a low number . xxmaj as a result of the learning behaviour of q - learning that was discussed in xxmaj section \\ ref{sec : xxmaj xxunk } , the lower diagonal of the state visit and measurement plots for q - learning , and the state visit plot for xxmaj amrl - q have a light red to black shading , with the xxunk black appearing in the lower left corner . xxmaj the upper diagonal , where the shading is uniformly dark red , shows the time at which the agent has learned a policy that enables it to directly transition from this current state to the goal . xxmaj this occurs within just a few episodes of training for q - learning in state 10 ( first plot , lower right ) , whereas it takes approximately 50 episodes of training for state 0 ( first plot , upper left ) . xxmaj whilst the state visit distributions are very similar for q - learning and xxmaj amrl - q , their state measurement distributions have an outstanding difference in magnitude . xxmaj the max state measurement value for xxmaj amrl - q ( right most plot ) is 6 , in comparison to 16 for for q - xxmaj learning . xxmaj moreover , in shading in the xxmaj amrl - q measurement plot quick shift from light red to dark red . xxmaj in fewer than 30 episodes of training , the agent is able to replace all measurements of the environment with its own estimate . \n",
              " \n",
              "  \\ xxunk xxmaj lake $ 8 \\ times 8 $ } \n",
              "  \\ begin{figure * } \n",
              "  \\ centering \n",
              "  \\ xxunk } \n",
              "  \\ xxunk } \n",
              "  \\ caption{left : xxmaj average number of steps to the goal by episode in the deterministic xxmaj frozen xxmaj lake environment . xxmaj right : xxmaj average costed return in the deterministic xxmaj frozen xxmaj lake environment . } \n",
              "  \\ label{fig : xxunk } \n",
              "  \\ end{figure * } \n",
              " \n",
              "  xxmaj figure \\ ref{fig : xxunk } shows the mean number of steps to the goal for each algorithm on the deterministic frozen lake . xxmaj similar to the deterministic chain , xxmaj amrl - q learns at the same rate as q - learning . xxmaj it takes approximately the same number of steps per episode ( green versus blue line ) . xxmaj dyna - q learns faster than the alternatives , but converges to a similar mean number of steps as q - learning and xxmaj amrl - q ( red line ) . xxmaj amrl - q requires fewer measurements on average ( purple line ) . xxmaj the mean number of steps per episode at the end of training for each method is : random agent = xxunk , q - xxmaj learning = 13.99 , xxmaj dyna - q = 15.45 , xxmaj amrl - q xxmaj steps = 18.52 . xxmaj importantly however , xxmaj amrl - q only takes a mean of xxunk measurements per episode . \n",
              " \n",
              " \n",
              "  \\ xxunk } \n",
              "  \\ begin{figure * } \n",
              "  \\ centering \n",
              "  \\ xxunk } \n",
              "  \\ xxunk } \n",
              "  \\ caption{left : xxmaj mean number of steps to the goal by episode in the xxmaj taxi environment . xxmaj right : xxmaj mean of the costed return in the xxmaj taxi environment . } \n",
              "  \\ label{fig : xxunk } \n",
              "  \\ end{figure * } \n",
              " \n",
              "  xxmaj figure \\ ref{fig : xxunk } depicts the mean number of steps to the goal for each algorithm on the xxmaj taxi environment . xxmaj this is a more challenging environment because it requires the agent to learn an intermediate goal . xxmaj nonetheless , the relative performance of the considered algorithms is consistent with our previous results . xxmaj amrl - q learns at a similar rate to q - learning , and takes approximately the same number of steps ( green versus blue line ) . xxmaj dyna - q learns faster ( red line ) , but converges to a similar average number of steps as q - learning and xxmaj amrl - xxup q. xxmaj amrl - q requires fewer measurements on average ( purple line ) . xxmaj the mean number of steps per episode are as follows : random agent = xxunk , q - xxmaj learning = 14.83 , xxmaj dyna - q = 14.67 , xxmaj amrl - q xxmaj steps = xxunk . xxmaj amrl - q take an average of 12.13 measurements per episode . \n",
              " \n",
              "  \\ xxunk xxmaj scientist } \n",
              " \n",
              "  \\ begin{figure * } \n",
              "  \\ centering \n",
              "  \\ xxunk } \n",
              "  \\ xxunk } \n",
              "  \\ caption{left : xxmaj mean steps per episode in the xxmaj junior xxmaj scientist environment . xxmaj right : xxmaj mean of the costed returns in the xxmaj junior xxmaj scientist environment . } \n",
              "  \\ label{fig : xxunk } \n",
              "  \\ end{figure * } \n",
              " \n",
              "  xxmaj figure \\ ref{fig : xxunk } shows the mean of the costed return for each algorithm on the xxmaj junior xxmaj scientist environment . xxmaj once again , xxmaj dyna - q learns slightly faster than q - learning and xxmaj amrl - xxup q. xxmaj the plot on the left clearly shows xxmaj amrl - q shifting away from measuring the state after approximately 2,000 episodes of training ( purple line ) . xxmaj the fact that the mean steps ( blue line ) is stable during this shift indicates that the agent is not becoming ` lost ' in the state space due to bad estimates . \n",
              " \n",
              "  \\ section{discussion } \n",
              "  % \\ subsection{evolution of the q - table in xxmaj xxunk - q } \n",
              "  \\ begin{figure * } \n",
              "  \\ centering \n",
              "  \\ xxunk } \n",
              "  \\ caption{evolution of the values of the q - table for xxmaj amrl - q on the deterministic xxmaj chain environment . } \n",
              "  \\ label{fig : xxunk } \n",
              "  \\ end{figure * } \n",
              " \n",
              "  xxmaj figure \\ ref{fig : xxunk } shows the evolution of the values of the q - table for xxmaj amrl - q over episodes of training on the deterministic chain environment . xxmaj the $ x$-axis shows the four action pairs [ ( \\ emph{move left , measure } ) , ( \\ emph{move right , measure } ) , ( \\ emph{move left , estimate } ) , ( \\ emph{move right estimate } ) ] that the agent chooses from . xxmaj the $ y$-axis shows each state , where 0 is the start state and 10 is the goal state . xxmaj from left to right , the first plot is the initialized q - table . xxmaj it is followed by the q - values after xxunk of 29 episodes of training . xxmaj in earlier episodes of training , the action pair ( \\ emph{move right , measure } ) has the highest values . xxmaj the sequence of plots demonstrates that over episodes of training , the action pair ( \\ emph{move right , estimate } ) comes to have the highest value . xxmaj thus , the agent shifts over time away from its reliance of more costly measurements . \n",
              " \n",
              "  xxmaj the shift to estimating the next state occurs naturally within the q - learning backup algorithm and sufficient exploration . xxmaj there is a clear trade - off in this evolution . xxmaj if an agent in state $ s$ relies on its state estimator $ \\ hat{p}$ before it is sufficiently accurate , it will be xxunk about its current location . xxmaj as a result , it is likely to select the wrong action and take more time to reach the goal . xxmaj moreover , the agent 's q updates will be applied to the wrong state . xxmaj alternatively , if an agent in state $ s$ utilizes measurements $ m=1 $ longer than is necessary ( \\ textit{i.e . } , when $ \\ hat{p}$ is sufficiently accurate ) , it xxunk pays the measurement cost which lowers its reward . xxmaj in xxmaj amrl - q , proper exploration and the initialization of the q - table serve to balance this trade - off . xxmaj however , more sophisticated solution using model confidence are expected to produce even better performance . xxmaj we leave the study of such methods to future work . \n",
              " \n",
              "  % \\ xxunk of q - xxmaj table xxmaj initialization on xxmaj measurement xxmaj frequency } \n",
              "  \\ begin{figure * } \n",
              "  \\ centering \n",
              "  \\ xxunk } \n",
              "  \\ caption{this figure demonstrates how the initialization of the q - values for \\ xxunk } affects the number of measurements made by the agent ( right column ) , and how it impacts the costed return in noisy environments . } \n",
              "  \\ label{fig : xxunk } \n",
              "  \\ end{figure * } \n",
              " \n",
              "  xxmaj the right column of xxmaj figure \\ ref{fig : xxunk } depicts how the initialization of the q - values associated with measure $ m=1 $ in xxmaj amrl - q shapes the number of measurements made by the agent . xxmaj the top plot depicts the number of steps on the deterministic chain and the bottom for the stochastic chain . xxmaj the episodes of training are plotted on the $ x$-axis and the mean number of measurements is plotted on the $ y$-axis . xxmaj this clearly shows that as the initialization is decreased towards zero , the number of measurements made by the agent reduces . \n",
              " \n",
              "  xxmaj the number of measurements per state - action pair has important implications on performance in the stochastic environments . xxmaj in the lower right plot , which applies to the stochastic environment , the difference between the initialization of 0.01 and 0.005 is much smaller than in the deterministic case . xxmaj in that case , the agent using the initialization of 0.005 shifts to using its state estimator before it is sufficiently accurate . xxmaj as result , the agent is operating from error prone estimates of is current state , and thus , requires more steps and more measurements on average . \n",
              " \n",
              "  xxmaj the column on the left shows how the initialization impacts the costed return . xxmaj the upper plot shows that given enough time , the agent overcomes the larger initialization to achieve an equivalent costed return as agents with smaller initial values . xxmaj the lower plot demonstrates the benefit of a large initial value in environments with stochastic transitions . xxmaj from early episodes of training the difference in mean performance ( shown without error bars in the embedded plot ) of the agents with different initialization is small . xxmaj in the large plot ( with error bars ) it is clear that the larger initial value leads to a notably lower standard deviation . xxmaj given the added robustness of the larger initial values , and the fact that the agent will converge to the same performance , we advise against setting it too close to zero . \n",
              " \n",
              "  % \\ xxunk of xxmaj stochastic xxmaj environments } \n",
              " \n",
              "  \\ begin{figure * } \n",
              "  \\ centering \n",
              "  \\ xxunk } \n",
              "  \\ xxunk } \n",
              "  \\ caption{left : xxmaj mean of the costed return on the stochastic xxmaj chain environment . xxmaj right : xxmaj mean of the costed return on the slippery xxmaj frozen xxmaj lake $ 8 \\ times 8 $ environment . } \n",
              "  \\ label{fig : xxunk } \n",
              "  \\ end{figure * } \n",
              " \n",
              "  xxmaj the plot on the left in xxmaj figure \\ ref{fig : xxunk } depicts the mean of the costed return for xxmaj amrl - q , q - learning and xxmaj dyna - q on the stochastic xxmaj chain . xxmaj in this case , the action pairs involving measure $ m=1 $ are initialized to 0.01 . xxmaj the results for xxmaj slippery xxmaj frozen xxmaj lake environment are plotted on the right . xxmaj this is much more complex than the stochastic chain because it involves a larger number of actions and more variability in the transition dynamics . xxmaj in this setting all methods have a high variance . xxmaj the actions pairs associated with measure $ m=1 $ must be set to a large value ( in this case 10.0 ) in order to provide $ \\ hat{p}$ time to stabilize . xxmaj the xxmaj amrl - q agent begins to slowly shift way from relying on measurements after approximately 1,000 episodes of training . \n",
              " \n",
              " \n",
              "  \\ section{conclusion } \n",
              " \n",
              "  xxmaj we introduced a sequential decision making framework , xxmaj amrl , in which the agent selects both an action and an observation class at each time step . xxmaj the observation classes have associated costs and provide information that depends on time and space . xxmaj we formulate our solution in terms of active learning , and empirically show that xxmaj amrl - q learns to shift from relying on costly measurements of the environment to using its state estimator via online experience . xxmaj amrl - q learns at a similar rate to q - learning and xxmaj dyna - q , and achieves a higher costed return . xxmaj amrl has the potential to expand the applicability of xxup rl to important applications in operational planning , scientific discovery , and medical treatments . xxmaj to achieve this , additional research is required to develop xxmaj amrl methods for continuous state and action environments , and function approximation methods , such as xxmaj gaussian processes and deep learning . \n",
              " \n",
              "  % \\ section*{broader xxmaj impact } \n",
              " \n",
              "  % xxmaj the recent successes of xxup rl at games and simulated environments has resulted in considerable interest and attention from new domains . \n",
              " \n",
              "  % \\ begin{ack } \n",
              " \n",
              "  % \\ end{ack } \n",
              " \n",
              " \n",
              "  \\ bibliographystyle{plain } \n",
              "  % \\ bibliographystyle{splncs04 } \n",
              "  \\ xxunk } \n",
              " \n",
              "  \\ end{document } \n",
              " ,xxbos \n",
              "  ewcommand { \\ xxunk cm } \n",
              " \n",
              "  ewcommand { \\ xxunk cm } \n",
              "  % \\ documentclass[journal , 10pt , xxunk } \n",
              "  \\ documentclass[journal , 10pt , xxunk } \n",
              "  \\ ieeeoverridecommandlockouts \n",
              "  \\ ifclassinfopdf \n",
              "  \\ usepackage[pdftex]{graphicx } \n",
              "  \\ else \n",
              "  \\ fi \n",
              "  \\ usepackage{amsmath } \n",
              "  \\ usepackage{array } \n",
              "  \\ ifclassoptioncompsoc \n",
              "  \\ usepackage[caption = false , font = normalsize , labelfont = sf , textfont = sf]{subfig } \n",
              "  \\ else \n",
              "  \\ usepackage[caption = false , font = footnotesize]{subfig } \n",
              "  \\ fi \n",
              "  \\ usepackage{fixltx2e } \n",
              "  \\ usepackage{stfloats } \n",
              "  \\ usepackage{cite } \n",
              "  \\ usepackage{url } \n",
              "  % \\ usepackage{hyperref } % xxmaj creates hyperlinks within document \n",
              "  % \\ hypersetup{colorlinks = true , linkcolor = blue , \n",
              "  % \t citecolor = blue , urlcolor = blue } \n",
              " \n",
              "  \\ usepackage{amssymb } \n",
              "  \\ usepackage{amsthm } \n",
              "  \\ usepackage{algpseudocode } \n",
              "  \\ usepackage{algorithm } \n",
              " \n",
              "  \\ usepackage{graphicx } \n",
              "  \\ usepackage{mathptmx } \n",
              "  \\ usepackage{amsmath } \n",
              "  \\ usepackage{xcolor } \n",
              "  \\ xxunk \n",
              "  \\ renewcommand { \\ xxunk \\ xxunk } \n",
              "  \\ xxunk } \n",
              "  \\ usepackage{multicol } \n",
              "  \\ declaremathoperator { \\ xxunk } \n",
              " \n",
              "  \\ usepackage{setspace } \n",
              " \n",
              " \n",
              "  \\ begin{document } \n",
              "  \\ xxunk } \t \n",
              "  \\ xxunk xxmaj intelligence xxmaj assisted xxmaj collaborative xxmaj edge xxmaj caching in xxmaj small xxmaj cell xxmaj networks } \n",
              " \n",
              "  \\ author { \\ xxunk xxmaj xxunk xxmaj xxunk \\ ieeeauthorrefmark{1 } , xxmaj le xxmaj thanh xxmaj tan \\ ieeeauthorrefmark{2 } and xxmaj rose xxmaj xxunk xxmaj hu \\ ieeeauthorrefmark{2 } } \\ \\ \n",
              "  \\ ieeeauthorblocka { \\ xxunk of xxmaj electrical and xxmaj computer xxmaj engineering , xxmaj north xxmaj carolina xxmaj state xxmaj university , xxmaj xxunk , xxup nc xxunk , xxup usa } \\ \\ \n",
              "  \\ ieeeauthorblocka { \\ xxunk of xxmaj electrical and xxmaj computer xxmaj engineering , xxmaj utah xxmaj state xxmaj university , xxmaj logan , xxup ut xxunk , xxup usa } \\ \\ \n",
              "  xxmaj email : \\ tt xxunk , \\ { xxunk , xxunk \\ } xxunk \\ vspace{-0.3 in } \n",
              " \n",
              "  \\ thanks{the work of xxup m. xxup f. xxmaj xxunk , xxup l. xxup t. xxmaj tan and xxup r. xxup q. xxmaj hu were supported in part by xxmaj national xxmaj science xxmaj foundation under grants nets xxunk and xxup ears xxunk as well as in part by the xxmaj intel xxmaj corporation . } } \n",
              " \n",
              "  \\ maketitle \n",
              "  \\ thispagestyle{empty } \n",
              "  \\ pagestyle{empty } \n",
              " \n",
              "  \\ begin{abstract } \n",
              "  xxmaj edge caching is a new paradigm that has been exploited over the past several years to reduce the load for the core network and to enhance the content delivery performance . \n",
              "  xxmaj many existing caching solutions only consider homogeneous caching placement due to the immense complexity associated with the heterogeneous caching models . \n",
              "  xxmaj unlike these legacy modeling paradigms , this paper considers heterogeneous ( 1 ) content preference of the users and ( 2 ) caching models at the edge nodes . \n",
              "  xxmaj besides , collaboration among these spatially distributed edge nodes is used aiming to maximize the cache hit ratio ( xxup chr ) in a two - tier heterogeneous network platform . \n",
              "  xxmaj however , due to complex combinatorial decision variables , the formulated problem is hard to solve in the polynomial time . \n",
              "  xxmaj moreover , there does not even exist a ready - to - use tool or software to solve the problem . \n",
              "  xxmaj thanks to artificial intelligence ( xxup ai ) , based on the methodologies of the conventional particle swarm optimization ( xxup pso ) , we propose a modified xxup pso ( m - xxup pso ) to efficiently solve the complex constraint problem in a reasonable time . \n",
              "  xxmaj using numerical analysis and simulation , we validate that the proposed algorithm significantly enhances the xxup chr performance when comparing to that of the existing baseline caching schemes . \n",
              "  \\ end{abstract } \n",
              " \n",
              "  \\ begin{ieeekeywords } \n",
              " \t xxmaj cache hit ratio , content delivery network , edge caching , particle swarm optimization , small cell network . \n",
              "  \\ end{ieeekeywords } \\ vspace{-0.1 in } \n",
              " \n",
              "  \\ ieeepeerreviewmaketitle \n",
              " \t \n",
              "  \\ section{introduction } \n",
              "  xxmaj owing to the ever growing requirements on the high data rates , good quality of service and low latency , wireless communication has evolved from generation to generation . \n",
              "  xxmaj with the exponential increase of the connected devices , existing wireless networks have already been experiencing performance bottleneck . \n",
              "  xxmaj while the general trends are shifting resources towards the edge of the network \\ xxunk , xxunk } , study shows that mobile video traffic is one of the dominant applications that cause this performance bottleneck \\ xxunk , xxunk , xxunk } . \n",
              "  xxmaj caching has become a promising technology to address this performance issue by storing popular contents close to the end users \\ xxunk } . \n",
              "  xxmaj therefore , during the network busy time , the requested contents can be delivered from these local nodes ensuring a xxunk pressure to the xxunk and the centralized core network and reducing the latency for content delivery . \n",
              "  xxmaj thus , the much - needed wireless spectrum and xxunk bandwidth can be better utilized in the cache - enabled network platform . \n",
              "  xxmaj in the ultra - dense network platform , caching at the edge nodes is therefore a powerful mechanism for delivering video traffic . \n",
              " \n",
              " \n",
              "  xxmaj while the caching solution can significantly benefit the next - generation wireless communication , various challenges need to be handled to ensure the xxunk performances of the cache - enabled network \\ xxunk , xxunk , xxunk , xxunk } . \n",
              "  xxmaj first of all , the content selection has an enormous impact on the cache - enabled platform \\ xxunk } . \n",
              "  % xxmaj the selection of the contents to store is critical in the edge caching . \n",
              "  xxmaj then , choosing at what node to store the contents needs to be answered . \n",
              "  xxmaj due to the broad combinatorial decision parameters , this is an immense challenge for any cache - enabled network platform . \n",
              "  xxmaj furthermore , owing to the necessity of the system performance metrics , the solution to this combinatorial decision problem may change . \n",
              "  xxmaj therefore , based on the performance metric , an efficient solution is demanded to handle the issue in a reasonable time . \n",
              "  xxmaj as such , under a practical system model in actual communication scenarios , a heterogeneous network platform needs to be adopted for evaluating the caching performance . \n",
              " \n",
              " \n",
              "  xxmaj there exist several caching solutions in the literature \\ xxunk } . \n",
              "  xxmaj caching policy and cooperative distance were designed in \\ xxunk } , by xxmaj lee \\ textit{et al . } , considering clustered device - to - device ( xxup d2d ) networks . \n",
              "  xxmaj while the authors showed some xxunk concepts for the caching policy design aiming to maximize ( a ) energy efficiency and ( b ) throughput , they only considered the collaboration among the xxup d2d users . \n",
              "  xxmaj lee \\ textit{et al . } also proposed a base station ( xxup bs ) assisted xxup d2d caching network in \\ xxunk } that maximizes the time - average service rate . \n",
              "  xxmaj however , the authors only considered a single xxup bs xxunk xxup d2d communication with homogeneous request probability modeling . \n",
              "  xxmaj tan \\ textit{et al . } \\ xxunk } adopted the collaboration based caching model in the heterogeneous network model . \n",
              "  a mobility aware probabilistic edge caching approach was explored in \\ cite{8667875 } . \n",
              "  xxmaj here , the proposed model considered the noble idea of collaboration by considering the spatial node distribution and the user - mobility . \n",
              "  xxmaj while some xxunk concept of relaying and collaboration was introduced in \\ xxunk } , only homogeneous caching placement strategies were incorporated . \n",
              " \n",
              " \n",
              "  xxmaj unlike these existing works , in this paper , we investigate heterogeneous content preference model leveraging heterogeneous cache placement strategy . \n",
              "  xxmaj particularly , in a small cell network ( xxup scn ) , we incorporate collaborations among spatially distributed full - duplex ( xxup fd ) enabled bss and half - duplex ( xxup hd ) operated xxup d2d users to maximize the average cache hit ratio ( xxup chr ) . \n",
              "  xxmaj however , the formulated problem contains hard combinatorial decision variables that are hard to determine in a polynomial time . \n",
              "  xxmaj therefore , we implement a modified particle swarm optimization ( m - xxup pso ) algorithm that effectively solves the grand probabilistic cache placement problem within a reasonable time . \n",
              "  % xxmaj our contributions are summarized as follows : \n",
              "  % \\ begin{itemize } \n",
              "  % \t  \\ item xxmaj to incorporate the goal of content caching in a content delivery network ( xxup cdn ) , we consider the collaborations among different heterogeneous edge nodes in proximity . \n",
              "  % \t  \\ item xxmaj we explore realistic spatial node distributions for the full - duplex ( xxup fd ) enabled bss and half - duplex ( xxup hd ) operated xxup d2d users . \n",
              "  % \t  \\ item xxmaj we consider the heterogeneous content preference and content placement considering the real world heterogeneous network . \n",
              "  % \t  \\ item xxmaj we propose the modified particle swarm optimization ( m - xxup pso ) to effectively solve our decision variables . \n",
              "  % \t  \\ item xxmaj we implement our m - xxup pso to maximize cache hit ratio ( xxup chr ) in a modern xxup scn . \n",
              "  % \\ end{itemize } \n",
              "  xxmaj to the best of our knowledge , this is the first work to consider heterogeneous user preference with a heterogeneous caching model in a practical xxup scn that uses collaborative content sharing among heterogeneous edge nodes to maximize the xxup chr . \n",
              " \n",
              "  xxmaj the outline of this paper is as follows . \n",
              "  xxmaj the system model and the proposed content access protocols are presented in xxmaj section~ \\ xxunk } , followed by the xxup chr analysis in xxmaj section~ \\ xxunk } . \n",
              "  xxmaj the optimization problem and the proposed m - xxup pso algorithm are described in xxmaj section~ \\ xxunk } . \n",
              "  xxmaj section~ \\ xxunk } gives the performance results , followed by the concluding remarks in xxmaj section~ \\ xxunk } . \n",
              " \n",
              " \n",
              "  \\ section{system xxmaj model and xxmaj content xxmaj access xxmaj protocols } \n",
              "  \\ xxunk } \n",
              "  xxmaj this section presents the node distributions and describes the caching properties , followed by the proposed content access protocols . \n",
              " \n",
              "  \\ xxunk xxmaj distributions } \n",
              " \n",
              "  xxmaj we consider a practical two - tier heterogeneous network , which consists of macro base stations ( xxup mbs ) and low - power sbss ( or xxunk ) with xxunk xxup d2d users . \n",
              "  xxmaj the nodes are distributed following an independent homogeneous xxmaj poisson point processes ( xxup xxunk ) model . \n",
              "  xxmaj let us denote the densities of the xxup d2d user , sbs and xxup mbs by $ \\ xxunk , $ \\ xxunk and $ \\ lambda_m$ , respectively . \n",
              "  xxmaj the sbss and mbss operate in the xxup fd mode whereas the xxup d2d users operate in the xxup hd mode . \n",
              "  xxmaj let us denote the set of xxup d2d users , sbss and mbss by $ \\ mathcal{u}$ , $ \\ mathcal{b}$ and $ \\ mathcal{m } $ , respectively . \n",
              "  xxmaj without any loss of generality , user , sbs and xxup mbs are denoted by $ u \\ in \\ { \\ mathcal{u } \\ } $ , $ b \\ in \\ { \\ mathcal{b } \\ } $ , and $ m \\ in \\ { \\ mathcal{m } \\ } $ , respectively . \n",
              "  xxmaj besides , the communication ranges of these nodes are denoted by $ xxmaj xxunk , $ xxmaj xxunk and $ xxmaj xxunk , respectively . \n",
              " \n",
              " \n",
              " \n",
              "  xxmaj the requesting user node is named as the tagged user node . \n",
              "  xxmaj while a user is always associated with the serving xxup mbs , it can also associate with a low powered sbs if the association rules are satisfied . xxmaj the main benefits of being connected to sbs over xxup mbs are higher data rate , less latency , less power consumption , more effective uses of radio resources , etc . \n",
              "  xxmaj we denote the associated sbs as the tagged sbs for that user . \n",
              "  xxmaj furthermore , if such a tagged sbs exists for the user , the user maintains its communication with the serving xxup mbs via the tagged sbs . \n",
              "  xxmaj in that case , the sbs can also use its xxup fd mode to deliver requested content from the other sbss or the cloud via the xxup mbs . \n",
              "  xxmaj if such a tagged sbs does not exist for the user , the user will have to rely on the neighbor sbs nodes and the serving xxup mbs for extracting the requested contents . \n",
              "  xxmaj as all the users may not place a content request at the same time , we assume that only $ \\ alpha$ portions of the users act as tagged users . \n",
              "  % xxmaj in other words , they can place content requests and serve as the xxunk , while the remaining $ \\ left(1- \\ alpha \\ right)$ portion of the users act as xxunk . \n",
              "  xxmaj without any loss of generality , the requesting user , the associated sbs , and the serving xxup mbs are denoted as $ u_0 $ , $ b_0 $ and $ xxunk $ , respectively . \n",
              " \n",
              " \n",
              " \n",
              " \n",
              "  \\ subsection{cache xxmaj storage , xxmaj caching xxmaj policy and xxmaj content xxmaj popularity } \n",
              " \n",
              "  xxmaj the cache storage of the users , sbss and mbss are denoted by $ \\ xxunk } , \\ xxunk and $ \\ xxunk , respectively . \n",
              "  xxmaj considering equal sized contents with a normalized size $ 1 $ \\ xxunk } , it is assumed that the users can make a content request from a content directory of $ \\ mathcal{f } = \\ { f_k \\ } $ , where $ k \\ in \\ { 1,2 , \\ dots , f \\ } $ . \n",
              "  xxmaj for the caching model , a probabilistic method is considered assuming a heterogeneous caching placement strategy . \n",
              "  xxmaj let $ \\ xxunk , $ \\ xxunk and $ \\ xxunk be the probabilities of storing a content $ f_k \\ in \\ { \\ mathcal{f } \\ } $ at the cache store of the user node $ u_i$ , the sbs $ b_j$ and the xxup mbs $ m_l$ , respectively . \n",
              "  xxmaj note that probabilistic caching is highly practical and adopted in many existing works \\ xxunk , xxunk , xxunk } . \n",
              " \n",
              "  xxmaj the content popularity is modeled by following the $ \\ xxunk distribution with the probability mass function $ \\ xxunk } = \\ xxunk \\ gamma } } { \\ sum_{k=1}^{f } xxunk \\ xxunk \n",
              "  xxmaj note that the skewness $ \\ gamma$ governs this distribution . \n",
              "  xxmaj it is assumed that each user has a different content preference . \n",
              "  xxmaj therefore , a random content preference order and a random skewness are chosen for each user . \n",
              "  xxmaj while the content order is chosen using random permutation , the parameter , $ \\ gamma$ , is chosen following $ \\ xxunk random distribution within a range of maximum $ \\ xxunk and minimum $ \\ gamma^{min}$ values . \n",
              "  % xxmaj this can be expressed as $ \\ xxunk } = \\ xxunk } \\ times \\ xxunk ) - \\ gamma^{min}$ , where $ \\ xxunk and $ \\ gamma^{min}$ are the maximum and minimum allowable values , respectively . \n",
              "  xxmaj without any loss of generality , the probability that user $ u_0 $ requests for content $ f_k$ is denoted by $ \\ xxunk \n",
              "  xxmaj this is modeled based on the $ \\ xxunk distribution . \n",
              " \n",
              " \n",
              " \n",
              " \n",
              " \n",
              "  \\ subsection{proposed xxmaj content xxmaj access xxmaj protocol } \n",
              "  \\ xxunk } \n",
              "  xxmaj for accessing the contents , the following practical cases are considered . \n",
              " \n",
              "  \\ textbf{case 1 - \\ textbf{local / self cache hit } } : xxmaj if a tagged user requests the content that is previously cached , the user can directly access the content from its own storage . \n",
              " \n",
              "  \\ textbf{case 2 - \\ xxunk cache hit } } : \n",
              "  xxmaj if the required content is not stored in its own storage , the tagged user sends the content request to the neighboring xxup d2d nodes . \n",
              "  xxmaj if any of the neighbors has the content , the user can extract the content from that neighboring user . \n",
              " \n",
              "  \\ textbf{case 3 - \\ xxunk cache hit } } : \n",
              "  xxmaj if the tagged user is under the communication range of any sbs , it maintains its communication via the tagged sbs . \n",
              "  xxmaj in this particular case , we have the following sub - cases : \n",
              " \n",
              "  \\ textit{case 3.1 } : xxmaj if the requested content is in the tagged sbs cache , it can access the content directly from there . \n",
              "  % xxmaj we denote this case as a direct cache hit from the tagged sbs . \n",
              " \t \n",
              "  \\ textit{case 3.2 } : xxmaj if the content is not stored in the tagged sbs cache but is available in one of the neighboring sbss , the tagged sbs extracts the content from the neighboring sbs via its xxup fd capability and delivers it to the tagged user . \n",
              "  % xxmaj we denote this term as soft - sbs ( xxunk ) cache hit . \n",
              " \n",
              "  \\ textit{case 3.3 } : xxmaj if the requested content is not available in any of the sbss , the tagged sbs forwards the request to the serving xxup mbs . \n",
              "  xxmaj if the content is in the serving xxup mbs , it is delivered to the tagged sbs and then to the user . \n",
              "  % xxmaj this case is denoted as the sbs - xxup mbs cache hit . \n",
              " \t \n",
              "  \\ textit{case 3.4 } : xxmaj if all of the above sub - cases fail , then the xxup mbs extracts the content from the cloud using its xxup fd capability . \n",
              "  xxmaj the sbs extracts the content from the xxup mbs using its own xxup fd capability and delivers it to the tagged user . \n",
              "  % xxmaj this case is denoted as the sbs cache miss . \n",
              " \n",
              " \t \n",
              "  \\ textbf{case 4 - \\ xxunk cache hit } } : \n",
              "  xxmaj if the tagged user is not in the communication range of any of the sbss , it has to rely on the serving xxup mbs for its communication . \n",
              "  xxmaj in this case , we consider the following sub - cases : \n",
              " \n",
              "  \\ textit{case 4.1 } : xxmaj if the requested content is available in the xxup mbs cache , the content is directly delivered to the tagged user . \n",
              "  % xxmaj this case is denoted as an xxup mbs cache hit . \n",
              " \n",
              "  \\ textit{case 4.2 } : xxmaj if the content is not available in the xxup mbs storage and the above case fails , the xxup mbs extracts the content from the cloud using its xxup fd capability . xxmaj then , the content is directly delivered to the user . \n",
              "  % xxmaj this case is referred as an xxup mbs cache miss . \n",
              " \n",
              "  xxmaj without loss of generality , \\ textit{case 3 } and \\ xxunk 4 ) } are denoted by the indicator function $ \\ xxunk and $ \\ xxunk , respectively . \n",
              "  xxmaj note that , in \\ textit{case 3 } , if the tagged user is in the communication ranges of multiple sbss , it gets connected to the one that provides the best received power . xxunk \\ xxunk xxmaj caching : xxmaj cache xxmaj hit xxmaj ratio xxmaj analysis } \t \n",
              "  \\ xxunk } \n",
              "  xxmaj in this section , we analyze and calculate the local cache hit probabilities . \n",
              "  % \\ vspace{-0.05 in } \n",
              "  \\ xxunk xxmaj probabilities } \n",
              "  xxmaj we now analyze the cache hit probability at different nodes for the cases mentioned in xxmaj section \\ xxunk } . \n",
              "  xxmaj note that a cache hit occurs at a node , if a requested content is available in that node . \n",
              " \n",
              "  \\ subsubsection{case 1 - xxmaj local / self cache hit } \n",
              "  xxmaj the local cache hit probability is denoted as $ \\ xxunk } = \\ xxunk , i.e. the probability of storing the content $ f$ at the self cache storage of the tagged user . \n",
              " \n",
              "  \\ subsubsection{case 2 - xxup d2d cache hit } \n",
              "  xxmaj the cache hit probability for the xxup d2d nodes can be calculated as follows : % \\ vspace{-0.05 in } \n",
              "  \\ begin{equation } \n",
              "  % \\ small \n",
              "  \\ xxunk } \n",
              " \t  \\ xxunk } = \\ left(1- \\ eta_{f_k}^{u_0 } \\ right ) \\ left[1 - \\ prod_{u_i \\ in \\ xxmaj phi_{u } \\ backslash u_0 } \\ left(1 - \\ eta_{f_k}^{u_i } \\ right ) \\ right ] , \n",
              "  \\ end{equation } % \\ vspace{-0.05 in } \n",
              "  where $ \\ prod_{u_i \\ in \\ xxmaj phi_{u } } \\ left(1 - \\ eta_{f_k}^{u_i } \\ right)$ means that none of the $ \\ xxmaj xxunk active neighbors ( xxup d2d nodes ) in its communication range have the content . \n",
              "  xxmaj thus , the complement of that is the probability that at least one of the users stores the content . \n",
              " \n",
              " \n",
              "  \\ subsubsection{case 3 - sbs cache hit } \n",
              "  xxmaj in this case , cache hit probabilities achieved via the tagged sbs for the respective sub - cases are calculated . \n",
              " \n",
              "  \\ textit{case 3.1 : } xxmaj the probability of getting a requested content from the tagged sbs is calculated as follows : % \\ vspace{-0.05 in } \n",
              "  \\ begin{equation } \n",
              "  % \\ small \n",
              "  \\ xxunk } \n",
              " \t  \\ xxunk } = \\ left(1- \\ eta_{f_k}^{u_0 } \\ right ) \\ prod_{u_i \\ in \\ xxmaj phi_{u } \\ backslash u_0 } \\ left(1 - \\ eta_{f_k}^{u_i } \\ right ) \\ eta_{f_k}^{b_0 } . \n",
              "  \\ end{equation } % \\ vspace{-0.05 in } \n",
              " \n",
              "  \\ textit{case 3.2 : } xxmaj the probability of getting a requested content from one of the neighbor sbss is considered in this sub - case . \n",
              "  xxmaj essentially , this case states that a cache miss occurs at the tagged sbs . xxmaj mathematically , this probability is expressed as % \\ vspace{-0.05 in } \n",
              "  \\ begin{equation } \n",
              "  % \\ small \n",
              "  \\ xxunk } \n",
              "  \\ begin{aligned } \n",
              " \t  \\ xxunk } & = \\ left(1- \\ eta_{f_k}^{u_0 } \\ right ) \\ prod_{u_i \\ in \\ xxmaj phi_{u } \\ backslash u_0 } \\ left(1 - \\ eta_{f_k}^{u_i } \\ right ) \\ left(1 - \\ eta_{f_k}^{b_0 } \\ right ) \\ \\ \n",
              " \t & \\ qquad \\ qquad \\ left(1 - \\ prod_{b_j \\ in \t\t  \\ xxmaj phi_{b } \\ backslash b_0 } \\ left ( 1 - \\ eta_{f_k}^{b_j } \\ right ) \\ right ) , \n",
              "  \\ end{aligned } \n",
              "  \\ end{equation } % \\ vspace{-0.05 in } \n",
              "  where $ \\ xxmaj xxunk is the set of active neighboring sbss that are in the communication range of the tagged sbs . \n",
              " \n",
              "  \\ textit{case 3.3 : } \n",
              "  xxmaj if sub - cases 3.1 and 3.2 fail , the content request is forwarded to the serving xxup mbs via the tagged sbs . \n",
              "  xxmaj the cache hit probability , for this case , is calculated as \n",
              "  \\ begin{equation } \n",
              "  \\ xxunk } \n",
              "  \\ begin{aligned } \n",
              " \t  \\ mathrm{p}_{m _ { \\ xxunk } & = \\ left(1- \\ eta_{f_k}^{u_0 } \\ right ) \\ prod_{u_i \\ in \\ xxmaj phi_{u } \\ backslash u_0 } \\ left(1 - \\ eta_{f_k}^{u_i } \\ right ) \\ left(1 - \\ eta_{f_k}^{b_0 } \\ right ) \\ \\ \n",
              " \t & \\ qquad \\ qquad \\ prod_{b_j \\ in \\ xxmaj phi_{b } \\ backslash xxunk } \\ left ( 1 - \\ eta_{f_k}^{b_j } \\ right ) \\ eta_{f_k}^{m_0 } . \n",
              "  \\ end{aligned } \n",
              "  \\ end{equation } \n",
              "  xxmaj when $ \\ mathbb{i}_s = 1 $ , i.e. the tagged user is in the communication range of at least one sbs , from the above cases and sub - cases , we calculate the total cache hit probability as \n",
              "  \\ begin{equation } \n",
              "  % \\ small \n",
              "  \\ xxunk } \n",
              "  \\ begin{aligned } \n",
              " \t  \\ mathrm{p}_{l}^ { \\ mathbb{i}_s } & % = \\ eta_{f_k}^{u_0 } + \\ xxunk } + \\ xxunk } + \\ xxunk } + \\ mathrm{p}_{m _ { \\ xxunk } \\ \\ & \n",
              " \t = 1 - \\ xxmaj bigg [ \\ left(1 - \\ eta_{f_k}^{u_0 } \\ right ) \\ prod_{u_i \\ in \\ xxmaj phi_{u } \\ backslash u_0 } \\ left(1 - \\ eta_{f_k}^{u_i } \\ right ) \\ left(1 - \\ eta_{f_k}^{b_0 } \\ right ) \\ \\ \n",
              " \t & \\ qquad \\ qquad \\ prod_{b_j \\ in \\ xxmaj phi_{b } \\ backslash b_0 } \\ left(1 - \\ eta_{f_k}^{b_j } \\ right ) \\ xxmaj bigg ] \\ left(1 - \\ eta_{f_k}^{m_0 } \\ right ) . \n",
              "  \\ end{aligned } \n",
              "  \\ end{equation } \n",
              " \n",
              "  \\ textit{case 3.4 : } xxmaj now , if the content is not even stored in the xxup mbs cache storage , it has to be downloaded from the cloud . \n",
              "  xxmaj this case is termed as a cache miss via both sbss and mbss . \n",
              "  xxmaj in this case , the xxup mbs initiates its xxup fd mode and downloads the content from the cloud . \n",
              "  xxmaj therefore , the cache miss probability is calculated from ( \\ xxunk } ) as \n",
              "  \\ begin{equation } \n",
              "  % \\ small \n",
              "  \\ xxunk } \n",
              "  \\ begin{aligned } \n",
              " \t  \\ xxunk _ { \\ xxunk \\ ! & % = 1 - \\ mathrm{p}_{l}^ { \\ mathbb{i}_s } \\ \\ \n",
              " \t  = \\ xxmaj bigg [ \\ left(1 - \\ eta_{f_k}^{u_0 } \\ right ) \\ prod_{u_i \\ in \\ xxmaj phi_{u } \\ backslash u_0 } \\ left(1 - \\ eta_{f_k}^{u_i } \\ right ) \\ left(1 - \\ eta_{f_k}^{b_0 } \\ right ) \\ \\ \n",
              " \t  & \\ qquad \\ qquad \\ prod_{b_j \\ in \\ xxmaj phi_{b } \\ backslash b_0 } \\ left(1 - \\ eta_{f_k}^{b_j } \\ right ) \\ xxmaj bigg ] \\ left(1 - \\ eta_{f_k}^{m_0 } \\ right ) . \n",
              "  \\ end{aligned } \n",
              "  \\ end{equation } \n",
              " \n",
              " \n",
              "  \\ subsubsection{case 4 - xxup mbs cache hit } \n",
              "  xxmaj recall that \\ textit{case 4 } is only considered when the tagged user is not under the coverage region of any of the sbss . \n",
              "  xxmaj firstly , we consider \\ textit{case 4.1 } , i.e. the requested content is available in the xxup mbs cache ( i.e. $ \\ xxunk $ and $ \\ xxunk $ ) . \n",
              "  xxmaj in this sub - case , the cache hit probability is expressed as \n",
              "  \\ begin{equation } \n",
              "  % \\ small \n",
              "  \\ xxunk } \n",
              " \t  \\ mathrm{p}_{m _ { \\ mathbb{i}_m}}^u = \\ left(1- \\ eta_{f_k}^{u_0 } \\ right ) \\ prod_{u_i \\ in \\ xxmaj phi_{u } \\ backslash u_i } \\ left(1 - \\ eta_{f_k}^{u_i } \\ right ) \\ eta_{f_k}^{m_0 } . \n",
              "  \\ end{equation } \n",
              "  xxmaj furthermore , the total local cache hit probability in this case is given as \n",
              "  \\ begin{equation } \n",
              "  % \\ small \n",
              "  \\ xxunk } \n",
              "  \\ begin{aligned } \n",
              " \t  \\ mathrm{p}_{l}^ { \\ mathbb{i}_m } % & = \\ xxunk } + \\ xxunk + \\ mathrm{p}_{m _ { \\ mathbb{i}_m}}^u \\ \\ \n",
              " \t & = 1 - \\ left(1 - \\ eta_{f_k}^{u_0 } \\ right ) \\ prod_{u_i \\ in \\ xxmaj phi_{u } \\ backslash u_0 } \\ left(1 - \\ eta_{f_k}^{u_i } \\ right ) \\ left ( 1 - \\ eta_{f_k}^{m_0 } \\ right ) . \n",
              "  \\ end{aligned } \n",
              "  \\ end{equation } \n",
              "  xxmaj note that the cache miss probability of \\ textit{case 4.2 } is derived as \n",
              "  \\ begin{equation } \n",
              "  % \\ small \n",
              "  \\ xxunk } \n",
              " \t  \\ xxunk _ { \\ mathbb{i}_m}}^u = \\ left(1 - \\ eta_{f_k}^{u_0 } \\ right ) \\ prod_{u_i \\ in \\ xxmaj phi_{u } \\ backslash u_0 } \\ left(1 - \\ eta_{f_k}^{u_i } \\ right ) \\ left ( 1 - \\ eta_{f_k}^{m_0 } \\ right ) . \n",
              "  \\ end{equation } \n",
              " \n",
              "  \\ subsection{cache xxmaj hit xxmaj ratio } \n",
              "  xxmaj we define xxup chr as the fraction of the requests that are served locally without reaching the cloud . \n",
              "  xxmaj let us denote the $ \\ alpha$ portion of the users by the set of $ \\ xxunk \n",
              "  xxmaj in a heterogeneous caching placement , the fraction of requests of $ u_0 $ that are served from the local nodes is as follows : \n",
              "  \\ begin{equation } \n",
              "  \\ small \n",
              "  \\ xxunk } \n",
              "  \\ begin{aligned } \n",
              "  \\ ! \\ ! \\ ! \\ ! \\ ! \\ ! \\ ! \\ xxunk } \\ ! \\ ! & = \\ ! \\ ! \\ sum_{k=1}^{f } \\ xxunk } \\ ! \\ xxmaj bigg [ \\ ! \\ ! \\ eta_{f_k}^{u_0 } + \\ xxunk \\ mathrm{p}_{s , xxunk } + \\ underbrace { \\ xxmaj big ( \\ xxunk } \\ mathrm{p}_{s , xxunk } + \\ xxunk \\ mathrm{p}_{s , xxunk } + \\ mathrm{p}_{m _ { \\ xxunk \\ mathrm{p}_{s , xxunk } \\ xxmaj big ) } _ { \\ xxunk hit in xxmaj case 3 } } \\ mathbb{i}_s \\ xxmaj bigg ] \\ \\ \n",
              "  & \\ qquad \t + \\ underbrace { \\ xxmaj big ( \\ mathrm{p}_{m _ { \\ mathbb{i}_m}}^u \\ mathrm{p}_{s , f , \\ mathbb{i}_m = xxunk } \\ xxmaj big ) } _ { \\ xxunk hit in xxmaj case 4 } } \\ mathbb{i}_m , \n",
              "  \\ end{aligned } \n",
              "  \\ end{equation } \n",
              "  where the first term represents the self cache hit , the second term represents the successfully achieved cache hit from xxup d2d neighbors . \n",
              "  xxmaj moreover , $ \\ mathrm{p}_{s , xxunk represents the successful transmission probability for the respective ` * ' cases . \n",
              "  xxmaj note that the transmission success probability between two nodes does not depend on the content index . \n",
              "  xxmaj therefore , we mention the success probability as $ \\ xxunk , xxunk instead of $ \\ xxunk , xxunk \n",
              "  % xxmaj now , we derive these transmission success probabilities using appropriate channel models . \n",
              "  % xxmaj however , owing to the space constraint , the detailed derivations of these probabilities are presented in our online technical report \\ xxunk } . \n",
              " \n",
              " \n",
              " \n",
              " \n",
              "  \\ xxunk of xxmaj successful xxmaj transmission } \n",
              " \n",
              "  xxmaj now , we calculate the transmission success probabilities among different nodes . \n",
              "  xxmaj when a tagged user requests a content , interference comes from other active xxup d2d users , active sbss and the xxup mbs . \n",
              "  xxmaj the wireless channel between two nodes follows a xxmaj xxunk fading distribution with $ \\ xxunk \n",
              "  xxmaj let us denote the channel between node $ i$ and node $ j$ by $ xxunk \n",
              "  xxmaj let us also denote the threshold xxup xxunk for successful communication by $ \\ phi$ xxunk \n",
              "  xxmaj the transmission power of the user , the sbs and the xxup mbs are denoted by $ p_u$ , $ p_b$ and $ xxunk , respectively . \n",
              "  xxmaj moreover , the path loss exponent is denoted by $ \\ beta$. \n",
              "  xxmaj owing to the space constraint , the detail derivations of these probabilities are omitted . \n",
              "  xxmaj however , interested readers can find them in our online technical report \\ xxunk } . \n",
              "  xxmaj also , note that we do not consider the case of obtaining the content from the cloud , when we calculate $ \\ xxunk \n",
              "  xxmaj this is due to the fact that we are interested in calculating the percentage of served request from the local nodes only . \n",
              " \n",
              " \n",
              "  \\ xxunk } \\ vspace{-0.2 in } \n",
              "  % \\ small \n",
              "  \\ begin{equation } \n",
              "  \\ xxunk } \n",
              "  \\ begin{aligned } \n",
              "  \\ xxmaj sigma & = \\ frac{1}{| \\ xxunk } \\ sum _ { u_0 \\ in \\ xxunk } \\ sum_{k=1}^{f } \\ xxunk } \\ xxmaj bigg \\ { \\ eta_{f_k}^{u_0 } + \\ left(1- \\ eta_{f_k}^{u_0 } \\ right ) \\ left[1 - \\ prod_{u_i \\ in \\ xxmaj phi_{u } \\ backslash u_0 } \\ left(1 - \\ eta_{f_k}^{u_i } \\ right ) \\ right ] \\ mathrm{p}_{s , xxunk } + \\ xxmaj bigg ( \\ left(1- \\ eta_{f_k}^{u_0 } \\ right ) \\ prod_{u_i \\ in \\ xxmaj phi_{u } \\ backslash u_0 } \\ ! \\ ! \\ ! \\ ! \\ ! \\ ! \\ left(1 - \\ eta_{f_k}^{u_i } \\ right ) \\ eta_{f_k}^{b_0 } \\ mathrm{p}_{s , xxunk } + \\ \\ \n",
              "  & \\ qquad \\ left(1- \\ eta_{f_k}^{u_0 } \\ right ) \\ ! \\ ! \\ ! \\ ! \\ prod_{u_i \\ in \\ xxmaj phi_{u } \\ backslash u_0 } \\ ! \\ ! \\ ! \\ ! \\ left(1 - \\ eta_{f_k}^{u_i } \\ right ) \\ ! \\ ! \\ left(1 - \\ eta_{f_k}^{b_0 } \\ right ) \\ ! \\ ! \\ left(1 - \\ ! \\ ! \\ ! \\ prod_{b_j \\ in \\ xxmaj phi_{b } \\ backslash b_0 } \\ ! \\ ! \\ ! \\ ! \\ left ( 1 - \\ eta_{f_k}^{b_j } \\ right ) \\ ! \\ ! \\ ! \\ right ) \\ mathrm{p}_{s , xxunk } + \\ left(1- \\ eta_{f_k}^{u_0 } \\ right ) \\ prod_{u_i \\ in \\ xxmaj phi_{u } \\ backslash u_0 } \\ left(1 - \\ eta_{f_k}^{u_i } \\ right ) \\ left(1 - \\ eta_{f_k}^{b_0 } \\ right ) \\ \\ \n",
              "  & \\ qquad \\ prod_{b_j \\ in \\ xxmaj phi_{b } \\ backslash xxunk } \\ left ( 1 - \\ eta_{f_k}^{b_j } \\ right ) \\ eta_{f_k}^{m_0 } \\ mathrm{p}_{s , xxunk } \\ xxmaj bigg ) \\ mathbb{i}_s + \\ xxmaj bigg ( \\ left(1- \\ eta_{f_k}^{u_0 } \\ right ) \\ prod_{u_i \\ in \\ xxmaj phi_{u } \\ backslash u_i } \\ left(1 - \\ eta_{f_k}^{u_i } \\ right ) \\ eta_{f_k}^{m_0 } \\ mathrm{p}_{s , f , \\ mathbb{i}_m = xxunk } \\ xxmaj bigg ) \\ mathbb{i}_m \\ xxmaj bigg \\ } . \n",
              "  \\ end{aligned } \n",
              "  \\ end{equation } \n",
              "  \\ xxunk } \n",
              " \n",
              " \n",
              " \n",
              "  \\ xxunk xxmaj hit xxmaj ratio xxmaj maximization using xxmaj particle xxmaj swarm xxmaj optimization } \n",
              "  \\ xxunk } \n",
              "  xxmaj we present the objective function , followed by the proposed m - xxup pso algorithm in this section . \n",
              " \n",
              "  \\ xxunk xxmaj maximization xxmaj objective xxmaj function } \n",
              "  xxmaj to this end , we calculate the average cache hit ratio for the requesting nodes , which is denoted by $ \\ xxmaj sigma$. \n",
              "  xxmaj the detailed derivation of the $ \\ xxmaj sigma$ is shown in ( \\ xxunk } ) . \n",
              "  xxmaj our objective is to maximize $ \\ xxmaj sigma$ given that the storage constraints are not violated . \n",
              "  xxmaj thus , the objective function in the heterogeneous caching model case is expressed as \n",
              "  \\ begin{subequations } \n",
              " \t  \\ begin{align } \n",
              " \t  \\ xxunk : } \\ quad \t & \\ underset { \\ eta_{f_k}^{u_i } , \\ eta_{f_k}^{b_j } , \\ eta_{f_k}^{m_l } } { \\ text{maximize } } \\ quad \\ xxmaj sigma \\ \\ \n",
              " \t & \\ quad \\ text{s . t. } ~ \\ xxunk } \\ sum_{k=1}^{f } \\ eta_{f_k}^{u_i } \\ leq \\ xxunk , \\ quad \\ xxunk u_i \\ in \\ { \\ mathcal{u } \\ } , f_k \\ in \\ { \\ mathcal{f } \\ } \\ \\ \n",
              " \t & \\ xxunk } \\ qquad \t  \\ sum_{k=1}^{f } \\ eta_{f_k}^{b_j } \\ leq \\ mathcal{c}_b , \\ quad \\ xxunk b_j \\ in \\ { \\ mathcal{b } \\ } , f_k \\ in \\ { \\ mathcal{f } \\ } \\ \\ \n",
              " \t & \\ xxunk } \\ qquad \t  \\ sum_{k=1}^{f } \\ eta_{f_k}^{m_l } \\ leq \\ mathcal{c}_m , \\ quad \\ forall ~ xxunk \\ in \\ { \\ mathcal{m } \\ } , f_k \\ in \\ { \\ mathcal{f } \\ } \\ \\ \n",
              " \t & \\ xxunk } \\ qquad \t 0 \\ leq \\ eta_{f_k}^{u_i } \\ leq 1,~ 0 \\ leq \\ eta_{f_k}^{b_j } \\ leq 1,~ 0 \\ leq \\ eta_{f_k}^{m_l } \\ leq 1 , \t \n",
              " \t  \\ end{align } \n",
              " \t  \\ xxunk } \n",
              "  \\ end{subequations } \n",
              "  where the constraints in ( \\ xxunk \\ xxunk } ) ensure the physical storage size limitations of the user , the sbs and the xxup mbs , respectively , while the constraints in ( \\ xxunk } ) are due to the probability range in $ [ 0,1]$. \n",
              "  xxmaj the goal is to find optimal caching placements that give us the optimal solutions . \n",
              "  % xxmaj however , the optimization problem $ \\ xxunk is highly challenging to solve . \n",
              "  xxmaj in general , problem $ \\ xxunk is non - convex \\ cite{8667875 } by nature and may not be solved efficiently in a polynomial time due to the nonlinear and combinatorial content placement variables . \n",
              "  % xxmaj the option of exhaustive search is also out of consideration due to its exponential complexity . \n",
              "  % xxmaj instead , we apply an xxup ai - based framework to obtain sub - optimal yet efficient solutions . \n",
              "  xxmaj in the following , a modified particle swarm optimization ( m - xxup pso ) framework is proposed to obtain the best set of parameters . \n",
              " \n",
              " \n",
              " \n",
              "  \\ xxunk - xxmaj particle xxmaj swarm xxmaj optimization xxmaj algorithm } \n",
              "  xxup pso is a swarm intelligence approach that guarantees to converge \\ xxunk } . \n",
              "  xxmaj in this meta - heuristic algorithm , all possible sets of the candidate solutions are named as the particles , which are denoted by $ i$. \n",
              "  xxmaj each particle has a position denoted by $ x_i$. \n",
              "  xxmaj furthermore , it maintains a personal best position of each particle , denoted by $ xxunk , and the global best positions of the entire swarm , denoted by $ xxunk \n",
              "  xxmaj the algorithm evolves with an exploration and exploitation manner by adding a velocity term $ xxunk at each particle 's previous position aiming to converge at the global optima . \n",
              "  xxmaj the following two simple equations , thus , govern the xxup pso algorithm . % \\ vspace{-0.1 in } \n",
              "  \\ begin{align } \n",
              "  xxunk } & = xxunk + \\ psi_1 \\ epsilon_1 \\ xxunk } - x_i \\ right ) + \\ psi_2 \\ epsilon_2 \\ xxunk } - x_i \\ right ) , \\ xxunk } \\ \\ \n",
              "  xxunk } & = xxunk + xxunk } , \\ xxunk } \n",
              "  \\ end{align } \n",
              "  where $ a$ , $ \\ psi_1 $ , and $ \\ psi_2 $ are the parameters that need to be selected properly . \n",
              "  xxmaj moreover , $ \\ epsilon_1 $ and $ \\ epsilon_2 $ are two $ \\ xxunk random variables . \n",
              "  xxmaj note that $ \\ psi_1 $ and $ \\ psi_2 $ are positive acceleration coefficients , which are also known as the cognitive and social learning factors \\ cite{8667875 } respectively . \n",
              "  xxmaj while this is a general framework for the xxup pso algorithm , it may not be used directly in the constraint optimization \\ xxunk } . \n",
              "  xxmaj in our objective function , each particle must have a position matrix , each dimension of which must not violate the restrictions . \n",
              "  xxmaj therefore , in the following , we modify the xxup pso algorithm to solve the optimization problem efficiently . \n",
              " \n",
              "  xxmaj let $ xxup p$ be the number of particles . \n",
              "  xxmaj let $ \\ pmb { \\ xxunk } \\ in \\ xxunk \\ times 1}$ denote the caching probabilities of user $ u_i$ for all the contents $ f_k \\ in \\ { \\ mathcal{f } \\ } $ . \n",
              "  % xxmaj then , this parameter has a size of $ f \\ times 1$. \n",
              "  xxmaj similarly , for all the sbss and mbss , let $ \\ pmb { \\ xxunk and $ \\ pmb { \\ xxunk denote their caching placement probabilities for all the contents . \n",
              "  xxmaj then , all of these parameters can be stacked into a matrix with dimension of $ ( | \\ mathcal{u}| + | \\ mathcal{b}| + | \\ mathcal{m}| ) \\ times | \\ xxunk , which is the exact shape of each particle . \n",
              "  xxmaj let the current position of each of these particles be denoted by $ \\ xxunk \n",
              "  % xxmaj note that in this case , each particle 's position $ \\ xxunk has a shape of $ ( | \\ mathcal{u}| + | \\ mathcal{b}| + | \\ mathcal{m}| ) \\ times | \\ xxunk \n",
              "  xxmaj let $ \\ xxunk } \\ in \\ xxunk \\ mathcal{u}| + | \\ mathcal{b}| + | \\ mathcal{m}| ) \\ times | \\ mathcal{f}|}$ denote the velocity . xxmaj furthermore , the personal best position of particle $ i$ is $ \\ mathbf{p}_i^ { \\ mathrm{best}}$ , while the global best for the entire swarm is $ \\ mathbf{g}^ { \\ xxunk \n",
              "  xxmaj therefore , each particle updates its velocity with social and individual cognition parameters . \n",
              "  xxmaj we use the following equation to govern these updates . \n",
              "  \\ begin{equation } \n",
              "  \\ small \n",
              "  \\ begin{aligned } \n",
              "  \\ xxunk } \n",
              "  \\ ! \\ ! \\ xxunk } \\ ! \\ ! & = \\ ! a \\ xxunk + \\ psi_1 \\ left [ \\ pmb { \\ xxunk \\ ! \\ odot \\ ! \\ ! \\ left ( \\ mathbf{p}_{i}^ { \\ mathrm{best } } \\ ! \\ ! - \\ ! \\ xxunk } \\ right ) \\ right ] \\ ! + \\ ! \\ psi_2 \\ left [ \\ pmb { \\ xxunk \\ ! \\ odot \\ ! \\ ! \\ left ( \\ mathbf{g}^ { \\ mathrm{best } } \\ ! \\ ! \\ ! - \\ xxunk \\ ! \\ right ) \\ ! \\ right ] \\ ! \\ ! , \n",
              "  \\ end{aligned } \n",
              "  \\ end{equation } \n",
              "  where $ a$ , $ \\ psi_1 $ and $ \\ psi_2 $ are the parameters as described in ( \\ xxunk } ) . \n",
              "  xxmaj moreover , $ \\ pmb { \\ xxunk $ and $ \\ pmb { \\ xxunk $ are two matrices with sizes of $ \\ xxunk \\ mathcal{u}| + | \\ mathcal{b}| + | \\ mathcal{m}| ) \\ times | \\ mathcal{f}|}$ respectively , where their elements are drawn from $ \\ xxunk random distribution . \n",
              "  xxmaj finally , $ \\ odot$ represents xxmaj xxunk product . \n",
              " \n",
              " \n",
              "  xxmaj the position of each particle is then updated by the velocity similar to ( \\ xxunk } ) . \n",
              "  xxmaj however , as there are constraints ( \\ xxunk ( \\ xxunk } ) , we need to modify this equation accordingly . \n",
              "  xxmaj let $ \\ xxunk denote an intermediate updated position of particle $ i$ as shown in the following expression . \n",
              "  \\ begin{equation } \n",
              "  % \\ small \n",
              "  \\ xxunk } \n",
              "  \\ xxunk } = \\ xxunk + \\ xxunk . \n",
              "  \\ end{equation } \n",
              "  % xxmaj we consider this intermediate position to keep each particle 's position in the feasible search space . \n",
              "  xxmaj besides , necessary normalization and scaling need to be performed . \n",
              "  xxmaj note that this intermediate particle position leads to a normalized particle position . \n",
              "  xxmaj this parameter is then used as the current particle position $ \\ xxunk \n",
              "  xxmaj moreover , the ultimate goal for each particle is to converge to an optimal position $ \\ xxunk ( i.e. , the global best $ \\ mathbf{g}^ { \\ mathrm{best}}$ ) . \n",
              "  xxmaj we summarize all the steps in xxmaj alg.~ \\ xxunk } . \n",
              "  xxmaj note that the proposed algorithm can be implemented to solve any similar hard combinatorial problems . \n",
              " \n",
              "  \\ begin{algorithm } \n",
              "  \\ small \n",
              "  \\ xxunk xxmaj maximization using m - xxup pso } \n",
              " \t  \\ begin{algorithmic } [ 1 ] \n",
              " \t\t  \\ xxmaj for { each particle , $ i = 1,2 , \\ dots , xxup p$ } \n",
              " \t\t  \\ xxmaj state { $ \\ mathbf{x}_i = [ ~]$ , $ \\ mathbf{v}_i = [ ~]$ } \n",
              " \t\t  \\ xxmaj for { each dimension $ j = 1,2 , \\ dots , xxup d$ } \\ xxunk \\ mathcal{u}| + | \\ mathcal{b}| + | \\ xxunk } \n",
              " \t\t  \\ xxmaj state initialize the particles positions , $ \\ mathbf{x}_{ji } $ with uniform random vector of size $ \\ mathbb{r}^{| \\ mathcal{f}|}$ by making sure $ \\ sum_{k = xxup xxunk } { xxunk ] = 1 $ and $ 0 \\ leq { xxunk ] \\ leq \\ frac{1 } { \\ xxunk , $ \\ forall ~k \\ in \\ mathcal{f}$ ; then set $ \\ mathbf{x}_i [ j , : ] \\ leftarrow \\ xxunk \\ xxmaj xxunk \\ xxunk is the cache storage of the node in $ j^{th}$ dimension } \\ xxunk } \n",
              " \t\t  \\ xxmaj state initialize particles velocity , $ \\ mathbf{v}_{ji}$ with uniform random vector of size $ \\ mathbb{r}^{| \\ mathcal{f}|}$ by making sure $ \\ sum_{k = xxup xxunk } { xxunk ] = 1 $ and $ 0 \\ leq { xxunk ] \\ leq \\ frac{1 } { \\ xxunk , $ \\ forall ~k \\ in \\ mathcal{f}$ ; then set $ \\ mathbf{v}_i [ j , : ] \\ leftarrow \\ mathbf{v}_{ji}$ \\ xxunk } \n",
              " \t\t  \\ endfor \n",
              " \t\t  \\ xxmaj state set particle best position , $ \\ xxunk as the initial position \n",
              " \t\t  \\ xxmaj if { $ \\ xxmaj sigma \\ left ( \\ mathbf{p}_{i}^ { \\ mathrm{best } } \\ right ) > \\ mathrm { \\ xxmaj sigma } \\ left ( \\ mathbf{g}^ { \\ mathrm{best } } \\ right)$ } \\ xxunk } \n",
              " \t\t  \\ xxmaj state $ \\ mathbf{g}^ { \\ mathrm{best } } \\ leftarrow \\ mathbf{p}_i^ { \\ mathrm{best}}$ \n",
              " \t\t  \\ endif \n",
              " \t\t  \\ endfor \n",
              " \t\t  \\ xxmaj while { termination criteria has not met } \n",
              " \t\t  \\ xxmaj for { each particle , $ i$ } \n",
              " \t\t  \\ xxmaj for { each dimension , $ j = 1,2 , \\ dots , xxup d$ } \n",
              " \t\t  \\ xxmaj state draw uniform random vectors , $ \\ pmb { \\ epsilon}_1 $ and $ \\ pmb { \\ epsilon}_1 $ of size $ \\ mathbb{r}^{| \\ mathcal{f}|}$ \n",
              " \t\t  \\ xxmaj state set $ \\ mathbf{v}_{ji } \\ leftarrow a \\ mathbf{v}_{ji } + \\ psi_1 \\ left [ \\ pmb { \\ epsilon}_1 \\ odot \\ left ( \\ xxunk { \\ mathrm{best } } - \\ mathbf{x}_{ji } \\ right ) \\ right ] + \\ psi_2 \\ left [ \\ pmb { \\ xxunk \\ odot \\ left ( \\ xxunk { \\ mathrm{best } } - \\ mathbf{x}_{ji } \\ right ) \\ right ] $ % \\ xxmaj xxunk \\ mathbf{v}_{ji}$ represents a single row of particle $ i$ 's $ j^{th}$ dimension } \n",
              " \t\t  \\ xxmaj state set $ \\ mathbf{v}_i [ j , : ] \\ leftarrow \\ mathbf{v}_{ji } $ \n",
              " \t\t  \\ endfor \n",
              " \t\t  \\ xxmaj state update particles intermediate position , $ \\ xxunk % using equation ( \\ xxunk } ) \n",
              " \t\t  \\ xxmaj state $ \\ mathbf{x}_{i}^ { \\ mathrm{scl } } = [ ~]$ , $ \\ mathbf{p}_{i}^ { \\ mathrm{scl \\ _ best } } = [ ~]$ , $ \\ mathbf{g}^ { \\ mathrm{scl \\ _ best } } = [ ~]$ \n",
              " \t\t  \\ xxmaj for{each dimension $ j = 1,2 , \\ dots , xxup d$ } \n",
              " \t\t  \\ xxmaj state $ \\ xxunk \\ _ xxunk } \\ leftarrow \\ xxunk } ( \\ xxunk \\ xxunk } \n",
              " \t\t  \\ xxmaj for { i in $ len ( \\ xxunk \\ _ xxunk } \n",
              " \t\t  \\ xxmaj state $ \\ mathbf{x}_{i_{int}}[j , \\ xxunk ) ] \\ leftarrow \\ frac { \\ sum_{k=1}^{f } \\ mathbf{x}_{i_{int}}[j , : ] } { \\ xxunk } $ \\ xxunk } \n",
              " \t\t  \\ endfor \n",
              " \t\t  \\ xxmaj state $ \\ xxunk , : ] \\ leftarrow \\ frac { \\ mathbf{x}_{i_{int}}[j , : ] } { \\ sum_{k=1}^{f } \\ mathbf{x}_{i_{int}}[j , : ] } $ ; $ \\ mathbf{x}_{i}^ { \\ xxunk , : ] \\ leftarrow \\ mathcal{c}^{j } \\ xxunk , : ] $ \\ xxunk particle position } \n",
              " \t\t  \\ xxmaj state $ \\ mathbf{p}_{i}^ { \\ mathrm{scl \\ _ best } } [ j , : ] \\ leftarrow \\ mathcal{c}^{j } \\ mathbf{p}_{i}^ { \\ xxunk , : ] $ \\ xxunk } \n",
              " \t\t  \\ xxmaj state $ \\ xxunk { \\ mathrm{scl \\ _ best } } [ j , : ] \\ leftarrow \\ mathcal{c}^{j } \\ xxunk { \\ xxunk , : ] $ \\ xxunk } \n",
              " \t\t  \\ endfor \n",
              " \t\t  \\ xxmaj if{$ \\ xxmaj sigma \\ left ( \\ mathbf{x}_{i}^ { \\ mathrm{scl } } \\ right ) > \\ mathrm { \\ xxmaj sigma } \\ left ( \\ mathbf{p}_{i}^ { \\ mathrm{scl \\ _ best } } \\ right)$ } \\ xxunk } \n",
              " \t\t  \\ xxmaj state $ \\ mathbf{p}_i^ { \\ mathrm{best } } \\ leftarrow \\ xxunk \n",
              " \t\t  \\ xxmaj state do necessary scaling following step \\ xxunk } \n",
              " \t\t  \\ xxmaj if{$ \\ xxmaj sigma \\ left ( \\ mathbf{p}_{i}^ { \\ mathrm{scl \\ _ best } } \\ right ) > \\ mathrm { \\ xxmaj sigma } \\ left ( \\ mathbf{g}^ { \\ mathrm{scl \\ _ best } } \\ right)$ } \\ xxunk } \n",
              " \t\t  \\ xxmaj state $ \\ mathbf{g}^ { \\ mathrm{best } } \\ leftarrow \\ mathbf{p}_i^ { \\ mathrm{best}}$ \n",
              " \t\t  \\ endif \n",
              " \t\t  \\ endif \n",
              " \t\t  \\ endfor \n",
              " \t\t  \\ endwhile \n",
              " \t\t  \\ xxmaj state \\ textbf{return } $ \\ mathbf{g}^ { \\ mathrm{best}}$ and do necessary scaling following step \\ xxunk } and \\ textbf{return } $ \\ mathbf{g}^ { \\ mathrm{scl \\ _ xxunk \n",
              " \t  \\ end{algorithmic } \\ xxunk } \n",
              "  \\ end{algorithm } \n",
              " \n",
              " \n",
              "  % \\ xxunk observations on the algorithm ] \n",
              "  % xxmaj we model the algorithm such a way that we deal with the normalized particle position and velocity . \n",
              "  % xxmaj the constraints guide us to restrict the particle position in a probability range , while the summation can not exceed the cache storage capacity of the respective node . \n",
              "  % xxmaj therefore , we consider to limit the initial values in the range of $ [ xxunk / \\ xxunk \n",
              "  % xxmaj by doing so , when we perform the necessary scaling , the obtained number does not violate the probability range . \n",
              "  % xxmaj then , we correspondingly initialize the particle position and the velocity in steps \\ xxunk } and \\ xxunk } following this notion . \n",
              "  % xxmaj furthermore , the caching probabilities of the nodes in dimension $ j$ are limited to $ \\ xxunk , in steps \\ xxunk } and \\ xxunk } , hence , we choose the random number of contents , $ \\ xxunk ( \\ xxunk ) } $ , to be stored with higher probability values . \n",
              "  % \\ end{rem } \n",
              " \n",
              "  \\ section{results and xxmaj discussions } \n",
              "  % \\ xxunk } \n",
              "  \\ label{result } \n",
              " \n",
              "  xxmaj the simulation parameters are listed as follows : $ \\ xxunk = 10^{-4}$ ( per $ m^2 $ ) , $ \\ lambda_b = 10^{-5}$ ( per $ m^2 $ ) , $ \\ lambda_m = xxunk ( per $ m^2 $ ) , $ xxmaj xxunk = 15 m$ , $ xxmaj r_b = 150 m$ and $ xxmaj xxunk = 500 m$ , $ | \\ mathcal{f}| = [ 10 , xxunk , $ \\ alpha \\ in [ 0.2 , 0.5]$ , $ \\ xxunk } = 0.1 $ , $ \\ xxunk $ , $ a = 0.9 $ , $ \\ psi_1 = \\ xxunk $ , $ xxunk = 23 $ dbm , $ xxunk $ dbm , $ p_m = 43 $ dbm , $ \\ phi = xxunk db , $ \\ beta = 4 $ , $ \\ xxunk $ and $ \\ sigma^2 = xxunk $ dbm / xxmaj hz . \n",
              "  xxmaj monte xxmaj carlo simulation is used for performance evaluation . \n",
              "  % xxmaj in the following , we use the proposed m - xxup pso algorithm to attain the optimal caching placement solution . \n",
              "  % xxmaj after that , we study its performances for our hard - combinatorial maximization problem . \n",
              " \n",
              " \n",
              "  % \\ subsection{cache xxmaj placement } \n",
              "  xxmaj to show the effectiveness of the proposed algorithm , we firstly validate that the obtained results do not violate any of the constraints . \n",
              "  xxmaj the global best $ \\ mathbf{g}^ { \\ mathrm{scl \\ _ xxunk obtained from xxmaj alg.~ \\ xxunk } is therefore xxunk as follows . \n",
              "  xxmaj note that it must not violate any of the caching storage constraints of the edge nodes . \n",
              "  xxmaj besides , each of the caching probabilities must be in the range of $ [ 0,1]$. \n",
              "  xxmaj furthermore , each node must store different copies of the content . \n",
              "  xxmaj all these constraints are considered in the proposed algorithm . \n",
              "  xxmaj therefore , it is expected that the obtained results shall meet these requirements . \n",
              "  xxmaj the caching probabilities of $ xxunk and $ xxunk for xxup d2d users , sbss and mbss are illustrated in xxmaj fig.~ \\ xxunk } . \n",
              "  xxmaj it is readily observed that each node stores different copies . \n",
              "  xxmaj moreover , caching probabilities and storage constraints are also satisfied . \n",
              "  xxmaj now , we study the performance of our proposed m - xxup pso algorithm and make a fair comparison with the following benchmark caching schemes in this sub - section . \n",
              " \n",
              " \n",
              "  % \\ begin{figure } \\ vspace{-0.1 in } \n",
              "  % \t  \\ centering \n",
              "  % \\ includegraphics[width= 0.45 \\ textwidth ] { xxmaj figures / xxunk } \n",
              "  % % xxmaj if you do n't want the xxunk in the bar plot , please use the following line instead of the above one \n",
              "  % % \\ includegraphics[width= 0.45 \\ textwidth]{figures / xxunk } \n",
              "  % \\ vspace{-0.18 in } \n",
              "  % \t  \\ xxunk caching probabilities at the local nodes when $ \\ mathcal{c}_d = 2 $ , $ \\ mathcal{c}_b = 4 $ and $ \\ mathcal{c}_m = 8 $ } \n",
              "  % \t  \\ xxunk } \n",
              "  % \\ end{figure } \n",
              " \n",
              "  % \\ begin{figure } \\ vspace{-0.1 in } \n",
              "  % \t  \\ centering \n",
              "  % \\ includegraphics[width= 0.45 \\ textwidth ] { xxmaj figures / xxunk } \n",
              "  % % xxmaj if you do n't want the xxmaj error xxmaj bar in the bar plot , please use the following line instead of the above one \n",
              "  % % \\ includegraphics[width= 0.45 \\ textwidth]{figures / xxunk } \n",
              "  % \\ vspace{-0.18 in } \n",
              "  % \t  \\ xxunk using the proposed m - xxup pso algorithms for $ 100 $ iteration , $ | \\ mathcal{f}| = 30 $ , $ \\ mathcal{c}_d = 2 $ , $ \\ mathcal{c}_b = 4 $ and $ \\ mathcal{c}_m = 8 $ } \n",
              "  % \t  \\ xxunk } \n",
              "  % \\ end{figure } \n",
              " \n",
              " \n",
              "  % \\ begin{figure } \n",
              "  % \\ centering \n",
              "  % \\ includegraphics[width= 0.45 \\ textwidth ] { xxmaj figures / xxunk } \n",
              "  % \\ vspace{-0.18 in } \n",
              "  % \t  \\ xxunk of catalog size : xxup chr with $ \\ mathcal{c}_d = 2 $ , $ \\ mathcal{c}_b = 4 $ and $ \\ mathcal{c}_m = 8 $ } \n",
              "  % \t  \\ xxunk } \n",
              "  % \\ end{figure } \n",
              " \n",
              "  \\ begin{figure * } \\ vspace{-0.2 in } \n",
              "  \\ centering \n",
              "  \\ xxunk caching probabilities at the local \n",
              "  ewline nodes when $ \\ mathcal{c}_d = 2 $ , $ \\ mathcal{c}_b = 4 $ and $ \\ mathcal{c}_m = 8 $ ] { \\ xxunk } \\ includegraphics[width= 0.33 \\ textwidth ] { xxmaj figures / xxunk } } \n",
              " \t  \\ subfloat[chr comparison when $ | \\ mathcal{f}| = 30 $ , $ \\ mathcal{c}_d = 2 $ , \n",
              "  ewline $ \\ mathcal{c}_b = 4 $ and $ \\ mathcal{c}_m = 8 $ ] { \\ xxunk } \\ includegraphics[width= 0.33 \\ textwidth ] { xxmaj figures / xxunk } } \n",
              " \t  \\ xxunk of catalog size : xxup chr with $ \\ mathcal{c}_d = 2 $ , \n",
              "  ewline $ \\ mathcal{c}_b = 4 $ and $ \\ mathcal{c}_m = 8 $ ] { \\ xxunk } \n",
              " \t  \\ includegraphics[width= 0.33 \\ textwidth ] { xxmaj figures / xxunk } } \n",
              " \t  \\ caption{performance observation of the proposed m - xxup pso algorithm } \n",
              " \t  \\ xxunk } \n",
              "  \\ end{figure * } \n",
              " \n",
              "  \\ begin{figure * } \\ vspace{-0.2 in } \n",
              " \t  \\ centering \n",
              " \t  \\ subfloat[chr for different user cache storage sizes ] { \\ xxunk } \\ includegraphics[width= 0.33 \\ textwidth ] { xxmaj figures / xxunk } } \n",
              " \t  \\ subfloat[chr for different sbs cache storage sizes ] { \\ xxunk } \\ includegraphics[width= 0.33 \\ textwidth ] { xxmaj figures / xxunk } } \n",
              " \t  \\ subfloat[chr for different xxup mbs cache storage sizes ] { \\ xxunk } \\ includegraphics[width= 0.33 \\ textwidth ] { xxmaj figures / xxunk } } \n",
              " \t  \\ xxunk of cache size on xxup chr } \n",
              " \t  \\ xxunk } \n",
              "  \\ end{figure * } % \\ vspace{-0.1 in } \n",
              " \n",
              " \n",
              "  \\ textbf { \\ textit{random xxmaj caching xxmaj scheme } } : \n",
              "  xxmaj in the random caching scheme , contents are stored randomly while satisfying the constraints . \n",
              " \n",
              "  \\ textbf { \\ xxunk xxmaj caching xxmaj scheme } } : \n",
              "  xxmaj in the equal caching scheme , each content is placed with the same probability . \n",
              " \n",
              "  xxmaj the proposed algorithm runs $ 100 $ iterations and it effectively converges . \n",
              "  xxmaj fig.~ \\ xxunk } demonstrates the xxup chr comparison of the proposed algorithm with the random caching scheme and equal caching scheme . \n",
              "  xxmaj it can be seen that the xxup xxunk achieves $ \\ approx 60 \\ % $ higher performance gain over these benchmark caching schemes . \n",
              "  xxmaj in the following , we use our algorithm to evaluate the system performance in terms of different parameter settings . \n",
              " \n",
              " \n",
              "  \\ subsubsection{impact of the xxmaj catalog xxmaj size } \n",
              " \n",
              "  % xxmaj recall that if the requested content is delivered from one of the cache - enabled edge nodes , a cache hit occurs . \n",
              "  xxmaj considering the catalog size = $ [ 10 , xxunk , we aim to store as many to - be - requested contents as possible into the local edge nodes . \n",
              "  % xxmaj furthermore , the intensities are set as $ \\ xxunk = 10^{-4}$ , $ \\ lambda_b = 10^{-5}$ and $ \\ lambda_m = xxunk \n",
              "  xxmaj the total number of iterations is chosen as $ 100 \\ times [ 1 , 10 , 20 , 40 , xxunk for the catalog size in $ [ 10 , 20 , 30 , 40 , xxunk , respectively . \n",
              "  xxmaj if the catalog size increases , the number of possible combinations also increases . \n",
              "  xxmaj therefore , whenever the content catalog increases , we slightly increase the total number of iterations . \n",
              "  xxmaj also , if the total number of contents increases and there are only a limited number of cache - enabled nodes , the chance of storing the contents locally decreases , meaning that more content requests need to be served from the cloud . \n",
              "  xxmaj therefore , the $ \\ xxmaj sigma$ should decrease if the content catalog increases . \n",
              "  xxmaj moreover , if the percentage of the requester nodes increases , the performance should degrade as we consider the heterogeneous preference of the users . \n",
              "  xxmaj fig.~ \\ xxunk } also demonstrates that if we increase the catalog size , $ | \\ xxunk or the number of requests ( $ \\ alpha$ ) , then $ \\ xxmaj sigma$ decreases . \n",
              " \n",
              " \n",
              "  \\ subsubsection{impact of the xxmaj storage xxmaj size } \n",
              "  % xxmaj we now investigate the impact of the cache sizes of the edge nodes on the system performance . \n",
              "  xxmaj recall that if the cache size increases , more contents can be stored at the cache - enabled nodes . \n",
              "  xxmaj therefore , increasing the cache size of the users means that users store more contents in their local storage . \n",
              "  xxmaj as these storage sizes increase , the proposed m - xxup pso algorithm determines the optimal caching placements . \n",
              "  xxmaj the simulation results , presented in xxmaj fig.~ \\ xxunk } , validate that as the storage size increases , more contents are locally stored leading to an improvement of xxup chr . \n",
              "  xxmaj note that increasing xxup mbs cache size provides a lower xxup chr gain than increasing the cache size of the xxup d2d users ( or , the sbss ) . \n",
              "  xxmaj this is because the total number of mbss is typically much lower than that of the available xxup d2d ( or , sbs ) nodes . \n",
              " \n",
              "  \\ xxunk } \n",
              "  \\ section{conclusion } \n",
              "  \\ xxunk } \n",
              "  xxmaj caching solution helps to achieve better system performances . \n",
              "  xxmaj however , the hard combinatorial decision - making problem of placing the contents at the local nodes is challenging . \n",
              "  xxmaj the e grand problem is effectively solved with good accuracy by using the artificial intelligence based technique . \n",
              "  xxmaj considering heterogeneous content preferences in a real - world network platform , the proposed algorithm converges fast and achieves a much better performance than the existing benchmark caching schemes . \n",
              " \n",
              " \n",
              "  % \\ section*{acknowledgment } \n",
              "  % xxmaj the authors sincerely thank xxmaj xxunk xxmaj shah for the critical and helpful % discussions during this work . \n",
              " \n",
              "  \\ bibliography{reference } \n",
              "  \\ bibliographystyle{ieeetran } \n",
              " \n",
              "  \\ end{document } \n",
              " \n",
              " ,xxbos \\ documentclass[10pt , twocolumn , letterpaper]{article } \n",
              " \n",
              "  \\ usepackage{cvpr } \n",
              "  \\ usepackage{times } \n",
              "  \\ usepackage{epsfig } \n",
              "  \\ usepackage{graphicx } \n",
              "  \\ usepackage{amsmath } \n",
              "  \\ usepackage{amssymb } \n",
              "  \\ usepackage{bm } \n",
              "  \\ usepackage{rotating } \n",
              "  \\ usepackage{mathtools } \n",
              "  \\ xxunk } \n",
              " \n",
              "  ewcommand { \\ r } { \\ mathbb{r } } \n",
              "  % xxmaj include other packages here , before hyperref . \n",
              " \n",
              "  % xxmaj if you comment hyperref and then uncomment it , you should delete \n",
              "  % egpaper.aux before re - running latex . ( xxmaj or just hit ' q ' on the first latex \n",
              "  % run , let it finish , and you should be clear ) . \n",
              "  \\ usepackage[pagebackref = true , breaklinks = true , letterpaper = true , colorlinks , bookmarks = false]{hyperref } \n",
              " \n",
              "  \\ cvprfinalcopy % * * * xxmaj uncomment this line for the final submission \n",
              " \n",
              "  \\ def \\ xxunk } % * * * xxmaj enter the xxup cvpr xxmaj paper xxup id here \n",
              "  \\ def \\ httilde { \\ mbox { \\ tt \\ raisebox{-.5ex } { \\ symbol{126 xxrep 4 } \n",
              " \n",
              "  % xxmaj pages are numbered in submission mode , and unnumbered in camera - ready \n",
              "  \\ ifcvprfinal \\ pagestyle{empty } \\ fi \n",
              "  \\ begin{document } \n",
              " \n",
              "  xxrep 9 % xxup title \n",
              "  \\ xxunk and xxmaj accurate xxmaj fine - grained xxmaj recognition via xxmaj region xxmaj grouping } \n",
              " \n",
              "  \\ xxunk xxmaj xxunk $ \\ quad \\ quad xxmaj yin xxmaj xxunk \\ \\ \n",
              "  $ ^1$department of xxmaj computer xxmaj sciences , $ ^2$department of xxmaj xxunk and xxmaj medical xxmaj informatics \\ \\ \n",
              "  xxmaj university of xxmaj xxunk -- xxmaj xxunk \\ \\ \n",
              "  { \\ tt \\ small \\ { xxunk , xxunk \\ } xxunk } \n",
              "  } % \n",
              " \n",
              "  \\ maketitle \n",
              "  \\ thispagestyle{empty } \n",
              " \n",
              "  xxrep 9 % xxup abstract \n",
              "  \\ begin{abstract } \n",
              "  \\ input{src / abstract.tex } \n",
              "  \\ end{abstract } \n",
              " \n",
              "  % xxmaj introduction \n",
              "  \\ input{src / intro.tex } \n",
              " \n",
              "  % xxmaj related xxmaj work \n",
              "  \\ input{src / related_work.tex } \n",
              " \n",
              "  % xxmaj method \n",
              "  \\ input{src / method.tex } \n",
              " \n",
              "  % xxmaj experiments and xxmaj results \n",
              "  \\ input{src / xxunk } \n",
              " \n",
              "  % xxmaj conclusion \n",
              "  \\ input{src / conclusion.tex } \n",
              " \n",
              " \n",
              "  \\ bibliographystyle{ieee_fullname } \n",
              "  \\ xxunk } \n",
              " \n",
              " \n",
              "  \\ end{document } \n",
              " ,xxbos \\ def \\ year{2020 } \\ relax \n",
              "  \\ documentclass[letterpaper]{article } \n",
              "  \\ usepackage{aaai20 } \n",
              "  \\ usepackage{times } \n",
              "  \\ usepackage{helvet } \n",
              "  \\ usepackage{courier } \n",
              "  % \\ usepackage[hyphens]{url } \n",
              "  % \\ usepackage{parskip } \n",
              " \n",
              "  \\ xxunk } \n",
              " \n",
              " \n",
              "  ewcommand { \\ xxunk \\ xxunk , xxup g)$ } \n",
              " \n",
              "  ewcommand { \n",
              "  xxunk \\ eta$ \\ xxunk } } \n",
              " \n",
              " \n",
              "  ewcommand { \\ xxunk ] { \\ todo [ # 1,color = xxunk \\ xxunk : # 2 } } \n",
              " \n",
              "  ewcommand { \\ xxunk ] { \\ todo [ # 1,color = xxunk \\ xxunk : # 2 } } \n",
              " \n",
              "  ewcommand { \\ xxunk ] { \\ todo [ # 1,color = xxunk \\ xxunk : # 2 } } \n",
              " \n",
              " \n",
              "  ewcommand { \\ idest } { { \\ it i.e. } } \n",
              " \n",
              "  ewcommand { \\ exemp } { { \\ it e.g. } } \n",
              " \n",
              "  ewcommand { \\ etc } { { \\ it etc . } } \n",
              " \n",
              "  ewcommand { \\ etal } { { \\ it et al . } } \n",
              " \n",
              "  \\ xxunk } \n",
              " \n",
              "  \\ usepackage{graphicx } \n",
              "  \\ frenchspacing \n",
              "  \\ setlength { \\ pdfpagewidth}{8.5 in } \n",
              "  \\ setlength { \\ pdfpageheight}{11 in } \n",
              " \n",
              "  \\ pdfinfo { \n",
              "  / xxmaj title ( xxmaj the xxmaj more the xxmaj xxunk ? xxmaj evaluating the xxmaj effect of xxmaj landmark xxmaj extraction xxmaj algorithms on xxmaj landmark - xxmaj based xxmaj goal xxmaj recognition ) \n",
              "  / xxmaj author ( xxmaj kin xxmaj max xxmaj xxunk xxmaj xxunk , xxmaj xxunk xxmaj fraga xxmaj pereira , and xxmaj felipe xxmaj meneguzzi ) \n",
              "  } \n",
              " \n",
              "  \\ setcounter{secnumdepth}{2 } \n",
              " \n",
              "  \\ setlength \\ titlebox{2.5 in } \n",
              " \n",
              "  \\ title{the xxmaj more the xxmaj xxunk ? ! xxmaj evaluating the xxmaj effect of xxmaj landmark xxmaj extraction xxmaj algorithms on xxmaj landmark - xxmaj based xxmaj goal xxmaj recognition } \n",
              " \n",
              "  \\ author { \n",
              "  xxmaj kin xxmaj max xxmaj xxunk xxmaj xxunk , xxmaj xxunk xxmaj fraga xxmaj pereira , and xxmaj felipe xxmaj meneguzzi \\ \\ \n",
              "  xxmaj xxunk xxmaj catholic xxmaj university of xxmaj rio xxmaj grande do xxmaj xxunk ( xxup xxunk ) , xxmaj brazil \\ \\ \n",
              "  % xxmaj graduate xxmaj program in xxmaj computer xxmaj science , xxmaj school of xxmaj technology \\ \\ \n",
              "  \\ xxunk } , \\ xxunk } \\ \\ \n",
              "  \\ xxunk } \n",
              "  } \n",
              " \n",
              "  \\ begin{document } \n",
              " \n",
              "  \\ maketitle \n",
              " \n",
              "  % xxrep 76 - \n",
              "  \\ begin{abstract } \n",
              " \t \n",
              "  xxmaj recent approaches to goal and plan recognition using classical planning domains have achieved state of the art results in terms of both recognition time and accuracy by using heuristics based on planning landmarks . \n",
              "  xxmaj to achieve such fast recognition time these approaches use efficient , but incomplete , algorithms to extract only a subset of landmarks for planning domains and problems , at the cost of some accuracy . \n",
              "  xxmaj in this paper , we investigate the impact and effect of using various landmark extraction algorithms capable of extracting a larger proportion of the landmarks for each given planning problem , up to exhaustive landmark extraction . \n",
              "  xxmaj we perform an extensive empirical evaluation of various landmark - based heuristics when using different percentages of the full set of landmarks . \n",
              "  xxmaj results show that having more landmarks does not necessarily mean achieving higher accuracy and lower spread , as the additional extracted landmarks may not necessarily increase be helpful towards the goal recognition task . \n",
              "  \\ end{abstract } \n",
              "  % xxrep 76 - \n",
              " \n",
              "  % xxrep 76 - \n",
              "  \\ section{introduction } \n",
              " \n",
              "  xxmaj anticipating and recognizing correctly the intended goal that an observed agent aims to achieve based on its interactions in an environment is an important task for several real - world applications~ \\ xxunk } , such as intent recognition for xxunk - xxunk \\ xxunk } , exploratory domain models~ \\ xxunk } , offline and online goal recognition in latent space~ \\ xxunk , xxunk } , and others . \n",
              "  xxmaj most approaches to goal and plan recognition rely on either plan xxunk \\ xxunk } or planning domain theory~ \\ xxunk } . \n",
              "  xxmaj recent work on goal recognition as planning has avoided running a full - fledged planner for recognizing goals , and recent approaches in the literature have successfully exploited the use of well - known automated planning techniques , such as planning graphs~ \\ xxunk } and xxunk \\ xxunk } . \n",
              "  xxmaj thus , as a result of exploiting planning techniques , such approaches have shown that it is possible to recognize goals and plans not only accurately , but also very quickly . \n",
              " \n",
              "  xxmaj in this paper , we investigate the effect of using various landmark extraction algorithms over the landmark - based heuristic to goal recognition proposed by xxmaj pereira , xxmaj oren , and xxmaj meneguzzi~ \\ shortcite{ramonnirmeneguzzi_aaai2017 } . \n",
              "  xxmaj for extracting landmarks , we use five landmark extraction algorithms~ \\ xxunk , xxunk , rhw , hm } from the planning literature . \n",
              "  xxmaj to do so , we use an exhaustive extraction algorithm ( i.e. , an extraction approach that exhaustively checks if all facts are landmark by using a relaxed planning graph ) , and use other extraction algorithms that extract only a subset of xxunk \\ xxunk , xxunk , rhw , hm } . \n",
              "  xxmaj thus , the main contribution of this paper is investigating the real impact of using more or fewer landmarks in the landmark - based goal recognition heuristics . \n",
              " \n",
              "  xxmaj we conduct extensive experiments to empirically evaluate the impact and effect of using a variety different landmark extraction algorithms over landmark - based recognition heuristics using well - known recognition datasets~ \\ xxunk } with missing and full observations , and noisy , missing , and full observations . \n",
              "  xxmaj results show that using more landmarks does not necessarily lead to improved precision and accuracy of the landmark - based heuristics , as the quality of the extracted landmarks is generally more important than the quantity . \n",
              " \n",
              "  xxmaj the remainder of this paper is organized as follows . \n",
              "  xxmaj section~ \\ ref{section : background } provides essential background on planning , goal recognition , and landmarks . \n",
              "  xxmaj we review the landmark - based heuristic approaches we use along with various landmark extraction algorithms in xxmaj section~ \\ ref{section : xxunk } . \n",
              "  xxmaj in xxmaj section~ \\ ref{section : xxunk } , we proceed to evaluate empirically the recognition heuristics we review . \n",
              "  xxmaj finally , in xxmaj section~ \\ ref{section : conclusions } , we conclude this paper by discussing the real impact of using more or fewer landmarks in the heuristics , and provide future directions of how such heuristics could be improved by taking advantage of more landmarks . \n",
              " \n",
              "  % xxrep 76 - \n",
              "  \\ section{background } \\ label{section : background } \n",
              " \n",
              "  % xxrep 72 # \n",
              "  \\ subsection{planning } \n",
              " \n",
              "  xxmaj planning is the problem of finding a sequence of actions ( \\ idest , a plan ) that achieves a goal from an initial state~ \\ xxunk } . \n",
              "  a \\ textit{state } is a finite set of facts that represent logical values according to some interpretation . \n",
              "  \\ xxunk } can be either positive , or negated ground predicates . \n",
              "  a predicate is denoted by an n - ary predicate symbol $ p$ applied to a sequence of zero or more terms ( $ \\ tau_1 $ , $ \\ xxunk $ , ... , $ \\ xxunk ) . \n",
              "  xxmaj an \\ xxunk } is represented by a triple $ a$ $ = $ $ \\ langle$ \\ xxunk ) , \\ xxunk ) , \\ xxunk \\ rangle$ where \\ xxunk ) represents the description or signature of $ a$ ; \\ xxunk ) describes the preconditions of $ a$ --- a set of facts or predicates that must exist in the current state for $ a$ to be executed ; $ \\ xxunk \\ xxunk \\ cup \\ xxunk represents the effects of $ a$ , with \\ xxunk an \\ xxunk - list } of positive facts or predicates , and \\ xxunk a \\ xxunk - list } of negative facts or predicates . \n",
              "  xxmaj when we instantiate an operator over its free variables , we call the resulting ground operator an \\ emph{action } . \n",
              "  a \\ textit{planning instance } is represented by a triple $ \\ xxmaj pi = \\ langle \\ xxmaj xi , \\ mathcal{i } , g \\ rangle$ , in which $ \\ xxmaj xi = \\ langle \\ xxmaj sigma , \\ mathcal{a } \\ rangle$ is a \\ textit{planning domain definition } ; $ \\ xxmaj sigma$ consists of a finite set of facts and $ \\ mathcal{a}$ a finite set of actions ; $ \\ mathcal{i}$ $ \\ subseteq$ $ \\ xxmaj sigma$ is the initial state ; and $ xxup g$ $ \\ subseteq$ $ \\ xxmaj sigma$ is the goal state . \n",
              "  a \\ xxunk } is a sequence of actions $ \\ pi = \\ langle a_1 , a_2 , ... , a_n \\ rangle$ that modifies the initial state $ \\ mathcal{i}$ into one in which the goal state $ xxup g$ holds by the successive execution of actions in a plan $ \\ pi$. xxmaj while actions have an associated cost , as in classical planning , in this paper we assume that this cost is 1 for all actions . a plan $ \\ pi$ is considered optimal if its cost , and thus length , is minimal . \n",
              " \n",
              "  % xxrep 72 # \n",
              "  \\ subsection{goal xxmaj recognition } \n",
              " \n",
              "  xxmaj goal recognition is the task of xxunk the intended goal of autonomous agents or humans by observing their interactions in a particular environment~ \\ cite[chapter xxunk } . \n",
              "  xxmaj such observed interactions are defined as available evidence that can be used to recognize goals . xxmaj we formally define the problem of goal recognition over planning domain theory by adopting the formalism proposed by xxmaj ram { \\ ' { \\ xxunk and xxmaj xxunk \\ xxunk } , as follows in xxmaj definition~ \\ ref{def : xxunk } . \n",
              " \n",
              "  \\ begin{definition } [ \\ textbf{goal xxmaj recognition xxmaj problem } ] \\ label{def : xxunk } \n",
              "  a goal recognition problem is a tuple $ xxup xxunk $ = $ $ \\ langle \\ xxmaj xi , \\ mathcal{i } , \\ mathcal{g } , o \\ rangle$ , in which $ \\ xxmaj xi = \\ langle \\ xxmaj sigma , \\ mathcal{a } \\ rangle$ is a planning domain definition ; $ \\ mathcal{i}$ is the initial state ; $ \\ mathcal{g}$ is the set of possible goals , which include the correct intended goal $ xxup xxunk ( \\ idest , $ xxup xxunk $ \\ in$ $ \\ mathcal{g}$ ) ; and $ xxup o$ $ = $ $ \\ xxunk $ , $ o_2 $ , ... , $ xxunk \\ rangle$ is an observation sequence of executed actions , with each observation $ o_i \\ in \\ mathcal{a}$. \n",
              "  \\ end{definition } \n",
              " \n",
              "  xxmaj the ideal solution for a goal recognition problem is finding the correct intended goal $ xxup g^ { * } \\ in \\ mathcal{g}$ that the observation sequence $ xxup o$ of a plan execution achieves . \n",
              "  xxmaj an observation sequence can be full or partial --- in a full observation sequence we observe all actions of an agent 's plan ; in a partial observation sequence , only a sub - sequence of actions are observed . a noisy observation sequence contains one or more actions ( or a set of facts ) that might not be part of a plan that achieves a particular goal , \\ exemp , when a sensor fails and generates abnormal or spurious readings . \n",
              " \n",
              "  % xxrep 72 # \n",
              "  \\ xxunk } \n",
              " \n",
              "  xxmaj in the planning literature , landmarks are defined as necessary fact ( or actions ) that must be true ( or executed ) at some point along all valid plans that achieve a particular goal from an initial state . xxmaj landmarks are often partially ordered based on the sequence in which they must be achieved . \n",
              "  xxmaj hoffman \\ etal~ \\ shortcite{hoffmann2004_orderedlandmarks } define fact landmarks as follows : \n",
              " \n",
              "  \\ begin{definition } [ \\ xxunk xxmaj landmark } ] \\ label{def : xxunk } \n",
              "  xxmaj given a planning instance $ \\ xxmaj pi = \\ langle \\ xxmaj xi , \\ mathcal{i } , g \\ rangle$ , a formula $ xxup l$ is a fact landmark in $ \\ xxmaj pi$ iff $ xxup l$ is true at some point along all valid plans that achieve $ xxup g$ from $ \\ mathcal{i}$. \n",
              "  a landmark is a type of formula ( \\ exemp , a conjunctive or disjunctive formula ) over a set of facts that must be satisfied at some point along all valid plan executions . \n",
              "  \\ end{definition } \n",
              " \n",
              "  xxmaj hoffman \\ etal~ \\ shortcite{hoffmann2004_orderedlandmarks } proves that the process of generating all landmarks and deciding their ordering is xxup pspace - complete , which is exactly the same complexity as deciding plan xxunk \\ xxunk } . \n",
              "  xxmaj thus , to operate efficiently , most landmark extraction algorithms extract only a subset of landmarks for a given planning instance . \n",
              " \n",
              "  % xxrep 72 # \n",
              "  \\ xxunk xxmaj extraction xxmaj algorithms } \n",
              " \n",
              "  % xxmaj we use various landmark extraction algorithms to investigate whether more or fewer landmarks impact in the recognition accuracy of landmark - based heuristics for goal recognition , and now , we present in detail the landmark extraction algorithms we use in this paper . \n",
              "  xxmaj in this paper , we use the following landmark extraction algorithms to investigate how the number of landmarks impacts on the recognition accuracy of landmark - based heuristics for goal recognition . \n",
              " \n",
              " \n",
              "  oindent \\ textit{exhaust } : xxmaj the first algorithm is an exhaustive extraction approach , its name says for itself , and we denote this algorithm as \\ textit{exhaust } . xxmaj this algorithm exhaustively extracts landmarks for a given planning instance . xxmaj namely , this algorithm uses a xxmaj relaxed xxmaj planning xxmaj graph ( xxup rpg ) and exhaustively checks every fact in the xxup rpg for if it is a landmark or not . xxmaj this is done by removing the fact from the xxup rpg and checking if the goal is still reachable without the given fact , and if not , such fact is considered as a landmark . xxmaj the number of landmarks extracted by this algorithm is used as a baseline in our experiments , as it can extract all landmarks for a planning instance . \n",
              " \n",
              " \n",
              "  oindent $ h^m$ : \\ xxunk \\ xxunk } developed a landmark extraction algorithm that performs a transformation of the original problem $ \\ xxmaj pi$ , originating a new problem $ \\ xxmaj xxunk , in which each fact is a set of facts of size $ m$ , originated from the original problem 's facts . xxmaj the actions are obtained by adding facts that are not required or caused by any action but might be true during plan development , to the action 's preconditions and effects . xxmaj the result is a problem without delete effects that yet has information on the delete effects of the original problem , hence allowing the extraction of landmarks that take delete effects into count . xxmaj this extraction algorithm is denoted as $ xxunk \n",
              " \n",
              " \n",
              "  oindent \\ textit{rhw } : xxmaj in~ \\ xxunk } , \\ xxunk \\ xxunk } develop a landmark extraction algorithm that starts the process by selecting an initial fact landmark , and from this initial landmark , it creates disjunctive sets from the preconditions of the actions that are first xxunk of the initial landmark . xxmaj each disjunctive set is then recorded as a landmark , and ordered before the initial landmark . xxmaj this extraction process is then repeated for all recorded landmarks . xxmaj we denote this algorithm as \\ textit{rhw } . \n",
              " \n",
              " \n",
              "  oindent \\ textit{zhu \\ & xxmaj givan } : xxmaj zhu and xxmaj xxunk \\ xxunk } developed a landmark extraction algorithm that works differently than the ones mentioned above . xxmaj this algorithm works by propagating labels across the planning graph , where each label is a fact or an action . a fact or action at a level $ i$ must be labeled with any fact or action that must occur in any $ xxunk plan that reaches it . xxmaj it starts by labeling each action in the first action level with itself . xxmaj every subsequent action level is then labeled with the union of the labels on its precondition fact nodes , while every subsequent fact node is labeled with the intersection of the labels on the action nodes that reach it . xxmaj at the last level , every label on a goal node is considered a landmark . xxmaj this algorithm is denoted as \\ textit{zhu \\ & xxmaj givan } . \n",
              " \n",
              " \n",
              " \n",
              "  oindent \\ textit{hoffmann et al . } : xxmaj the extraction algorithm originally used by \\ xxunk } is the landmark extraction algorithm of xxmaj hoffman \\ etal~ \\ shortcite{hoffmann2004_orderedlandmarks } . \n",
              "  xxmaj initially , this algorithm builds an xxup rpg ( ignoring all delete effects of all actions ) from the initial state to the goal state , and starts selecting all facts in goal state as candidate landmarks . \n",
              "  xxmaj afterward , it selects the preconditions for all actions that achieve each candidate landmark , checking if those are landmarks by removing them from the graph and checking the reachability of the goal . \n",
              "  xxmaj after , it records as landmarks all preconditions that passed this check and then repeats the process for every fact level on the graph back to the initial state . \n",
              "  xxmaj similar to the \\ textit{exhaust } method , this algorithm evaluates whether a candidate landmark is indeed a landmark by testing the solvability of the problem by removing all actions that achieve such candidate landmark , and if the problem is unsolvable , then this candidate landmark is indeed a landmark . \n",
              "  xxmaj we denote this algorithm as \\ textit{hoffmann et al . } \n",
              " \n",
              "  % xxrep 76 - \n",
              "  \\ xxunk - xxmaj based xxmaj goal xxmaj recognition } \\ label{section : xxunk } \n",
              " \n",
              "  xxmaj we now describe the goal recognition heuristics that rely on planning landmarks that we use to evaluate the effect of using different landmark extraction algorithms . xxmaj such heuristics have proved to be accurate and very quick for recognizing goals over a variety of domain models~ \\ xxunk } . \n",
              " \n",
              "  xxmaj the first landmark - based heuristic proposed by xxmaj pereira , xxmaj oren , and xxmaj meneguzzi~ \\ shortcite{ramonnirmeneguzzi_aaai2017 } is called \\ emph{goal completion heuristic } , and denoted as $ \\ xxunk \n",
              "  xxmaj basically , this heuristic computes a score for a goal $ xxup g$ by calculating the ratio between the number achieved landmarks for $ xxup g$ and the total number of extracted landmarks for $ xxup g$. \n",
              "  xxmaj this score represents the percentage of completion of goal based on the ratio of achieved landmarks and the total number of landmarks . \n",
              " \n",
              "  xxmaj as an extension of $ \\ xxunk , the second heuristic developed by xxmaj pereira , xxmaj oren , and xxmaj meneguzzi~ \\ shortcite{ramonnirmeneguzzi_aaai2017 } exploits the concept of \\ emph{landmark uniqueness xxunk \\ xxunk } , which is a value that represents how unique a landmark is among the set of landmarks for all possible goals . \n",
              "  xxmaj this heuristic is called \\ emph{landmark uniqueness heuristic } , and denoted as $ \\ xxunk \n",
              "  xxmaj thus , by using this uniqueness value , $ \\ xxunk estimates which possible goal is most likely the intended one by summing the uniqueness values of the landmarks achieved in the observations . \n",
              " \n",
              "  % % xxrep 72 # \n",
              "  % \\ subsection{goal xxmaj completion xxmaj heuristic } \n",
              "  % \n",
              "  % % xxrep 72 # \n",
              "  % \\ xxunk xxmaj heuristic } \n",
              " \n",
              "  % xxrep 76 - \n",
              "  \\ section{experiments and xxmaj evaluation } \\ label{section : xxunk } \n",
              " \n",
              "  xxmaj in this section , we present the experiments and evaluations we carried out from using various extraction algorithms over the landmark - based goal recognition heuristics . \n",
              " \n",
              "  % xxrep 72 # \n",
              "  \\ subsection{domains and xxmaj setup } \n",
              " \n",
              "  xxmaj for evaluating each one of the landmark extraction algorithms using both recognition heuristics , we executed several tests using datasets created by xxmaj pereira and xxmaj meneguzzi \\ xxunk } , containing several non - trivial recognition problems . \n",
              "  xxmaj these datasets contain goal recognition problems from 15 classical planning domains and include problems with noisy observations . \n",
              "  xxmaj the domains we used are : xxmaj blocks xxmaj world , xxmaj campus , xxmaj depots , xxmaj xxunk xxmaj worker xxmaj robots , xxmaj xxunk , xxmaj easy xxup xxunk xxmaj grid , xxmaj ferry , xxmaj intrusion xxmaj detection , xxmaj logistics , xxmaj xxunk , xxmaj rovers , xxmaj satellite , xxmaj sokoban and xxmaj zeno xxmaj travel . \n",
              "  xxmaj the xxmaj kitchen domain has been removed from our evaluation , as it is an adaptation of an xxup xxunk planning domain and it caused some issues when using some of the landmark extractors . \n",
              " \n",
              "  xxmaj each domain in these datasets includes recognition problems with partial and full observations . \n",
              "  xxmaj partial observations vary the level ( percentage ) of observability between 10 \\ % , 30 \\ % , 50 \\ % and 70 \\ % of actions observed for missing observations , and 100 \\ % for full observations . \n",
              "  xxmaj for problems with noisy observations , the level ( percentage ) of observability varies between 25 \\ % , 50 \\ % and 75 \\ % of observed actions for missing observations , and consequently 100 \\ % for full observations . \n",
              " \n",
              "  % xxmaj xxunk \n",
              " \n",
              "  % xxmaj with this experimentation setup , we aim to have a complete vision on how each of the heuristics behave when allied to each of the algorithms , with various recognition thresholds . \n",
              " \n",
              "  % xxrep 72 # \n",
              "  \\ subsection{evaluation xxmaj metrics } \n",
              " \n",
              "  xxmaj to evaluate the recognition heuristics , we use three metrics : recognition time ( xxmaj time ) , accuracy ( xxmaj acc \\ % ) and xxmaj spread in $ \\ mathcal{g}$ ( s in $ \\ mathcal{g}$ ) . \n",
              "  xxmaj the recognition time metric is simply the time in seconds that the algorithm took to return the set of recognized goals , including the time for extracting the landmarks . \n",
              "  xxmaj accuracy is a percentage that represents the average number of problems in which the correct goal was among the recognized goals list . \n",
              "  xxmaj finally , xxmaj spread in $ \\ mathcal{g}$ is the average number of returned goals , when multiple goal hypotheses were tied in the recognition algorithm . \n",
              "  xxmaj to have a concise precision metric of the approach , we combine accuracy and xxmaj spread in $ \\ mathcal{g}$ to obtain a third metric . \n",
              "  xxmaj this metric can be considered as a precision metric and is obtained by calculating the ratio between accuracy and xxmaj spread in $ \\ mathcal{g}$. \n",
              " \n",
              "  xxmaj since our goal is to find out if there is a relation between the number of extracted landmarks and the effectiveness of a landmark - based goal recognition technique , we also use a metric to evaluate the extraction capability of each landmark extraction algorithm . \n",
              "  xxmaj we do this by calculating the ratio between the number of landmarks extracted by each algorithm and the number of landmarks extracted by the \\ textit{exhaust } algorithm , since it can extract all landmarks in the planning instance . xxmaj the result is the percentage of extracted landmarks . \n",
              " \n",
              "  % xxrep 72 # \n",
              "  \\ subsection{results : xxmaj missing and xxmaj full xxmaj observations } \n",
              " \n",
              "  xxmaj we now present the results for datasets with missing and full observations . \n",
              "  xxmaj table \\ ref{tab : results } shows the results comparing the use of the five different extraction algorithms along with the landmark - based heuristics . \n",
              "  xxmaj we can see the average number of landmarks extracted , represented by $ \\ mathcal{l}$ , average recognition time in seconds , average accuracy ( xxmaj acc \\ % ) and average xxmaj spread in $ \\ mathcal{g}$ ( s in $ \\ mathcal{g}$ ) for each combination of extraction algorithm and threshold used for heuristics $ xxunk and $ xxunk \n",
              "  xxmaj columns represent different levels of observability . \n",
              " \n",
              "  \\ begin{table*}[ht ! ] \n",
              "  \\ centering \n",
              "  \\ xxunk } \\ selectfont \n",
              "  \\ setlength \\ tabcolsep{3pt } \n",
              "  \\ begin{tabular } { xxrep 5 r @ { \\ hspace*{8mm}}rrr@ { \\ hspace*{8mm}}rrr@ { \\ hspace*{8mm}}rrr@ { \\ xxunk } \n",
              "  \\ toprule \t \n",
              "  \\ hline \n",
              " \n",
              "  & \n",
              "  & \\ multicolumn{3}{c } { \\ bf 10 \\ % } \n",
              "  & \\ multicolumn{3}{c } { \\ bf 30 \\ % } \n",
              "  & \\ multicolumn{3}{c } { \\ bf 50 \\ % } \n",
              "  & \\ multicolumn{3}{c } { \\ bf 70 \\ % } \n",
              "  & \\ multicolumn{3}{c } { \\ bf 100 \\ % } \\ \\ \\ hline \n",
              " \n",
              "  \\ xxunk } \n",
              "  & $ | \\ xxunk \n",
              "  & \\ multicolumn{1}{r } { \\ bf xxmaj time } & \\ multicolumn{1}{r } { \\ bf xxmaj acc \\ % } & \\ multicolumn{1}{l } { \\ bf s in $ \\ mathcal{g}$ } \n",
              "  & \\ multicolumn{1}{r } { \\ bf xxmaj time } & \\ multicolumn{1}{r } { \\ bf xxmaj acc \\ % } & \\ multicolumn{1}{l } { \\ bf s in $ \\ mathcal{g}$ } \n",
              "  & \\ multicolumn{1}{r } { \\ bf xxmaj time } & \\ multicolumn{1}{r } { \\ bf xxmaj acc \\ % } & \\ multicolumn{1}{l } { \\ bf s in $ \\ mathcal{g}$ } \n",
              "  & \\ multicolumn{1}{r } { \\ bf xxmaj time } & \\ multicolumn{1}{r } { \\ bf xxmaj acc \\ % } & \\ multicolumn{1}{l } { \\ bf s in $ \\ mathcal{g}$ } \n",
              "  & \\ multicolumn{1}{r } { \\ bf xxmaj time } & \\ multicolumn{1}{r } { \\ bf xxmaj acc \\ % } & \\ multicolumn{1}{r } { \\ bf s in $ \\ mathcal{g}$ } \\ \\ \\ hline \n",
              "  $ \\ mathit{h_{gc}}$ ( xxmaj exhaust $ \\ theta = 0 $ ) \n",
              "  & 36.9 & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 84.2 \\ % & xxunk \n",
              "  & xxunk & 89.9 \\ % & xxunk \n",
              "  & xxunk & 96.4 \\ % & xxunk \n",
              "  & xxunk & 99.6 \\ % & 1.025 \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{gc}}$ ( xxmaj exhaust $ \\ theta = 10 $ ) \n",
              "  & 36.9 & xxunk & 88.7 \\ % & xxunk \n",
              "  & xxunk & 96.9 \\ % & xxunk \n",
              "  & xxunk & 98.9 \\ % & xxunk \n",
              "  & xxunk & 99.6 \\ % & xxunk \n",
              "  & xxunk & 100.0 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{gc}}$ ( $ h^m$ $ \\ theta = 0 $ ) \n",
              "  & 20.6 & xxunk & 66.7 \\ % & xxunk \n",
              "  & xxunk & 83.2 \\ % & xxunk \n",
              "  & xxunk & 89.7 \\ % & xxunk \n",
              "  & xxunk & 96.5 \\ % & 1.054 \n",
              "  & xxunk & 99.7 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{gc}}$ ( $ h^m$ $ \\ theta = 10 $ ) \n",
              "  & 20.6 & xxunk & 83.6 \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 97.1 \\ % & xxunk \n",
              "  & xxunk & 99.2 \\ % & xxunk \n",
              "  & xxunk & 100.0 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{gc}}$ ( xxup rhw $ \\ theta = 0 $ ) \n",
              "  & 23.5 & xxunk & 64.8 \\ % & xxunk \n",
              "  & xxunk & 81.6 \\ % & xxunk \n",
              "  & xxunk & 89.1 \\ % & xxunk \n",
              "  & xxunk & 96.3 \\ % & 1.062 \n",
              "  & xxunk & 99.5 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{gc}}$ ( xxup rhw $ \\ theta = 10 $ ) \n",
              "  & 23.5 & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 91.2 \\ % & xxunk \n",
              "  & xxunk & 96.3 \\ % & xxunk \n",
              "  & xxunk & 98.6 \\ % & xxunk \n",
              "  & xxunk & 100.0 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{gc}}$ ( xxmaj zhu \\ & xxmaj givan $ \\ theta = 0 $ ) \n",
              "  & 19.9 & xxunk & 66.4 \\ % & xxunk \n",
              "  & xxunk & 83.1 \\ % & xxunk \n",
              "  & xxunk & 89.7 \\ % & xxunk \n",
              "  & xxunk & 96.4 \\ % & xxunk \n",
              "  & xxunk & 99.7 \\ % & 1.054 \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{gc}}$ ( xxmaj zhu \\ & xxmaj givan $ \\ theta = 10 $ ) \n",
              "  & 19.9 & xxunk & 81.9 \\ % & xxunk \n",
              "  & xxunk & 92.6 \\ % & xxunk \n",
              "  & xxunk & 96.5 \\ % & xxunk \n",
              "  & xxunk & 98.6 \\ % & xxunk \n",
              "  & xxunk & 100.0 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{gc}}$ ( xxmaj hoffmann $ \\ theta = 0 $ ) \n",
              "  & 18.8 & xxunk & 61.3 \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 86.1 \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 99.5 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{gc}}$ ( xxmaj hoffmann $ \\ theta = 10 $ ) \n",
              "  & 18.8 & xxunk & 77.8 \\ % & xxunk \n",
              "  & xxunk & 87.4 \\ % & xxunk \n",
              "  & xxunk & 92.5 \\ % & xxunk \n",
              "  & xxunk & 96.5 \\ % & xxunk \n",
              "  & xxunk & 100.0 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  \\ hline \n",
              "  $ \\ mathit{h_{uniq}}$ ( xxmaj exhaust $ \\ theta = 0 $ ) \n",
              "  & 36.9 & xxunk & 56.7 \\ % & xxunk \n",
              "  & xxunk & 76.8 \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 93.4 \\ % & xxunk \n",
              "  & xxunk & 99.2 \\ % & 1.025 \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{uniq}}$ ( xxmaj exhaust $ \\ theta = 10 $ ) \n",
              "  & 36.9 & xxunk & 71.3 \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 97.2 \\ % & xxunk \n",
              "  & xxunk & 100.0 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{uniq}}$ ( $ h^m$ $ \\ theta = 0 $ ) \n",
              "  & 20.6 & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 94.2 \\ % & xxunk \n",
              "  & xxunk & 99.7 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{uniq}}$ ( $ h^m$ $ \\ theta = 10 $ ) \n",
              "  & 20.6 & xxunk & 69.7 \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 90.9 \\ % & xxunk \n",
              "  & xxunk & 97.1 \\ % & xxunk \n",
              "  & xxunk & 100.0 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{uniq}}$ ( xxup rhw $ \\ theta = 0 $ ) \n",
              "  & 23.5 & xxunk & 56.4 \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 85.1 \\ % & xxunk \n",
              "  & xxunk & 93.8 \\ % & xxunk \n",
              "  & xxunk & 99.5 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{uniq}}$ ( xxup rhw $ \\ theta = 10 $ ) \n",
              "  & 23.5 & xxunk & 69.3 \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 90.4 \\ % & xxunk \n",
              "  & xxunk & 96.7 \\ % & xxunk \n",
              "  & xxunk & 100.0 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{uniq}}$ ( xxmaj zhu \\ & xxmaj givan $ \\ theta = 0 $ ) \n",
              "  & 19.9 & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 75.7 \\ % & xxunk \n",
              "  & xxunk & 85.0 \\ % & xxunk \n",
              "  & xxunk & 93.9 \\ % & xxunk \n",
              "  & xxunk & 99.7 \\ % & 1.054 \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{uniq}}$ ( xxmaj zhu \\ & xxmaj givan $ \\ theta = 10 $ ) \n",
              "  & 19.9 & xxunk & 69.3 \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 90.7 \\ % & xxunk \n",
              "  & xxunk & 96.8 \\ % & xxunk \n",
              "  & xxunk & 100.0 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{uniq}}$ ( xxmaj hoffmann $ \\ theta = 0 $ ) \n",
              "  & 18.8 & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 70.8 \\ % & xxunk \n",
              "  & xxunk & 80.2 \\ % & xxunk \n",
              "  & xxunk & 90.8 \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{uniq}}$ ( xxmaj hoffmann $ \\ theta = 10 $ ) \n",
              "  & 18.8 & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 79.9 \\ % & xxunk \n",
              "  & xxunk & 86.9 \\ % & xxunk \n",
              "  & xxunk & 93.9 \\ % & xxunk \n",
              "  & xxunk & 99.2 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  \\ hline \n",
              "  \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  \\ caption{experiments and evaluations with missing and full observations . } \n",
              "  \\ label{tab : results } \t \n",
              "  \\ end{table * } \n",
              " \n",
              "  xxmaj we can see that even with 100 \\ % of actions being observed , the heuristic recognition algorithms do not yield 100 \\ % accuracy . \n",
              "  xxmaj there are some cases , for instance , in xxmaj xxunk and xxmaj logistics for $ \\ mathit{h_{gc}}$ , in which the real goal had more total landmarks than a wrong candidate goal , but only a few extra achieved landmarks than the wrong one . \n",
              "  xxmaj as a result , the heuristic chooses the wrong goal instead the correct one , especially with lower threshold values . \n",
              " \n",
              "  xxmaj we can also see that the extraction $ h^m$ algorithm has the highest recognition time in comparison to all algorithms . \n",
              "  \\ textit{hoffmann et al . } has the second highest recognition time , while other algorithms come in third with similar recognition time . \n",
              " \n",
              "  xxmaj figure~ \\ ref{fig : percentage } shows the average percentage of extracted landmarks by each extraction algorithm we used in our experiments for xxmaj table~ \\ ref{tab : results } . \n",
              "  xxmaj note that , after \\ textit{exhaust } , \\ textit{rhw } was the extraction algorithm that managed to extract the highest number of landmarks , on average , followed by $ h^m$ , \\ textit{zhu \\ & xxmaj givan } , and finally \\ xxunk et al . } . \n",
              " \n",
              "  \\ begin{figure}[h ! ] \n",
              "  \\ centering \n",
              "  \\ includegraphics[width=0.45 \\ xxunk } \n",
              "  \\ caption{percentage of extracted landmarks by algorithm with missing and full observations . } \n",
              "  \\ label{fig : percentage } \n",
              "  \\ end{figure } \n",
              " \n",
              "  xxmaj figures \\ ref{fig : accuracy_gc } and \\ ref{fig : accuracy_uniq } show the average xxmaj accuracy / xxmaj spread in $ \\ mathcal{g}$ ratio with a threshold $ \\ theta$ value of 10 for each combination of heuristic , extraction algorithm , and the level of observability . \n",
              "  xxmaj although \\ textit{exhaust } and \\ textit{rhw } managed to extract the highest number of landmarks , $ h^m$ was the algorithm that led both heuristics to the highest xxmaj accuracy / xxmaj spread in $ \\ mathcal{g}$ ratio , leaving even \\ textit{exhaust } behind . \n",
              " \n",
              "  \\ begin{figure}[h ! ] \n",
              "  \\ centering \n",
              "  \\ includegraphics[width=0.45 \\ xxunk } \n",
              "  \\ caption{accuracy / xxmaj spread in $ \\ mathcal{g}$ ratio for $ \\ mathit{h_{gc}}$ with missing and full observations . } \n",
              "  \\ label{fig : accuracy_gc } \n",
              "  \\ end{figure } \n",
              " \n",
              "  \\ begin{figure}[h ! ] \n",
              "  \\ centering \n",
              "  \\ includegraphics[width=0.45 \\ xxunk } \n",
              "  \\ caption{accuracy / xxmaj spread in $ \\ mathcal{g}$ ratio for $ \\ mathit{h_{uniq}}$ with missing and full observations . } \n",
              "  \\ label{fig : accuracy_uniq } \n",
              "  \\ end{figure } \n",
              " \n",
              "  xxmaj based on the results of xxmaj figures~ \\ ref{fig : accuracy_gc } and~ \\ ref{fig : accuracy_uniq } , we can see that that the amount of extracted landmarks is not the only factor that affects the effectiveness for recognition using landmarks . \n",
              "  xxmaj we note that the quality of the extracted landmarks and how well they inform the heuristics cause real impact in the recognition process . \n",
              "  xxmaj we believe this is the reason $ \\ mathit{h_{uniq}}$ yields a higher xxmaj accuracy / xxmaj spread ratio in the datasets with missing and full observations when compared to $ \\ xxunk \n",
              "  xxmaj the $ \\ mathit{h_{uniq}}$ heuristic considers the degree of information provided by a landmark ( \\ idest , \\ emph{landmark uniqueness values } ) , instead of just estimating using the amount of landmarks , as $ \\ mathit{h_{gc}}$ does . \n",
              "  xxmaj the $ \\ mathit{h_{uniq}}$ heuristic can filter relatively uninformative landmarks , assigning a greater \\ emph{landmark uniqueness value } for those that are found in fewer goals , hence better informing the heuristic . \n",
              " \n",
              "  xxmaj figures~ \\ ref{fig : xxunk } and \\ ref{fig : xxunk } , show how the recognition time varies with the growth of observation length for $ \\ mathit{h_{gc}}$ and $ \\ mathit{h_{uniq}}$ , respectively . \n",
              "  xxmaj we can see that all algorithms provide a close to constant recognition time , except for $ h^m$ , in which we see the recognition time grows as the observation grows in length . xxmaj note that some curves are overlaid by others , causing them to not appear . \n",
              " \n",
              "  xxmaj note that the sequence of observations does not have a direct impact on the landmark extraction algorithms since they are not provided to the algorithms . \n",
              "  xxmaj however , longer observations generally translate to more complex problems , resulting in the increasing recognition time . \n",
              " \n",
              "  \\ begin{figure}[h ! ] \n",
              "  \\ centering \n",
              "  \\ includegraphics[width=0.45 \\ xxunk } \n",
              "  \\ caption{recognition time for $ \\ mathit{h_{gc}}$ with missing and full observations . } \n",
              "  \\ label{fig : xxunk } \n",
              "  \\ end{figure } \n",
              " \n",
              "  \\ begin{figure}[h ! ] \n",
              "  \\ centering \n",
              "  \\ includegraphics[width=0.45 \\ xxunk } \n",
              "  \\ caption{recognition time for $ \\ mathit{h_{uniq}}$ with missing and full observations . } \n",
              "  \\ label{fig : xxunk } \n",
              "  \\ end{figure } \n",
              " \n",
              "  % xxmaj although $ h^m$ shows the best performance in accuracy and % spread , it has the longest running time from all % algorithms . xxmaj the second longest running time we see is in % xxmaj xxunk et al . solution . xxmaj all other algorithms have % similar execution times , being faster than both xxmaj hoffmann et % al . and $ xxunk \n",
              " \n",
              "  % xxrep 72 # \n",
              "  \\ subsection{results : xxmaj noisy , xxmaj missing , and xxmaj full xxmaj observations } \n",
              " \n",
              "  xxmaj in this section , we present and analyze the results obtained by experimenting the different recognition approaches in problems under noisy observations . xxmaj we refer to noisy observations as a set of observed actions in which some of the actions are spurious actions . xxmaj as mentioned before , for the datasets with noisy observations , we have 4 levels of observability , as follows : 25 \\ % , 50 \\ % , 75 \\ % , and 100 \\ % . \n",
              " \n",
              "  xxmaj we can see the results for both recognition heuristics in xxmaj table~ \\ ref{tab : results_noisy } . \n",
              "  xxmaj this table has the same format as the one presented in the previous section , for missing and full observations , the only difference is the number of columns , as now we have four observability levels instead of five . \n",
              " \n",
              "  \\ begin{table*}[ht ! ] \n",
              "  \\ centering \n",
              "  \\ xxunk } \\ selectfont \n",
              "  \\ setlength \\ tabcolsep{3pt } \n",
              "  \\ begin{tabular } { xxrep 5 r @ { \\ hspace*{8mm}}rrr@ { \\ hspace*{8mm}}rrr@ { \\ hspace*{8mm}}rrr@ { \\ xxunk } \n",
              "  \\ toprule \t \n",
              "  \\ hline \n",
              " \n",
              "  & \n",
              "  & \\ multicolumn{3}{c } { \\ bf 25 \\ % } \n",
              "  & \\ multicolumn{3}{c } { \\ bf 50 \\ % } \n",
              "  & \\ multicolumn{3}{c } { \\ bf 75 \\ % } \n",
              "  & \\ multicolumn{3}{c } { \\ bf 100 \\ % } \\ \\ \\ hline \n",
              " \n",
              "  \\ xxunk } \n",
              "  & $ | \\ xxunk \n",
              "  & \\ multicolumn{1}{r } { \\ bf xxmaj time } & \\ multicolumn{1}{r } { \\ bf xxmaj acc \\ % } & \\ multicolumn{1}{l } { \\ bf s in $ \\ mathcal{g}$ } \n",
              "  & \\ multicolumn{1}{r } { \\ bf xxmaj time } & \\ multicolumn{1}{r } { \\ bf xxmaj acc \\ % } & \\ multicolumn{1}{l } { \\ bf s in $ \\ mathcal{g}$ } \n",
              "  & \\ multicolumn{1}{r } { \\ bf xxmaj time } & \\ multicolumn{1}{r } { \\ bf xxmaj acc \\ % } & \\ multicolumn{1}{l } { \\ bf s in $ \\ mathcal{g}$ } \n",
              "  & \\ multicolumn{1}{r } { \\ bf xxmaj time } & \\ multicolumn{1}{r } { \\ bf xxmaj acc \\ % } & \\ multicolumn{1}{l } { \\ bf s in $ \\ mathcal{g}$ } \\ \\ \\ hline \n",
              "  $ \\ mathit{h_{gc}}$ ( xxmaj exhaust $ \\ theta = 0 $ ) \n",
              "  & 29.8 & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 87.3 \\ % & xxunk \n",
              "  & xxunk & 95.7 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{gc}}$ ( xxmaj exhaust $ \\ theta = 10 $ ) \n",
              "  & 29.8 & xxunk & 72.2 \\ % & xxunk \n",
              "  & xxunk & 90.7 \\ % & xxunk \n",
              "  & xxunk & 96.8 \\ % & xxunk \n",
              "  & xxunk & 99.7 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{gc}}$ ( $ h^m$ $ \\ theta = 0 $ ) \n",
              "  & 17.5 & xxunk & 49.5 \\ % & xxunk \n",
              "  & xxunk & 73.4 \\ % & xxunk \n",
              "  & xxunk & 86.9 \\ % & xxunk \n",
              "  & xxunk & 95.7 \\ % & 1.125 \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{gc}}$ ( $ h^m$ $ \\ theta = 10 $ ) \n",
              "  & 17.5 & xxunk & 65.7 \\ % & xxunk \n",
              "  & xxunk & 85.6 \\ % & xxunk \n",
              "  & xxunk & 95.3 \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{gc}}$ ( xxup rhw $ \\ theta = 0 $ ) \n",
              "  & 19.7 & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 86.8 \\ % & xxunk \n",
              "  & xxunk & 95.1 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{gc}}$ ( xxup rhw $ \\ theta = 10 $ ) \n",
              "  & 19.7 & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{gc}}$ ( xxmaj zhu \\ & xxmaj givan $ \\ theta = 0 $ ) \n",
              "  & 16.8 & xxunk & 48.3 \\ % & xxunk \n",
              "  & xxunk & 73.4 \\ % & xxunk \n",
              "  & xxunk & 86.9 \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{gc}}$ ( xxmaj zhu \\ & xxmaj givan $ \\ theta = 10 $ ) \n",
              "  & 16.8 & xxunk & 65.7 \\ % & xxunk \n",
              "  & xxunk & 84.8 \\ % & xxunk \n",
              "  & xxunk & 94.3 \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{gc}}$ ( xxmaj hoffmann $ \\ theta = 0 $ ) \n",
              "  & 16.3 & xxunk & 44.9 \\ % & xxunk \n",
              "  & xxunk & 68.8 \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{gc}}$ ( xxmaj hoffmann $ \\ theta = 10 $ ) \n",
              "  & 16.3 & xxunk & 61.2 \\ % & xxunk \n",
              "  & xxunk & 81.2 \\ % & xxunk \n",
              "  & xxunk & 90.1 \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  \\ \\ \n",
              "  \\ hline \n",
              "  $ \\ mathit{h_{uniq}}$ ( xxmaj exhaust $ \\ theta = 0 $ ) \n",
              "  & 29.8 & xxunk & 38.5 \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 82.1 \\ % & xxunk \n",
              "  & xxunk & 93.8 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{uniq}}$ ( xxmaj exhaust $ \\ theta = 10 $ ) \n",
              "  & 29.8 & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 75.6 \\ % & xxunk \n",
              "  & xxunk & 88.7 \\ % & xxunk \n",
              "  & xxunk & 96.7 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{uniq}}$ ( $ h^m$ $ \\ theta = 0 $ ) \n",
              "  & 17.5 & xxunk & 39.1 \\ % & xxunk \n",
              "  & xxunk & 62.7 \\ % & 1.062 \n",
              "  & xxunk & 82.3 \\ % & 1.054 \n",
              "  & xxunk & 94.2 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{uniq}}$ ( $ h^m$ $ \\ theta = 10 $ ) \n",
              "  & 17.5 & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 74.1 \\ % & xxunk \n",
              "  & xxunk & 88.7 \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{uniq}}$ ( xxup rhw $ \\ theta = 0 $ ) \n",
              "  & 19.7 & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 62.8 \\ % & xxunk \n",
              "  & xxunk & 81.3 \\ % & xxunk \n",
              "  & xxunk & 94.2 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{uniq}}$ ( xxup rhw $ \\ theta = 10 $ ) \n",
              "  & 19.7 & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 75.1 \\ % & xxunk \n",
              "  & xxunk & 87.5 \\ % & xxunk \n",
              "  & xxunk & 96.5 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{uniq}}$ ( xxmaj zhu \\ & xxmaj givan $ \\ theta = 0 $ ) \n",
              "  & 16.8 & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 62.7 \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & 1.062 \n",
              "  & xxunk & 94.2 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{uniq}}$ ( xxmaj zhu \\ & xxmaj givan $ \\ theta = 10 $ ) \n",
              "  & 16.8 & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 96.7 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{uniq}}$ ( xxmaj hoffmann $ \\ theta = 0 $ ) \n",
              "  & 16.3 & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 59.7 \\ % & xxunk \n",
              "  & xxunk & 77.0 \\ % & xxunk \n",
              "  & xxunk & 88.3 \\ % & xxunk \n",
              "  \\ \\ \n",
              "  $ \\ mathit{h_{uniq}}$ ( xxmaj hoffmann $ \\ theta = 10 $ ) \n",
              "  & 16.3 & xxunk & xxunk \\ % & xxunk \n",
              "  & xxunk & 70.7 \\ % & xxunk \n",
              "  & xxunk & 83.2 \\ % & xxunk \n",
              "  & xxunk & xxunk \\ % & xxunk \n",
              "  \\ \\ \n",
              "  \\ hline \n",
              "  \\ bottomrule \n",
              "  \\ end{tabular } \n",
              "  \\ caption{experiments and evaluations with missing , noisy and full observations . } \n",
              "  \\ label{tab : results_noisy } \t \n",
              "  \\ end{table * } \n",
              " \n",
              "  xxmaj we notice a drop in the accuracy metric by comparing the results in xxmaj tables~ \\ ref{tab : results } and \\ ref{tab : results_noisy } and argue that it is an expected behavior , as the noise within the observations tends to mislead the recognition heuristics into recognizing the wrong goals as correct . \n",
              "  xxmaj also , as expected , the recognition time is unaffected with relation to noiseless observations , with $ h^m$ having the longest recognition times , followed by \\ textit{hoffmann et al . } and the other algorithms . \n",
              "  xxmaj we can see that in noisy experiments , there is less difference between \\ textit{hoffmann et al . } and $ h^m$ recognition times . \n",
              " \n",
              "  xxmaj figure~ \\ ref{fig : xxunk } shows the average percentage of landmarks extracted by each algorithm for the datasets with noisy observations . \n",
              "  xxmaj this metric has to be xxunk for noisy observations , as the goal recognition problems with noisy observations \\ emph{are different } from the ones without noise . \n",
              "  xxmaj we can see all algorithms , except for \\ textit{exhaust } , managed to achieve a higher percentage of achieved landmarks in comparison to noiseless experiments , as the number of landmarks extracted by \\ textit{exhaust } dropped . \n",
              "  xxmaj yet , the algorithm ranking for the percentage of landmarks extracted remains similar to the noiseless experiments . \n",
              " \n",
              "  \\ begin{figure}[h ! ] \n",
              "  \\ centering \n",
              "  \\ includegraphics[width=0.45 \\ xxunk } \n",
              "  \\ caption{percentage of extracted landmarks by algorithm with missing , noisy and full observations . } \n",
              "  \\ label{fig : xxunk } \n",
              "  \\ end{figure } \n",
              " \n",
              "  xxmaj figures~ \\ ref{fig : xxunk } and \\ ref{fig : xxunk } show the xxmaj accuracy / xxmaj spread in $ \\ xxunk ratio for each algorithm and observability degree for a threshold value of 10 , for $ \\ mathit{h_{gc}}$ and $ \\ mathit{h_{uniq}}$ respectively . \n",
              " \n",
              "  \\ begin{figure}[h ! ] \n",
              "  \\ centering \n",
              "  \\ includegraphics[width=0.45 \\ xxunk } \n",
              "  \\ caption{accuracy / xxmaj spread in $ \\ mathcal{g}$ ratio for $ \\ mathit{h_{gc}}$ with missing , noisy and full observations . } \n",
              "  \\ label{fig : xxunk } \n",
              "  \\ end{figure } \n",
              " \n",
              "  \\ begin{figure}[h ! ] \n",
              "  \\ centering \n",
              "  \\ includegraphics[width=0.45 \\ xxunk } \n",
              "  \\ caption{accuracy / xxmaj spread in $ \\ mathcal{g}$ ratio for $ \\ mathit{h_{uniq}}$ with missing , noisy and full observations . } \n",
              "  \\ label{fig : xxunk } \n",
              "  \\ end{figure } \n",
              " \n",
              "  xxmaj as for the results using the $ \\ mathit{h_{gc}}$ heuristic , we can see a different scenario when comparing to noiseless experiments . \n",
              "  xxmaj with noisy observations , the extraction algorithm that had the best overall performance in xxmaj accuracy / xxmaj spread in $ \\ mathcal{g}$ was \\ textit{rhw } , which also extracted the most landmarks after \\ textit{exhaust } . \n",
              "  \\ textit{rhw } dominated the score for 25 \\ % and 50 \\ % observability levels , only being beaten by $ h^m$ in 75 \\ % and \\ textit{zhu \\ & xxmaj givan } in 100 \\ % . \n",
              " \n",
              "  xxmaj with respect to the results of the $ \\ mathit{h_{uniq}}$ heuristic results , we see the same behavior in noiseless experiments . \n",
              "  xxmaj algorithms that extract a larger number of landmarks yielded better results in comparison to $ \\ mathit{h_{gc}}$ , as we can see from \\ textit{exhaust } results in 25 \\ % and 50 \\ % observability levels , only being beaten by $ h^m$ in 75 \\ % and 100 \\ % . \n",
              " \n",
              "  xxmaj from these results , we can see how the presence of noise in observations really affects the recognition with different landmark extraction algorithms . \n",
              "  xxmaj when we work with noisy observations , the number of landmarks extracted seems have a stronger impact . \n",
              "  xxmaj this can be explained by the fact that having irrelevant actions within the observations makes so that having more landmarks may help the heuristic while comparing them against the relevant observations , as noisy actions are unlikely to coincide within the landmarks for the correct goal . \n",
              "  % xxmaj the recognition time is similar to noiseless experiments though . \n",
              " \n",
              "  xxmaj finally , in xxmaj figures~ \\ ref{fig : xxunk } and~ \\ ref{fig : xxunk } , we can see the recognition time variation as observation length grows for $ \\ mathit{h_{gc}}$ and $ \\ mathit{h_{uniq}}$ , respectively . \n",
              "  a similar time marks can be seen without noisy observations , with $ h^m$ 's running time growing with observation length , while the other algorithms remain almost constant , with minor differences . xxmaj we also see the same curve overlay effect that causes some curves to not appear . \n",
              " \n",
              "  \\ begin{figure}[h ] \n",
              "  \\ centering \n",
              "  \\ includegraphics[width=0.45 \\ xxunk } \n",
              "  \\ caption{recognition time for $ \\ mathit{h_{gc}}$ with missing , noisy and full observations . } \n",
              "  \\ label{fig : xxunk } \n",
              "  \\ end{figure } \n",
              " \n",
              "  \\ begin{figure}[h ] \n",
              "  \\ centering \n",
              "  \\ includegraphics[width=0.45 \\ xxunk } \n",
              "  \\ caption{recognition time for $ \\ mathit{h_{uniq}}$ with missing , noisy and full observations . } \n",
              "  \\ label{fig : xxunk } \n",
              "  \\ end{figure } \n",
              " \n",
              "  % xxrep 76 - \n",
              "  \\ section{conclusions } \\ label{section : conclusions } \n",
              " \n",
              "  xxmaj we have presented an extensive empirical evaluation of how different landmark extraction algorithms affect the performance of landmark - based goal recognition approaches . \n",
              "  xxmaj after analyzing the results in the experiments , we conclude that the number of extracted landmarks does not tell us all about the quality or utility of a landmark when using it in landmark - based goal recognition . \n",
              "  xxmaj we can see from the results that having more landmarks is not necessarily more important than having informative landmarks . \n",
              " \n",
              "  xxmaj as future work , we intend to perform a more qualitative analysis of the landmark extraction algorithms , analyzing not only the amount of extracted landmarks , but also the information level of the landmarks themselves . \n",
              "  xxmaj this ought to provide even more answers on what kind of extraction algorithm is best suited for landmark - based goal recognition , and consequently enabling us to fine - tune solutions to maximize the effectiveness of the goal recognition process . \n",
              "  xxmaj finally , we aim to conduct a similar extensive empirical evaluation by using some of the landmark extraction algorithms over the landmark - based approaches under incomplete domain information~ \\ xxunk } . \n",
              " \n",
              "  % xxrep 76 - \n",
              "  \\ bibliographystyle{aaai } \n",
              "  \\ xxunk } \n",
              " \n",
              "  \\ end{document } \n",
              " \n",
              "y: CategoryList\n",
              "not_peer_reviewed,not_peer_reviewed,not_peer_reviewed,not_peer_reviewed,not_peer_reviewed\n",
              "Path: /content/gdrive/My Drive/fastai-v3/SCIgan/clean;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(38368, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(38368, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f979dfc2d08>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/content/gdrive/My Drive/fastai-v3/SCIgan/clean'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
              "  (0): Embedding(38368, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(38368, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): Embedding(38368, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(38368, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5gopo4Y6JVf",
        "colab_type": "code",
        "outputId": "3ab381af-7723-4747-bada-dbd53ac7ea3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 839
        }
      },
      "source": [
        "# explore and plot the learning rates\n",
        "learn.lr_find()\n",
        "learn.recorder.plot()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='15' class='' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      88.24% [15/17 1:02:55<08:23]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.860431</td>\n",
              "      <td>#na#</td>\n",
              "      <td>04:24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.854542</td>\n",
              "      <td>#na#</td>\n",
              "      <td>04:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.841494</td>\n",
              "      <td>#na#</td>\n",
              "      <td>04:26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.837027</td>\n",
              "      <td>#na#</td>\n",
              "      <td>04:18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.837918</td>\n",
              "      <td>#na#</td>\n",
              "      <td>04:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.838234</td>\n",
              "      <td>#na#</td>\n",
              "      <td>04:28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.840605</td>\n",
              "      <td>#na#</td>\n",
              "      <td>04:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.828864</td>\n",
              "      <td>#na#</td>\n",
              "      <td>04:13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.815729</td>\n",
              "      <td>#na#</td>\n",
              "      <td>04:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.791260</td>\n",
              "      <td>#na#</td>\n",
              "      <td>04:21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.756292</td>\n",
              "      <td>#na#</td>\n",
              "      <td>04:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.700376</td>\n",
              "      <td>#na#</td>\n",
              "      <td>04:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.631196</td>\n",
              "      <td>#na#</td>\n",
              "      <td>04:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.611270</td>\n",
              "      <td>#na#</td>\n",
              "      <td>04:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.748794</td>\n",
              "      <td>#na#</td>\n",
              "      <td>04:15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='3' class='' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      50.00% [3/6 03:01<03:01 2.1044]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJRpWVnkqiks",
        "colab_type": "code",
        "outputId": "63c6ca2f-1c52-4e7d-9c80-65f776102fd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "# according to the graph, it seems that 2e-2 is a good point -\n",
        "# the loss is decreasing, before overfitting\n",
        "learn.fit_one_cycle(1, 2e-2, moms=(0.8,0.7))\n",
        "learn.save(base_dir + 'first')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.866141</td>\n",
              "      <td>0.672836</td>\n",
              "      <td>0.645570</td>\n",
              "      <td>01:56</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIjdirCbcFc6",
        "colab_type": "code",
        "outputId": "9ebc1073-17bb-42bf-d086-02fcb2f9d787",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "# now we start 'peeling' layer after layer, and fine tune\n",
        "learn.load(base_dir + 'first');\n",
        "learn.freeze_to(-2)\n",
        "learn.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2), moms=(0.8,0.7))\n",
        "learn.save(base_dir + 'second')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.605608</td>\n",
              "      <td>0.523277</td>\n",
              "      <td>0.924051</td>\n",
              "      <td>01:54</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCXLdqsecKLE",
        "colab_type": "code",
        "outputId": "0ace53c7-1cf3-4c59-e8c2-3ea7fdb26ec8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "learn.load(base_dir + 'second');\n",
        "learn.freeze_to(-3)\n",
        "learn.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.7))\n",
        "learn.save(base_dir + 'third')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.489047</td>\n",
              "      <td>0.441886</td>\n",
              "      <td>0.936709</td>\n",
              "      <td>01:54</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E39hOrNtcOg3",
        "colab_type": "code",
        "outputId": "4d380d6f-a8f8-40cf-d699-afedc5349ba8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "learn.load(base_dir + 'third');\n",
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3) , moms=(0.8,0.7))\n",
        "learn.save(base_dir + 'final')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.454464</td>\n",
              "      <td>0.440046</td>\n",
              "      <td>0.936709</td>\n",
              "      <td>02:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.454871</td>\n",
              "      <td>0.432176</td>\n",
              "      <td>0.936709</td>\n",
              "      <td>01:58</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}